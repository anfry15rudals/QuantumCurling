{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ksJVcTLxzskm"
   },
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "N8fPchWjlyM1"
   },
   "outputs": [],
   "source": [
    "import qiskit\n",
    "import pylatexenc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from functools import reduce\n",
    "from collections import deque, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GfudJfnDmH06"
   },
   "outputs": [],
   "source": [
    "import qiskit\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math, random, time, itertools\n",
    "from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister, Aer\n",
    "from qiskit.quantum_info.operators import Operator\n",
    "from qiskit.circuit import Parameter, ParameterVector\n",
    "from tqdm.notebook import tqdm\n",
    "from qiskit.opflow import Z, X, I, StateFn, CircuitStateFn, SummedOp, CircuitOp, AerPauliExpectation, Zero, One, ListOp, PauliSumOp\n",
    "from qiskit.opflow.gradients import Gradient, NaturalGradient, QFI, Hessian\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "from qiskit_machine_learning.neural_networks import OpflowQNN\n",
    "from qiskit.utils import QuantumInstance, algorithm_globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Curling_win_flag import Curling\n",
    "from ansatz import build_circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jySdpQf_zuiE"
   },
   "source": [
    "# Build CIrucit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ansatz list\n",
    "- 'base'\n",
    "- 'hw_eff'\n",
    "- 'universal'\n",
    "- 'universal_encoding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 641.233x144.48 with 1 Axes>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def draw_example():\n",
    "    quantum_circuit, param_rot, param_enc = build_circuit(n_qubits=2, n_layers=1, opt='omega2')\n",
    "    return quantum_circuit\n",
    "draw_example().draw('mpl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# circuit, rot_params, enc_params = build_circuit(n_qubits=2, n_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PQC_with_DataReuploading(nn.Module):\n",
    "    def __init__(self, n_qubits, n_layers, output_dim, observables=None, ansatz='base', activation='linear'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_layers = n_layers\n",
    "        self.output_dim = output_dim\n",
    "        self.activation = activation\n",
    "        self.ansatz = ansatz\n",
    "        \n",
    "        if observables == None:\n",
    "            self.observables = Z^n_qubits\n",
    "        else:\n",
    "            self.observables = observables\n",
    "        \n",
    "        # Build circuits / Parameter Vectors\n",
    "        self.circuit, self.rot_params, self.enc_params = build_circuit(self.n_qubits, self.n_layers, ansatz)\n",
    "        self.len_rot_params = len(self.rot_params)\n",
    "        self.len_enc_params = len(self.enc_params)\n",
    "        \n",
    "        self.psi = CircuitStateFn(primitive=self.circuit, coeff=1.)\n",
    "        self.Op = ~StateFn(self.observables) @ self.psi\n",
    "#         print(self.Op)\n",
    "        # set method to calculcate expected values\n",
    "        expval = AerPauliExpectation()\n",
    "        # define gradient method\n",
    "        gradient = Gradient(grad_method='param_shift')\n",
    "        # define quantum instances (statevector and sample based)\n",
    "        qi_sv = QuantumInstance(Aer.get_backend(\"aer_simulator_statevector\"))\n",
    "        # we set shots to 10 as this will determine the number of samples later on.\n",
    "        qi_qasm = QuantumInstance(Aer.get_backend(\"aer_simulator\"), shots=1000)\n",
    "        \n",
    "        self.qnn = OpflowQNN(operator=self.Op, input_params=self.enc_params, weight_params=self.rot_params, \n",
    "                             exp_val=expval, gradient=gradient, quantum_instance=qi_sv, input_gradients=True)\n",
    "        \n",
    "        self.total_params = []\n",
    "        for p in self.rot_params:\n",
    "            self.total_params.append(p)\n",
    "        for p in self.enc_params:\n",
    "            self.total_params.append(p)\n",
    "        \n",
    "        # Initial Parameters for circuit\n",
    "        self.rot_param_vals = nn.Parameter(2*np.pi * torch.rand(len(self.rot_params)))\n",
    "#         self.rot_param_vals = nn.Parameter(2*np.pi * torch.zeros(len(self.rot_params)))\n",
    "#         self.rot_param_vals = nn.Parameter(torch.tensor([-np.pi/2+0.1*np.random.rand(), -np.pi+0.1*np.random.rand(),\n",
    "#                                                          -np.pi/2+0.1*np.random.rand(), -np.pi+0.1*np.random.rand()]))\n",
    "#         self.enc_param_vals = nn.Parameter(torch.zeros(len(self.enc_params)))\n",
    "        self.enc_param_vals  = nn.Parameter(torch.rand(len(self.enc_params)))\n",
    "#         self.enc_param_vals  = nn.Parameter(torch.tensor([np.pi/2+0.1*np.random.rand(), -np.pi/2+0.1*np.random.rand()]))\n",
    "        \n",
    "        # Parameter for circuit output\n",
    "#         self.w = nn.Parameter(nn.Parameter(torch.rand(self.output_dim)))\n",
    "#         self.w = nn.Parameter(torch.tensor([-1,1], dtype=torch.float32))\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        input_tiled = self.get_input_tiled(inputs)\n",
    "        input_scaled = self.enc_param_vals * input_tiled\n",
    "        input_params = input_scaled\n",
    "    \n",
    "        expectation = self.qnn.forward(input_params.detach(), self.rot_param_vals.detach())\n",
    "        \n",
    "#         action_exp = torch.tensor(expectation) * self.w\n",
    "#         action_prob = F.softmax(action_exp, dim=1)\n",
    "        \n",
    "#         return action_prob\n",
    "        return expectation\n",
    "\n",
    "    def backward(self, inputs):\n",
    "        input_tiled = self.get_input_tiled(inputs)\n",
    "        input_scaled = self.enc_param_vals * input_tiled\n",
    "        input_params = input_scaled\n",
    "        expectation = self.qnn.forward(input_params.detach(), self.rot_param_vals.detach())\n",
    "        enc_grad, rot_grad = self.qnn.backward(input_params.detach(), self.rot_param_vals.detach())\n",
    "#         w_grad = torch.tensor(expectation).tile(self.output_dim)\n",
    "#         return torch.tensor(rot_grad.squeeze()), torch.tensor(enc_grad.squeeze()), w_grad\n",
    "        return torch.tensor(rot_grad.squeeze()), torch.tensor(enc_grad.squeeze())\n",
    "    \n",
    "    def get_input_tiled(self, inputs):\n",
    "        # Input: State values -> Need to insert into Encoding gates with scaling parameters(encoding params)\n",
    "        if self.ansatz == 'universal_encoding' or self.ansatz == 'hw_eff':\n",
    "            input_tiled = inputs.tile(2)\n",
    "            input_tiled = input_tiled.tile(self.n_layers)\n",
    "        elif self.ansatz == 'universal':\n",
    "            input_tiled = torch.zeros((inputs.shape[0], inputs.shape[1]+1))\n",
    "            input_tiled[:,:2] = inputs\n",
    "            input_tiled[:,-1] = inputs[:,-1]\n",
    "        else:\n",
    "            input_tiled = inputs.tile(self.n_layers)\n",
    "        return input_tiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = PQC_with_DataReuploading(n_qubits=2, n_layers=1, output_dim=2, ansatz='omega2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PauliOp(Pauli('ZZ'), coeff=1.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 641.378x144.48 with 1 Axes>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.circuit.draw('mpl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([3.6398, 4.3774, 1.7679, 0.5780, 2.8442, 3.0178, 3.2316, 5.4090],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.rot_param_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.2901, 0.7580], requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.enc_param_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.rand((10,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23216308],\n",
       "       [0.19343   ],\n",
       "       [0.22298987],\n",
       "       [0.22990325],\n",
       "       [0.21319031],\n",
       "       [0.3329947 ],\n",
       "       [0.24803457],\n",
       "       [0.31917596],\n",
       "       [0.33064734],\n",
       "       [0.2369679 ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.forward(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23216308],\n",
       "       [0.19343   ],\n",
       "       [0.22298987],\n",
       "       [0.22990325],\n",
       "       [0.21319031],\n",
       "       [0.3329947 ],\n",
       "       [0.24803457],\n",
       "       [0.31917596],\n",
       "       [0.33064734],\n",
       "       [0.2369679 ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.forward(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23216308],\n",
       "       [0.19343   ],\n",
       "       [0.22298987],\n",
       "       [0.22990325],\n",
       "       [0.21319031],\n",
       "       [0.3329947 ],\n",
       "       [0.24803457],\n",
       "       [0.31917596],\n",
       "       [0.33064734],\n",
       "       [0.2369679 ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.forward(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.651566743850708\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "a,b = policy.backward(inputs)\n",
    "print(time.time()-s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Quantum Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumAgent():\n",
    "    def __init__(self, input_state_dim, n_actions, n_layers=1, ansatz='base'):\n",
    "        self.policy = PQC_with_DataReuploading(n_qubits=input_state_dim, n_layers=n_layers, \n",
    "                                               output_dim=n_actions, observables=None, ansatz=ansatz,\n",
    "                                               activation='linear')\n",
    "        self.n_layers = n_layers\n",
    "        self.variational_optim = torch.optim.Adam([self.policy.rot_param_vals], lr=0.1)\n",
    "        self.encoding_optim = torch.optim.Adam([self.policy.enc_param_vals], lr=0.1)\n",
    "#         self.weight_optim = torch.optim.Adam([self.policy.w], lr=0.01)\n",
    "        \n",
    "        self.lr = 2\n",
    "        \n",
    "        self.optims = [self.variational_optim, self.encoding_optim]\n",
    "        \n",
    "    def get_actions(self, input_state):\n",
    "        return self.policy.forward(input_state)\n",
    "    \n",
    "    def update_policy(self, states, returns, batch_size, action_probs):\n",
    "        r_grad, e_grad = self.policy.backward(states)\n",
    "        \n",
    "#         p_actions = torch.tensor([action_probs[id_action_pairs[i][0], id_action_pairs[i][1]] for i in range(action_probs.shape[0])])\n",
    "#         p_actions = p_actions.reshape(p_actions.shape[0], -1)\n",
    "#         action_idxs = id_action_pairs[:,1]\n",
    "        \n",
    "        returns = returns.reshape(returns.shape[0], -1)\n",
    "\n",
    "#         action_weights = agent.policy.w.detach().numpy()[id_action_pairs[:,1]]\n",
    "#         action_weights = action_weights[:,np.newaxis]        \n",
    "#         w = agent.policy.w.tile(len(states)).reshape(len(states),-1)\n",
    "        \n",
    "#         rot_grad = returns * ( r_grad * torch.tensor(action_weights) - torch.sum(p_actions * w) * r_grad)\n",
    "#         input_scaled = self.policy.enc_param_vals * self.policy.get_input_tiled(states)        \n",
    "#         enc_grad = returns * ( e_grad * torch.tensor(action_weights) - input_scaled * torch.sum(p_actions * w) * e_grad)\n",
    "        \n",
    "        rot_grad = -1*returns * r_grad * action_probs / torch.abs(action_probs)\n",
    "        enc_grad = -1*returns * e_grad * action_probs / torch.abs(action_probs)\n",
    "\n",
    "#         weight_grad = returns * ( w_grad * torch.tensor(action_weights) - torch.sum(p_actions * w) * w_grad)\n",
    "        \n",
    "        prev = self.policy.rot_param_vals.detach().numpy().copy()\n",
    "        prev1 = self.policy.enc_param_vals.detach().numpy().copy()\n",
    "#         prev2 = self.policy.w.detach().numpy().copy()\n",
    "        \n",
    "#         rot_update = (torch.mean(rot_grad.detach(), dim=0) / batch_size).type(torch.float32)\n",
    "#         enc_update = (torch.mean(enc_grad, dim=0).detach() / batch_size).type(torch.float32)\n",
    "#         w_update = (torch.mean(weight_grad, dim=0).detach() / batch_size).type(torch.float32)\n",
    "        \n",
    "        rot_update = torch.mean(rot_grad, dim=0) / batch_size\n",
    "        enc_update = torch.mean(enc_grad, dim=0) / batch_size\n",
    "#         w_update = torch.mean(weight_grad, dim=0) / batch_size\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():            \n",
    "            self.policy.rot_param_vals += self.lr * rot_update\n",
    "            self.policy.enc_param_vals += self.lr * enc_update\n",
    "            \n",
    "        print('Rot')\n",
    "        print(self.policy.rot_param_vals.detach().numpy() / np.pi)\n",
    "        print('Enc')\n",
    "        print(self.policy.enc_param_vals.detach().numpy() / np.pi)\n",
    "#             self.policy.w += 0.1 * w_update\n",
    "    \n",
    "#         self.policy.rot_param_vals.grad = -1*rot_update\n",
    "#         self.policy.enc_param_vals.grad = -1*enc_update\n",
    "#         self.policy.w.grad = -1*w_update\n",
    "                \n",
    "#         print(rot_update)\n",
    "#         print(enc_update)\n",
    "        \n",
    "#         self.variational_optim.step()\n",
    "#         self.encoding_optim.step()\n",
    "#         self.weight_optim.step()\n",
    "\n",
    "#         print(self.policy.rot_param_vals.detach() - prev)\n",
    "#         print(rot_update)\n",
    "        \n",
    "#         print(self.policy.enc_param_vals.detach() - prev1)\n",
    "#         print(enc_update)\n",
    "#         print(self.policy.w.detach() - prev2)\n",
    "#         print(w_update)\n",
    "        \n",
    "#         print('w', self.policy.w)\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             self.policy.rot_param_vals[self.policy.rot_param_vals > 2*np.pi] = 2*np.pi\n",
    "#             self.policy.enc_param_vals[self.policy.enc_param_vals > 2*np.pi] = 2*np.pi\n",
    "#             self.policy.rot_param_vals[self.policy.rot_param_vals < 0] = 0\n",
    "#             self.policy.enc_param_vals[self.policy.enc_param_vals < 0] = 0\n",
    "        \n",
    "#         print(self.policy.rot_param_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 2 # Dimension of the state vectors in CartPole\n",
    "n_layers = 1\n",
    "n_actions = 2 # Number of actions in CartPole\n",
    "agent = QuantumAgent(input_state_dim = n_qubits, n_actions=n_actions, n_layers=n_layers, ansatz='omega2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 668.066x144.48 with 1 Axes>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.policy.circuit.draw('mpl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     agent.policy.rot_param_vals[0] = -np.pi/2 + np.pi/4 * torch.rand(1)\n",
    "#     agent.policy.rot_param_vals[1] = np.pi + np.pi/2 * torch.rand(1)\n",
    "#     agent.policy.rot_param_vals[2] = -np.pi/2 + np.pi/4 * torch.rand(1)\n",
    "#     agent.policy.rot_param_vals[3] = np.pi + np.pi/2 * torch.rand(1)\n",
    "    \n",
    "#     agent.policy.rot_param_vals[4] = -np.pi/2 + np.pi/4 * torch.rand(1)\n",
    "#     agent.policy.rot_param_vals[5] = np.pi + np.pi/2 * torch.rand(1)\n",
    "#     agent.policy.rot_param_vals[6] = -np.pi/2 + np.pi/4 * torch.rand(1)\n",
    "#     agent.policy.rot_param_vals[7] = np.pi + np.pi/2 * torch.rand(1)\n",
    "    \n",
    "#     agent.policy.enc_param_vals[0] = np.pi/2 + np.pi/4 * torch.rand(1)\n",
    "#     agent.policy.enc_param_vals[1] = np.pi/2 + np.pi/4 * torch.rand(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     agent.policy.rot_param_vals[0] = -np.pi/2 \n",
    "#     agent.policy.rot_param_vals[1] = np.pi \n",
    "#     agent.policy.rot_param_vals[2] = -np.pi/2 \n",
    "#     agent.policy.rot_param_vals[3] = np.pi \n",
    "    \n",
    "# #     agent.policy.rot_param_vals[4] = -np.pi/2 \n",
    "# #     agent.policy.rot_param_vals[5] = np.pi\n",
    "# #     agent.policy.rot_param_vals[6] = -np.pi/2 \n",
    "# #     agent.policy.rot_param_vals[7] = np.pi\n",
    "    \n",
    "#     agent.policy.enc_param_vals[0] = np.pi/2 \n",
    "#     agent.policy.enc_param_vals[1] = np.pi/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.3108, 1.5643, 0.4194, 1.9177, 0.3734, 1.8641, 1.7464, 0.7519],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.policy.rot_param_vals / np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3117, 0.2417], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.policy.enc_param_vals / np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Episodes and Update Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_episodes(state_bounds, n_actions, agent, n_episodes, env_name):\n",
    "    \"\"\"Interact with environment in batched fashion.\"\"\"\n",
    "\n",
    "    trajectories = [defaultdict(list) for _ in range(n_episodes)]\n",
    "    if env_name == 'Curling':\n",
    "        envs = [Curling(reward_type='each_end_counts') for _ in range(n_episodes)]\n",
    "#         envs = [Curling(reward_type='winner_takes_it_all') for _ in range(n_episodes)]\n",
    "    else:\n",
    "        envs = [gym.make(env_name) for _ in range(n_episodes)]\n",
    "\n",
    "    done = [False for _ in range(n_episodes)]\n",
    "    states = [e.reset() for e in envs]\n",
    "    \n",
    "\n",
    "    while not all(done):\n",
    "        unfinished_ids = [i for i in range(n_episodes) if not done[i]]\n",
    "        normalized_states = [s for i, s in enumerate(states) if not done[i]]\n",
    "\n",
    "        for i, state in zip(unfinished_ids, normalized_states):\n",
    "            trajectories[i]['states'].append(state)\n",
    "\n",
    "        states = torch.from_numpy(np.array(normalized_states))\n",
    "#         print(states)\n",
    "        action_probs = agent.get_actions(states)\n",
    "#         print(action_probs)\n",
    "        # Store action and transition all environments to the next state\n",
    "        states = [None for i in range(n_episodes)]\n",
    "        \n",
    "        for i, action_prob in zip(unfinished_ids, action_probs):\n",
    "            if action_prob > 0: #  ( )\n",
    "                action = 0 # \n",
    "            else:\n",
    "                action = 1 # \n",
    "            states[i], reward, done[i], _ = envs[i].step(action)\n",
    "            trajectories[i]['actions'].append(action)\n",
    "            trajectories[i]['rewards'].append(reward)  \n",
    "            trajectories[i]['action probs'].append(action_prob)  \n",
    "#             print('action', action)\n",
    "#             print('reward', reward)\n",
    "#             print('')\n",
    "#             print('state', states[i])\n",
    "            \n",
    "    return trajectories\n",
    "\n",
    "def compute_returns(rewards_history, gamma):\n",
    "    \"\"\"Compute discounted returns with discount factor `gamma`.\"\"\"\n",
    "    returns = []\n",
    "    discounted_sum = 0\n",
    "    for r in rewards_history[::-1]:\n",
    "        discounted_sum = r + gamma * discounted_sum\n",
    "        returns.insert(0, discounted_sum)\n",
    "\n",
    "    # Normalize them for faster and more stable learning\n",
    "    returns = np.array(returns)\n",
    "    returns = (returns - np.mean(returns)) / (np.std(returns) + 1e-8)\n",
    "    returns = returns.tolist()\n",
    "\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"Curling\"\n",
    "# env_name = \"Curling\"\n",
    "if env_name == \"CartPole-v1\":\n",
    "    state_bounds = np.array([2.4, 2.5, 0.21, 2.5])\n",
    "elif env_name == 'Curling':\n",
    "    state_bounds = np.array([0, 1])\n",
    "gamma = 1\n",
    "batch_size = 5\n",
    "n_episodes = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b921af0d5742e3b10801adc88bba5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_game 50\n",
      "Rot\n",
      "[1.3168867  1.5527661  0.42008352 1.9177859  0.3588515  1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.32953033 0.24234247]\n",
      "tensor([[-0.0683],\n",
      "        [ 0.6152],\n",
      "        [ 0.6152],\n",
      "        [ 0.6152],\n",
      "        [ 0.6152],\n",
      "        [ 0.6152],\n",
      "        [ 0.6152],\n",
      "        [ 0.6152],\n",
      "        [ 0.6152],\n",
      "        [ 0.6152],\n",
      "        [-0.0683],\n",
      "        [-0.7631],\n",
      "        [-0.6914],\n",
      "        [-0.7631],\n",
      "        [-0.6914],\n",
      "        [-0.0683],\n",
      "        [-0.7631],\n",
      "        [-0.7631],\n",
      "        [-0.7631],\n",
      "        [-0.6914],\n",
      "        [-0.1753],\n",
      "        [ 0.6152],\n",
      "        [ 0.6152],\n",
      "        [ 0.6152],\n",
      "        [ 0.6152],\n",
      "        [ 0.6152],\n",
      "        [ 0.6152],\n",
      "        [ 0.6152],\n",
      "        [ 0.5675],\n",
      "        [ 0.5675],\n",
      "        [-0.1753],\n",
      "        [-0.7631],\n",
      "        [-0.7631],\n",
      "        [-0.7631],\n",
      "        [-0.7631],\n",
      "        [-0.7631],\n",
      "        [-0.7631],\n",
      "        [-0.7631],\n",
      "        [-0.6914],\n",
      "        [-0.7631],\n",
      "        [-0.0683],\n",
      "        [-0.0683],\n",
      "        [ 0.6152],\n",
      "        [ 0.5675],\n",
      "        [-0.1753],\n",
      "        [-0.7631],\n",
      "        [-0.6914],\n",
      "        [ 0.6152],\n",
      "        [ 0.6152],\n",
      "        [ 0.6152]], dtype=torch.float64)\n",
      "Finished episode 5 Average rewards:  19.0\n",
      "len_game 51\n",
      "Rot\n",
      "[1.3269433  1.5553857  0.41851568 1.917918   0.36178938 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.3272052  0.24069506]\n",
      "tensor([[-0.2310],\n",
      "        [-0.7984],\n",
      "        [-0.7984],\n",
      "        [-0.7984],\n",
      "        [-0.7984],\n",
      "        [-0.7265],\n",
      "        [-0.7265],\n",
      "        [-0.1117],\n",
      "        [-0.7984],\n",
      "        [-0.1117],\n",
      "        [-0.2310],\n",
      "        [-0.7984],\n",
      "        [-0.7984],\n",
      "        [-0.7984],\n",
      "        [-0.7984],\n",
      "        [-0.7984],\n",
      "        [-0.7265],\n",
      "        [-0.7265],\n",
      "        [ 0.6125],\n",
      "        [-0.2310],\n",
      "        [-0.2310],\n",
      "        [-0.7984],\n",
      "        [-0.7984],\n",
      "        [-0.7984],\n",
      "        [-0.7984],\n",
      "        [-0.7984],\n",
      "        [-0.7984],\n",
      "        [-0.7265],\n",
      "        [-0.7984],\n",
      "        [-0.7265],\n",
      "        [-0.2310],\n",
      "        [-0.7984],\n",
      "        [-0.7984],\n",
      "        [-0.7984],\n",
      "        [-0.7265],\n",
      "        [-0.7265],\n",
      "        [-0.7984],\n",
      "        [-0.7984],\n",
      "        [-0.7984],\n",
      "        [-0.7984],\n",
      "        [-0.1117],\n",
      "        [ 0.6125],\n",
      "        [ 0.5626],\n",
      "        [ 0.5626],\n",
      "        [ 0.5626],\n",
      "        [-0.7984],\n",
      "        [-0.7984],\n",
      "        [-0.7984],\n",
      "        [-0.7984],\n",
      "        [-0.7265],\n",
      "        [-0.1117]], dtype=torch.float64)\n",
      "Finished episode 10 Average rewards:  104.0\n",
      "Monitored episode 50 Average Monitored rewards:  16.46\n",
      "len_game 50\n",
      "Rot\n",
      "[1.3327513  1.5497994  0.42058924 1.9178486  0.3545364  1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.33731318 0.24276765]\n",
      "tensor([[-0.2326],\n",
      "        [ 0.6244],\n",
      "        [ 0.6244],\n",
      "        [ 0.6244],\n",
      "        [ 0.6244],\n",
      "        [ 0.5727],\n",
      "        [ 0.5727],\n",
      "        [-0.2326],\n",
      "        [ 0.6244],\n",
      "        [ 0.6244],\n",
      "        [-0.2326],\n",
      "        [-0.8131],\n",
      "        [-0.8131],\n",
      "        [-0.8131],\n",
      "        [-0.8131],\n",
      "        [-0.8131],\n",
      "        [-0.8131],\n",
      "        [-0.7397],\n",
      "        [-0.7397],\n",
      "        [-0.7397],\n",
      "        [-0.2326],\n",
      "        [-0.2326],\n",
      "        [-0.2326],\n",
      "        [-0.8131],\n",
      "        [-0.7397],\n",
      "        [-0.1117],\n",
      "        [-0.8131],\n",
      "        [-0.8131],\n",
      "        [-0.7397],\n",
      "        [-0.8131],\n",
      "        [-0.2326],\n",
      "        [-0.8131],\n",
      "        [-0.8131],\n",
      "        [-0.8131],\n",
      "        [-0.8131],\n",
      "        [-0.8131],\n",
      "        [-0.7397],\n",
      "        [-0.7397],\n",
      "        [-0.7397],\n",
      "        [ 0.6244],\n",
      "        [-0.1117],\n",
      "        [ 0.6244],\n",
      "        [ 0.6244],\n",
      "        [ 0.6244],\n",
      "        [ 0.6244],\n",
      "        [ 0.6244],\n",
      "        [ 0.5727],\n",
      "        [ 0.5727],\n",
      "        [ 0.5727],\n",
      "        [ 0.5727]], dtype=torch.float64)\n",
      "Finished episode 15 Average rewards:  39.2\n",
      "len_game 50\n",
      "Rot\n",
      "[1.3374265  1.5430855  0.42192122 1.9178419  0.34428447 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.34948042 0.24406229]\n",
      "tensor([[-0.2603],\n",
      "        [-0.8305],\n",
      "        [-0.8305],\n",
      "        [-0.8305],\n",
      "        [-0.7590],\n",
      "        [-0.8305],\n",
      "        [-0.7590],\n",
      "        [ 0.6275],\n",
      "        [ 0.6275],\n",
      "        [ 0.6275],\n",
      "        [-0.1344],\n",
      "        [ 0.6275],\n",
      "        [ 0.6275],\n",
      "        [ 0.6275],\n",
      "        [ 0.6275],\n",
      "        [ 0.6275],\n",
      "        [ 0.6275],\n",
      "        [ 0.6275],\n",
      "        [ 0.5759],\n",
      "        [ 0.5759],\n",
      "        [-0.2603],\n",
      "        [-0.8305],\n",
      "        [-0.7590],\n",
      "        [-0.8305],\n",
      "        [-0.8305],\n",
      "        [-0.8305],\n",
      "        [-0.8305],\n",
      "        [-0.8305],\n",
      "        [-0.8305],\n",
      "        [-0.8305],\n",
      "        [-0.2603],\n",
      "        [-0.8305],\n",
      "        [-0.8305],\n",
      "        [-0.8305],\n",
      "        [-0.7590],\n",
      "        [-0.7590],\n",
      "        [-0.7590],\n",
      "        [-0.7590],\n",
      "        [-0.7590],\n",
      "        [-0.8305],\n",
      "        [-0.2603],\n",
      "        [ 0.6275],\n",
      "        [ 0.6275],\n",
      "        [ 0.6275],\n",
      "        [ 0.6275],\n",
      "        [ 0.6275],\n",
      "        [ 0.6275],\n",
      "        [ 0.6275],\n",
      "        [ 0.6275],\n",
      "        [ 0.6275]], dtype=torch.float64)\n",
      "Finished episode 20 Average rewards:  39.0\n",
      "Monitored episode 50 Average Monitored rewards:  22.7\n",
      "len_game 50\n",
      "Rot\n",
      "[1.3457942  1.5335699  0.42501616 1.9177665  0.33123052 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.3674361  0.24713168]\n",
      "tensor([[-0.2949],\n",
      "        [-0.8437],\n",
      "        [-0.8437],\n",
      "        [-0.8437],\n",
      "        [-0.8437],\n",
      "        [-0.8437],\n",
      "        [-0.8437],\n",
      "        [-0.7738],\n",
      "        [-0.7738],\n",
      "        [-0.7738],\n",
      "        [-0.2949],\n",
      "        [-0.8437],\n",
      "        [-0.8437],\n",
      "        [-0.7738],\n",
      "        [-0.7738],\n",
      "        [ 0.6268],\n",
      "        [ 0.6268],\n",
      "        [ 0.6268],\n",
      "        [ 0.6268],\n",
      "        [ 0.6268],\n",
      "        [-0.1614],\n",
      "        [-0.8437],\n",
      "        [-0.8437],\n",
      "        [-0.8437],\n",
      "        [-0.8437],\n",
      "        [-0.8437],\n",
      "        [-0.8437],\n",
      "        [-0.8437],\n",
      "        [-0.8437],\n",
      "        [-0.7738],\n",
      "        [-0.2949],\n",
      "        [ 0.6268],\n",
      "        [ 0.6268],\n",
      "        [ 0.6268],\n",
      "        [ 0.6268],\n",
      "        [ 0.5750],\n",
      "        [-0.2949],\n",
      "        [-0.8437],\n",
      "        [-0.7738],\n",
      "        [ 0.6268],\n",
      "        [-0.2949],\n",
      "        [-0.8437],\n",
      "        [-0.8437],\n",
      "        [-0.7738],\n",
      "        [-0.7738],\n",
      "        [-0.7738],\n",
      "        [ 0.6268],\n",
      "        [ 0.6268],\n",
      "        [ 0.6268],\n",
      "        [ 0.6268]], dtype=torch.float64)\n",
      "Finished episode 25 Average rewards:  19.8\n",
      "len_game 50\n",
      "Rot\n",
      "[1.3490268  1.5300924  0.4327067  1.9173434  0.32778877 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.37434742 0.2550175 ]\n",
      "tensor([[-0.3389],\n",
      "        [-0.8546],\n",
      "        [-0.8546],\n",
      "        [-0.7902],\n",
      "        [-0.8546],\n",
      "        [-0.8546],\n",
      "        [-0.8546],\n",
      "        [-0.8546],\n",
      "        [-0.7902],\n",
      "        [-0.7902],\n",
      "        [-0.1974],\n",
      "        [-0.8546],\n",
      "        [-0.1974],\n",
      "        [ 0.6305],\n",
      "        [ 0.6305],\n",
      "        [ 0.6305],\n",
      "        [ 0.6305],\n",
      "        [ 0.6305],\n",
      "        [ 0.6305],\n",
      "        [ 0.6305],\n",
      "        [-0.1974],\n",
      "        [ 0.6305],\n",
      "        [ 0.6305],\n",
      "        [ 0.6305],\n",
      "        [ 0.6305],\n",
      "        [ 0.6305],\n",
      "        [ 0.6305],\n",
      "        [ 0.6305],\n",
      "        [ 0.6305],\n",
      "        [ 0.6305],\n",
      "        [-0.3389],\n",
      "        [-0.8546],\n",
      "        [-0.8546],\n",
      "        [-0.8546],\n",
      "        [-0.8546],\n",
      "        [-0.8546],\n",
      "        [-0.8546],\n",
      "        [-0.8546],\n",
      "        [-0.7902],\n",
      "        [-0.7902],\n",
      "        [-0.3389],\n",
      "        [-0.8546],\n",
      "        [-0.8546],\n",
      "        [-0.8546],\n",
      "        [-0.7902],\n",
      "        [ 0.6305],\n",
      "        [-0.3389],\n",
      "        [-0.8546],\n",
      "        [-0.8546],\n",
      "        [-0.8546]], dtype=torch.float64)\n",
      "Finished episode 30 Average rewards:  40.6\n",
      "Monitored episode 50 Average Monitored rewards:  29.72\n",
      "len_game 50\n",
      "Rot\n",
      "[1.3514115  1.5259571  0.43729225 1.9171307  0.3222204  1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.38259152 0.2597037 ]\n",
      "tensor([[-0.3415],\n",
      "        [-0.8522],\n",
      "        [-0.8522],\n",
      "        [-0.8522],\n",
      "        [-0.8522],\n",
      "        [-0.7949],\n",
      "        [-0.8522],\n",
      "        [-0.8522],\n",
      "        [-0.8522],\n",
      "        [-0.8522],\n",
      "        [-0.3415],\n",
      "        [-0.8522],\n",
      "        [-0.8522],\n",
      "        [-0.7949],\n",
      "        [-0.8522],\n",
      "        [-0.8522],\n",
      "        [-0.7949],\n",
      "        [-0.7949],\n",
      "        [-0.7949],\n",
      "        [ 0.6349],\n",
      "        [-0.3415],\n",
      "        [-0.8522],\n",
      "        [-0.8522],\n",
      "        [-0.8522],\n",
      "        [-0.8522],\n",
      "        [-0.8522],\n",
      "        [-0.7949],\n",
      "        [-0.8522],\n",
      "        [-0.7949],\n",
      "        [-0.8522],\n",
      "        [-0.2080],\n",
      "        [-0.2080],\n",
      "        [ 0.6349],\n",
      "        [ 0.6349],\n",
      "        [ 0.6349],\n",
      "        [ 0.6349],\n",
      "        [ 0.6349],\n",
      "        [ 0.6349],\n",
      "        [ 0.6349],\n",
      "        [ 0.6349],\n",
      "        [-0.3415],\n",
      "        [ 0.6349],\n",
      "        [ 0.6349],\n",
      "        [ 0.6349],\n",
      "        [ 0.6349],\n",
      "        [ 0.6349],\n",
      "        [ 0.6349],\n",
      "        [ 0.6349],\n",
      "        [ 0.6349],\n",
      "        [ 0.5895]], dtype=torch.float64)\n",
      "Finished episode 35 Average rewards:  41.4\n",
      "len_game 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[1.356012   1.5236237  0.44515115 1.9167544  0.32176137 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.38758102 0.26778302]\n",
      "tensor([[-0.3521],\n",
      "        [ 0.6361],\n",
      "        [-0.3521],\n",
      "        [-0.8480],\n",
      "        [-0.8480],\n",
      "        [-0.7960],\n",
      "        [-0.7960],\n",
      "        [-0.2217],\n",
      "        [-0.8480],\n",
      "        [-0.8480],\n",
      "        [-0.3521],\n",
      "        [-0.8480],\n",
      "        [-0.8480],\n",
      "        [-0.8480],\n",
      "        [-0.8480],\n",
      "        [-0.7960],\n",
      "        [-0.7960],\n",
      "        [-0.2217],\n",
      "        [-0.8480],\n",
      "        [-0.8480],\n",
      "        [-0.3521],\n",
      "        [-0.8480],\n",
      "        [-0.8480],\n",
      "        [-0.8480],\n",
      "        [-0.8480],\n",
      "        [-0.8480],\n",
      "        [-0.8480],\n",
      "        [-0.8480],\n",
      "        [-0.8480],\n",
      "        [-0.7960],\n",
      "        [-0.2217],\n",
      "        [-0.8480],\n",
      "        [-0.7960],\n",
      "        [-0.8480],\n",
      "        [-0.7960],\n",
      "        [ 0.6361],\n",
      "        [ 0.6361],\n",
      "        [ 0.6361],\n",
      "        [ 0.6361],\n",
      "        [ 0.6361],\n",
      "        [-0.2217],\n",
      "        [-0.2217],\n",
      "        [ 0.6361],\n",
      "        [ 0.6361],\n",
      "        [ 0.6361],\n",
      "        [ 0.6361],\n",
      "        [ 0.6361],\n",
      "        [ 0.6361],\n",
      "        [ 0.6361],\n",
      "        [ 0.6361]], dtype=torch.float64)\n",
      "Finished episode 40 Average rewards:  61.4\n",
      "Monitored episode 50 Average Monitored rewards:  33.9\n",
      "len_game 50\n",
      "Rot\n",
      "[1.360641   1.5139208  0.44160894 1.9169899  0.30408177 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.40783587 0.26401135]\n",
      "tensor([[-0.2273],\n",
      "        [ 0.6450],\n",
      "        [-0.3452],\n",
      "        [ 0.6450],\n",
      "        [ 0.6450],\n",
      "        [ 0.6082],\n",
      "        [ 0.6082],\n",
      "        [-0.3452],\n",
      "        [-0.8470],\n",
      "        [-0.8470],\n",
      "        [-0.2273],\n",
      "        [-0.8470],\n",
      "        [-0.8470],\n",
      "        [-0.8470],\n",
      "        [-0.8022],\n",
      "        [-0.8470],\n",
      "        [-0.8022],\n",
      "        [-0.8022],\n",
      "        [-0.2273],\n",
      "        [-0.8470],\n",
      "        [-0.3452],\n",
      "        [ 0.6450],\n",
      "        [ 0.6450],\n",
      "        [ 0.6450],\n",
      "        [ 0.6082],\n",
      "        [ 0.6082],\n",
      "        [ 0.6450],\n",
      "        [ 0.6450],\n",
      "        [ 0.6082],\n",
      "        [ 0.6082],\n",
      "        [-0.2273],\n",
      "        [-0.8470],\n",
      "        [-0.2273],\n",
      "        [-0.8470],\n",
      "        [-0.8470],\n",
      "        [-0.8022],\n",
      "        [-0.8022],\n",
      "        [-0.2273],\n",
      "        [ 0.6450],\n",
      "        [ 0.6450],\n",
      "        [-0.3452],\n",
      "        [ 0.6450],\n",
      "        [ 0.6450],\n",
      "        [ 0.6082],\n",
      "        [ 0.6082],\n",
      "        [ 0.6082],\n",
      "        [-0.3452],\n",
      "        [-0.8470],\n",
      "        [-0.2273],\n",
      "        [-0.8470]], dtype=torch.float64)\n",
      "Finished episode 45 Average rewards:  60.0\n",
      "len_game 50\n",
      "Rot\n",
      "[1.361975   1.5112432  0.44551405 1.9168296  0.29931527 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.4136086  0.26800743]\n",
      "tensor([[-0.4000],\n",
      "        [-0.8311],\n",
      "        [-0.8311],\n",
      "        [-0.8311],\n",
      "        [-0.7896],\n",
      "        [-0.8311],\n",
      "        [-0.7896],\n",
      "        [-0.7896],\n",
      "        [-0.7896],\n",
      "        [-0.2641],\n",
      "        [-0.2641],\n",
      "        [-0.8311],\n",
      "        [ 0.6388],\n",
      "        [ 0.6026],\n",
      "        [-0.4000],\n",
      "        [ 0.6388],\n",
      "        [ 0.6388],\n",
      "        [ 0.6388],\n",
      "        [ 0.6388],\n",
      "        [ 0.6388],\n",
      "        [-0.2641],\n",
      "        [ 0.6388],\n",
      "        [ 0.6388],\n",
      "        [ 0.6026],\n",
      "        [ 0.6026],\n",
      "        [ 0.6388],\n",
      "        [ 0.6388],\n",
      "        [ 0.6388],\n",
      "        [ 0.6388],\n",
      "        [ 0.6388],\n",
      "        [-0.4000],\n",
      "        [ 0.6388],\n",
      "        [ 0.6388],\n",
      "        [ 0.6388],\n",
      "        [ 0.6388],\n",
      "        [ 0.6388],\n",
      "        [ 0.6388],\n",
      "        [ 0.6388],\n",
      "        [ 0.6388],\n",
      "        [ 0.6388],\n",
      "        [-0.4000],\n",
      "        [-0.8311],\n",
      "        [-0.8311],\n",
      "        [-0.8311],\n",
      "        [-0.8311],\n",
      "        [-0.8311],\n",
      "        [-0.7896],\n",
      "        [-0.8311],\n",
      "        [-0.7896],\n",
      "        [-0.8311]], dtype=torch.float64)\n",
      "Finished episode 50 Average rewards:  18.0\n",
      "Monitored episode 50 Average Monitored rewards:  42.8\n",
      "len_game 50\n",
      "Rot\n",
      "[1.3651483 1.5096961 0.441722  1.917032  0.2953544 1.8641111 1.7464267\n",
      " 0.7518858]\n",
      "Enc\n",
      "[0.41705996 0.2640415 ]\n",
      "tensor([[-0.4048],\n",
      "        [ 0.6374],\n",
      "        [ 0.6374],\n",
      "        [ 0.6374],\n",
      "        [ 0.6374],\n",
      "        [ 0.6374],\n",
      "        [ 0.6374],\n",
      "        [ 0.6374],\n",
      "        [ 0.6374],\n",
      "        [ 0.6374],\n",
      "        [-0.4048],\n",
      "        [ 0.6374],\n",
      "        [ 0.6374],\n",
      "        [ 0.6374],\n",
      "        [ 0.6374],\n",
      "        [ 0.6374],\n",
      "        [ 0.6374],\n",
      "        [ 0.6374],\n",
      "        [ 0.6374],\n",
      "        [ 0.6374],\n",
      "        [-0.4048],\n",
      "        [-0.8212],\n",
      "        [-0.7840],\n",
      "        [-0.2734],\n",
      "        [-0.8212],\n",
      "        [-0.8212],\n",
      "        [-0.7840],\n",
      "        [-0.2734],\n",
      "        [-0.8212],\n",
      "        [-0.2734],\n",
      "        [-0.4048],\n",
      "        [-0.8212],\n",
      "        [-0.8212],\n",
      "        [-0.8212],\n",
      "        [-0.7840],\n",
      "        [-0.2734],\n",
      "        [-0.8212],\n",
      "        [-0.2734],\n",
      "        [ 0.6374],\n",
      "        [ 0.6374],\n",
      "        [-0.2734],\n",
      "        [-0.8212],\n",
      "        [ 0.6374],\n",
      "        [ 0.6374],\n",
      "        [ 0.6374],\n",
      "        [ 0.6374],\n",
      "        [ 0.6374],\n",
      "        [ 0.6374],\n",
      "        [ 0.6374],\n",
      "        [ 0.6374]], dtype=torch.float64)\n",
      "Finished episode 55 Average rewards:  -5.0\n",
      "len_game 51\n",
      "Rot\n",
      "[1.3676376  1.5060238  0.44224373 1.9170543  0.28787166 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.42527556 0.2645146 ]\n",
      "tensor([[-0.4238],\n",
      "        [-0.8199],\n",
      "        [-0.8199],\n",
      "        [-0.7815],\n",
      "        [-0.7815],\n",
      "        [-0.8199],\n",
      "        [-0.7815],\n",
      "        [-0.2819],\n",
      "        [-0.8199],\n",
      "        [-0.2819],\n",
      "        [-0.2819],\n",
      "        [-0.8199],\n",
      "        [-0.8199],\n",
      "        [-0.2819],\n",
      "        [ 0.6362],\n",
      "        [ 0.6362],\n",
      "        [ 0.6362],\n",
      "        [ 0.6016],\n",
      "        [ 0.6016],\n",
      "        [ 0.6016],\n",
      "        [-0.4238],\n",
      "        [-0.2819],\n",
      "        [ 0.6362],\n",
      "        [ 0.6362],\n",
      "        [ 0.6362],\n",
      "        [ 0.6362],\n",
      "        [ 0.6362],\n",
      "        [ 0.6362],\n",
      "        [ 0.6362],\n",
      "        [ 0.6362],\n",
      "        [ 0.6362],\n",
      "        [-0.4238],\n",
      "        [-0.8199],\n",
      "        [-0.7815],\n",
      "        [-0.2819],\n",
      "        [ 0.6362],\n",
      "        [ 0.6362],\n",
      "        [ 0.6362],\n",
      "        [ 0.6362],\n",
      "        [ 0.6362],\n",
      "        [ 0.6362],\n",
      "        [-0.2819],\n",
      "        [-0.8199],\n",
      "        [-0.8199],\n",
      "        [-0.8199],\n",
      "        [-0.8199],\n",
      "        [-0.8199],\n",
      "        [-0.8199],\n",
      "        [-0.7815],\n",
      "        [-0.7815],\n",
      "        [-0.7815]], dtype=torch.float64)\n",
      "Finished episode 60 Average rewards:  36.4\n",
      "Monitored episode 50 Average Monitored rewards:  35.14\n",
      "len_game 50\n",
      "Rot\n",
      "[1.3664474  1.4938082  0.44706374 1.9169177  0.26293895 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.45291162 0.2693637 ]\n",
      "tensor([[-0.2961],\n",
      "        [ 0.6329],\n",
      "        [ 0.6329],\n",
      "        [ 0.6329],\n",
      "        [ 0.6329],\n",
      "        [ 0.6329],\n",
      "        [ 0.6329],\n",
      "        [ 0.6329],\n",
      "        [ 0.6329],\n",
      "        [ 0.6329],\n",
      "        [-0.2961],\n",
      "        [ 0.6329],\n",
      "        [ 0.6329],\n",
      "        [ 0.6329],\n",
      "        [ 0.6329],\n",
      "        [ 0.6329],\n",
      "        [ 0.6329],\n",
      "        [ 0.6329],\n",
      "        [ 0.6329],\n",
      "        [ 0.6002],\n",
      "        [-0.4418],\n",
      "        [ 0.6329],\n",
      "        [ 0.6329],\n",
      "        [ 0.6329],\n",
      "        [ 0.6329],\n",
      "        [ 0.6329],\n",
      "        [ 0.6329],\n",
      "        [ 0.6329],\n",
      "        [ 0.6002],\n",
      "        [ 0.6002],\n",
      "        [-0.4418],\n",
      "        [ 0.6329],\n",
      "        [ 0.6329],\n",
      "        [ 0.6002],\n",
      "        [ 0.6002],\n",
      "        [-0.4418],\n",
      "        [ 0.6329],\n",
      "        [-0.4418],\n",
      "        [-0.8057],\n",
      "        [-0.8057],\n",
      "        [-0.2961],\n",
      "        [ 0.6329],\n",
      "        [ 0.6329],\n",
      "        [ 0.6329],\n",
      "        [ 0.6329],\n",
      "        [ 0.6329],\n",
      "        [ 0.6002],\n",
      "        [ 0.6002],\n",
      "        [ 0.6002],\n",
      "        [ 0.6002]], dtype=torch.float64)\n",
      "Finished episode 65 Average rewards:  15.2\n",
      "len_game 52\n",
      "Rot\n",
      "[1.3665963  1.4907572  0.45381925 1.9166477  0.2568502  1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.45974746 0.27630556]\n",
      "tensor([[-0.4846],\n",
      "        [-0.7315],\n",
      "        [-0.7109],\n",
      "        [-0.7109],\n",
      "        [ 0.6117],\n",
      "        [-0.4846],\n",
      "        [-0.4846],\n",
      "        [-0.7315],\n",
      "        [-0.7315],\n",
      "        [-0.7109],\n",
      "        [-0.3363],\n",
      "        [-0.3363],\n",
      "        [-0.4846],\n",
      "        [-0.7315],\n",
      "        [ 0.6117],\n",
      "        [-0.4846],\n",
      "        [-0.7315],\n",
      "        [-0.7109],\n",
      "        [-0.7315],\n",
      "        [-0.7315],\n",
      "        [-0.7315],\n",
      "        [-0.7109],\n",
      "        [-0.3363],\n",
      "        [-0.3363],\n",
      "        [ 0.6117],\n",
      "        [ 0.6117],\n",
      "        [ 0.6117],\n",
      "        [ 0.6117],\n",
      "        [ 0.5886],\n",
      "        [ 0.5886],\n",
      "        [ 0.5886],\n",
      "        [ 0.5886],\n",
      "        [-0.4846],\n",
      "        [ 0.6117],\n",
      "        [ 0.6117],\n",
      "        [ 0.6117],\n",
      "        [ 0.6117],\n",
      "        [ 0.6117],\n",
      "        [ 0.6117],\n",
      "        [ 0.6117],\n",
      "        [ 0.6117],\n",
      "        [ 0.5886],\n",
      "        [-0.3363],\n",
      "        [ 0.6117],\n",
      "        [ 0.6117],\n",
      "        [ 0.6117],\n",
      "        [ 0.6117],\n",
      "        [ 0.6117],\n",
      "        [ 0.6117],\n",
      "        [ 0.6117],\n",
      "        [ 0.6117],\n",
      "        [ 0.6117]], dtype=torch.float64)\n",
      "Finished episode 70 Average rewards:  17.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  22.22\n",
      "len_game 50\n",
      "Rot\n",
      "[1.366939   1.4888437  0.45193803 1.9167377  0.2515055  1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.46403113 0.27432892]\n",
      "tensor([[-0.4800],\n",
      "        [-0.7089],\n",
      "        [-0.7089],\n",
      "        [-0.6936],\n",
      "        [-0.6936],\n",
      "        [-0.7089],\n",
      "        [-0.7089],\n",
      "        [-0.6936],\n",
      "        [-0.6936],\n",
      "        [-0.3453],\n",
      "        [-0.3453],\n",
      "        [-0.3453],\n",
      "        [ 0.6065],\n",
      "        [ 0.6065],\n",
      "        [ 0.6065],\n",
      "        [ 0.6065],\n",
      "        [ 0.6065],\n",
      "        [ 0.5878],\n",
      "        [ 0.5878],\n",
      "        [ 0.5878],\n",
      "        [-0.4800],\n",
      "        [ 0.6065],\n",
      "        [ 0.6065],\n",
      "        [ 0.6065],\n",
      "        [ 0.6065],\n",
      "        [ 0.6065],\n",
      "        [ 0.6065],\n",
      "        [ 0.6065],\n",
      "        [ 0.6065],\n",
      "        [ 0.6065],\n",
      "        [-0.4800],\n",
      "        [ 0.6065],\n",
      "        [ 0.6065],\n",
      "        [ 0.6065],\n",
      "        [ 0.6065],\n",
      "        [ 0.6065],\n",
      "        [ 0.6065],\n",
      "        [ 0.6065],\n",
      "        [ 0.6065],\n",
      "        [ 0.6065],\n",
      "        [-0.3453],\n",
      "        [-0.7089],\n",
      "        [-0.3453],\n",
      "        [-0.7089],\n",
      "        [-0.7089],\n",
      "        [-0.7089],\n",
      "        [-0.7089],\n",
      "        [-0.7089],\n",
      "        [-0.7089],\n",
      "        [-0.7089]], dtype=torch.float64)\n",
      "Finished episode 75 Average rewards:  17.2\n",
      "len_game 50\n",
      "Rot\n",
      "[1.3663473  1.4847547  0.45374656 1.9166954  0.2412713  1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.4732513  0.27614796]\n",
      "tensor([[-0.4950],\n",
      "        [-0.6934],\n",
      "        [-0.6934],\n",
      "        [-0.6934],\n",
      "        [-0.6934],\n",
      "        [-0.6934],\n",
      "        [-0.6934],\n",
      "        [-0.6934],\n",
      "        [-0.6934],\n",
      "        [-0.6934],\n",
      "        [-0.3531],\n",
      "        [ 0.6000],\n",
      "        [ 0.6000],\n",
      "        [ 0.6000],\n",
      "        [ 0.6000],\n",
      "        [ 0.6000],\n",
      "        [ 0.5818],\n",
      "        [ 0.5818],\n",
      "        [ 0.5818],\n",
      "        [ 0.5818],\n",
      "        [-0.3531],\n",
      "        [-0.6934],\n",
      "        [-0.6934],\n",
      "        [-0.6934],\n",
      "        [-0.6934],\n",
      "        [-0.6796],\n",
      "        [-0.6934],\n",
      "        [-0.6934],\n",
      "        [-0.6934],\n",
      "        [-0.6934],\n",
      "        [-0.4950],\n",
      "        [-0.6934],\n",
      "        [-0.3531],\n",
      "        [ 0.6000],\n",
      "        [ 0.6000],\n",
      "        [ 0.6000],\n",
      "        [ 0.6000],\n",
      "        [ 0.6000],\n",
      "        [ 0.6000],\n",
      "        [ 0.6000],\n",
      "        [-0.4950],\n",
      "        [ 0.6000],\n",
      "        [ 0.6000],\n",
      "        [ 0.6000],\n",
      "        [ 0.6000],\n",
      "        [ 0.6000],\n",
      "        [ 0.6000],\n",
      "        [ 0.6000],\n",
      "        [ 0.6000],\n",
      "        [ 0.6000]], dtype=torch.float64)\n",
      "Finished episode 80 Average rewards:  40.6\n",
      "Monitored episode 50 Average Monitored rewards:  26.2\n",
      "len_game 50\n",
      "Rot\n",
      "[1.3667711  1.4840944  0.45701104 1.9165819  0.23827572 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.4747082  0.27950197]\n",
      "tensor([[-0.5085],\n",
      "        [-0.6577],\n",
      "        [-0.6577],\n",
      "        [-0.6577],\n",
      "        [-0.6577],\n",
      "        [-0.6488],\n",
      "        [-0.6488],\n",
      "        [-0.6577],\n",
      "        [-0.6577],\n",
      "        [-0.6577],\n",
      "        [-0.5085],\n",
      "        [ 0.5872],\n",
      "        [ 0.5872],\n",
      "        [ 0.5872],\n",
      "        [ 0.5872],\n",
      "        [ 0.5872],\n",
      "        [ 0.5872],\n",
      "        [ 0.5872],\n",
      "        [ 0.5872],\n",
      "        [ 0.5872],\n",
      "        [-0.3670],\n",
      "        [-0.6577],\n",
      "        [-0.6577],\n",
      "        [-0.6577],\n",
      "        [ 0.5872],\n",
      "        [ 0.5872],\n",
      "        [ 0.5872],\n",
      "        [ 0.5872],\n",
      "        [ 0.5872],\n",
      "        [ 0.5872],\n",
      "        [-0.5085],\n",
      "        [-0.6577],\n",
      "        [-0.6488],\n",
      "        [-0.6488],\n",
      "        [-0.6577],\n",
      "        [-0.6577],\n",
      "        [-0.6577],\n",
      "        [-0.6577],\n",
      "        [-0.6577],\n",
      "        [-0.6488],\n",
      "        [-0.3670],\n",
      "        [ 0.5872],\n",
      "        [ 0.5723],\n",
      "        [ 0.5723],\n",
      "        [-0.5085],\n",
      "        [-0.6577],\n",
      "        [-0.6488],\n",
      "        [-0.3670],\n",
      "        [ 0.5872],\n",
      "        [ 0.5872]], dtype=torch.float64)\n",
      "Finished episode 85 Average rewards:  39.4\n",
      "len_game 50\n",
      "Rot\n",
      "[1.3659141 1.477934  0.4555012 1.9166732 0.2228075 1.8641111 1.7464267\n",
      " 0.7518858]\n",
      "Enc\n",
      "[0.4885823  0.27786943]\n",
      "tensor([[-0.5044],\n",
      "        [ 0.5826],\n",
      "        [ 0.5826],\n",
      "        [ 0.5690],\n",
      "        [-0.5044],\n",
      "        [-0.6490],\n",
      "        [-0.6490],\n",
      "        [-0.6490],\n",
      "        [-0.6490],\n",
      "        [-0.6490],\n",
      "        [-0.5044],\n",
      "        [ 0.5826],\n",
      "        [ 0.5826],\n",
      "        [ 0.5826],\n",
      "        [ 0.5826],\n",
      "        [ 0.5826],\n",
      "        [ 0.5826],\n",
      "        [ 0.5690],\n",
      "        [ 0.5690],\n",
      "        [ 0.5690],\n",
      "        [-0.5044],\n",
      "        [-0.5044],\n",
      "        [-0.5044],\n",
      "        [ 0.5826],\n",
      "        [ 0.5826],\n",
      "        [ 0.5826],\n",
      "        [ 0.5690],\n",
      "        [ 0.5690],\n",
      "        [ 0.5690],\n",
      "        [ 0.5690],\n",
      "        [-0.5044],\n",
      "        [-0.6490],\n",
      "        [-0.6490],\n",
      "        [-0.6490],\n",
      "        [-0.6490],\n",
      "        [-0.6490],\n",
      "        [-0.6490],\n",
      "        [-0.6414],\n",
      "        [-0.6414],\n",
      "        [-0.6490],\n",
      "        [-0.5044],\n",
      "        [-0.6490],\n",
      "        [-0.3704],\n",
      "        [ 0.5826],\n",
      "        [ 0.5826],\n",
      "        [ 0.5826],\n",
      "        [ 0.5826],\n",
      "        [ 0.5826],\n",
      "        [ 0.5690],\n",
      "        [ 0.5690]], dtype=torch.float64)\n",
      "Finished episode 90 Average rewards:  43.4\n",
      "Monitored episode 50 Average Monitored rewards:  34.28\n",
      "len_game 52\n",
      "Rot\n",
      "[1.3653982  1.4738077  0.4508774  1.9168782  0.21019068 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.49780536 0.2730261 ]\n",
      "tensor([[-0.5344],\n",
      "        [-0.5907],\n",
      "        [-0.5907],\n",
      "        [-0.5907],\n",
      "        [-0.5907],\n",
      "        [-0.5900],\n",
      "        [ 0.5620],\n",
      "        [ 0.5620],\n",
      "        [ 0.5620],\n",
      "        [ 0.5620],\n",
      "        [-0.3904],\n",
      "        [-0.5907],\n",
      "        [-0.5907],\n",
      "        [-0.5907],\n",
      "        [-0.5900],\n",
      "        [-0.5907],\n",
      "        [-0.5907],\n",
      "        [-0.5900],\n",
      "        [-0.5900],\n",
      "        [-0.5900],\n",
      "        [-0.3904],\n",
      "        [-0.5907],\n",
      "        [ 0.5620],\n",
      "        [ 0.5620],\n",
      "        [ 0.5620],\n",
      "        [ 0.5620],\n",
      "        [ 0.5523],\n",
      "        [ 0.5523],\n",
      "        [ 0.5523],\n",
      "        [-0.5907],\n",
      "        [-0.3904],\n",
      "        [-0.3904],\n",
      "        [-0.5344],\n",
      "        [ 0.5620],\n",
      "        [ 0.5620],\n",
      "        [ 0.5620],\n",
      "        [ 0.5620],\n",
      "        [ 0.5620],\n",
      "        [ 0.5620],\n",
      "        [ 0.5620],\n",
      "        [ 0.5620],\n",
      "        [ 0.5620],\n",
      "        [-0.5344],\n",
      "        [-0.5344],\n",
      "        [ 0.5620],\n",
      "        [ 0.5620],\n",
      "        [ 0.5620],\n",
      "        [ 0.5620],\n",
      "        [ 0.5620],\n",
      "        [ 0.5620],\n",
      "        [ 0.5620],\n",
      "        [ 0.5620]], dtype=torch.float64)\n",
      "Finished episode 95 Average rewards:  15.0\n",
      "len_game 50\n",
      "Rot\n",
      "[1.3658621  1.4785016  0.46221346 1.9163826  0.22017547 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.48737213 0.28480047]\n",
      "tensor([[-0.5671],\n",
      "        [-0.5430],\n",
      "        [-0.5430],\n",
      "        [-0.5430],\n",
      "        [-0.5430],\n",
      "        [-0.5479],\n",
      "        [-0.5479],\n",
      "        [-0.5430],\n",
      "        [-0.5479],\n",
      "        [-0.5479],\n",
      "        [-0.5671],\n",
      "        [-0.5430],\n",
      "        [-0.5430],\n",
      "        [-0.5479],\n",
      "        [-0.5430],\n",
      "        [-0.5430],\n",
      "        [-0.5479],\n",
      "        [-0.5430],\n",
      "        [-0.5479],\n",
      "        [-0.5479],\n",
      "        [-0.4053],\n",
      "        [ 0.5423],\n",
      "        [ 0.5423],\n",
      "        [ 0.5423],\n",
      "        [ 0.5423],\n",
      "        [ 0.5423],\n",
      "        [ 0.5423],\n",
      "        [ 0.5423],\n",
      "        [ 0.5423],\n",
      "        [ 0.5423],\n",
      "        [-0.5671],\n",
      "        [-0.5430],\n",
      "        [-0.5430],\n",
      "        [-0.5430],\n",
      "        [-0.5430],\n",
      "        [-0.5430],\n",
      "        [-0.5430],\n",
      "        [-0.5479],\n",
      "        [-0.5430],\n",
      "        [-0.5479],\n",
      "        [-0.4053],\n",
      "        [-0.5430],\n",
      "        [-0.5430],\n",
      "        [-0.5479],\n",
      "        [ 0.5423],\n",
      "        [ 0.5423],\n",
      "        [ 0.5423],\n",
      "        [ 0.5423],\n",
      "        [ 0.5423],\n",
      "        [ 0.5423]], dtype=torch.float64)\n",
      "Finished episode 100 Average rewards:  59.0\n",
      "Monitored episode 50 Average Monitored rewards:  24.78\n",
      "len_game 50\n",
      "Rot\n",
      "[1.3655341  1.4758714  0.46200988 1.9164048  0.21203057 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.49324816 0.2845554 ]\n",
      "tensor([[-0.3916],\n",
      "        [-0.5870],\n",
      "        [-0.5870],\n",
      "        [-0.5858],\n",
      "        [-0.5858],\n",
      "        [-0.3916],\n",
      "        [-0.3916],\n",
      "        [-0.5870],\n",
      "        [-0.5870],\n",
      "        [-0.5858],\n",
      "        [-0.5170],\n",
      "        [-0.5870],\n",
      "        [-0.5858],\n",
      "        [-0.3916],\n",
      "        [ 0.5548],\n",
      "        [ 0.5548],\n",
      "        [ 0.5548],\n",
      "        [ 0.5548],\n",
      "        [ 0.5548],\n",
      "        [ 0.5548],\n",
      "        [-0.3916],\n",
      "        [-0.5870],\n",
      "        [ 0.5548],\n",
      "        [ 0.5548],\n",
      "        [ 0.5548],\n",
      "        [ 0.5548],\n",
      "        [ 0.5548],\n",
      "        [ 0.5548],\n",
      "        [ 0.5548],\n",
      "        [ 0.5548],\n",
      "        [-0.5170],\n",
      "        [ 0.5548],\n",
      "        [ 0.5548],\n",
      "        [ 0.5548],\n",
      "        [ 0.5460],\n",
      "        [ 0.5460],\n",
      "        [-0.5170],\n",
      "        [-0.5170],\n",
      "        [-0.5870],\n",
      "        [-0.3916],\n",
      "        [-0.3916],\n",
      "        [ 0.5548],\n",
      "        [ 0.5548],\n",
      "        [ 0.5548],\n",
      "        [ 0.5548],\n",
      "        [ 0.5548],\n",
      "        [ 0.5548],\n",
      "        [ 0.5548],\n",
      "        [ 0.5548],\n",
      "        [ 0.5548]], dtype=torch.float64)\n",
      "Finished episode 105 Average rewards:  -4.6\n",
      "len_game 51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[1.3662975  1.4777334  0.4591516  1.9164916  0.21530175 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.48906013 0.28160718]\n",
      "tensor([[-0.4009],\n",
      "        [-0.5574],\n",
      "        [-0.5574],\n",
      "        [-0.5574],\n",
      "        [-0.5574],\n",
      "        [-0.5590],\n",
      "        [-0.5590],\n",
      "        [-0.5574],\n",
      "        [-0.5590],\n",
      "        [-0.5590],\n",
      "        [-0.4009],\n",
      "        [-0.5294],\n",
      "        [-0.5574],\n",
      "        [-0.5574],\n",
      "        [-0.5574],\n",
      "        [-0.5574],\n",
      "        [-0.5574],\n",
      "        [-0.5574],\n",
      "        [-0.5590],\n",
      "        [-0.5590],\n",
      "        [-0.5590],\n",
      "        [-0.5294],\n",
      "        [ 0.5420],\n",
      "        [ 0.5420],\n",
      "        [ 0.5420],\n",
      "        [ 0.5420],\n",
      "        [ 0.5420],\n",
      "        [ 0.5420],\n",
      "        [ 0.5349],\n",
      "        [ 0.5349],\n",
      "        [ 0.5349],\n",
      "        [-0.4009],\n",
      "        [-0.5574],\n",
      "        [-0.5574],\n",
      "        [-0.5574],\n",
      "        [-0.5574],\n",
      "        [-0.5574],\n",
      "        [-0.5590],\n",
      "        [-0.5574],\n",
      "        [-0.5574],\n",
      "        [-0.5574],\n",
      "        [-0.4009],\n",
      "        [ 0.5420],\n",
      "        [ 0.5420],\n",
      "        [ 0.5420],\n",
      "        [ 0.5349],\n",
      "        [ 0.5349],\n",
      "        [ 0.5420],\n",
      "        [ 0.5420],\n",
      "        [ 0.5420],\n",
      "        [ 0.5420]], dtype=torch.float64)\n",
      "Finished episode 110 Average rewards:  41.2\n",
      "Monitored episode 50 Average Monitored rewards:  16.16\n",
      "len_game 51\n",
      "Rot\n",
      "[1.364493   1.4707965  0.46076488 1.9164742  0.19645773 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.5046802 0.2832005]\n",
      "tensor([[-0.3971],\n",
      "        [ 0.5458],\n",
      "        [ 0.5458],\n",
      "        [ 0.5458],\n",
      "        [ 0.5458],\n",
      "        [ 0.5368],\n",
      "        [ 0.5368],\n",
      "        [ 0.5368],\n",
      "        [ 0.5368],\n",
      "        [ 0.5368],\n",
      "        [-0.5333],\n",
      "        [-0.5333],\n",
      "        [ 0.5458],\n",
      "        [ 0.5458],\n",
      "        [ 0.5368],\n",
      "        [ 0.5368],\n",
      "        [ 0.5368],\n",
      "        [ 0.5368],\n",
      "        [ 0.5458],\n",
      "        [ 0.5458],\n",
      "        [ 0.5368],\n",
      "        [-0.3971],\n",
      "        [-0.5735],\n",
      "        [-0.3971],\n",
      "        [-0.3971],\n",
      "        [ 0.5458],\n",
      "        [ 0.5458],\n",
      "        [ 0.5458],\n",
      "        [ 0.5458],\n",
      "        [ 0.5458],\n",
      "        [ 0.5458],\n",
      "        [-0.5333],\n",
      "        [ 0.5458],\n",
      "        [ 0.5458],\n",
      "        [ 0.5458],\n",
      "        [ 0.5458],\n",
      "        [ 0.5458],\n",
      "        [ 0.5458],\n",
      "        [ 0.5458],\n",
      "        [ 0.5458],\n",
      "        [ 0.5458],\n",
      "        [-0.5333],\n",
      "        [-0.5735],\n",
      "        [-0.5735],\n",
      "        [-0.5730],\n",
      "        [-0.5735],\n",
      "        [-0.5735],\n",
      "        [-0.5735],\n",
      "        [-0.5735],\n",
      "        [-0.5735],\n",
      "        [-0.5735]], dtype=torch.float64)\n",
      "Finished episode 115 Average rewards:  38.8\n",
      "len_game 51\n",
      "Rot\n",
      "[1.364832   1.4721007  0.45763463 1.916579   0.19538699 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.50178504 0.27995804]\n",
      "tensor([[-0.5545],\n",
      "        [ 0.5167],\n",
      "        [ 0.5167],\n",
      "        [ 0.5167],\n",
      "        [ 0.5167],\n",
      "        [ 0.5167],\n",
      "        [ 0.5167],\n",
      "        [ 0.5131],\n",
      "        [ 0.5131],\n",
      "        [ 0.5131],\n",
      "        [-0.5545],\n",
      "        [-0.4175],\n",
      "        [ 0.5167],\n",
      "        [ 0.5167],\n",
      "        [ 0.5131],\n",
      "        [ 0.5131],\n",
      "        [ 0.5131],\n",
      "        [ 0.5131],\n",
      "        [ 0.5167],\n",
      "        [ 0.5167],\n",
      "        [ 0.5167],\n",
      "        [-0.5545],\n",
      "        [-0.4968],\n",
      "        [-0.5045],\n",
      "        [-0.5045],\n",
      "        [ 0.5167],\n",
      "        [ 0.5167],\n",
      "        [ 0.5167],\n",
      "        [ 0.5167],\n",
      "        [ 0.5167],\n",
      "        [ 0.5167],\n",
      "        [-0.5545],\n",
      "        [-0.5545],\n",
      "        [-0.4968],\n",
      "        [-0.4968],\n",
      "        [-0.5045],\n",
      "        [-0.4175],\n",
      "        [-0.4175],\n",
      "        [-0.4968],\n",
      "        [-0.4968],\n",
      "        [-0.4968],\n",
      "        [-0.4175],\n",
      "        [-0.4968],\n",
      "        [-0.5045],\n",
      "        [-0.5045],\n",
      "        [-0.4968],\n",
      "        [-0.4968],\n",
      "        [-0.5045],\n",
      "        [-0.4968],\n",
      "        [-0.4968],\n",
      "        [-0.4968]], dtype=torch.float64)\n",
      "Finished episode 120 Average rewards:  61.0\n",
      "Monitored episode 50 Average Monitored rewards:  45.34\n",
      "len_game 50\n",
      "Rot\n",
      "[1.3636205  1.4686059  0.4625466  1.9164271  0.18446864 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.50959104 0.28499594]\n",
      "tensor([[-0.5650],\n",
      "        [-0.5001],\n",
      "        [-0.5001],\n",
      "        [-0.5068],\n",
      "        [-0.5001],\n",
      "        [-0.5001],\n",
      "        [-0.5068],\n",
      "        [-0.5001],\n",
      "        [-0.5001],\n",
      "        [-0.5001],\n",
      "        [-0.5650],\n",
      "        [-0.5001],\n",
      "        [-0.5001],\n",
      "        [-0.5068],\n",
      "        [-0.4179],\n",
      "        [-0.5001],\n",
      "        [-0.5001],\n",
      "        [-0.4179],\n",
      "        [ 0.5115],\n",
      "        [ 0.5115],\n",
      "        [-0.4179],\n",
      "        [-0.4179],\n",
      "        [ 0.5115],\n",
      "        [ 0.5115],\n",
      "        [ 0.5115],\n",
      "        [ 0.5115],\n",
      "        [ 0.5065],\n",
      "        [ 0.5065],\n",
      "        [ 0.5065],\n",
      "        [ 0.5065],\n",
      "        [-0.5650],\n",
      "        [ 0.5115],\n",
      "        [ 0.5115],\n",
      "        [ 0.5115],\n",
      "        [ 0.5115],\n",
      "        [ 0.5115],\n",
      "        [ 0.5115],\n",
      "        [ 0.5115],\n",
      "        [ 0.5115],\n",
      "        [ 0.5065],\n",
      "        [-0.5650],\n",
      "        [-0.5001],\n",
      "        [-0.4179],\n",
      "        [ 0.5115],\n",
      "        [ 0.5115],\n",
      "        [ 0.5115],\n",
      "        [ 0.5115],\n",
      "        [ 0.5065],\n",
      "        [ 0.5065],\n",
      "        [-0.5650]], dtype=torch.float64)\n",
      "Finished episode 125 Average rewards:  40.6\n",
      "len_game 52\n",
      "Rot\n",
      "[1.3639916  1.4728599  0.4705143  1.91616    0.19226524 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.5002859  0.29327706]\n",
      "tensor([[-0.4276],\n",
      "        [ 0.4926],\n",
      "        [ 0.4926],\n",
      "        [ 0.4926],\n",
      "        [ 0.4926],\n",
      "        [ 0.4926],\n",
      "        [ 0.4906],\n",
      "        [ 0.4906],\n",
      "        [ 0.4906],\n",
      "        [ 0.4906],\n",
      "        [-0.4276],\n",
      "        [ 0.4926],\n",
      "        [ 0.4926],\n",
      "        [ 0.4926],\n",
      "        [ 0.4906],\n",
      "        [ 0.4906],\n",
      "        [ 0.4906],\n",
      "        [ 0.4906],\n",
      "        [ 0.4906],\n",
      "        [ 0.4906],\n",
      "        [-0.5623],\n",
      "        [-0.5623],\n",
      "        [-0.5623],\n",
      "        [-0.5623],\n",
      "        [-0.4567],\n",
      "        [-0.4567],\n",
      "        [-0.4668],\n",
      "        [-0.4276],\n",
      "        [-0.4276],\n",
      "        [-0.4567],\n",
      "        [-0.4567],\n",
      "        [-0.4567],\n",
      "        [-0.5623],\n",
      "        [-0.4567],\n",
      "        [-0.4567],\n",
      "        [-0.4567],\n",
      "        [-0.4668],\n",
      "        [-0.4567],\n",
      "        [-0.4668],\n",
      "        [-0.4567],\n",
      "        [-0.4567],\n",
      "        [-0.4567],\n",
      "        [-0.5623],\n",
      "        [-0.5623],\n",
      "        [-0.4567],\n",
      "        [-0.4567],\n",
      "        [-0.4567],\n",
      "        [-0.4668],\n",
      "        [-0.4668],\n",
      "        [-0.4668],\n",
      "        [-0.4668],\n",
      "        [-0.4567]], dtype=torch.float64)\n",
      "Finished episode 130 Average rewards:  63.8\n",
      "Monitored episode 50 Average Monitored rewards:  18.48\n",
      "len_game 51\n",
      "Rot\n",
      "[1.3608577  1.4616548  0.47705403 1.9160264  0.1637268  1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.52507144 0.2999659 ]\n",
      "tensor([[-0.5244],\n",
      "        [-0.4969],\n",
      "        [-0.4969],\n",
      "        [-0.5011],\n",
      "        [-0.4178],\n",
      "        [-0.4178],\n",
      "        [ 0.5018],\n",
      "        [ 0.5018],\n",
      "        [ 0.5018],\n",
      "        [ 0.5018],\n",
      "        [-0.5244],\n",
      "        [ 0.5018],\n",
      "        [ 0.5018],\n",
      "        [ 0.5018],\n",
      "        [ 0.5018],\n",
      "        [ 0.5018],\n",
      "        [ 0.5018],\n",
      "        [ 0.5018],\n",
      "        [ 0.5018],\n",
      "        [ 0.5018],\n",
      "        [-0.4178],\n",
      "        [-0.4178],\n",
      "        [-0.4178],\n",
      "        [ 0.5018],\n",
      "        [ 0.5018],\n",
      "        [ 0.5018],\n",
      "        [ 0.4978],\n",
      "        [ 0.4978],\n",
      "        [ 0.4978],\n",
      "        [ 0.4978],\n",
      "        [-0.5244],\n",
      "        [-0.5244],\n",
      "        [-0.4969],\n",
      "        [-0.5011],\n",
      "        [-0.5011],\n",
      "        [ 0.5018],\n",
      "        [-0.5244],\n",
      "        [-0.5244],\n",
      "        [ 0.5018],\n",
      "        [ 0.5018],\n",
      "        [ 0.5018],\n",
      "        [-0.4178],\n",
      "        [-0.4178],\n",
      "        [ 0.5018],\n",
      "        [ 0.5018],\n",
      "        [ 0.5018],\n",
      "        [ 0.5018],\n",
      "        [ 0.5018],\n",
      "        [ 0.5018],\n",
      "        [ 0.5018],\n",
      "        [ 0.5018]], dtype=torch.float64)\n",
      "Finished episode 135 Average rewards:  -6.4\n",
      "len_game 50\n",
      "Rot\n",
      "[1.3612055 1.4666289 0.4775138 1.9160093 0.1726485 1.8641111 1.7464267\n",
      " 0.7518858]\n",
      "Enc\n",
      "[0.51446205 0.30047134]\n",
      "tensor([[-0.4431],\n",
      "        [ 0.4558],\n",
      "        [ 0.4558],\n",
      "        [ 0.4558],\n",
      "        [ 0.4558],\n",
      "        [ 0.4558],\n",
      "        [ 0.4558],\n",
      "        [ 0.4558],\n",
      "        [ 0.4558],\n",
      "        [ 0.4558],\n",
      "        [-0.5319],\n",
      "        [-0.3741],\n",
      "        [-0.3741],\n",
      "        [-0.3741],\n",
      "        [-0.3861],\n",
      "        [-0.3861],\n",
      "        [ 0.4558],\n",
      "        [ 0.4558],\n",
      "        [ 0.4558],\n",
      "        [ 0.4558],\n",
      "        [-0.5319],\n",
      "        [-0.3741],\n",
      "        [-0.3861],\n",
      "        [-0.3741],\n",
      "        [-0.3741],\n",
      "        [-0.3741],\n",
      "        [-0.3861],\n",
      "        [-0.3861],\n",
      "        [-0.4431],\n",
      "        [-0.4431],\n",
      "        [-0.4431],\n",
      "        [-0.3741],\n",
      "        [-0.3741],\n",
      "        [-0.3741],\n",
      "        [-0.3741],\n",
      "        [-0.3861],\n",
      "        [-0.3741],\n",
      "        [-0.3741],\n",
      "        [-0.3741],\n",
      "        [-0.3861],\n",
      "        [-0.4431],\n",
      "        [-0.3741],\n",
      "        [ 0.4558],\n",
      "        [ 0.4558],\n",
      "        [ 0.4558],\n",
      "        [ 0.4558],\n",
      "        [ 0.4558],\n",
      "        [ 0.4558],\n",
      "        [ 0.4558],\n",
      "        [ 0.4558]], dtype=torch.float64)\n",
      "Finished episode 140 Average rewards:  36.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  38.28\n",
      "len_game 51\n",
      "Rot\n",
      "[1.3581835  1.4568204  0.48576486 1.9158666  0.1475002  1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.5357134  0.30896267]\n",
      "tensor([[-0.4342],\n",
      "        [ 0.4671],\n",
      "        [ 0.4671],\n",
      "        [ 0.4671],\n",
      "        [ 0.4671],\n",
      "        [ 0.4671],\n",
      "        [ 0.4671],\n",
      "        [ 0.4671],\n",
      "        [ 0.4671],\n",
      "        [ 0.4671],\n",
      "        [-0.5199],\n",
      "        [-0.4196],\n",
      "        [-0.4276],\n",
      "        [-0.4276],\n",
      "        [ 0.4671],\n",
      "        [ 0.4671],\n",
      "        [ 0.4671],\n",
      "        [ 0.4671],\n",
      "        [ 0.4671],\n",
      "        [ 0.4668],\n",
      "        [-0.5199],\n",
      "        [-0.5199],\n",
      "        [ 0.4671],\n",
      "        [ 0.4671],\n",
      "        [ 0.4671],\n",
      "        [ 0.4671],\n",
      "        [ 0.4668],\n",
      "        [ 0.4668],\n",
      "        [ 0.4671],\n",
      "        [ 0.4671],\n",
      "        [ 0.4671],\n",
      "        [-0.4342],\n",
      "        [ 0.4671],\n",
      "        [ 0.4671],\n",
      "        [ 0.4671],\n",
      "        [ 0.4671],\n",
      "        [ 0.4671],\n",
      "        [ 0.4671],\n",
      "        [ 0.4671],\n",
      "        [ 0.4671],\n",
      "        [ 0.4671],\n",
      "        [-0.4342],\n",
      "        [-0.4342],\n",
      "        [ 0.4671],\n",
      "        [ 0.4671],\n",
      "        [ 0.4671],\n",
      "        [ 0.4671],\n",
      "        [ 0.4668],\n",
      "        [ 0.4668],\n",
      "        [ 0.4668],\n",
      "        [ 0.4668]], dtype=torch.float64)\n",
      "Finished episode 145 Average rewards:  -4.8\n",
      "len_game 50\n",
      "Rot\n",
      "[1.3556352  1.4510365  0.47809622 1.9159628  0.12911613 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.5480584  0.30099878]\n",
      "tensor([[-0.5102],\n",
      "        [ 0.4241],\n",
      "        [ 0.4241],\n",
      "        [ 0.4241],\n",
      "        [ 0.4241],\n",
      "        [ 0.4269],\n",
      "        [ 0.4269],\n",
      "        [ 0.4241],\n",
      "        [ 0.4241],\n",
      "        [ 0.4241],\n",
      "        [-0.5102],\n",
      "        [-0.3126],\n",
      "        [-0.4527],\n",
      "        [-0.3126],\n",
      "        [-0.3126],\n",
      "        [-0.4527],\n",
      "        [ 0.4241],\n",
      "        [ 0.4241],\n",
      "        [ 0.4241],\n",
      "        [ 0.4241],\n",
      "        [-0.5102],\n",
      "        [-0.3126],\n",
      "        [-0.3227],\n",
      "        [ 0.4241],\n",
      "        [ 0.4241],\n",
      "        [ 0.4241],\n",
      "        [ 0.4241],\n",
      "        [ 0.4241],\n",
      "        [ 0.4241],\n",
      "        [ 0.4241],\n",
      "        [-0.5102],\n",
      "        [-0.5102],\n",
      "        [ 0.4241],\n",
      "        [ 0.4241],\n",
      "        [ 0.4241],\n",
      "        [ 0.4241],\n",
      "        [ 0.4241],\n",
      "        [ 0.4241],\n",
      "        [ 0.4241],\n",
      "        [ 0.4241],\n",
      "        [-0.5102],\n",
      "        [-0.3126],\n",
      "        [-0.3126],\n",
      "        [-0.3227],\n",
      "        [-0.4527],\n",
      "        [ 0.4241],\n",
      "        [ 0.4241],\n",
      "        [ 0.4241],\n",
      "        [ 0.4241],\n",
      "        [ 0.4241]], dtype=torch.float64)\n",
      "Finished episode 150 Average rewards:  -8.0\n",
      "Monitored episode 50 Average Monitored rewards:  33.98\n",
      "len_game 50\n",
      "Rot\n",
      "[1.353863   1.4476305  0.4794787  1.9159416  0.11753904 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.55523527 0.3024137 ]\n",
      "tensor([[-0.5532],\n",
      "        [ 0.3882],\n",
      "        [ 0.3882],\n",
      "        [ 0.3882],\n",
      "        [ 0.3882],\n",
      "        [ 0.3882],\n",
      "        [ 0.3950],\n",
      "        [ 0.3950],\n",
      "        [ 0.3950],\n",
      "        [ 0.3882],\n",
      "        [-0.5532],\n",
      "        [-0.2286],\n",
      "        [-0.2286],\n",
      "        [-0.2286],\n",
      "        [-0.2485],\n",
      "        [-0.2485],\n",
      "        [-0.2286],\n",
      "        [-0.2286],\n",
      "        [-0.2286],\n",
      "        [-0.2485],\n",
      "        [-0.4643],\n",
      "        [-0.2286],\n",
      "        [ 0.3882],\n",
      "        [ 0.3882],\n",
      "        [ 0.3882],\n",
      "        [ 0.3882],\n",
      "        [ 0.3882],\n",
      "        [ 0.3882],\n",
      "        [ 0.3882],\n",
      "        [ 0.3882],\n",
      "        [-0.4643],\n",
      "        [ 0.3882],\n",
      "        [ 0.3882],\n",
      "        [ 0.3882],\n",
      "        [ 0.3882],\n",
      "        [ 0.3882],\n",
      "        [ 0.3882],\n",
      "        [ 0.3882],\n",
      "        [ 0.3882],\n",
      "        [ 0.3882],\n",
      "        [-0.5532],\n",
      "        [-0.5532],\n",
      "        [-0.2286],\n",
      "        [-0.2485],\n",
      "        [ 0.3882],\n",
      "        [ 0.3882],\n",
      "        [ 0.3882],\n",
      "        [ 0.3882],\n",
      "        [ 0.3882],\n",
      "        [ 0.3882]], dtype=torch.float64)\n",
      "Finished episode 155 Average rewards:  16.8\n",
      "len_game 50\n",
      "Rot\n",
      "[1.3526391  1.4516146  0.49004737 1.9157499  0.12373633 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.54748505 0.31339133]\n",
      "tensor([[-0.4692],\n",
      "        [-0.1810],\n",
      "        [-0.4692],\n",
      "        [ 0.3644],\n",
      "        [ 0.3644],\n",
      "        [ 0.3644],\n",
      "        [ 0.3644],\n",
      "        [ 0.3644],\n",
      "        [ 0.3644],\n",
      "        [ 0.3644],\n",
      "        [-0.5537],\n",
      "        [-0.1810],\n",
      "        [-0.1810],\n",
      "        [-0.1810],\n",
      "        [-0.1810],\n",
      "        [-0.1810],\n",
      "        [-0.2024],\n",
      "        [-0.2024],\n",
      "        [-0.2024],\n",
      "        [-0.2024],\n",
      "        [-0.5537],\n",
      "        [-0.5537],\n",
      "        [-0.1810],\n",
      "        [-0.1810],\n",
      "        [-0.1810],\n",
      "        [-0.1810],\n",
      "        [-0.2024],\n",
      "        [-0.1810],\n",
      "        [-0.1810],\n",
      "        [-0.1810],\n",
      "        [-0.5537],\n",
      "        [-0.1810],\n",
      "        [-0.2024],\n",
      "        [-0.1810],\n",
      "        [-0.2024],\n",
      "        [-0.4692],\n",
      "        [-0.1810],\n",
      "        [-0.4692],\n",
      "        [-0.1810],\n",
      "        [-0.1810],\n",
      "        [-0.4692],\n",
      "        [-0.4692],\n",
      "        [ 0.3644],\n",
      "        [ 0.3722],\n",
      "        [-0.5537],\n",
      "        [-0.5537],\n",
      "        [ 0.3644],\n",
      "        [ 0.3644],\n",
      "        [ 0.3644],\n",
      "        [ 0.3644]], dtype=torch.float64)\n",
      "Finished episode 160 Average rewards:  61.4\n",
      "Monitored episode 50 Average Monitored rewards:  31.86\n",
      "len_game 50\n",
      "Rot\n",
      "[1.3512253 1.4552838 0.5007221 1.9156578 0.1292514 1.8641111 1.7464267\n",
      " 0.7518858]\n",
      "Enc\n",
      "[0.54043263 0.32446548]\n",
      "tensor([[-0.5043],\n",
      "        [-0.2246],\n",
      "        [-0.2246],\n",
      "        [-0.2339],\n",
      "        [-0.2339],\n",
      "        [ 0.3715],\n",
      "        [-0.5043],\n",
      "        [-0.2246],\n",
      "        [-0.2246],\n",
      "        [-0.2339],\n",
      "        [-0.4627],\n",
      "        [ 0.3715],\n",
      "        [ 0.3715],\n",
      "        [ 0.3715],\n",
      "        [ 0.3715],\n",
      "        [ 0.3715],\n",
      "        [ 0.3715],\n",
      "        [ 0.3715],\n",
      "        [ 0.3715],\n",
      "        [ 0.3715],\n",
      "        [-0.5043],\n",
      "        [-0.2246],\n",
      "        [-0.2246],\n",
      "        [-0.2246],\n",
      "        [-0.2246],\n",
      "        [-0.2246],\n",
      "        [-0.2339],\n",
      "        [-0.2246],\n",
      "        [-0.2339],\n",
      "        [-0.2339],\n",
      "        [-0.4627],\n",
      "        [-0.2246],\n",
      "        [ 0.3715],\n",
      "        [ 0.3745],\n",
      "        [-0.5043],\n",
      "        [-0.5043],\n",
      "        [-0.2246],\n",
      "        [-0.2339],\n",
      "        [ 0.3715],\n",
      "        [ 0.3715],\n",
      "        [-0.4627],\n",
      "        [-0.2246],\n",
      "        [-0.4627],\n",
      "        [-0.2246],\n",
      "        [-0.2246],\n",
      "        [-0.2339],\n",
      "        [ 0.3715],\n",
      "        [ 0.3715],\n",
      "        [ 0.3715],\n",
      "        [ 0.3715]], dtype=torch.float64)\n",
      "Finished episode 165 Average rewards:  18.0\n",
      "len_game 50\n",
      "Rot\n",
      "[1.3515242  1.4626719  0.5089549  1.9156628  0.14582883 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.52589595 0.33299437]\n",
      "tensor([[-0.4531],\n",
      "        [-0.2624],\n",
      "        [-0.2624],\n",
      "        [-0.2624],\n",
      "        [-0.2624],\n",
      "        [-0.2624],\n",
      "        [-0.2624],\n",
      "        [-0.2624],\n",
      "        [-0.2618],\n",
      "        [-0.2618],\n",
      "        [-0.4531],\n",
      "        [-0.2624],\n",
      "        [-0.2624],\n",
      "        [-0.2618],\n",
      "        [-0.4562],\n",
      "        [ 0.3773],\n",
      "        [ 0.3773],\n",
      "        [ 0.3773],\n",
      "        [ 0.3773],\n",
      "        [ 0.3773],\n",
      "        [-0.4562],\n",
      "        [-0.2624],\n",
      "        [-0.2624],\n",
      "        [-0.2624],\n",
      "        [-0.2624],\n",
      "        [-0.2624],\n",
      "        [-0.2618],\n",
      "        [-0.2618],\n",
      "        [-0.2618],\n",
      "        [-0.2624],\n",
      "        [-0.4531],\n",
      "        [-0.2624],\n",
      "        [-0.2624],\n",
      "        [-0.2624],\n",
      "        [-0.2624],\n",
      "        [-0.2618],\n",
      "        [-0.2618],\n",
      "        [-0.2624],\n",
      "        [-0.2624],\n",
      "        [-0.2618],\n",
      "        [-0.4531],\n",
      "        [-0.2624],\n",
      "        [-0.2624],\n",
      "        [-0.2624],\n",
      "        [-0.2618],\n",
      "        [-0.2618],\n",
      "        [-0.2624],\n",
      "        [-0.2618],\n",
      "        [-0.2624],\n",
      "        [-0.2618]], dtype=torch.float64)\n",
      "Finished episode 170 Average rewards:  84.2\n",
      "Monitored episode 50 Average Monitored rewards:  29.18\n",
      "len_game 52\n",
      "Rot\n",
      "[1.3506553  1.4616661  0.5114308  1.9156817  0.14277254 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.52798164 0.3355603 ]\n",
      "tensor([[-0.4432],\n",
      "        [ 0.4051],\n",
      "        [ 0.4051],\n",
      "        [ 0.4051],\n",
      "        [ 0.4051],\n",
      "        [ 0.4051],\n",
      "        [ 0.4042],\n",
      "        [ 0.4042],\n",
      "        [ 0.4051],\n",
      "        [ 0.4051],\n",
      "        [-0.4432],\n",
      "        [ 0.4051],\n",
      "        [ 0.4042],\n",
      "        [ 0.4042],\n",
      "        [-0.4056],\n",
      "        [-0.3383],\n",
      "        [-0.4432],\n",
      "        [-0.3383],\n",
      "        [-0.3383],\n",
      "        [-0.3383],\n",
      "        [-0.4056],\n",
      "        [-0.3383],\n",
      "        [-0.3383],\n",
      "        [-0.3383],\n",
      "        [-0.3330],\n",
      "        [-0.3330],\n",
      "        [-0.3330],\n",
      "        [-0.3383],\n",
      "        [-0.3383],\n",
      "        [-0.3330],\n",
      "        [-0.4432],\n",
      "        [ 0.4051],\n",
      "        [ 0.4051],\n",
      "        [ 0.4051],\n",
      "        [ 0.4051],\n",
      "        [ 0.4051],\n",
      "        [ 0.4042],\n",
      "        [ 0.4042],\n",
      "        [ 0.4042],\n",
      "        [ 0.4042],\n",
      "        [-0.4056],\n",
      "        [-0.4056],\n",
      "        [-0.4432],\n",
      "        [-0.3383],\n",
      "        [-0.3383],\n",
      "        [-0.3383],\n",
      "        [-0.3383],\n",
      "        [-0.3383],\n",
      "        [-0.3330],\n",
      "        [-0.3330],\n",
      "        [-0.3330],\n",
      "        [-0.3383]], dtype=torch.float64)\n",
      "Finished episode 175 Average rewards:  80.6\n",
      "len_game 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[1.3482547  1.4551227  0.51241904 1.9156934  0.12632264 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.5410842  0.33659878]\n",
      "tensor([[-0.4445],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [-0.4445],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [-0.4445],\n",
      "        [-0.4445],\n",
      "        [ 0.3988],\n",
      "        [ 0.3975],\n",
      "        [-0.3961],\n",
      "        [-0.3279],\n",
      "        [-0.3279],\n",
      "        [-0.3207],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [-0.3961],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [-0.3961],\n",
      "        [-0.3961],\n",
      "        [-0.3279],\n",
      "        [-0.3207],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [ 0.3988],\n",
      "        [ 0.3975]], dtype=torch.float64)\n",
      "Finished episode 180 Average rewards:  -7.0\n",
      "Monitored episode 50 Average Monitored rewards:  27.44\n",
      "len_game 50\n",
      "Rot\n",
      "[1.3468932  1.4522314  0.5200815  1.9157753  0.11874422 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.5468185  0.34454307]\n",
      "tensor([[-0.4539],\n",
      "        [ 0.3681],\n",
      "        [ 0.3681],\n",
      "        [ 0.3681],\n",
      "        [ 0.3681],\n",
      "        [ 0.3681],\n",
      "        [ 0.3681],\n",
      "        [ 0.3681],\n",
      "        [ 0.3681],\n",
      "        [ 0.3681],\n",
      "        [-0.4002],\n",
      "        [-0.2621],\n",
      "        [-0.2621],\n",
      "        [-0.2621],\n",
      "        [-0.2513],\n",
      "        [-0.2513],\n",
      "        [-0.2513],\n",
      "        [-0.2621],\n",
      "        [-0.2513],\n",
      "        [-0.2513],\n",
      "        [-0.4002],\n",
      "        [ 0.3681],\n",
      "        [ 0.3681],\n",
      "        [ 0.3681],\n",
      "        [ 0.3681],\n",
      "        [ 0.3681],\n",
      "        [ 0.3681],\n",
      "        [ 0.3681],\n",
      "        [ 0.3681],\n",
      "        [ 0.3681],\n",
      "        [-0.4539],\n",
      "        [ 0.3681],\n",
      "        [ 0.3651],\n",
      "        [-0.4002],\n",
      "        [-0.2621],\n",
      "        [-0.2621],\n",
      "        [-0.4539],\n",
      "        [-0.2621],\n",
      "        [-0.4539],\n",
      "        [ 0.3681],\n",
      "        [-0.4539],\n",
      "        [ 0.3681],\n",
      "        [ 0.3681],\n",
      "        [ 0.3681],\n",
      "        [ 0.3681],\n",
      "        [ 0.3681],\n",
      "        [ 0.3681],\n",
      "        [ 0.3681],\n",
      "        [ 0.3681],\n",
      "        [ 0.3681]], dtype=torch.float64)\n",
      "Finished episode 185 Average rewards:  13.8\n",
      "len_game 51\n",
      "Rot\n",
      "[1.3459727  1.454165   0.51376486 1.9156631  0.12314347 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.54329276 0.33798167]\n",
      "tensor([[-0.4562],\n",
      "        [-0.2394],\n",
      "        [-0.2394],\n",
      "        [-0.2394],\n",
      "        [-0.2195],\n",
      "        [-0.2195],\n",
      "        [-0.2394],\n",
      "        [-0.2394],\n",
      "        [-0.2394],\n",
      "        [-0.2394],\n",
      "        [-0.3674],\n",
      "        [-0.2394],\n",
      "        [-0.2195],\n",
      "        [-0.2195],\n",
      "        [-0.2394],\n",
      "        [-0.2394],\n",
      "        [-0.2394],\n",
      "        [-0.2394],\n",
      "        [-0.2195],\n",
      "        [-0.2195],\n",
      "        [-0.4562],\n",
      "        [-0.2394],\n",
      "        [ 0.3532],\n",
      "        [ 0.3532],\n",
      "        [ 0.3532],\n",
      "        [ 0.3532],\n",
      "        [ 0.3532],\n",
      "        [ 0.3532],\n",
      "        [ 0.3532],\n",
      "        [ 0.3532],\n",
      "        [-0.3674],\n",
      "        [-0.2394],\n",
      "        [-0.2394],\n",
      "        [-0.2394],\n",
      "        [-0.2394],\n",
      "        [-0.2195],\n",
      "        [-0.2195],\n",
      "        [-0.2195],\n",
      "        [-0.4562],\n",
      "        [-0.2394],\n",
      "        [-0.4562],\n",
      "        [-0.3674],\n",
      "        [ 0.3532],\n",
      "        [ 0.3532],\n",
      "        [ 0.3532],\n",
      "        [ 0.3532],\n",
      "        [ 0.3470],\n",
      "        [ 0.3470],\n",
      "        [ 0.3470],\n",
      "        [-0.3674],\n",
      "        [-0.3674]], dtype=torch.float64)\n",
      "Finished episode 190 Average rewards:  60.4\n",
      "Monitored episode 50 Average Monitored rewards:  28.64\n",
      "len_game 50\n",
      "Rot\n",
      "[1.345264   1.4591386  0.51255596 1.915645   0.13391326 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.53402895 0.33670536]\n",
      "tensor([[-0.3944],\n",
      "        [ 0.3604],\n",
      "        [ 0.3604],\n",
      "        [ 0.3604],\n",
      "        [ 0.3604],\n",
      "        [ 0.3604],\n",
      "        [ 0.3604],\n",
      "        [ 0.3604],\n",
      "        [ 0.3604],\n",
      "        [ 0.3604],\n",
      "        [-0.3944],\n",
      "        [-0.3944],\n",
      "        [ 0.3604],\n",
      "        [ 0.3604],\n",
      "        [ 0.3568],\n",
      "        [ 0.3568],\n",
      "        [ 0.3568],\n",
      "        [-0.3944],\n",
      "        [-0.2498],\n",
      "        [-0.2498],\n",
      "        [-0.3944],\n",
      "        [-0.2498],\n",
      "        [-0.2498],\n",
      "        [-0.2373],\n",
      "        [-0.2373],\n",
      "        [-0.2373],\n",
      "        [-0.2373],\n",
      "        [-0.2498],\n",
      "        [-0.2373],\n",
      "        [-0.2498],\n",
      "        [-0.3944],\n",
      "        [-0.2498],\n",
      "        [-0.2498],\n",
      "        [-0.4542],\n",
      "        [-0.4542],\n",
      "        [-0.4542],\n",
      "        [-0.2498],\n",
      "        [-0.2498],\n",
      "        [-0.2373],\n",
      "        [-0.2498],\n",
      "        [-0.3944],\n",
      "        [-0.2498],\n",
      "        [-0.2373],\n",
      "        [ 0.3604],\n",
      "        [ 0.3604],\n",
      "        [ 0.3604],\n",
      "        [ 0.3604],\n",
      "        [ 0.3604],\n",
      "        [ 0.3604],\n",
      "        [ 0.3568]], dtype=torch.float64)\n",
      "Finished episode 195 Average rewards:  59.2\n",
      "len_game 50\n",
      "Rot\n",
      "[1.3435872  1.4557503  0.52426195 1.9157711  0.1253658  1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.54060304 0.34883973]\n",
      "tensor([[-0.4470],\n",
      "        [ 0.3783],\n",
      "        [ 0.3783],\n",
      "        [ 0.3783],\n",
      "        [ 0.3762],\n",
      "        [-0.2922],\n",
      "        [ 0.3783],\n",
      "        [-0.3935],\n",
      "        [-0.2922],\n",
      "        [-0.2922],\n",
      "        [-0.4470],\n",
      "        [ 0.3783],\n",
      "        [ 0.3783],\n",
      "        [ 0.3783],\n",
      "        [ 0.3783],\n",
      "        [ 0.3783],\n",
      "        [ 0.3783],\n",
      "        [ 0.3783],\n",
      "        [ 0.3783],\n",
      "        [ 0.3783],\n",
      "        [-0.3935],\n",
      "        [-0.2922],\n",
      "        [-0.2922],\n",
      "        [-0.2922],\n",
      "        [-0.2829],\n",
      "        [-0.2922],\n",
      "        [-0.2922],\n",
      "        [-0.2829],\n",
      "        [-0.2829],\n",
      "        [-0.2829],\n",
      "        [-0.4470],\n",
      "        [-0.2922],\n",
      "        [-0.4470],\n",
      "        [ 0.3783],\n",
      "        [ 0.3783],\n",
      "        [ 0.3783],\n",
      "        [ 0.3783],\n",
      "        [ 0.3783],\n",
      "        [ 0.3783],\n",
      "        [ 0.3783],\n",
      "        [-0.3935],\n",
      "        [-0.2922],\n",
      "        [-0.4470],\n",
      "        [ 0.3783],\n",
      "        [ 0.3783],\n",
      "        [ 0.3783],\n",
      "        [ 0.3783],\n",
      "        [ 0.3783],\n",
      "        [ 0.3783],\n",
      "        [ 0.3783]], dtype=torch.float64)\n",
      "Finished episode 200 Average rewards:  35.8\n",
      "Monitored episode 50 Average Monitored rewards:  25.56\n",
      "len_game 50\n",
      "Rot\n",
      "[1.3415838  1.4498043  0.5401887  1.9161066  0.11146741 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.5518842  0.36536074]\n",
      "tensor([[-0.4495],\n",
      "        [ 0.3616],\n",
      "        [ 0.3616],\n",
      "        [ 0.3616],\n",
      "        [ 0.3616],\n",
      "        [ 0.3616],\n",
      "        [ 0.3558],\n",
      "        [ 0.3616],\n",
      "        [ 0.3616],\n",
      "        [ 0.3616],\n",
      "        [-0.3431],\n",
      "        [-0.2686],\n",
      "        [-0.2686],\n",
      "        [-0.2686],\n",
      "        [-0.2686],\n",
      "        [-0.2686],\n",
      "        [-0.2472],\n",
      "        [-0.2472],\n",
      "        [-0.2472],\n",
      "        [ 0.3616],\n",
      "        [-0.4495],\n",
      "        [-0.4495],\n",
      "        [-0.4495],\n",
      "        [ 0.3616],\n",
      "        [ 0.3616],\n",
      "        [ 0.3616],\n",
      "        [ 0.3616],\n",
      "        [ 0.3616],\n",
      "        [ 0.3616],\n",
      "        [ 0.3616],\n",
      "        [-0.4495],\n",
      "        [-0.2686],\n",
      "        [-0.2686],\n",
      "        [-0.2686],\n",
      "        [-0.2686],\n",
      "        [-0.2472],\n",
      "        [-0.2472],\n",
      "        [-0.4495],\n",
      "        [ 0.3616],\n",
      "        [ 0.3616],\n",
      "        [-0.4495],\n",
      "        [ 0.3616],\n",
      "        [ 0.3616],\n",
      "        [ 0.3616],\n",
      "        [ 0.3616],\n",
      "        [ 0.3616],\n",
      "        [ 0.3616],\n",
      "        [ 0.3616],\n",
      "        [ 0.3616],\n",
      "        [ 0.3616]], dtype=torch.float64)\n",
      "Finished episode 205 Average rewards:  -6.8\n",
      "len_game 50\n",
      "Rot\n",
      "[1.339039   1.4439261  0.53800243 1.9160476  0.09929782 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.5629693  0.36312863]\n",
      "tensor([[-0.2703],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [-0.2703],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [-0.4533],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [-0.2703],\n",
      "        [-0.2330],\n",
      "        [-0.2330],\n",
      "        [-0.1879],\n",
      "        [-0.1879],\n",
      "        [-0.1879],\n",
      "        [-0.1879],\n",
      "        [-0.1879],\n",
      "        [-0.2330],\n",
      "        [-0.1879],\n",
      "        [-0.2703],\n",
      "        [-0.2330],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350],\n",
      "        [ 0.3350]], dtype=torch.float64)\n",
      "Finished episode 210 Average rewards:  13.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  31.96\n",
      "len_game 50\n",
      "Rot\n",
      "[1.3377357  1.4472989  0.53859264 1.9160408  0.10707131 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.55720055 0.36368343]\n",
      "tensor([[-0.2837],\n",
      "        [-0.1830],\n",
      "        [-0.1830],\n",
      "        [-0.1830],\n",
      "        [-0.1322],\n",
      "        [-0.1322],\n",
      "        [-0.4577],\n",
      "        [-0.1830],\n",
      "        [-0.1830],\n",
      "        [-0.1322],\n",
      "        [-0.4577],\n",
      "        [ 0.3122],\n",
      "        [ 0.3122],\n",
      "        [ 0.3122],\n",
      "        [ 0.3122],\n",
      "        [ 0.2945],\n",
      "        [ 0.3122],\n",
      "        [ 0.3122],\n",
      "        [ 0.3122],\n",
      "        [ 0.3122],\n",
      "        [-0.4577],\n",
      "        [ 0.3122],\n",
      "        [ 0.3122],\n",
      "        [ 0.3122],\n",
      "        [ 0.3122],\n",
      "        [ 0.3122],\n",
      "        [ 0.3122],\n",
      "        [ 0.3122],\n",
      "        [ 0.3122],\n",
      "        [ 0.3122],\n",
      "        [-0.2837],\n",
      "        [-0.1830],\n",
      "        [-0.1322],\n",
      "        [-0.1830],\n",
      "        [-0.1322],\n",
      "        [-0.4577],\n",
      "        [ 0.3122],\n",
      "        [ 0.3122],\n",
      "        [ 0.3122],\n",
      "        [ 0.2945],\n",
      "        [-0.4577],\n",
      "        [-0.4577],\n",
      "        [-0.4577],\n",
      "        [-0.1830],\n",
      "        [-0.1830],\n",
      "        [-0.1830],\n",
      "        [-0.1830],\n",
      "        [-0.1322],\n",
      "        [-0.1322],\n",
      "        [-0.1322]], dtype=torch.float64)\n",
      "Finished episode 215 Average rewards:  37.0\n",
      "len_game 50\n",
      "Rot\n",
      "[1.3350866  1.4414419  0.54065907 1.9161214  0.09420058 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.56797045 0.36585087]\n",
      "tensor([[-0.4537],\n",
      "        [ 0.3258],\n",
      "        [ 0.3258],\n",
      "        [ 0.3258],\n",
      "        [ 0.3258],\n",
      "        [ 0.3258],\n",
      "        [ 0.3258],\n",
      "        [ 0.3258],\n",
      "        [ 0.3258],\n",
      "        [ 0.3258],\n",
      "        [-0.4537],\n",
      "        [-0.2108],\n",
      "        [-0.2108],\n",
      "        [-0.2108],\n",
      "        [-0.1636],\n",
      "        [-0.2108],\n",
      "        [-0.2108],\n",
      "        [-0.1636],\n",
      "        [-0.2108],\n",
      "        [-0.1636],\n",
      "        [-0.2787],\n",
      "        [ 0.3258],\n",
      "        [ 0.3258],\n",
      "        [ 0.3258],\n",
      "        [ 0.3104],\n",
      "        [ 0.3104],\n",
      "        [-0.2108],\n",
      "        [ 0.3258],\n",
      "        [ 0.3258],\n",
      "        [ 0.3258],\n",
      "        [-0.4537],\n",
      "        [ 0.3258],\n",
      "        [ 0.3258],\n",
      "        [ 0.3104],\n",
      "        [-0.2787],\n",
      "        [ 0.3258],\n",
      "        [ 0.3258],\n",
      "        [ 0.3258],\n",
      "        [ 0.3258],\n",
      "        [ 0.3258],\n",
      "        [-0.4537],\n",
      "        [-0.2108],\n",
      "        [-0.4537],\n",
      "        [ 0.3258],\n",
      "        [ 0.3258],\n",
      "        [ 0.3258],\n",
      "        [ 0.3104],\n",
      "        [ 0.3258],\n",
      "        [ 0.3258],\n",
      "        [ 0.3258]], dtype=torch.float64)\n",
      "Finished episode 220 Average rewards:  15.2\n",
      "Monitored episode 50 Average Monitored rewards:  22.84\n",
      "len_game 50\n",
      "Rot\n",
      "[1.3330591  1.4404039  0.54634535 1.9163072  0.0916044  1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.5701315  0.37171796]\n",
      "tensor([[-0.2703],\n",
      "        [-0.1655],\n",
      "        [-0.1069],\n",
      "        [ 0.3006],\n",
      "        [ 0.3006],\n",
      "        [ 0.2800],\n",
      "        [ 0.2800],\n",
      "        [-0.2703],\n",
      "        [ 0.3006],\n",
      "        [ 0.3006],\n",
      "        [-0.4569],\n",
      "        [-0.1655],\n",
      "        [-0.1655],\n",
      "        [-0.1655],\n",
      "        [-0.1655],\n",
      "        [-0.1655],\n",
      "        [-0.1069],\n",
      "        [-0.1655],\n",
      "        [-0.1655],\n",
      "        [-0.1655],\n",
      "        [-0.2703],\n",
      "        [-0.1655],\n",
      "        [-0.1655],\n",
      "        [-0.1655],\n",
      "        [-0.1655],\n",
      "        [-0.1069],\n",
      "        [-0.1655],\n",
      "        [-0.1069],\n",
      "        [-0.1655],\n",
      "        [-0.1655],\n",
      "        [-0.2703],\n",
      "        [-0.1655],\n",
      "        [-0.1655],\n",
      "        [-0.4569],\n",
      "        [ 0.3006],\n",
      "        [ 0.3006],\n",
      "        [ 0.2800],\n",
      "        [ 0.2800],\n",
      "        [ 0.3006],\n",
      "        [ 0.3006],\n",
      "        [-0.4569],\n",
      "        [ 0.3006],\n",
      "        [ 0.3006],\n",
      "        [ 0.3006],\n",
      "        [ 0.3006],\n",
      "        [ 0.3006],\n",
      "        [ 0.3006],\n",
      "        [ 0.3006],\n",
      "        [ 0.3006],\n",
      "        [ 0.2800]], dtype=torch.float64)\n",
      "Finished episode 225 Average rewards:  41.4\n",
      "len_game 50\n",
      "Rot\n",
      "[1.3301948  1.4303384  0.5550761  1.9166974  0.06636963 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.58776003 0.38084003]\n",
      "tensor([[-0.4555],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942],\n",
      "        [ 0.2699],\n",
      "        [ 0.2699],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942],\n",
      "        [-0.4555],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942],\n",
      "        [ 0.2699],\n",
      "        [ 0.2699],\n",
      "        [ 0.2699],\n",
      "        [-0.2416],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942],\n",
      "        [-0.4555],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942],\n",
      "        [ 0.2699],\n",
      "        [ 0.2699],\n",
      "        [-0.2416],\n",
      "        [-0.1643],\n",
      "        [-0.4555],\n",
      "        [-0.4555],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942],\n",
      "        [ 0.2942]], dtype=torch.float64)\n",
      "Finished episode 230 Average rewards:  14.2\n",
      "Monitored episode 50 Average Monitored rewards:  20.9\n",
      "len_game 50\n",
      "Rot\n",
      "[1.3264922  1.4280248  0.5633232  1.9170458  0.06240311 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.5923879  0.38932213]\n",
      "tensor([[-0.4567],\n",
      "        [-0.4567],\n",
      "        [ 0.2423],\n",
      "        [ 0.2423],\n",
      "        [ 0.2423],\n",
      "        [ 0.2423],\n",
      "        [ 0.2423],\n",
      "        [ 0.2423],\n",
      "        [ 0.2423],\n",
      "        [ 0.2423],\n",
      "        [-0.1959],\n",
      "        [-0.0968],\n",
      "        [ 0.0063],\n",
      "        [-0.4567],\n",
      "        [-0.4567],\n",
      "        [-0.0968],\n",
      "        [-0.0968],\n",
      "        [-0.0968],\n",
      "        [-0.0968],\n",
      "        [ 0.0063],\n",
      "        [-0.4567],\n",
      "        [-0.4567],\n",
      "        [-0.0968],\n",
      "        [-0.0968],\n",
      "        [ 0.0063],\n",
      "        [ 0.0063],\n",
      "        [ 0.0063],\n",
      "        [-0.0968],\n",
      "        [-0.0968],\n",
      "        [-0.0968],\n",
      "        [-0.4567],\n",
      "        [ 0.2423],\n",
      "        [ 0.2423],\n",
      "        [ 0.2423],\n",
      "        [ 0.2423],\n",
      "        [ 0.2423],\n",
      "        [ 0.2423],\n",
      "        [ 0.2423],\n",
      "        [ 0.2423],\n",
      "        [ 0.2423],\n",
      "        [-0.1959],\n",
      "        [-0.1959],\n",
      "        [-0.0968],\n",
      "        [-0.0968],\n",
      "        [ 0.0063],\n",
      "        [ 0.0063],\n",
      "        [ 0.0063],\n",
      "        [-0.4567],\n",
      "        [ 0.2423],\n",
      "        [ 0.2423]], dtype=torch.float64)\n",
      "Finished episode 235 Average rewards:  38.6\n",
      "len_game 50\n",
      "Rot\n",
      "[1.3219992  1.4185537  0.56689197 1.9172854  0.03812163 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.6086167  0.39307672]\n",
      "tensor([[-0.4534],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332],\n",
      "        [-0.1522],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332],\n",
      "        [-0.4534],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332],\n",
      "        [ 0.1863],\n",
      "        [ 0.1863],\n",
      "        [-0.1522],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332],\n",
      "        [-0.4534],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332],\n",
      "        [-0.1522],\n",
      "        [-0.0992],\n",
      "        [-0.0992],\n",
      "        [ 0.0263],\n",
      "        [ 0.0263],\n",
      "        [ 0.0263],\n",
      "        [ 0.0263],\n",
      "        [-0.4534],\n",
      "        [ 0.2332],\n",
      "        [ 0.2332]], dtype=torch.float64)\n",
      "Finished episode 240 Average rewards:  -6.8\n",
      "Monitored episode 50 Average Monitored rewards:  24.42\n",
      "len_game 50\n",
      "Rot\n",
      "[1.3173844  1.4127281  0.5761841  1.9177874  0.02330943 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.61879027 0.40266162]\n",
      "tensor([[-0.4475],\n",
      "        [ 0.1808],\n",
      "        [ 0.1808],\n",
      "        [ 0.1808],\n",
      "        [ 0.1808],\n",
      "        [ 0.1808],\n",
      "        [ 0.1808],\n",
      "        [ 0.1808],\n",
      "        [ 0.1808],\n",
      "        [ 0.1808],\n",
      "        [-0.4475],\n",
      "        [ 0.1808],\n",
      "        [ 0.1214],\n",
      "        [-0.1272],\n",
      "        [-0.0363],\n",
      "        [-0.0363],\n",
      "        [ 0.1187],\n",
      "        [-0.0363],\n",
      "        [-0.0363],\n",
      "        [ 0.1187],\n",
      "        [-0.1272],\n",
      "        [ 0.1808],\n",
      "        [ 0.1808],\n",
      "        [ 0.1808],\n",
      "        [ 0.1808],\n",
      "        [ 0.1808],\n",
      "        [ 0.1808],\n",
      "        [ 0.1808],\n",
      "        [ 0.1808],\n",
      "        [ 0.1808],\n",
      "        [-0.1272],\n",
      "        [-0.0363],\n",
      "        [ 0.1187],\n",
      "        [ 0.1808],\n",
      "        [ 0.1808],\n",
      "        [ 0.1808],\n",
      "        [ 0.1808],\n",
      "        [ 0.1808],\n",
      "        [ 0.1808],\n",
      "        [ 0.1808],\n",
      "        [-0.1272],\n",
      "        [-0.0363],\n",
      "        [-0.0363],\n",
      "        [-0.0363],\n",
      "        [-0.0363],\n",
      "        [ 0.1187],\n",
      "        [ 0.1187],\n",
      "        [-0.0363],\n",
      "        [-0.0363],\n",
      "        [-0.0363]], dtype=torch.float64)\n",
      "Finished episode 245 Average rewards:  37.2\n",
      "len_game 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[1.3133776  1.4048337  0.5990667  1.9192168  0.00729295 1.8641111\n",
      " 1.7464267  0.7518858 ]\n",
      "Enc\n",
      "[0.6316352  0.42628127]\n",
      "tensor([[-0.4388],\n",
      "        [-0.0206],\n",
      "        [ 0.1475],\n",
      "        [ 0.1475],\n",
      "        [ 0.1475],\n",
      "        [ 0.1475],\n",
      "        [ 0.1475],\n",
      "        [ 0.1475],\n",
      "        [ 0.1475],\n",
      "        [ 0.1475],\n",
      "        [-0.0727],\n",
      "        [-0.0206],\n",
      "        [-0.0206],\n",
      "        [-0.0206],\n",
      "        [-0.0206],\n",
      "        [-0.0206],\n",
      "        [-0.0206],\n",
      "        [-0.0206],\n",
      "        [-0.0206],\n",
      "        [ 0.1725],\n",
      "        [-0.4388],\n",
      "        [-0.0206],\n",
      "        [ 0.1725],\n",
      "        [-0.4388],\n",
      "        [ 0.1475],\n",
      "        [ 0.1475],\n",
      "        [ 0.1475],\n",
      "        [ 0.1475],\n",
      "        [ 0.1475],\n",
      "        [ 0.1475],\n",
      "        [-0.0727],\n",
      "        [-0.0727],\n",
      "        [-0.0206],\n",
      "        [-0.0206],\n",
      "        [ 0.1725],\n",
      "        [ 0.1725],\n",
      "        [ 0.1725],\n",
      "        [-0.4388],\n",
      "        [-0.0206],\n",
      "        [-0.0206],\n",
      "        [-0.4388],\n",
      "        [-0.0206],\n",
      "        [-0.4388],\n",
      "        [ 0.1475],\n",
      "        [ 0.1475],\n",
      "        [ 0.1475],\n",
      "        [ 0.1475],\n",
      "        [ 0.1475],\n",
      "        [ 0.1475],\n",
      "        [ 0.1475]], dtype=torch.float64)\n",
      "Finished episode 250 Average rewards:  38.2\n",
      "Monitored episode 50 Average Monitored rewards:  25.16\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.3068973e+00  1.3982567e+00  6.0581887e-01  1.9196557e+00\n",
      " -1.0377708e-03  1.8641111e+00  1.7464267e+00  7.5188577e-01]\n",
      "Enc\n",
      "[0.6430068  0.43315986]\n",
      "tensor([[ 0.0546],\n",
      "        [-0.0498],\n",
      "        [-0.0498],\n",
      "        [ 0.2293],\n",
      "        [-0.4260],\n",
      "        [-0.0498],\n",
      "        [-0.0498],\n",
      "        [ 0.2293],\n",
      "        [ 0.2293],\n",
      "        [-0.4260],\n",
      "        [ 0.0546],\n",
      "        [-0.0498],\n",
      "        [ 0.1130],\n",
      "        [ 0.1130],\n",
      "        [ 0.1130],\n",
      "        [ 0.1130],\n",
      "        [ 0.1130],\n",
      "        [ 0.1130],\n",
      "        [ 0.1130],\n",
      "        [ 0.1130],\n",
      "        [-0.4260],\n",
      "        [ 0.1130],\n",
      "        [ 0.1130],\n",
      "        [ 0.1130],\n",
      "        [ 0.0060],\n",
      "        [ 0.0060],\n",
      "        [ 0.0546],\n",
      "        [-0.0498],\n",
      "        [-0.0498],\n",
      "        [ 0.2293],\n",
      "        [ 0.0546],\n",
      "        [ 0.1130],\n",
      "        [ 0.1130],\n",
      "        [ 0.1130],\n",
      "        [ 0.1130],\n",
      "        [ 0.1130],\n",
      "        [ 0.1130],\n",
      "        [ 0.1130],\n",
      "        [ 0.1130],\n",
      "        [ 0.1130],\n",
      "        [ 0.0546],\n",
      "        [-0.0498],\n",
      "        [-0.0498],\n",
      "        [-0.0498],\n",
      "        [ 0.2293],\n",
      "        [ 0.2293],\n",
      "        [ 0.2293],\n",
      "        [ 0.2293],\n",
      "        [ 0.2293],\n",
      "        [-0.4260]], dtype=torch.float64)\n",
      "Finished episode 255 Average rewards:  16.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.3002273   1.3923204   0.60775673  1.9197115  -0.00698137  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.65322393 0.43507653]\n",
      "tensor([[-0.4152],\n",
      "        [-0.0559],\n",
      "        [ 0.0962],\n",
      "        [ 0.0962],\n",
      "        [ 0.0962],\n",
      "        [ 0.0962],\n",
      "        [-0.0246],\n",
      "        [-0.0246],\n",
      "        [-0.0246],\n",
      "        [ 0.0962],\n",
      "        [-0.4152],\n",
      "        [ 0.0962],\n",
      "        [ 0.0962],\n",
      "        [ 0.0962],\n",
      "        [-0.0246],\n",
      "        [-0.0246],\n",
      "        [ 0.0962],\n",
      "        [ 0.0962],\n",
      "        [ 0.0962],\n",
      "        [ 0.0962],\n",
      "        [-0.4152],\n",
      "        [-0.4152],\n",
      "        [-0.0559],\n",
      "        [-0.0559],\n",
      "        [-0.0559],\n",
      "        [-0.0559],\n",
      "        [-0.0559],\n",
      "        [-0.0559],\n",
      "        [-0.0559],\n",
      "        [-0.0559],\n",
      "        [-0.4152],\n",
      "        [-0.0559],\n",
      "        [-0.0559],\n",
      "        [-0.0559],\n",
      "        [-0.0559],\n",
      "        [ 0.2644],\n",
      "        [ 0.2644],\n",
      "        [ 0.2644],\n",
      "        [ 0.2644],\n",
      "        [ 0.2644],\n",
      "        [-0.4152],\n",
      "        [-0.0559],\n",
      "        [-0.0559],\n",
      "        [ 0.2644],\n",
      "        [ 0.2644],\n",
      "        [ 0.2644],\n",
      "        [ 0.2644],\n",
      "        [ 0.2644],\n",
      "        [-0.4152],\n",
      "        [-0.0559]], dtype=torch.float64)\n",
      "Finished episode 260 Average rewards:  61.0\n",
      "Monitored episode 50 Average Monitored rewards:  27.04\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2983252   1.383539    0.6195804   1.92084    -0.01658037  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.6652739  0.44732612]\n",
      "tensor([[-0.4052],\n",
      "        [ 0.0845],\n",
      "        [ 0.0845],\n",
      "        [ 0.0845],\n",
      "        [ 0.0845],\n",
      "        [ 0.0845],\n",
      "        [ 0.0845],\n",
      "        [ 0.0845],\n",
      "        [ 0.0845],\n",
      "        [ 0.0845],\n",
      "        [ 0.1045],\n",
      "        [ 0.1045],\n",
      "        [-0.0540],\n",
      "        [-0.4052],\n",
      "        [-0.0540],\n",
      "        [-0.0540],\n",
      "        [-0.0540],\n",
      "        [ 0.2907],\n",
      "        [ 0.2907],\n",
      "        [ 0.2907],\n",
      "        [ 0.1045],\n",
      "        [-0.0540],\n",
      "        [-0.0540],\n",
      "        [ 0.2907],\n",
      "        [ 0.2907],\n",
      "        [ 0.2907],\n",
      "        [-0.4052],\n",
      "        [-0.4052],\n",
      "        [ 0.0845],\n",
      "        [ 0.0845],\n",
      "        [-0.4052],\n",
      "        [ 0.0845],\n",
      "        [ 0.0845],\n",
      "        [ 0.0845],\n",
      "        [ 0.0845],\n",
      "        [ 0.0845],\n",
      "        [-0.0427],\n",
      "        [-0.0427],\n",
      "        [-0.0427],\n",
      "        [ 0.1045],\n",
      "        [ 0.1045],\n",
      "        [-0.4052],\n",
      "        [-0.4052],\n",
      "        [ 0.0845],\n",
      "        [ 0.0845],\n",
      "        [ 0.0845],\n",
      "        [ 0.0845],\n",
      "        [ 0.0845],\n",
      "        [ 0.0845],\n",
      "        [-0.0427],\n",
      "        [-0.0427]], dtype=torch.float64)\n",
      "Finished episode 265 Average rewards:  35.6\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2911701   1.373426    0.62839794  1.921637   -0.02336259  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.6806891 0.4563698]\n",
      "tensor([[-0.3946],\n",
      "        [-0.3946],\n",
      "        [-0.0842],\n",
      "        [ 0.0668],\n",
      "        [ 0.0668],\n",
      "        [ 0.0668],\n",
      "        [-0.0845],\n",
      "        [-0.0842],\n",
      "        [-0.0842],\n",
      "        [-0.0842],\n",
      "        [ 0.1700],\n",
      "        [ 0.1700],\n",
      "        [-0.0842],\n",
      "        [-0.3946],\n",
      "        [ 0.0668],\n",
      "        [ 0.0668],\n",
      "        [ 0.0668],\n",
      "        [ 0.0668],\n",
      "        [ 0.0668],\n",
      "        [ 0.0668],\n",
      "        [ 0.1700],\n",
      "        [-0.0842],\n",
      "        [-0.0842],\n",
      "        [-0.0842],\n",
      "        [-0.0842],\n",
      "        [ 0.3248],\n",
      "        [ 0.3248],\n",
      "        [ 0.3248],\n",
      "        [ 0.3248],\n",
      "        [ 0.3248],\n",
      "        [ 0.1700],\n",
      "        [-0.0842],\n",
      "        [-0.3946],\n",
      "        [-0.0842],\n",
      "        [-0.0842],\n",
      "        [ 0.3248],\n",
      "        [ 0.3248],\n",
      "        [-0.3946],\n",
      "        [-0.0842],\n",
      "        [-0.3946],\n",
      "        [-0.3946],\n",
      "        [ 0.0668],\n",
      "        [ 0.0668],\n",
      "        [ 0.0668],\n",
      "        [ 0.0668],\n",
      "        [ 0.0668],\n",
      "        [ 0.0668],\n",
      "        [ 0.0668],\n",
      "        [ 0.0668],\n",
      "        [ 0.0668]], dtype=torch.float64)\n",
      "Finished episode 270 Average rewards:  39.0\n",
      "Monitored episode 50 Average Monitored rewards:  30.04\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2864836   1.3613724   0.64765847  1.9236052  -0.04762515  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.6969401  0.47617346]\n",
      "tensor([[ 0.2160],\n",
      "        [ 0.0555],\n",
      "        [ 0.0555],\n",
      "        [ 0.0555],\n",
      "        [ 0.0555],\n",
      "        [ 0.0555],\n",
      "        [-0.1152],\n",
      "        [ 0.0555],\n",
      "        [ 0.0555],\n",
      "        [-0.1152],\n",
      "        [ 0.2160],\n",
      "        [-0.1171],\n",
      "        [ 0.0555],\n",
      "        [ 0.0555],\n",
      "        [ 0.0555],\n",
      "        [ 0.0555],\n",
      "        [ 0.0555],\n",
      "        [ 0.0555],\n",
      "        [ 0.0555],\n",
      "        [ 0.0555],\n",
      "        [-0.3800],\n",
      "        [ 0.0555],\n",
      "        [ 0.0555],\n",
      "        [-0.1152],\n",
      "        [ 0.2160],\n",
      "        [ 0.0555],\n",
      "        [ 0.0555],\n",
      "        [ 0.0555],\n",
      "        [ 0.0555],\n",
      "        [ 0.0555],\n",
      "        [-0.3800],\n",
      "        [-0.3800],\n",
      "        [-0.1171],\n",
      "        [-0.3800],\n",
      "        [-0.3800],\n",
      "        [-0.3800],\n",
      "        [ 0.0555],\n",
      "        [ 0.0555],\n",
      "        [ 0.0555],\n",
      "        [ 0.0555],\n",
      "        [ 0.2160],\n",
      "        [-0.1171],\n",
      "        [-0.3800],\n",
      "        [ 0.0555],\n",
      "        [ 0.0555],\n",
      "        [ 0.0555],\n",
      "        [ 0.0555],\n",
      "        [ 0.0555],\n",
      "        [ 0.0555],\n",
      "        [ 0.0555]], dtype=torch.float64)\n",
      "Finished episode 275 Average rewards:  -6.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2815568   1.353554    0.65276957  1.9242444  -0.04968256  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.70795155 0.4814418 ]\n",
      "tensor([[ 0.3230],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [ 0.4029],\n",
      "        [ 0.4029],\n",
      "        [ 0.4029],\n",
      "        [ 0.4029],\n",
      "        [ 0.4029],\n",
      "        [-0.3484],\n",
      "        [ 0.0013],\n",
      "        [ 0.0013],\n",
      "        [ 0.0013],\n",
      "        [ 0.0013],\n",
      "        [ 0.0013],\n",
      "        [ 0.0013],\n",
      "        [ 0.0013],\n",
      "        [ 0.0013],\n",
      "        [ 0.0013],\n",
      "        [ 0.3230],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [ 0.4029],\n",
      "        [ 0.4029],\n",
      "        [ 0.4029],\n",
      "        [ 0.3230],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [ 0.0013],\n",
      "        [ 0.0013],\n",
      "        [ 0.0013],\n",
      "        [ 0.0013],\n",
      "        [ 0.0013],\n",
      "        [ 0.0013],\n",
      "        [ 0.3230],\n",
      "        [ 0.3230],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.1696]], dtype=torch.float64)\n",
      "Finished episode 280 Average rewards:  61.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  54.52\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2883492   1.3556355   0.67323655  1.9268632  -0.01236125  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.7026585  0.50251794]\n",
      "tensor([[ 3.4657e-01],\n",
      "        [ 3.4657e-01],\n",
      "        [-2.0261e-01],\n",
      "        [-2.0261e-01],\n",
      "        [-2.0261e-01],\n",
      "        [-2.0261e-01],\n",
      "        [ 4.1126e-01],\n",
      "        [ 4.1126e-01],\n",
      "        [ 4.1126e-01],\n",
      "        [ 4.1126e-01],\n",
      "        [ 3.4657e-01],\n",
      "        [-2.0261e-01],\n",
      "        [-3.3809e-01],\n",
      "        [-2.6725e-04],\n",
      "        [-2.6725e-04],\n",
      "        [-2.1869e-01],\n",
      "        [-2.1869e-01],\n",
      "        [-2.6725e-04],\n",
      "        [-2.6725e-04],\n",
      "        [-2.1869e-01],\n",
      "        [-3.3809e-01],\n",
      "        [-2.6725e-04],\n",
      "        [-2.6725e-04],\n",
      "        [-2.6725e-04],\n",
      "        [-2.1869e-01],\n",
      "        [-2.6725e-04],\n",
      "        [-2.6725e-04],\n",
      "        [-2.1869e-01],\n",
      "        [-2.6725e-04],\n",
      "        [-2.6725e-04],\n",
      "        [-3.3809e-01],\n",
      "        [-2.6725e-04],\n",
      "        [-2.1869e-01],\n",
      "        [-2.1869e-01],\n",
      "        [-2.0261e-01],\n",
      "        [-3.3809e-01],\n",
      "        [-2.6725e-04],\n",
      "        [-2.6725e-04],\n",
      "        [-2.6725e-04],\n",
      "        [-2.1869e-01],\n",
      "        [ 3.4657e-01],\n",
      "        [-2.0261e-01],\n",
      "        [-2.0261e-01],\n",
      "        [-2.6725e-04],\n",
      "        [ 3.4657e-01],\n",
      "        [-2.0261e-01],\n",
      "        [-2.0261e-01],\n",
      "        [-2.0261e-01],\n",
      "        [ 4.1126e-01],\n",
      "        [-3.3809e-01]], dtype=torch.float64)\n",
      "Finished episode 285 Average rewards:  15.4\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2819183   1.3457032   0.6797164   1.9277972  -0.02061334  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.71686375 0.509179  ]\n",
      "tensor([[-0.3806],\n",
      "        [ 0.0937],\n",
      "        [ 0.0937],\n",
      "        [ 0.0937],\n",
      "        [ 0.0937],\n",
      "        [ 0.0937],\n",
      "        [ 0.0937],\n",
      "        [ 0.0937],\n",
      "        [ 0.0937],\n",
      "        [ 0.0937],\n",
      "        [-0.3806],\n",
      "        [-0.3315],\n",
      "        [-0.3315],\n",
      "        [-0.3315],\n",
      "        [-0.3315],\n",
      "        [-0.3315],\n",
      "        [-0.3315],\n",
      "        [-0.3315],\n",
      "        [-0.3315],\n",
      "        [-0.3315],\n",
      "        [ 0.4123],\n",
      "        [ 0.0937],\n",
      "        [ 0.0937],\n",
      "        [ 0.0937],\n",
      "        [ 0.0937],\n",
      "        [ 0.0937],\n",
      "        [ 0.0937],\n",
      "        [ 0.0937],\n",
      "        [ 0.0937],\n",
      "        [ 0.0937],\n",
      "        [ 0.4123],\n",
      "        [-0.3315],\n",
      "        [-0.3806],\n",
      "        [ 0.0937],\n",
      "        [-0.1587],\n",
      "        [-0.3315],\n",
      "        [-0.3806],\n",
      "        [ 0.0937],\n",
      "        [ 0.0937],\n",
      "        [ 0.0937],\n",
      "        [-0.3806],\n",
      "        [-0.3315],\n",
      "        [ 0.3589],\n",
      "        [ 0.3589],\n",
      "        [ 0.3589],\n",
      "        [ 0.3589],\n",
      "        [-0.3806],\n",
      "        [-0.3315],\n",
      "        [-0.3315],\n",
      "        [-0.3315],\n",
      "        [-0.3806]], dtype=torch.float64)\n",
      "Finished episode 290 Average rewards:  38.4\n",
      "Monitored episode 50 Average Monitored rewards:  26.84\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2789508   1.3370246   0.69112384  1.9294626  -0.0292915   1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.72764343 0.5208855 ]\n",
      "tensor([[ 0.4406],\n",
      "        [ 0.4406],\n",
      "        [-0.3632],\n",
      "        [-0.3632],\n",
      "        [ 0.3822],\n",
      "        [ 0.3822],\n",
      "        [-0.3632],\n",
      "        [-0.3632],\n",
      "        [-0.3632],\n",
      "        [ 0.3822],\n",
      "        [ 0.4406],\n",
      "        [-0.3632],\n",
      "        [-0.3648],\n",
      "        [-0.3648],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [-0.3648],\n",
      "        [-0.3648],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [-0.1917],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [-0.3648],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [-0.3648],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [-0.1917],\n",
      "        [-0.1917],\n",
      "        [-0.1917],\n",
      "        [ 0.0773]], dtype=torch.float64)\n",
      "Finished episode 295 Average rewards:  13.8\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2684221   1.321612    0.7013108   1.9310603  -0.04127396  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.7489346  0.53133625]\n",
      "tensor([[-0.3506],\n",
      "        [ 0.0597],\n",
      "        [ 0.0597],\n",
      "        [ 0.0597],\n",
      "        [ 0.0597],\n",
      "        [-0.2329],\n",
      "        [ 0.4910],\n",
      "        [-0.4111],\n",
      "        [-0.4111],\n",
      "        [-0.4111],\n",
      "        [ 0.4910],\n",
      "        [-0.4111],\n",
      "        [-0.4111],\n",
      "        [-0.4111],\n",
      "        [ 0.4001],\n",
      "        [ 0.4001],\n",
      "        [ 0.4001],\n",
      "        [ 0.4001],\n",
      "        [ 0.0597],\n",
      "        [ 0.0597],\n",
      "        [-0.3506],\n",
      "        [-0.4111],\n",
      "        [-0.4111],\n",
      "        [-0.4111],\n",
      "        [ 0.4001],\n",
      "        [ 0.4001],\n",
      "        [ 0.4001],\n",
      "        [-0.3506],\n",
      "        [ 0.0597],\n",
      "        [ 0.0597],\n",
      "        [ 0.4910],\n",
      "        [-0.4111],\n",
      "        [-0.4111],\n",
      "        [-0.4111],\n",
      "        [-0.4111],\n",
      "        [ 0.4001],\n",
      "        [ 0.4001],\n",
      "        [-0.4111],\n",
      "        [ 0.4001],\n",
      "        [ 0.4001],\n",
      "        [ 0.4910],\n",
      "        [-0.4111],\n",
      "        [-0.4111],\n",
      "        [-0.4111],\n",
      "        [-0.4111],\n",
      "        [-0.4111],\n",
      "        [-0.4111],\n",
      "        [-0.4111],\n",
      "        [ 0.4001],\n",
      "        [ 0.4001]], dtype=torch.float64)\n",
      "Finished episode 300 Average rewards:  61.2\n",
      "Monitored episode 50 Average Monitored rewards:  33.16\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2611938   1.3082114   0.7119953   1.9328974  -0.05217939  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.7655236  0.54230976]\n",
      "tensor([[ 0.5299],\n",
      "        [-0.4675],\n",
      "        [-0.4675],\n",
      "        [-0.4675],\n",
      "        [-0.4675],\n",
      "        [-0.4675],\n",
      "        [ 0.4179],\n",
      "        [ 0.4179],\n",
      "        [ 0.4179],\n",
      "        [ 0.4179],\n",
      "        [-0.3210],\n",
      "        [-0.4675],\n",
      "        [ 0.0346],\n",
      "        [ 0.0346],\n",
      "        [ 0.0346],\n",
      "        [ 0.0346],\n",
      "        [-0.2793],\n",
      "        [ 0.0346],\n",
      "        [ 0.0346],\n",
      "        [ 0.0346],\n",
      "        [ 0.5299],\n",
      "        [-0.4675],\n",
      "        [-0.3210],\n",
      "        [ 0.0346],\n",
      "        [ 0.0346],\n",
      "        [ 0.0346],\n",
      "        [ 0.0346],\n",
      "        [ 0.0346],\n",
      "        [ 0.0346],\n",
      "        [ 0.0346],\n",
      "        [ 0.5299],\n",
      "        [-0.4675],\n",
      "        [-0.4675],\n",
      "        [ 0.4179],\n",
      "        [-0.3210],\n",
      "        [-0.4675],\n",
      "        [-0.4675],\n",
      "        [-0.4675],\n",
      "        [-0.4675],\n",
      "        [-0.4675],\n",
      "        [-0.3210],\n",
      "        [-0.4675],\n",
      "        [-0.3210],\n",
      "        [ 0.0346],\n",
      "        [ 0.0346],\n",
      "        [ 0.0346],\n",
      "        [ 0.0346],\n",
      "        [ 0.0346],\n",
      "        [ 0.0346],\n",
      "        [ 0.0346]], dtype=torch.float64)\n",
      "Finished episode 305 Average rewards:  38.8\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2552586   1.2982955   0.7200728   1.9343253  -0.05766801  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.7776529  0.55058867]\n",
      "tensor([[-0.2939],\n",
      "        [-0.5224],\n",
      "        [-0.5224],\n",
      "        [-0.5224],\n",
      "        [-0.5224],\n",
      "        [-0.5224],\n",
      "        [-0.5224],\n",
      "        [-0.5224],\n",
      "        [ 0.4246],\n",
      "        [ 0.4246],\n",
      "        [-0.2939],\n",
      "        [-0.5224],\n",
      "        [ 0.0109],\n",
      "        [ 0.0109],\n",
      "        [ 0.0109],\n",
      "        [ 0.0109],\n",
      "        [ 0.0109],\n",
      "        [ 0.0109],\n",
      "        [ 0.0109],\n",
      "        [ 0.0109],\n",
      "        [-0.2939],\n",
      "        [-0.2939],\n",
      "        [ 0.0109],\n",
      "        [ 0.0109],\n",
      "        [ 0.0109],\n",
      "        [ 0.0109],\n",
      "        [ 0.0109],\n",
      "        [ 0.0109],\n",
      "        [ 0.0109],\n",
      "        [ 0.0109],\n",
      "        [ 0.5705],\n",
      "        [-0.5224],\n",
      "        [-0.5224],\n",
      "        [-0.5224],\n",
      "        [-0.5224],\n",
      "        [ 0.4246],\n",
      "        [ 0.4246],\n",
      "        [ 0.4246],\n",
      "        [ 0.4246],\n",
      "        [-0.5224],\n",
      "        [-0.2939],\n",
      "        [-0.2939],\n",
      "        [-0.2939],\n",
      "        [-0.5224],\n",
      "        [-0.2939],\n",
      "        [ 0.0109],\n",
      "        [-0.3227],\n",
      "        [-0.5224],\n",
      "        [-0.2939],\n",
      "        [-0.5224]], dtype=torch.float64)\n",
      "Finished episode 310 Average rewards:  37.8\n",
      "Monitored episode 50 Average Monitored rewards:  58.3\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2541887   1.2944304   0.73160326  1.9362593  -0.03405752  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.78150576 0.5623532 ]\n",
      "tensor([[-0.2752],\n",
      "        [-0.0012],\n",
      "        [-0.0012],\n",
      "        [-0.0012],\n",
      "        [-0.3474],\n",
      "        [-0.3474],\n",
      "        [-0.5654],\n",
      "        [-0.0012],\n",
      "        [-0.0012],\n",
      "        [-0.0012],\n",
      "        [-0.2752],\n",
      "        [-0.0012],\n",
      "        [-0.0012],\n",
      "        [-0.0012],\n",
      "        [-0.0012],\n",
      "        [-0.0012],\n",
      "        [-0.3474],\n",
      "        [-0.3474],\n",
      "        [-0.3474],\n",
      "        [-0.3474],\n",
      "        [ 0.5960],\n",
      "        [-0.5654],\n",
      "        [-0.5654],\n",
      "        [-0.5654],\n",
      "        [-0.5654],\n",
      "        [-0.5654],\n",
      "        [ 0.4228],\n",
      "        [ 0.4228],\n",
      "        [ 0.4228],\n",
      "        [ 0.4228],\n",
      "        [ 0.5960],\n",
      "        [-0.0012],\n",
      "        [-0.5654],\n",
      "        [-0.5654],\n",
      "        [-0.5654],\n",
      "        [-0.5654],\n",
      "        [ 0.4228],\n",
      "        [ 0.4228],\n",
      "        [ 0.4228],\n",
      "        [ 0.4228],\n",
      "        [ 0.5960],\n",
      "        [ 0.5960],\n",
      "        [-0.5654],\n",
      "        [-0.5654],\n",
      "        [ 0.4228],\n",
      "        [ 0.4228],\n",
      "        [-0.2752],\n",
      "        [-0.5654],\n",
      "        [-0.5654],\n",
      "        [-0.5654]], dtype=torch.float64)\n",
      "Finished episode 315 Average rewards:  59.8\n",
      "len_game 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[ 1.2512294   1.2880272   0.7405245   1.937631   -0.04850473  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.7885369 0.5714025]\n",
      "tensor([[ 0.6037],\n",
      "        [-0.6262],\n",
      "        [-0.6262],\n",
      "        [-0.6262],\n",
      "        [-0.6262],\n",
      "        [-0.6262],\n",
      "        [ 0.4167],\n",
      "        [ 0.4167],\n",
      "        [ 0.4167],\n",
      "        [ 0.4167],\n",
      "        [ 0.6037],\n",
      "        [-0.6262],\n",
      "        [-0.6262],\n",
      "        [-0.6262],\n",
      "        [-0.6262],\n",
      "        [-0.6262],\n",
      "        [-0.6262],\n",
      "        [-0.6262],\n",
      "        [-0.6262],\n",
      "        [ 0.4167],\n",
      "        [-0.3070],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [ 0.6037],\n",
      "        [-0.6262],\n",
      "        [ 0.4167],\n",
      "        [-0.3070],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [-0.3070],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [-0.3078],\n",
      "        [-0.3078],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583]], dtype=torch.float64)\n",
      "Finished episode 320 Average rewards:  37.8\n",
      "Monitored episode 50 Average Monitored rewards:  32.5\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2400603   1.2712216   0.74782085  1.9396392  -0.05671327  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8087544  0.57897425]\n",
      "tensor([[ 0.6397],\n",
      "        [-0.6541],\n",
      "        [-0.6541],\n",
      "        [-0.6541],\n",
      "        [-0.6541],\n",
      "        [ 0.4182],\n",
      "        [ 0.4182],\n",
      "        [ 0.4182],\n",
      "        [ 0.4182],\n",
      "        [ 0.4182],\n",
      "        [-0.2805],\n",
      "        [ 0.0234],\n",
      "        [ 0.0234],\n",
      "        [ 0.0234],\n",
      "        [-0.3533],\n",
      "        [-0.3533],\n",
      "        [-0.3533],\n",
      "        [ 0.6397],\n",
      "        [-0.6541],\n",
      "        [-0.6541],\n",
      "        [ 0.6397],\n",
      "        [-0.6541],\n",
      "        [ 0.4182],\n",
      "        [-0.2805],\n",
      "        [ 0.0234],\n",
      "        [ 0.0234],\n",
      "        [ 0.0234],\n",
      "        [ 0.0234],\n",
      "        [ 0.0234],\n",
      "        [ 0.0234],\n",
      "        [ 0.6397],\n",
      "        [-0.6541],\n",
      "        [-0.6541],\n",
      "        [-0.6541],\n",
      "        [ 0.4182],\n",
      "        [ 0.4182],\n",
      "        [-0.2805],\n",
      "        [-0.6541],\n",
      "        [-0.2805],\n",
      "        [ 0.0234],\n",
      "        [ 0.6397],\n",
      "        [-0.6541],\n",
      "        [-0.2805],\n",
      "        [-0.6541],\n",
      "        [ 0.4182],\n",
      "        [ 0.4182],\n",
      "        [-0.6541],\n",
      "        [-0.6541],\n",
      "        [-0.6541],\n",
      "        [-0.6541]], dtype=torch.float64)\n",
      "Finished episode 325 Average rewards:  60.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2344044   1.2613659   0.7592249   1.9416251  -0.06333637  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.819447  0.5905534]\n",
      "tensor([[ 0.6534],\n",
      "        [ 0.6534],\n",
      "        [-0.6955],\n",
      "        [-0.2476],\n",
      "        [-0.6955],\n",
      "        [-0.6955],\n",
      "        [ 0.4047],\n",
      "        [ 0.4047],\n",
      "        [ 0.4047],\n",
      "        [ 0.4047],\n",
      "        [-0.2476],\n",
      "        [-0.2476],\n",
      "        [-0.2476],\n",
      "        [ 0.0039],\n",
      "        [ 0.0039],\n",
      "        [ 0.0039],\n",
      "        [-0.3824],\n",
      "        [ 0.0039],\n",
      "        [ 0.0039],\n",
      "        [ 0.0039],\n",
      "        [-0.2476],\n",
      "        [ 0.0039],\n",
      "        [ 0.0039],\n",
      "        [ 0.0039],\n",
      "        [ 0.0039],\n",
      "        [ 0.0039],\n",
      "        [ 0.0039],\n",
      "        [ 0.0039],\n",
      "        [ 0.0039],\n",
      "        [-0.3824],\n",
      "        [ 0.6534],\n",
      "        [ 0.6534],\n",
      "        [-0.6955],\n",
      "        [ 0.4047],\n",
      "        [ 0.4047],\n",
      "        [-0.2476],\n",
      "        [-0.2476],\n",
      "        [-0.2476],\n",
      "        [ 0.0039],\n",
      "        [ 0.0039],\n",
      "        [-0.2476],\n",
      "        [-0.6955],\n",
      "        [ 0.0039],\n",
      "        [ 0.0039],\n",
      "        [ 0.0039],\n",
      "        [ 0.0039],\n",
      "        [-0.3824],\n",
      "        [ 0.0039],\n",
      "        [ 0.0039],\n",
      "        [ 0.0039]], dtype=torch.float64)\n",
      "Finished episode 330 Average rewards:  15.2\n",
      "Monitored episode 50 Average Monitored rewards:  51.54\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2368847   1.2568599   0.77201855  1.9441739  -0.04061825  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8207465 0.6035711]\n",
      "tensor([[-0.2253],\n",
      "        [-0.0126],\n",
      "        [-0.0126],\n",
      "        [-0.0126],\n",
      "        [-0.0126],\n",
      "        [-0.4098],\n",
      "        [-0.4098],\n",
      "        [-0.0126],\n",
      "        [-0.4098],\n",
      "        [-0.0126],\n",
      "        [ 0.6785],\n",
      "        [-0.7346],\n",
      "        [-0.7346],\n",
      "        [-0.7346],\n",
      "        [ 0.3926],\n",
      "        [-0.2253],\n",
      "        [-0.0126],\n",
      "        [-0.0126],\n",
      "        [-0.4098],\n",
      "        [-0.4098],\n",
      "        [-0.2253],\n",
      "        [-0.7346],\n",
      "        [ 0.3926],\n",
      "        [-0.2253],\n",
      "        [-0.7346],\n",
      "        [ 0.3926],\n",
      "        [-0.2253],\n",
      "        [-0.7346],\n",
      "        [-0.2253],\n",
      "        [-0.7346],\n",
      "        [ 0.6785],\n",
      "        [-0.7346],\n",
      "        [-0.7346],\n",
      "        [-0.7346],\n",
      "        [-0.7346],\n",
      "        [-0.7346],\n",
      "        [-0.7346],\n",
      "        [-0.7346],\n",
      "        [-0.7346],\n",
      "        [ 0.3926],\n",
      "        [-0.2253],\n",
      "        [-0.0126],\n",
      "        [-0.0126],\n",
      "        [-0.0126],\n",
      "        [-0.0126],\n",
      "        [-0.0126],\n",
      "        [-0.0126],\n",
      "        [-0.4098],\n",
      "        [-0.0126],\n",
      "        [-0.4098]], dtype=torch.float64)\n",
      "Finished episode 335 Average rewards:  40.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2302397  1.2426237  0.7752144  1.9460669 -0.0626162  1.8641111\n",
      "  1.7464267  0.7518858]\n",
      "Enc\n",
      "[0.83480984 0.6070054 ]\n",
      "tensor([[ 0.6786],\n",
      "        [ 0.6786],\n",
      "        [ 0.6786],\n",
      "        [ 0.6786],\n",
      "        [-0.7739],\n",
      "        [-0.7739],\n",
      "        [ 0.4049],\n",
      "        [ 0.4049],\n",
      "        [ 0.4049],\n",
      "        [-0.2671],\n",
      "        [ 0.6786],\n",
      "        [-0.7739],\n",
      "        [-0.7739],\n",
      "        [-0.7739],\n",
      "        [ 0.4049],\n",
      "        [ 0.4049],\n",
      "        [ 0.4049],\n",
      "        [-0.2671],\n",
      "        [-0.2671],\n",
      "        [-0.2671],\n",
      "        [ 0.6786],\n",
      "        [-0.7739],\n",
      "        [-0.7739],\n",
      "        [ 0.4049],\n",
      "        [-0.7739],\n",
      "        [-0.7739],\n",
      "        [-0.2671],\n",
      "        [-0.7739],\n",
      "        [ 0.0467],\n",
      "        [ 0.0467],\n",
      "        [ 0.6786],\n",
      "        [ 0.6786],\n",
      "        [ 0.0467],\n",
      "        [ 0.0467],\n",
      "        [ 0.0467],\n",
      "        [ 0.0467],\n",
      "        [ 0.0467],\n",
      "        [ 0.0467],\n",
      "        [ 0.0467],\n",
      "        [ 0.0467],\n",
      "        [ 0.6786],\n",
      "        [ 0.6786],\n",
      "        [-0.7739],\n",
      "        [-0.2671],\n",
      "        [ 0.0467],\n",
      "        [ 0.0467],\n",
      "        [ 0.0467],\n",
      "        [ 0.0467],\n",
      "        [ 0.0467],\n",
      "        [ 0.0467]], dtype=torch.float64)\n",
      "Finished episode 340 Average rewards:  16.2\n",
      "Monitored episode 50 Average Monitored rewards:  44.72\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.238773    1.241546    0.7869587   1.9483021  -0.04500367  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8292949  0.61890304]\n",
      "tensor([[ 0.7045],\n",
      "        [-0.7907],\n",
      "        [-0.7907],\n",
      "        [-0.7907],\n",
      "        [-0.7907],\n",
      "        [ 0.3808],\n",
      "        [-0.7907],\n",
      "        [-0.7907],\n",
      "        [ 0.3808],\n",
      "        [ 0.3808],\n",
      "        [-0.2146],\n",
      "        [-0.0080],\n",
      "        [-0.0080],\n",
      "        [-0.0080],\n",
      "        [-0.0080],\n",
      "        [-0.4327],\n",
      "        [-0.0080],\n",
      "        [-0.4327],\n",
      "        [-0.4327],\n",
      "        [-0.4327],\n",
      "        [-0.2146],\n",
      "        [-0.0080],\n",
      "        [-0.0080],\n",
      "        [-0.0080],\n",
      "        [-0.0080],\n",
      "        [-0.0080],\n",
      "        [-0.4327],\n",
      "        [-0.0080],\n",
      "        [-0.0080],\n",
      "        [-0.0080],\n",
      "        [-0.2146],\n",
      "        [-0.2146],\n",
      "        [-0.7907],\n",
      "        [-0.7907],\n",
      "        [-0.7907],\n",
      "        [-0.7907],\n",
      "        [-0.7907],\n",
      "        [ 0.3808],\n",
      "        [-0.7907],\n",
      "        [-0.7907],\n",
      "        [ 0.7045],\n",
      "        [-0.7907],\n",
      "        [-0.0080],\n",
      "        [-0.0080],\n",
      "        [-0.0080],\n",
      "        [-0.0080],\n",
      "        [-0.4327],\n",
      "        [-0.4327],\n",
      "        [-0.4327],\n",
      "        [-0.7907]], dtype=torch.float64)\n",
      "Finished episode 345 Average rewards:  61.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2344276   1.2378118   0.79277915  1.9491408  -0.04160785  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8348423 0.6247542]\n",
      "tensor([[ 0.7139],\n",
      "        [ 0.0406],\n",
      "        [ 0.0406],\n",
      "        [ 0.0406],\n",
      "        [ 0.0406],\n",
      "        [ 0.0406],\n",
      "        [ 0.0406],\n",
      "        [-0.4085],\n",
      "        [-0.4085],\n",
      "        [-0.4085],\n",
      "        [ 0.7139],\n",
      "        [-0.8189],\n",
      "        [-0.8189],\n",
      "        [-0.8189],\n",
      "        [-0.8189],\n",
      "        [-0.8189],\n",
      "        [-0.8189],\n",
      "        [-0.8189],\n",
      "        [ 0.4042],\n",
      "        [-0.8189],\n",
      "        [-0.2587],\n",
      "        [ 0.0406],\n",
      "        [ 0.0406],\n",
      "        [ 0.0406],\n",
      "        [ 0.0406],\n",
      "        [ 0.0406],\n",
      "        [ 0.0406],\n",
      "        [-0.4085],\n",
      "        [-0.4085],\n",
      "        [ 0.0406],\n",
      "        [-0.2587],\n",
      "        [ 0.0406],\n",
      "        [ 0.0406],\n",
      "        [ 0.0406],\n",
      "        [ 0.0406],\n",
      "        [ 0.0406],\n",
      "        [ 0.0406],\n",
      "        [ 0.0406],\n",
      "        [ 0.0406],\n",
      "        [ 0.0406],\n",
      "        [-0.2587],\n",
      "        [-0.8189],\n",
      "        [-0.8189],\n",
      "        [-0.8189],\n",
      "        [ 0.4042],\n",
      "        [ 0.4042],\n",
      "        [ 0.4042],\n",
      "        [ 0.4042],\n",
      "        [ 0.4042],\n",
      "        [ 0.4042]], dtype=torch.float64)\n",
      "Finished episode 350 Average rewards:  38.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  40.28\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2302399   1.2296907   0.7886505   1.9499102  -0.05152392  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8429179 0.6207714]\n",
      "tensor([[-0.2584],\n",
      "        [-0.8275],\n",
      "        [-0.8275],\n",
      "        [-0.8275],\n",
      "        [ 0.3999],\n",
      "        [ 0.3999],\n",
      "        [-0.2584],\n",
      "        [-0.8275],\n",
      "        [ 0.3999],\n",
      "        [-0.2584],\n",
      "        [-0.2584],\n",
      "        [ 0.0488],\n",
      "        [ 0.0488],\n",
      "        [ 0.0488],\n",
      "        [ 0.0488],\n",
      "        [ 0.0488],\n",
      "        [ 0.0488],\n",
      "        [ 0.0488],\n",
      "        [ 0.0488],\n",
      "        [ 0.0488],\n",
      "        [-0.2584],\n",
      "        [-0.8275],\n",
      "        [-0.8275],\n",
      "        [-0.8275],\n",
      "        [-0.8275],\n",
      "        [-0.8275],\n",
      "        [-0.8275],\n",
      "        [ 0.3999],\n",
      "        [ 0.3999],\n",
      "        [ 0.3999],\n",
      "        [ 0.7083],\n",
      "        [-0.8275],\n",
      "        [-0.8275],\n",
      "        [-0.8275],\n",
      "        [ 0.3999],\n",
      "        [ 0.3999],\n",
      "        [ 0.3999],\n",
      "        [-0.8275],\n",
      "        [-0.8275],\n",
      "        [ 0.3999],\n",
      "        [ 0.7083],\n",
      "        [ 0.0488],\n",
      "        [ 0.0488],\n",
      "        [ 0.0488],\n",
      "        [ 0.0488],\n",
      "        [ 0.0488],\n",
      "        [ 0.0488],\n",
      "        [-0.4027],\n",
      "        [-0.4027],\n",
      "        [ 0.0488]], dtype=torch.float64)\n",
      "Finished episode 355 Average rewards:  37.8\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2233298   1.2177914   0.7876771   1.9512953  -0.06826705  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.85504615 0.6199799 ]\n",
      "tensor([[ 0.7117],\n",
      "        [ 0.7117],\n",
      "        [-0.8264],\n",
      "        [-0.8264],\n",
      "        [ 0.3850],\n",
      "        [ 0.3850],\n",
      "        [ 0.3850],\n",
      "        [-0.2322],\n",
      "        [-0.8264],\n",
      "        [-0.8264],\n",
      "        [-0.2322],\n",
      "        [-0.8264],\n",
      "        [-0.8264],\n",
      "        [-0.8264],\n",
      "        [-0.8264],\n",
      "        [ 0.3850],\n",
      "        [-0.8264],\n",
      "        [-0.8264],\n",
      "        [-0.8264],\n",
      "        [-0.8264],\n",
      "        [-0.2322],\n",
      "        [-0.8264],\n",
      "        [-0.8264],\n",
      "        [ 0.3850],\n",
      "        [ 0.3850],\n",
      "        [ 0.3850],\n",
      "        [-0.2322],\n",
      "        [ 0.0239],\n",
      "        [ 0.0239],\n",
      "        [ 0.0239],\n",
      "        [-0.2322],\n",
      "        [-0.8264],\n",
      "        [-0.8264],\n",
      "        [-0.8264],\n",
      "        [ 0.3850],\n",
      "        [ 0.3850],\n",
      "        [ 0.3850],\n",
      "        [-0.2322],\n",
      "        [-0.8264],\n",
      "        [-0.8264],\n",
      "        [ 0.7117],\n",
      "        [-0.8264],\n",
      "        [ 0.0239],\n",
      "        [ 0.0239],\n",
      "        [ 0.0239],\n",
      "        [ 0.0239],\n",
      "        [ 0.0239],\n",
      "        [ 0.0239],\n",
      "        [ 0.0239],\n",
      "        [-0.4272]], dtype=torch.float64)\n",
      "Finished episode 360 Average rewards:  60.6\n",
      "Monitored episode 50 Average Monitored rewards:  78.14\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2414925   1.2127373   0.80558807  1.9556385  -0.03590824  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.84367096 0.6382029 ]\n",
      "tensor([[-0.1857],\n",
      "        [-0.0193],\n",
      "        [-0.0193],\n",
      "        [-0.0193],\n",
      "        [-0.4699],\n",
      "        [-0.4699],\n",
      "        [-0.4699],\n",
      "        [-0.0193],\n",
      "        [-0.0193],\n",
      "        [-0.0193],\n",
      "        [-0.1857],\n",
      "        [-0.8322],\n",
      "        [-0.8322],\n",
      "        [-0.8322],\n",
      "        [-0.8322],\n",
      "        [-0.0193],\n",
      "        [-0.0193],\n",
      "        [-0.0193],\n",
      "        [-0.4699],\n",
      "        [-0.0193],\n",
      "        [ 0.7249],\n",
      "        [-0.8322],\n",
      "        [-0.0193],\n",
      "        [-0.0193],\n",
      "        [-0.0193],\n",
      "        [-0.0193],\n",
      "        [-0.0193],\n",
      "        [-0.4699],\n",
      "        [-0.4699],\n",
      "        [-0.4699],\n",
      "        [-0.1857],\n",
      "        [-0.0193],\n",
      "        [-0.4699],\n",
      "        [-0.4699],\n",
      "        [-0.8322],\n",
      "        [-0.0193],\n",
      "        [ 0.7249],\n",
      "        [-0.8322],\n",
      "        [-0.8322],\n",
      "        [-0.8322],\n",
      "        [ 0.7249],\n",
      "        [ 0.7249],\n",
      "        [-0.0193],\n",
      "        [-0.0193],\n",
      "        [-0.4699],\n",
      "        [-0.8322],\n",
      "        [-0.8322],\n",
      "        [-0.8322],\n",
      "        [-0.8322],\n",
      "        [-0.8322]], dtype=torch.float64)\n",
      "Finished episode 365 Average rewards:  39.4\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2349056   1.2031703   0.8109018   1.9573643  -0.05322267  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.85446054 0.6436329 ]\n",
      "tensor([[-0.2741],\n",
      "        [-0.8699],\n",
      "        [-0.8699],\n",
      "        [-0.8699],\n",
      "        [-0.8699],\n",
      "        [ 0.4103],\n",
      "        [ 0.4103],\n",
      "        [ 0.4103],\n",
      "        [ 0.4103],\n",
      "        [ 0.4103],\n",
      "        [-0.2741],\n",
      "        [-0.2741],\n",
      "        [-0.2741],\n",
      "        [-0.8699],\n",
      "        [ 0.0731],\n",
      "        [ 0.0731],\n",
      "        [ 0.0731],\n",
      "        [ 0.0731],\n",
      "        [ 0.0731],\n",
      "        [ 0.0731],\n",
      "        [ 0.7321],\n",
      "        [-0.8699],\n",
      "        [-0.8699],\n",
      "        [ 0.4103],\n",
      "        [-0.2741],\n",
      "        [ 0.0731],\n",
      "        [ 0.0731],\n",
      "        [ 0.0731],\n",
      "        [ 0.0731],\n",
      "        [ 0.0731],\n",
      "        [-0.2741],\n",
      "        [-0.8699],\n",
      "        [ 0.4103],\n",
      "        [-0.2741],\n",
      "        [ 0.0731],\n",
      "        [ 0.0731],\n",
      "        [ 0.0731],\n",
      "        [ 0.0731],\n",
      "        [-0.4213],\n",
      "        [-0.4213],\n",
      "        [ 0.7321],\n",
      "        [-0.8699],\n",
      "        [-0.8699],\n",
      "        [-0.8699],\n",
      "        [-0.8699],\n",
      "        [-0.8699],\n",
      "        [-0.8699],\n",
      "        [-0.8699],\n",
      "        [ 0.4103],\n",
      "        [ 0.4103]], dtype=torch.float64)\n",
      "Finished episode 370 Average rewards:  59.2\n",
      "Monitored episode 50 Average Monitored rewards:  44.08\n",
      "len_game 52\n",
      "Rot\n",
      "[ 1.2293289   1.1915591   0.8074776   1.9588795  -0.07871585  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.86523056 0.64037603]\n",
      "tensor([[ 0.7511],\n",
      "        [ 0.0285],\n",
      "        [ 0.0285],\n",
      "        [ 0.0285],\n",
      "        [ 0.0285],\n",
      "        [ 0.0285],\n",
      "        [ 0.0285],\n",
      "        [ 0.0285],\n",
      "        [ 0.0285],\n",
      "        [ 0.0285],\n",
      "        [ 0.7511],\n",
      "        [-0.8788],\n",
      "        [-0.2295],\n",
      "        [-0.8788],\n",
      "        [-0.8788],\n",
      "        [-0.8788],\n",
      "        [ 0.3834],\n",
      "        [ 0.3834],\n",
      "        [-0.8788],\n",
      "        [ 0.3834],\n",
      "        [-0.2295],\n",
      "        [-0.2295],\n",
      "        [-0.2295],\n",
      "        [ 0.0285],\n",
      "        [-0.4691],\n",
      "        [-0.8788],\n",
      "        [-0.8788],\n",
      "        [ 0.3834],\n",
      "        [ 0.3834],\n",
      "        [ 0.3834],\n",
      "        [-0.8788],\n",
      "        [-0.8788],\n",
      "        [ 0.7511],\n",
      "        [-0.8788],\n",
      "        [ 0.0285],\n",
      "        [ 0.0285],\n",
      "        [ 0.0285],\n",
      "        [ 0.0285],\n",
      "        [ 0.0285],\n",
      "        [ 0.0285],\n",
      "        [ 0.0285],\n",
      "        [-0.4691],\n",
      "        [ 0.7511],\n",
      "        [-0.8788],\n",
      "        [-0.2295],\n",
      "        [ 0.0285],\n",
      "        [ 0.0285],\n",
      "        [ 0.0285],\n",
      "        [ 0.0285],\n",
      "        [ 0.0285],\n",
      "        [ 0.0285],\n",
      "        [ 0.0285]], dtype=torch.float64)\n",
      "Finished episode 375 Average rewards:  15.2\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2371032   1.1883476   0.815616    1.9609227  -0.06431594  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8604182 0.6486286]\n",
      "tensor([[ 0.7788],\n",
      "        [ 0.7788],\n",
      "        [-0.8856],\n",
      "        [-0.8856],\n",
      "        [ 0.3389],\n",
      "        [-0.1650],\n",
      "        [-0.0381],\n",
      "        [-0.5344],\n",
      "        [-0.5344],\n",
      "        [-0.8856],\n",
      "        [-0.1650],\n",
      "        [-0.1650],\n",
      "        [-0.0381],\n",
      "        [-0.5344],\n",
      "        [-0.0381],\n",
      "        [-0.0381],\n",
      "        [-0.0381],\n",
      "        [-0.5344],\n",
      "        [-0.5344],\n",
      "        [-0.0381],\n",
      "        [-0.0381],\n",
      "        [-0.1650],\n",
      "        [-0.1650],\n",
      "        [-0.0381],\n",
      "        [-0.8856],\n",
      "        [-0.8856],\n",
      "        [ 0.3389],\n",
      "        [-0.8856],\n",
      "        [-0.8856],\n",
      "        [ 0.3389],\n",
      "        [-0.8856],\n",
      "        [-0.1650],\n",
      "        [-0.8856],\n",
      "        [-0.8856],\n",
      "        [-0.8856],\n",
      "        [-0.8856],\n",
      "        [-0.8856],\n",
      "        [-0.8856],\n",
      "        [-0.8856],\n",
      "        [-0.8856],\n",
      "        [-0.8856],\n",
      "        [ 0.7788],\n",
      "        [-0.8856],\n",
      "        [-0.8856],\n",
      "        [-0.8856],\n",
      "        [-0.8856],\n",
      "        [-0.8856],\n",
      "        [-0.8856],\n",
      "        [ 0.3389],\n",
      "        [ 0.3389],\n",
      "        [ 0.3389]], dtype=torch.float64)\n",
      "Finished episode 380 Average rewards:  62.4\n",
      "Monitored episode 50 Average Monitored rewards:  31.14\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2309543   1.1792716   0.81723136  1.9623476  -0.08011826  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.87018967 0.6503459 ]\n",
      "tensor([[-0.2064],\n",
      "        [-0.2064],\n",
      "        [-0.8980],\n",
      "        [ 0.0034],\n",
      "        [ 0.0034],\n",
      "        [-0.5119],\n",
      "        [-0.8980],\n",
      "        [-0.2064],\n",
      "        [-0.8980],\n",
      "        [-0.8980],\n",
      "        [-0.2064],\n",
      "        [-0.2064],\n",
      "        [-0.2064],\n",
      "        [ 0.0034],\n",
      "        [ 0.0034],\n",
      "        [ 0.0034],\n",
      "        [ 0.0034],\n",
      "        [ 0.0034],\n",
      "        [ 0.0034],\n",
      "        [-0.5119],\n",
      "        [ 0.0034],\n",
      "        [-0.2064],\n",
      "        [ 0.0034],\n",
      "        [ 0.0034],\n",
      "        [ 0.0034],\n",
      "        [ 0.0034],\n",
      "        [ 0.0034],\n",
      "        [-0.5119],\n",
      "        [-0.5119],\n",
      "        [-0.5119],\n",
      "        [-0.5119],\n",
      "        [-0.2064],\n",
      "        [ 0.0034],\n",
      "        [-0.5119],\n",
      "        [-0.5119],\n",
      "        [-0.8980],\n",
      "        [-0.8980],\n",
      "        [-0.8980],\n",
      "        [-0.8980],\n",
      "        [-0.8980],\n",
      "        [-0.8980],\n",
      "        [-0.2064],\n",
      "        [-0.2064],\n",
      "        [ 0.0034],\n",
      "        [ 0.0034],\n",
      "        [ 0.0034],\n",
      "        [ 0.0034],\n",
      "        [ 0.0034],\n",
      "        [ 0.0034],\n",
      "        [ 0.0034],\n",
      "        [ 0.0034]], dtype=torch.float64)\n",
      "Finished episode 385 Average rewards:  58.6\n",
      "len_game 51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[ 1.2589784  1.1793056  0.8329542  1.965666  -0.0543646  1.8641111\n",
      "  1.7464267  0.7518858]\n",
      "Enc\n",
      "[0.84647775 0.6662123 ]\n",
      "tensor([[ 0.7935],\n",
      "        [-0.0383],\n",
      "        [-0.0383],\n",
      "        [ 0.7935],\n",
      "        [ 0.7935],\n",
      "        [-0.0383],\n",
      "        [-0.0383],\n",
      "        [-0.0383],\n",
      "        [-0.0383],\n",
      "        [-0.0383],\n",
      "        [ 0.7935],\n",
      "        [-0.0383],\n",
      "        [-0.0383],\n",
      "        [-0.9033],\n",
      "        [-0.9033],\n",
      "        [ 0.3335],\n",
      "        [ 0.3335],\n",
      "        [ 0.3335],\n",
      "        [-0.1608],\n",
      "        [-0.0383],\n",
      "        [ 0.7935],\n",
      "        [ 0.7935],\n",
      "        [-0.9033],\n",
      "        [-0.1608],\n",
      "        [-0.0383],\n",
      "        [-0.0383],\n",
      "        [-0.5535],\n",
      "        [-0.5535],\n",
      "        [-0.0383],\n",
      "        [-0.0383],\n",
      "        [-0.0383],\n",
      "        [-0.1608],\n",
      "        [-0.9033],\n",
      "        [-0.0383],\n",
      "        [-0.0383],\n",
      "        [-0.0383],\n",
      "        [-0.5535],\n",
      "        [-0.0383],\n",
      "        [-0.5535],\n",
      "        [-0.5535],\n",
      "        [-0.5535],\n",
      "        [-0.1608],\n",
      "        [-0.9033],\n",
      "        [ 0.3335],\n",
      "        [-0.9033],\n",
      "        [ 0.3335],\n",
      "        [ 0.3335],\n",
      "        [-0.9033],\n",
      "        [-0.9033],\n",
      "        [ 0.3335],\n",
      "        [ 0.3335]], dtype=torch.float64)\n",
      "Finished episode 390 Average rewards:  37.0\n",
      "Monitored episode 50 Average Monitored rewards:  28.6\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2528361   1.1722999   0.83302814  1.9667826  -0.07106413  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8556292  0.66635543]\n",
      "tensor([[ 0.8118],\n",
      "        [-0.9262],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.8118],\n",
      "        [-0.9262],\n",
      "        [-0.2564],\n",
      "        [-0.9262],\n",
      "        [-0.9262],\n",
      "        [-0.9262],\n",
      "        [ 0.4161],\n",
      "        [ 0.4161],\n",
      "        [ 0.4161],\n",
      "        [-0.9262],\n",
      "        [-0.2564],\n",
      "        [-0.9262],\n",
      "        [-0.9262],\n",
      "        [-0.9262],\n",
      "        [-0.9262],\n",
      "        [-0.9262],\n",
      "        [-0.9262],\n",
      "        [-0.9262],\n",
      "        [-0.9262],\n",
      "        [ 0.4161],\n",
      "        [-0.2564],\n",
      "        [-0.2564],\n",
      "        [-0.2564],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [-0.5122],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [-0.5122],\n",
      "        [-0.2564],\n",
      "        [-0.9262],\n",
      "        [-0.2564],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383]], dtype=torch.float64)\n",
      "Finished episode 395 Average rewards:  37.4\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.261101    1.1687361   0.8365872   1.9686296  -0.06179778  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.85041505 0.67000645]\n",
      "tensor([[-0.2120],\n",
      "        [-0.0059],\n",
      "        [-0.5559],\n",
      "        [-0.9287],\n",
      "        [-0.9287],\n",
      "        [-0.9287],\n",
      "        [ 0.3871],\n",
      "        [ 0.3871],\n",
      "        [-0.2120],\n",
      "        [-0.0059],\n",
      "        [-0.2120],\n",
      "        [-0.9287],\n",
      "        [-0.9287],\n",
      "        [-0.9287],\n",
      "        [-0.9287],\n",
      "        [-0.9287],\n",
      "        [ 0.3871],\n",
      "        [-0.2120],\n",
      "        [-0.9287],\n",
      "        [-0.2120],\n",
      "        [ 0.8258],\n",
      "        [-0.0059],\n",
      "        [-0.0059],\n",
      "        [-0.0059],\n",
      "        [-0.0059],\n",
      "        [-0.5559],\n",
      "        [-0.0059],\n",
      "        [-0.5559],\n",
      "        [-0.0059],\n",
      "        [-0.0059],\n",
      "        [-0.2120],\n",
      "        [-0.9287],\n",
      "        [-0.2120],\n",
      "        [-0.9287],\n",
      "        [-0.9287],\n",
      "        [ 0.3871],\n",
      "        [ 0.3871],\n",
      "        [-0.9287],\n",
      "        [-0.9287],\n",
      "        [-0.9287],\n",
      "        [-0.2120],\n",
      "        [-0.0059],\n",
      "        [-0.0059],\n",
      "        [-0.5559],\n",
      "        [-0.5559],\n",
      "        [-0.5559],\n",
      "        [-0.0059],\n",
      "        [-0.0059],\n",
      "        [-0.0059],\n",
      "        [-0.5559]], dtype=torch.float64)\n",
      "Finished episode 400 Average rewards:  17.2\n",
      "Monitored episode 50 Average Monitored rewards:  20.76\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2532189   1.1622053   0.83879375  1.9696454  -0.07569456  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8607563 0.6722587]\n",
      "tensor([[ 0.8283],\n",
      "        [-0.9351],\n",
      "        [-0.9351],\n",
      "        [-0.9351],\n",
      "        [-0.9351],\n",
      "        [-0.9351],\n",
      "        [-0.9351],\n",
      "        [ 0.4098],\n",
      "        [ 0.4098],\n",
      "        [ 0.4098],\n",
      "        [ 0.8283],\n",
      "        [-0.9351],\n",
      "        [ 0.0226],\n",
      "        [ 0.0226],\n",
      "        [ 0.0226],\n",
      "        [ 0.0226],\n",
      "        [ 0.0226],\n",
      "        [ 0.0226],\n",
      "        [ 0.0226],\n",
      "        [ 0.0226],\n",
      "        [ 0.8283],\n",
      "        [-0.9351],\n",
      "        [-0.9351],\n",
      "        [-0.9351],\n",
      "        [-0.9351],\n",
      "        [-0.9351],\n",
      "        [ 0.4098],\n",
      "        [ 0.4098],\n",
      "        [ 0.4098],\n",
      "        [ 0.4098],\n",
      "        [-0.2425],\n",
      "        [-0.9351],\n",
      "        [-0.2425],\n",
      "        [ 0.0226],\n",
      "        [ 0.0226],\n",
      "        [ 0.0226],\n",
      "        [ 0.0226],\n",
      "        [ 0.0226],\n",
      "        [ 0.0226],\n",
      "        [ 0.0226],\n",
      "        [ 0.8283],\n",
      "        [-0.9351],\n",
      "        [-0.9351],\n",
      "        [-0.9351],\n",
      "        [ 0.4098],\n",
      "        [ 0.4098],\n",
      "        [ 0.4098],\n",
      "        [ 0.0226],\n",
      "        [ 0.0226],\n",
      "        [ 0.0226]], dtype=torch.float64)\n",
      "Finished episode 405 Average rewards:  38.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2738439   1.1582786   0.85131913  1.9732175  -0.03873689  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8447065  0.68491596]\n",
      "tensor([[ 0.8353],\n",
      "        [-0.9359],\n",
      "        [-0.0145],\n",
      "        [ 0.8353],\n",
      "        [-0.9359],\n",
      "        [-0.9359],\n",
      "        [-0.9359],\n",
      "        [-0.2005],\n",
      "        [-0.0145],\n",
      "        [ 0.8353],\n",
      "        [ 0.8353],\n",
      "        [-0.9359],\n",
      "        [-0.2005],\n",
      "        [-0.0145],\n",
      "        [-0.0145],\n",
      "        [-0.5773],\n",
      "        [ 0.8353],\n",
      "        [-0.9359],\n",
      "        [-0.9359],\n",
      "        [-0.9359],\n",
      "        [-0.2005],\n",
      "        [-0.0145],\n",
      "        [-0.9359],\n",
      "        [-0.0145],\n",
      "        [-0.9359],\n",
      "        [-0.2005],\n",
      "        [-0.2005],\n",
      "        [-0.2005],\n",
      "        [-0.0145],\n",
      "        [-0.0145],\n",
      "        [-0.2005],\n",
      "        [-0.9359],\n",
      "        [-0.2005],\n",
      "        [-0.9359],\n",
      "        [-0.0145],\n",
      "        [-0.5773],\n",
      "        [ 0.8353],\n",
      "        [-0.9359],\n",
      "        [-0.2005],\n",
      "        [-0.0145],\n",
      "        [-0.2005],\n",
      "        [-0.2005],\n",
      "        [-0.9359],\n",
      "        [-0.0145],\n",
      "        [ 0.8353],\n",
      "        [ 0.8353],\n",
      "        [-0.9359],\n",
      "        [-0.9359],\n",
      "        [ 0.3777],\n",
      "        [-0.9359]], dtype=torch.float64)\n",
      "Finished episode 410 Average rewards:  59.8\n",
      "Monitored episode 50 Average Monitored rewards:  23.3\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2648708   1.1515499   0.8493688   1.974226   -0.05912935  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8563235 0.6830152]\n",
      "tensor([[-0.3041],\n",
      "        [-0.9412],\n",
      "        [-0.9412],\n",
      "        [ 0.4442],\n",
      "        [ 0.4442],\n",
      "        [ 0.4442],\n",
      "        [-0.3041],\n",
      "        [-0.9412],\n",
      "        [-0.3041],\n",
      "        [-0.3041],\n",
      "        [-0.3041],\n",
      "        [ 0.0930],\n",
      "        [ 0.0930],\n",
      "        [ 0.0930],\n",
      "        [ 0.0930],\n",
      "        [ 0.0930],\n",
      "        [ 0.0930],\n",
      "        [ 0.0930],\n",
      "        [ 0.0930],\n",
      "        [ 0.0930],\n",
      "        [ 0.8152],\n",
      "        [-0.9412],\n",
      "        [-0.9412],\n",
      "        [ 0.4442],\n",
      "        [-0.3041],\n",
      "        [-0.3041],\n",
      "        [ 0.0930],\n",
      "        [ 0.0930],\n",
      "        [ 0.0930],\n",
      "        [ 0.0930],\n",
      "        [-0.3041],\n",
      "        [ 0.0930],\n",
      "        [ 0.0930],\n",
      "        [ 0.0930],\n",
      "        [ 0.0930],\n",
      "        [ 0.0930],\n",
      "        [ 0.0930],\n",
      "        [ 0.0930],\n",
      "        [ 0.0930],\n",
      "        [ 0.0930],\n",
      "        [-0.3041],\n",
      "        [ 0.0930],\n",
      "        [ 0.0930],\n",
      "        [-0.4989],\n",
      "        [ 0.8152],\n",
      "        [ 0.8152],\n",
      "        [-0.9412],\n",
      "        [-0.9412],\n",
      "        [ 0.4442],\n",
      "        [ 0.0930]], dtype=torch.float64)\n",
      "Finished episode 415 Average rewards:  -6.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2638583  1.1485298  0.8534949  1.9748904 -0.0766697  1.8641111\n",
      "  1.7464267  0.7518858]\n",
      "Enc\n",
      "[0.8587432  0.68715537]\n",
      "tensor([[-0.2504],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [-0.2504],\n",
      "        [-0.9434],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [-0.2504],\n",
      "        [-0.2504],\n",
      "        [-0.2504],\n",
      "        [-0.2504],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [-0.2504],\n",
      "        [ 0.0383],\n",
      "        [-0.5533],\n",
      "        [-0.5533],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [-0.2504],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383]], dtype=torch.float64)\n",
      "Finished episode 420 Average rewards:  -7.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  49.38\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2709079   1.1450131   0.8563902   1.9765888  -0.06088636  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8541735 0.690108 ]\n",
      "tensor([[-0.2117],\n",
      "        [-0.9433],\n",
      "        [-0.0093],\n",
      "        [-0.0093],\n",
      "        [ 0.8524],\n",
      "        [-0.9433],\n",
      "        [-0.9433],\n",
      "        [-0.9433],\n",
      "        [-0.9433],\n",
      "        [-0.9433],\n",
      "        [-0.2117],\n",
      "        [-0.2117],\n",
      "        [-0.9433],\n",
      "        [-0.9433],\n",
      "        [ 0.3917],\n",
      "        [ 0.3917],\n",
      "        [-0.2117],\n",
      "        [-0.0093],\n",
      "        [-0.9433],\n",
      "        [-0.0093],\n",
      "        [-0.2117],\n",
      "        [-0.9433],\n",
      "        [-0.9433],\n",
      "        [-0.9433],\n",
      "        [-0.9433],\n",
      "        [-0.9433],\n",
      "        [ 0.3917],\n",
      "        [ 0.3917],\n",
      "        [ 0.3917],\n",
      "        [ 0.3917],\n",
      "        [ 0.8524],\n",
      "        [-0.9433],\n",
      "        [-0.2117],\n",
      "        [-0.2117],\n",
      "        [-0.0093],\n",
      "        [-0.5964],\n",
      "        [-0.9433],\n",
      "        [-0.9433],\n",
      "        [-0.9433],\n",
      "        [-0.9433],\n",
      "        [-0.2117],\n",
      "        [-0.0093],\n",
      "        [-0.0093],\n",
      "        [-0.0093],\n",
      "        [-0.0093],\n",
      "        [-0.0093],\n",
      "        [-0.0093],\n",
      "        [-0.0093],\n",
      "        [-0.0093],\n",
      "        [-0.0093]], dtype=torch.float64)\n",
      "Finished episode 425 Average rewards:  61.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2638836   1.1415159   0.85865396  1.9771103  -0.06340011  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8622367  0.69238424]\n",
      "tensor([[ 0.8415],\n",
      "        [-0.9452],\n",
      "        [-0.9452],\n",
      "        [-0.9452],\n",
      "        [ 0.4191],\n",
      "        [ 0.4191],\n",
      "        [ 0.4191],\n",
      "        [ 0.4191],\n",
      "        [ 0.4191],\n",
      "        [-0.2543],\n",
      "        [-0.2543],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [-0.2543],\n",
      "        [-0.9452],\n",
      "        [-0.2543],\n",
      "        [-0.9452],\n",
      "        [-0.2543],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [-0.5642],\n",
      "        [-0.2543],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.8415],\n",
      "        [-0.9452],\n",
      "        [-0.9452],\n",
      "        [-0.9452],\n",
      "        [-0.9452],\n",
      "        [-0.9452],\n",
      "        [-0.9452],\n",
      "        [-0.9452],\n",
      "        [-0.9452],\n",
      "        [-0.9452]], dtype=torch.float64)\n",
      "Finished episode 430 Average rewards:  18.4\n",
      "Monitored episode 50 Average Monitored rewards:  29.58\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2562201   1.1359134   0.85478413  1.9777858  -0.08082307  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.87178475 0.6885475 ]\n",
      "tensor([[-0.2385],\n",
      "        [-0.9418],\n",
      "        [-0.9418],\n",
      "        [-0.9418],\n",
      "        [-0.9418],\n",
      "        [-0.9418],\n",
      "        [-0.9418],\n",
      "        [-0.9418],\n",
      "        [-0.9418],\n",
      "        [-0.9418],\n",
      "        [-0.2385],\n",
      "        [ 0.0307],\n",
      "        [ 0.0307],\n",
      "        [ 0.0307],\n",
      "        [ 0.0307],\n",
      "        [ 0.0307],\n",
      "        [ 0.0307],\n",
      "        [ 0.0307],\n",
      "        [ 0.0307],\n",
      "        [ 0.0307],\n",
      "        [ 0.8327],\n",
      "        [-0.9418],\n",
      "        [-0.9418],\n",
      "        [ 0.4023],\n",
      "        [ 0.4023],\n",
      "        [-0.2385],\n",
      "        [ 0.0307],\n",
      "        [ 0.0307],\n",
      "        [ 0.0307],\n",
      "        [ 0.0307],\n",
      "        [ 0.8327],\n",
      "        [-0.9418],\n",
      "        [-0.2385],\n",
      "        [ 0.0307],\n",
      "        [ 0.0307],\n",
      "        [ 0.0307],\n",
      "        [ 0.0307],\n",
      "        [ 0.0307],\n",
      "        [ 0.0307],\n",
      "        [ 0.0307],\n",
      "        [ 0.8327],\n",
      "        [ 0.8327],\n",
      "        [-0.9418],\n",
      "        [-0.9418],\n",
      "        [-0.9418],\n",
      "        [-0.9418],\n",
      "        [-0.9418],\n",
      "        [ 0.4023],\n",
      "        [ 0.4023],\n",
      "        [ 0.4023]], dtype=torch.float64)\n",
      "Finished episode 435 Average rewards:  37.4\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2664068   1.1330385   0.8656669   1.9797473  -0.05108261  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.86375064 0.69947094]\n",
      "tensor([[ 0.8484],\n",
      "        [-0.9463],\n",
      "        [-0.9463],\n",
      "        [ 0.3632],\n",
      "        [ 0.3632],\n",
      "        [ 0.3632],\n",
      "        [ 0.3632],\n",
      "        [-0.1883],\n",
      "        [-0.0167],\n",
      "        [-0.6148],\n",
      "        [-0.1883],\n",
      "        [-0.0167],\n",
      "        [-0.6148],\n",
      "        [-0.9463],\n",
      "        [-0.9463],\n",
      "        [-0.0167],\n",
      "        [-0.0167],\n",
      "        [-0.0167],\n",
      "        [-0.0167],\n",
      "        [-0.0167],\n",
      "        [ 0.8484],\n",
      "        [-0.9463],\n",
      "        [-0.9463],\n",
      "        [-0.9463],\n",
      "        [-0.9463],\n",
      "        [ 0.3632],\n",
      "        [ 0.3632],\n",
      "        [-0.1883],\n",
      "        [-0.0167],\n",
      "        [-0.0167],\n",
      "        [ 0.8484],\n",
      "        [-0.9463],\n",
      "        [-0.9463],\n",
      "        [ 0.3632],\n",
      "        [-0.1883],\n",
      "        [-0.9463],\n",
      "        [-0.9463],\n",
      "        [-0.9463],\n",
      "        [-0.9463],\n",
      "        [-0.9463],\n",
      "        [-0.1883],\n",
      "        [-0.0167],\n",
      "        [-0.6148],\n",
      "        [-0.6148],\n",
      "        [-0.6148],\n",
      "        [ 0.8484],\n",
      "        [-0.9463],\n",
      "        [-0.9463],\n",
      "        [-0.9463],\n",
      "        [ 0.3632]], dtype=torch.float64)\n",
      "Finished episode 440 Average rewards:  39.2\n",
      "Monitored episode 50 Average Monitored rewards:  42.22\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2608796   1.1289519   0.8621833   1.9802557  -0.06923238  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8706412 0.6960088]\n",
      "tensor([[ 0.8145],\n",
      "        [-0.9369],\n",
      "        [-0.2667],\n",
      "        [-0.9369],\n",
      "        [-0.9369],\n",
      "        [ 0.4166],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [-0.5450],\n",
      "        [ 0.8145],\n",
      "        [ 0.0687],\n",
      "        [ 0.8145],\n",
      "        [ 0.8145],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [-0.2667],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [-0.5450],\n",
      "        [-0.5450],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [ 0.8145],\n",
      "        [-0.9369],\n",
      "        [-0.9369],\n",
      "        [-0.9369],\n",
      "        [-0.9369],\n",
      "        [ 0.4166],\n",
      "        [ 0.4166],\n",
      "        [ 0.4166],\n",
      "        [ 0.4166],\n",
      "        [ 0.4166],\n",
      "        [ 0.8145],\n",
      "        [-0.9369],\n",
      "        [-0.9369],\n",
      "        [-0.9369],\n",
      "        [ 0.4166],\n",
      "        [ 0.4166],\n",
      "        [ 0.4166],\n",
      "        [ 0.4166],\n",
      "        [ 0.4166],\n",
      "        [-0.9369]], dtype=torch.float64)\n",
      "Finished episode 445 Average rewards:  58.6\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2481394   1.1218745   0.8549795   1.9809917  -0.08374858  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.885337   0.68884003]\n",
      "tensor([[-0.2195],\n",
      "        [-0.9434],\n",
      "        [-0.9434],\n",
      "        [-0.9434],\n",
      "        [-0.9434],\n",
      "        [ 0.3843],\n",
      "        [ 0.3843],\n",
      "        [-0.2195],\n",
      "        [-0.2195],\n",
      "        [ 0.0189],\n",
      "        [-0.2195],\n",
      "        [-0.9434],\n",
      "        [ 0.0189],\n",
      "        [ 0.0189],\n",
      "        [ 0.0189],\n",
      "        [ 0.0189],\n",
      "        [ 0.0189],\n",
      "        [ 0.0189],\n",
      "        [-0.5926],\n",
      "        [-0.5926],\n",
      "        [ 0.8361],\n",
      "        [-0.9434],\n",
      "        [-0.9434],\n",
      "        [-0.9434],\n",
      "        [-0.9434],\n",
      "        [-0.9434],\n",
      "        [-0.9434],\n",
      "        [ 0.3843],\n",
      "        [ 0.3843],\n",
      "        [ 0.3843],\n",
      "        [-0.2195],\n",
      "        [ 0.0189],\n",
      "        [ 0.0189],\n",
      "        [ 0.0189],\n",
      "        [ 0.0189],\n",
      "        [-0.5926],\n",
      "        [-0.5926],\n",
      "        [-0.5926],\n",
      "        [ 0.8361],\n",
      "        [-0.9434],\n",
      "        [-0.2195],\n",
      "        [-0.9434],\n",
      "        [ 0.3843],\n",
      "        [-0.2195],\n",
      "        [-0.2195],\n",
      "        [-0.9434],\n",
      "        [-0.9434],\n",
      "        [ 0.0189],\n",
      "        [ 0.0189],\n",
      "        [ 0.0189]], dtype=torch.float64)\n",
      "Finished episode 450 Average rewards:  39.2\n",
      "Monitored episode 50 Average Monitored rewards:  51.72\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2562071   1.1194834   0.85992867  1.982153   -0.07067538  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8787364  0.69381434]\n",
      "tensor([[-0.1659],\n",
      "        [-0.9466],\n",
      "        [-0.9466],\n",
      "        [-0.9466],\n",
      "        [ 0.3314],\n",
      "        [ 0.3314],\n",
      "        [ 0.3314],\n",
      "        [ 0.3314],\n",
      "        [ 0.3314],\n",
      "        [ 0.3314],\n",
      "        [ 0.8430],\n",
      "        [-0.9466],\n",
      "        [-0.9466],\n",
      "        [-0.9466],\n",
      "        [ 0.3314],\n",
      "        [ 0.3314],\n",
      "        [ 0.3314],\n",
      "        [-0.9466],\n",
      "        [-0.9466],\n",
      "        [-0.9466],\n",
      "        [-0.1659],\n",
      "        [-0.9466],\n",
      "        [-0.9466],\n",
      "        [ 0.3314],\n",
      "        [-0.1659],\n",
      "        [-0.1659],\n",
      "        [-0.0208],\n",
      "        [-0.0208],\n",
      "        [-0.0208],\n",
      "        [-0.6312],\n",
      "        [ 0.8430],\n",
      "        [-0.1659],\n",
      "        [-0.9466],\n",
      "        [ 0.3314],\n",
      "        [-0.0208],\n",
      "        [ 0.8430],\n",
      "        [-0.9466],\n",
      "        [-0.1659],\n",
      "        [-0.9466],\n",
      "        [-0.9466],\n",
      "        [-0.9466],\n",
      "        [-0.1659],\n",
      "        [-0.9466],\n",
      "        [-0.9466],\n",
      "        [ 0.3314],\n",
      "        [ 0.3314],\n",
      "        [ 0.3314],\n",
      "        [-0.1659],\n",
      "        [-0.1659],\n",
      "        [-0.0208],\n",
      "        [ 0.8430]], dtype=torch.float64)\n",
      "Finished episode 455 Average rewards:  102.4\n",
      "len_game 51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[ 1.2439512   1.1129936   0.85447323  1.9828385  -0.08463355  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.89261276 0.68838555]\n",
      "tensor([[-0.2076],\n",
      "        [ 0.0174],\n",
      "        [ 0.0174],\n",
      "        [ 0.0174],\n",
      "        [-0.6032],\n",
      "        [-0.6032],\n",
      "        [-0.6032],\n",
      "        [ 0.8343],\n",
      "        [-0.9457],\n",
      "        [-0.9457],\n",
      "        [-0.2076],\n",
      "        [ 0.0174],\n",
      "        [-0.6032],\n",
      "        [-0.6032],\n",
      "        [-0.9457],\n",
      "        [ 0.3681],\n",
      "        [-0.2076],\n",
      "        [ 0.0174],\n",
      "        [ 0.0174],\n",
      "        [ 0.0174],\n",
      "        [-0.2076],\n",
      "        [ 0.0174],\n",
      "        [ 0.0174],\n",
      "        [ 0.0174],\n",
      "        [ 0.0174],\n",
      "        [ 0.0174],\n",
      "        [ 0.0174],\n",
      "        [ 0.0174],\n",
      "        [-0.6032],\n",
      "        [-0.6032],\n",
      "        [ 0.8343],\n",
      "        [-0.9457],\n",
      "        [-0.9457],\n",
      "        [-0.9457],\n",
      "        [ 0.3681],\n",
      "        [ 0.3681],\n",
      "        [ 0.3681],\n",
      "        [ 0.3681],\n",
      "        [-0.2076],\n",
      "        [-0.2076],\n",
      "        [-0.2076],\n",
      "        [-0.2076],\n",
      "        [ 0.0174],\n",
      "        [ 0.0174],\n",
      "        [-0.6032],\n",
      "        [ 0.8343],\n",
      "        [-0.9457],\n",
      "        [-0.9457],\n",
      "        [ 0.0174],\n",
      "        [ 0.0174],\n",
      "        [ 0.0174]], dtype=torch.float64)\n",
      "Finished episode 460 Average rewards:  36.6\n",
      "Monitored episode 50 Average Monitored rewards:  65.3\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2519002   1.1091185   0.8505414   1.9839089  -0.08191159  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.886456  0.6844878]\n",
      "tensor([[ 0.8399],\n",
      "        [-0.0211],\n",
      "        [-0.9458],\n",
      "        [-0.0211],\n",
      "        [-0.0211],\n",
      "        [-0.0211],\n",
      "        [-0.0211],\n",
      "        [-0.0211],\n",
      "        [-0.6393],\n",
      "        [-0.0211],\n",
      "        [-0.1553],\n",
      "        [-0.9458],\n",
      "        [-0.9458],\n",
      "        [ 0.3142],\n",
      "        [ 0.3142],\n",
      "        [-0.1553],\n",
      "        [-0.9458],\n",
      "        [-0.9458],\n",
      "        [ 0.3142],\n",
      "        [ 0.3142],\n",
      "        [-0.1553],\n",
      "        [-0.1553],\n",
      "        [-0.1553],\n",
      "        [-0.9458],\n",
      "        [-0.9458],\n",
      "        [-0.9458],\n",
      "        [ 0.3142],\n",
      "        [ 0.3142],\n",
      "        [ 0.3142],\n",
      "        [ 0.3142],\n",
      "        [-0.0211],\n",
      "        [-0.1553],\n",
      "        [-0.9458],\n",
      "        [-0.9458],\n",
      "        [ 0.3142],\n",
      "        [ 0.3142],\n",
      "        [-0.9458],\n",
      "        [-0.1553],\n",
      "        [-0.0211],\n",
      "        [-0.6393],\n",
      "        [-0.0211],\n",
      "        [ 0.8399],\n",
      "        [-0.9458],\n",
      "        [-0.9458],\n",
      "        [ 0.3142],\n",
      "        [ 0.3142],\n",
      "        [-0.9458],\n",
      "        [-0.9458],\n",
      "        [-0.9458],\n",
      "        [-0.9458],\n",
      "        [-0.9458]], dtype=torch.float64)\n",
      "Finished episode 465 Average rewards:  19.0\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2588967   1.1047443   0.8501976   1.9851999  -0.07201099  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88135445 0.6841776 ]\n",
      "tensor([[-0.1737],\n",
      "        [-0.9567],\n",
      "        [-0.9567],\n",
      "        [-0.9567],\n",
      "        [ 0.3371],\n",
      "        [-0.1737],\n",
      "        [-0.0117],\n",
      "        [-0.0117],\n",
      "        [-0.6392],\n",
      "        [-0.0117],\n",
      "        [ 0.8516],\n",
      "        [-0.9567],\n",
      "        [-0.9567],\n",
      "        [-0.1737],\n",
      "        [-0.9567],\n",
      "        [-0.9567],\n",
      "        [-0.1737],\n",
      "        [-0.1737],\n",
      "        [-0.9567],\n",
      "        [-0.1737],\n",
      "        [-0.1737],\n",
      "        [-0.1737],\n",
      "        [-0.9567],\n",
      "        [-0.1737],\n",
      "        [-0.9567],\n",
      "        [-0.0117],\n",
      "        [ 0.8516],\n",
      "        [-0.9567],\n",
      "        [-0.9567],\n",
      "        [-0.1737],\n",
      "        [-0.9567],\n",
      "        [ 0.8516],\n",
      "        [-0.9567],\n",
      "        [-0.9567],\n",
      "        [ 0.3371],\n",
      "        [ 0.3371],\n",
      "        [ 0.3371],\n",
      "        [-0.1737],\n",
      "        [-0.9567],\n",
      "        [-0.0117],\n",
      "        [-0.6392],\n",
      "        [-0.1737],\n",
      "        [-0.0117],\n",
      "        [-0.9567],\n",
      "        [-0.9567],\n",
      "        [-0.9567],\n",
      "        [ 0.3371],\n",
      "        [ 0.3371],\n",
      "        [-0.9567],\n",
      "        [-0.9567],\n",
      "        [-0.9567]], dtype=torch.float64)\n",
      "Finished episode 470 Average rewards:  60.0\n",
      "Monitored episode 50 Average Monitored rewards:  45.06\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2548709   1.1027457   0.8567279   1.9855819  -0.07529086  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8858473 0.6907098]\n",
      "tensor([[ 0.8492],\n",
      "        [-0.9608],\n",
      "        [-0.2064],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [-0.6210],\n",
      "        [-0.6210],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [-0.2064],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [-0.6210],\n",
      "        [-0.6210],\n",
      "        [-0.6210],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [-0.2064],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [-0.6210],\n",
      "        [-0.2064],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [-0.6210],\n",
      "        [-0.6210],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [-0.2064],\n",
      "        [-0.2064],\n",
      "        [-0.2064],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181]], dtype=torch.float64)\n",
      "Finished episode 475 Average rewards:  -8.0\n",
      "len_game 52\n",
      "Rot\n",
      "[ 1.2424272   1.0961438   0.842558    1.986074   -0.10215198  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8998076  0.67656523]\n",
      "tensor([[-0.1924],\n",
      "        [-0.9542],\n",
      "        [ 0.3513],\n",
      "        [-0.1924],\n",
      "        [-0.1924],\n",
      "        [ 0.0091],\n",
      "        [-0.6270],\n",
      "        [-0.9542],\n",
      "        [-0.1924],\n",
      "        [-0.9542],\n",
      "        [ 0.8443],\n",
      "        [-0.9542],\n",
      "        [-0.1924],\n",
      "        [-0.9542],\n",
      "        [-0.1924],\n",
      "        [ 0.0091],\n",
      "        [ 0.0091],\n",
      "        [ 0.0091],\n",
      "        [ 0.0091],\n",
      "        [ 0.0091],\n",
      "        [-0.1924],\n",
      "        [-0.9542],\n",
      "        [-0.9542],\n",
      "        [ 0.3513],\n",
      "        [ 0.3513],\n",
      "        [ 0.3513],\n",
      "        [ 0.3513],\n",
      "        [-0.1924],\n",
      "        [-0.9542],\n",
      "        [-0.9542],\n",
      "        [-0.1924],\n",
      "        [ 0.0091],\n",
      "        [ 0.0091],\n",
      "        [ 0.0091],\n",
      "        [-0.6270],\n",
      "        [-0.6270],\n",
      "        [ 0.0091],\n",
      "        [-0.6270],\n",
      "        [-0.9542],\n",
      "        [-0.9542],\n",
      "        [ 0.8443],\n",
      "        [-0.9542],\n",
      "        [-0.9542],\n",
      "        [-0.1924],\n",
      "        [-0.9542],\n",
      "        [-0.9542],\n",
      "        [ 0.3513],\n",
      "        [ 0.3513],\n",
      "        [ 0.3513],\n",
      "        [ 0.3513],\n",
      "        [-0.1924],\n",
      "        [-0.1924]], dtype=torch.float64)\n",
      "Finished episode 480 Average rewards:  60.2\n",
      "Monitored episode 50 Average Monitored rewards:  48.96\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2617934   1.0950587   0.8529748   1.9872265  -0.08294913  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8816259 0.6869992]\n",
      "tensor([[ 0.8712],\n",
      "        [-0.9635],\n",
      "        [-0.9635],\n",
      "        [ 0.2709],\n",
      "        [ 0.2709],\n",
      "        [-0.1078],\n",
      "        [-0.0659],\n",
      "        [-0.0659],\n",
      "        [-0.6933],\n",
      "        [ 0.8712],\n",
      "        [ 0.8712],\n",
      "        [ 0.8712],\n",
      "        [-0.0659],\n",
      "        [-0.0659],\n",
      "        [-0.0659],\n",
      "        [-0.6933],\n",
      "        [-0.0659],\n",
      "        [-0.0659],\n",
      "        [-0.0659],\n",
      "        [-0.0659],\n",
      "        [-0.1078],\n",
      "        [-0.9635],\n",
      "        [-0.9635],\n",
      "        [ 0.2709],\n",
      "        [-0.1078],\n",
      "        [-0.9635],\n",
      "        [-0.9635],\n",
      "        [ 0.2709],\n",
      "        [ 0.2709],\n",
      "        [ 0.2709],\n",
      "        [-0.1078],\n",
      "        [-0.1078],\n",
      "        [-0.9635],\n",
      "        [-0.9635],\n",
      "        [-0.1078],\n",
      "        [-0.0659],\n",
      "        [-0.0659],\n",
      "        [-0.0659],\n",
      "        [-0.6933],\n",
      "        [-0.0659],\n",
      "        [-0.0659],\n",
      "        [-0.1078],\n",
      "        [-0.1078],\n",
      "        [-0.9635],\n",
      "        [-0.9635],\n",
      "        [-0.9635],\n",
      "        [ 0.2709],\n",
      "        [ 0.2709],\n",
      "        [ 0.2709],\n",
      "        [ 0.2709],\n",
      "        [-0.0659]], dtype=torch.float64)\n",
      "Finished episode 485 Average rewards:  -5.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2641941   1.0936468   0.86135006  1.9878846  -0.06437702  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8797788  0.69538087]\n",
      "tensor([[-0.1847],\n",
      "        [-0.0101],\n",
      "        [-0.0101],\n",
      "        [-0.0101],\n",
      "        [-0.0101],\n",
      "        [-0.0101],\n",
      "        [-0.0101],\n",
      "        [-0.6524],\n",
      "        [-0.6524],\n",
      "        [-0.0101],\n",
      "        [-0.1847],\n",
      "        [-0.9680],\n",
      "        [-0.9680],\n",
      "        [-0.9680],\n",
      "        [-0.9680],\n",
      "        [ 0.3543],\n",
      "        [-0.1847],\n",
      "        [-0.0101],\n",
      "        [-0.0101],\n",
      "        [-0.6524],\n",
      "        [-0.1847],\n",
      "        [-0.1847],\n",
      "        [-0.9680],\n",
      "        [-0.9680],\n",
      "        [-0.9680],\n",
      "        [-0.9680],\n",
      "        [-0.9680],\n",
      "        [-0.9680],\n",
      "        [ 0.3543],\n",
      "        [ 0.3543],\n",
      "        [ 0.8696],\n",
      "        [-0.9680],\n",
      "        [-0.9680],\n",
      "        [-0.9680],\n",
      "        [ 0.3543],\n",
      "        [ 0.3543],\n",
      "        [ 0.3543],\n",
      "        [ 0.3543],\n",
      "        [ 0.3543],\n",
      "        [ 0.3543],\n",
      "        [ 0.8696],\n",
      "        [ 0.8696],\n",
      "        [-0.9680],\n",
      "        [-0.9680],\n",
      "        [ 0.3543],\n",
      "        [ 0.3543],\n",
      "        [-0.1847],\n",
      "        [-0.9680],\n",
      "        [-0.9680],\n",
      "        [-0.0101]], dtype=torch.float64)\n",
      "Finished episode 490 Average rewards:  58.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  29.58\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2548686   1.0889924   0.85278565  1.988293   -0.09254964  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.89017946 0.6868299 ]\n",
      "tensor([[ 0.8408],\n",
      "        [-0.9564],\n",
      "        [ 0.0430],\n",
      "        [ 0.0430],\n",
      "        [ 0.0430],\n",
      "        [ 0.0430],\n",
      "        [ 0.0430],\n",
      "        [ 0.0430],\n",
      "        [ 0.0430],\n",
      "        [ 0.0430],\n",
      "        [-0.2299],\n",
      "        [ 0.0430],\n",
      "        [ 0.0430],\n",
      "        [ 0.0430],\n",
      "        [ 0.0430],\n",
      "        [-0.6067],\n",
      "        [ 0.0430],\n",
      "        [ 0.0430],\n",
      "        [ 0.0430],\n",
      "        [ 0.0430],\n",
      "        [ 0.8408],\n",
      "        [-0.9564],\n",
      "        [-0.9564],\n",
      "        [ 0.3845],\n",
      "        [ 0.3845],\n",
      "        [ 0.3845],\n",
      "        [ 0.3845],\n",
      "        [ 0.3845],\n",
      "        [-0.2299],\n",
      "        [ 0.0430],\n",
      "        [-0.2299],\n",
      "        [-0.9564],\n",
      "        [-0.9564],\n",
      "        [ 0.3845],\n",
      "        [ 0.3845],\n",
      "        [-0.2299],\n",
      "        [ 0.0430],\n",
      "        [ 0.0430],\n",
      "        [ 0.0430],\n",
      "        [ 0.0430],\n",
      "        [ 0.8408],\n",
      "        [-0.9564],\n",
      "        [ 0.3845],\n",
      "        [ 0.3845],\n",
      "        [-0.2299],\n",
      "        [-0.9564],\n",
      "        [-0.9564],\n",
      "        [ 0.3845],\n",
      "        [ 0.3845],\n",
      "        [-0.2299],\n",
      "        [-0.2299]], dtype=torch.float64)\n",
      "Finished episode 495 Average rewards:  -6.2\n",
      "len_game 52\n",
      "Rot\n",
      "[ 1.2546848   1.0848023   0.844887    1.9889798  -0.09335062  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8915482 0.6789492]\n",
      "tensor([[-0.1503],\n",
      "        [-0.0360],\n",
      "        [-0.6769],\n",
      "        [-0.9678],\n",
      "        [-0.9678],\n",
      "        [-0.9678],\n",
      "        [ 0.3190],\n",
      "        [-0.1503],\n",
      "        [-0.9678],\n",
      "        [-0.9678],\n",
      "        [-0.1503],\n",
      "        [-0.1503],\n",
      "        [-0.9678],\n",
      "        [-0.9678],\n",
      "        [-0.9678],\n",
      "        [-0.9678],\n",
      "        [ 0.3190],\n",
      "        [ 0.3190],\n",
      "        [-0.1503],\n",
      "        [-0.1503],\n",
      "        [-0.1503],\n",
      "        [-0.1503],\n",
      "        [-0.1503],\n",
      "        [-0.9678],\n",
      "        [-0.9678],\n",
      "        [-0.9678],\n",
      "        [-0.9678],\n",
      "        [-0.9678],\n",
      "        [-0.9678],\n",
      "        [ 0.3190],\n",
      "        [ 0.3190],\n",
      "        [-0.1503],\n",
      "        [-0.9678],\n",
      "        [-0.9678],\n",
      "        [-0.1503],\n",
      "        [-0.0360],\n",
      "        [ 0.8739],\n",
      "        [ 0.8739],\n",
      "        [ 0.8739],\n",
      "        [-0.9678],\n",
      "        [-0.9678],\n",
      "        [ 0.8739],\n",
      "        [-0.9678],\n",
      "        [-0.1503],\n",
      "        [-0.0360],\n",
      "        [-0.0360],\n",
      "        [-0.0360],\n",
      "        [-0.6769],\n",
      "        [-0.6769],\n",
      "        [-0.6769],\n",
      "        [-0.6769],\n",
      "        [ 0.8739]], dtype=torch.float64)\n",
      "Finished episode 500 Average rewards:  101.2\n",
      "Monitored episode 50 Average Monitored rewards:  62.54\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2731594   1.086211    0.8599513   1.9896141  -0.06522201  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8733434  0.69401604]\n",
      "tensor([[-0.1475],\n",
      "        [-0.1475],\n",
      "        [-0.0373],\n",
      "        [-0.0373],\n",
      "        [-0.0373],\n",
      "        [-0.0373],\n",
      "        [-0.0373],\n",
      "        [-0.6834],\n",
      "        [-0.0373],\n",
      "        [-0.0373],\n",
      "        [-0.1475],\n",
      "        [-0.9733],\n",
      "        [-0.9733],\n",
      "        [-0.9733],\n",
      "        [-0.9733],\n",
      "        [-0.9733],\n",
      "        [-0.9733],\n",
      "        [-0.9733],\n",
      "        [-0.9733],\n",
      "        [-0.9733],\n",
      "        [-0.1475],\n",
      "        [-0.0373],\n",
      "        [-0.0373],\n",
      "        [-0.6834],\n",
      "        [-0.6834],\n",
      "        [-0.0373],\n",
      "        [-0.0373],\n",
      "        [-0.6834],\n",
      "        [-0.0373],\n",
      "        [-0.0373],\n",
      "        [ 0.8789],\n",
      "        [-0.9733],\n",
      "        [-0.0373],\n",
      "        [-0.0373],\n",
      "        [-0.0373],\n",
      "        [-0.6834],\n",
      "        [-0.0373],\n",
      "        [-0.0373],\n",
      "        [-0.0373],\n",
      "        [-0.6834],\n",
      "        [-0.1475],\n",
      "        [-0.0373],\n",
      "        [-0.0373],\n",
      "        [-0.0373],\n",
      "        [-0.6834],\n",
      "        [-0.0373],\n",
      "        [-0.0373],\n",
      "        [-0.0373],\n",
      "        [-0.0373],\n",
      "        [-0.6834]], dtype=torch.float64)\n",
      "Finished episode 505 Average rewards:  16.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2657399   1.0843568   0.86276233  1.9898206  -0.06694563  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8810666 0.6968287]\n",
      "tensor([[ 0.8581],\n",
      "        [ 0.8581],\n",
      "        [-0.9669],\n",
      "        [-0.9669],\n",
      "        [-0.9669],\n",
      "        [-0.9669],\n",
      "        [-0.9669],\n",
      "        [-0.9669],\n",
      "        [ 0.4003],\n",
      "        [ 0.4003],\n",
      "        [-0.2405],\n",
      "        [-0.9669],\n",
      "        [ 0.0431],\n",
      "        [ 0.0431],\n",
      "        [ 0.0431],\n",
      "        [ 0.0431],\n",
      "        [ 0.0431],\n",
      "        [ 0.0431],\n",
      "        [ 0.0431],\n",
      "        [ 0.0431],\n",
      "        [ 0.8581],\n",
      "        [-0.9669],\n",
      "        [-0.9669],\n",
      "        [-0.9669],\n",
      "        [-0.9669],\n",
      "        [-0.9669],\n",
      "        [-0.9669],\n",
      "        [-0.9669],\n",
      "        [-0.9669],\n",
      "        [ 0.4003],\n",
      "        [-0.2405],\n",
      "        [ 0.0431],\n",
      "        [ 0.0431],\n",
      "        [ 0.0431],\n",
      "        [-0.6152],\n",
      "        [-0.6152],\n",
      "        [ 0.0431],\n",
      "        [ 0.0431],\n",
      "        [ 0.0431],\n",
      "        [ 0.0431],\n",
      "        [ 0.8581],\n",
      "        [-0.9669],\n",
      "        [-0.9669],\n",
      "        [-0.2405],\n",
      "        [-0.2405],\n",
      "        [-0.9669],\n",
      "        [-0.9669],\n",
      "        [ 0.4003],\n",
      "        [-0.9669],\n",
      "        [-0.9669]], dtype=torch.float64)\n",
      "Finished episode 510 Average rewards:  63.0\n",
      "Monitored episode 50 Average Monitored rewards:  49.34\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2605933   1.0819671   0.86271554  1.9900876  -0.08222338  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8867246 0.6967859]\n",
      "tensor([[-0.2255],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [-0.2255],\n",
      "        [-0.2255],\n",
      "        [-0.9594],\n",
      "        [-0.9594],\n",
      "        [ 0.3815],\n",
      "        [ 0.3815],\n",
      "        [-0.2255],\n",
      "        [-0.2255],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [-0.2255],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [-0.6181],\n",
      "        [-0.6181],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [-0.2255],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [-0.2255],\n",
      "        [-0.9594],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [ 0.0383],\n",
      "        [-0.6181],\n",
      "        [-0.6181]], dtype=torch.float64)\n",
      "Finished episode 515 Average rewards:  -6.6\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2771834  1.0812793  0.8770705  1.9910128 -0.0515312  1.8641111\n",
      "  1.7464267  0.7518858]\n",
      "Enc\n",
      "[0.8708686 0.7111471]\n",
      "tensor([[ 0.8622],\n",
      "        [-0.0046],\n",
      "        [-0.0046],\n",
      "        [-0.6546],\n",
      "        [-0.9618],\n",
      "        [-0.9618],\n",
      "        [-0.9618],\n",
      "        [ 0.3469],\n",
      "        [ 0.3469],\n",
      "        [ 0.3469],\n",
      "        [-0.1826],\n",
      "        [-0.0046],\n",
      "        [-0.9618],\n",
      "        [-0.9618],\n",
      "        [-0.9618],\n",
      "        [-0.9618],\n",
      "        [-0.9618],\n",
      "        [-0.9618],\n",
      "        [ 0.3469],\n",
      "        [ 0.3469],\n",
      "        [-0.1826],\n",
      "        [-0.0046],\n",
      "        [-0.6546],\n",
      "        [-0.6546],\n",
      "        [-0.9618],\n",
      "        [-0.9618],\n",
      "        [-0.9618],\n",
      "        [-0.9618],\n",
      "        [-0.9618],\n",
      "        [-0.9618],\n",
      "        [-0.1826],\n",
      "        [-0.0046],\n",
      "        [-0.6546],\n",
      "        [-0.0046],\n",
      "        [-0.0046],\n",
      "        [-0.0046],\n",
      "        [-0.0046],\n",
      "        [-0.6546],\n",
      "        [-0.0046],\n",
      "        [-0.0046],\n",
      "        [ 0.8622],\n",
      "        [-0.9618],\n",
      "        [-0.9618],\n",
      "        [-0.9618],\n",
      "        [-0.9618],\n",
      "        [ 0.3469],\n",
      "        [-0.9618],\n",
      "        [-0.1826],\n",
      "        [-0.0046],\n",
      "        [-0.0046],\n",
      "        [ 0.8622]], dtype=torch.float64)\n",
      "Finished episode 520 Average rewards:  82.6\n",
      "Monitored episode 50 Average Monitored rewards:  53.36\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2641879   1.0771109   0.866104    1.9913547  -0.07597493  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8846926  0.70018893]\n",
      "tensor([[-0.2752],\n",
      "        [-0.2752],\n",
      "        [-0.9440],\n",
      "        [-0.9440],\n",
      "        [-0.2752],\n",
      "        [-0.9440],\n",
      "        [-0.2752],\n",
      "        [ 0.0834],\n",
      "        [ 0.0834],\n",
      "        [ 0.0834],\n",
      "        [-0.2752],\n",
      "        [ 0.0834],\n",
      "        [-0.5744],\n",
      "        [-0.9440],\n",
      "        [-0.9440],\n",
      "        [-0.9440],\n",
      "        [ 0.4223],\n",
      "        [ 0.4223],\n",
      "        [ 0.4223],\n",
      "        [ 0.0834],\n",
      "        [-0.2752],\n",
      "        [-0.2752],\n",
      "        [-0.9440],\n",
      "        [-0.9440],\n",
      "        [-0.9440],\n",
      "        [-0.9440],\n",
      "        [ 0.4223],\n",
      "        [ 0.4223],\n",
      "        [ 0.4223],\n",
      "        [ 0.4223],\n",
      "        [ 0.8263],\n",
      "        [-0.9440],\n",
      "        [-0.9440],\n",
      "        [-0.9440],\n",
      "        [-0.9440],\n",
      "        [-0.9440],\n",
      "        [ 0.4223],\n",
      "        [ 0.4223],\n",
      "        [ 0.4223],\n",
      "        [ 0.4223],\n",
      "        [ 0.8263],\n",
      "        [-0.9440],\n",
      "        [-0.9440],\n",
      "        [-0.2752],\n",
      "        [-0.9440],\n",
      "        [ 0.0834],\n",
      "        [ 0.0834],\n",
      "        [ 0.0834],\n",
      "        [ 0.0834],\n",
      "        [ 0.0834]], dtype=torch.float64)\n",
      "Finished episode 525 Average rewards:  39.2\n",
      "len_game 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[ 1.2591491   1.0751961   0.8639071   1.991517   -0.08777327  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.89008665 0.6979948 ]\n",
      "tensor([[ 0.8562],\n",
      "        [ 0.8562],\n",
      "        [-0.9595],\n",
      "        [-0.9595],\n",
      "        [-0.9595],\n",
      "        [-0.9595],\n",
      "        [-0.9595],\n",
      "        [ 0.3629],\n",
      "        [ 0.3629],\n",
      "        [ 0.3629],\n",
      "        [-0.2019],\n",
      "        [-0.9595],\n",
      "        [-0.9595],\n",
      "        [-0.9595],\n",
      "        [-0.9595],\n",
      "        [-0.9595],\n",
      "        [-0.9595],\n",
      "        [-0.9595],\n",
      "        [-0.9595],\n",
      "        [-0.9595],\n",
      "        [ 0.8562],\n",
      "        [ 0.0147],\n",
      "        [ 0.0147],\n",
      "        [ 0.0147],\n",
      "        [ 0.0147],\n",
      "        [ 0.0147],\n",
      "        [ 0.0147],\n",
      "        [ 0.0147],\n",
      "        [-0.6418],\n",
      "        [-0.6418],\n",
      "        [-0.2019],\n",
      "        [ 0.0147],\n",
      "        [ 0.0147],\n",
      "        [ 0.0147],\n",
      "        [ 0.0147],\n",
      "        [ 0.0147],\n",
      "        [ 0.0147],\n",
      "        [ 0.0147],\n",
      "        [ 0.0147],\n",
      "        [ 0.0147],\n",
      "        [ 0.8562],\n",
      "        [-0.9595],\n",
      "        [-0.2019],\n",
      "        [ 0.0147],\n",
      "        [ 0.0147],\n",
      "        [ 0.0147],\n",
      "        [ 0.0147],\n",
      "        [ 0.0147],\n",
      "        [ 0.0147],\n",
      "        [ 0.0147]], dtype=torch.float64)\n",
      "Finished episode 530 Average rewards:  58.0\n",
      "Monitored episode 50 Average Monitored rewards:  46.38\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2679926   1.0742524   0.8705951   1.9920305  -0.07308324  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8817227 0.7046867]\n",
      "tensor([[ 0.8680],\n",
      "        [-0.0185],\n",
      "        [-0.0185],\n",
      "        [-0.6706],\n",
      "        [-0.6706],\n",
      "        [-0.0185],\n",
      "        [-0.0185],\n",
      "        [-0.6706],\n",
      "        [-0.6706],\n",
      "        [ 0.8680],\n",
      "        [ 0.8680],\n",
      "        [-0.9630],\n",
      "        [-0.9630],\n",
      "        [-0.9630],\n",
      "        [-0.9630],\n",
      "        [-0.9630],\n",
      "        [-0.9630],\n",
      "        [-0.9630],\n",
      "        [-0.9630],\n",
      "        [-0.9630],\n",
      "        [ 0.8680],\n",
      "        [-0.9630],\n",
      "        [-0.0185],\n",
      "        [-0.0185],\n",
      "        [ 0.8680],\n",
      "        [-0.9630],\n",
      "        [-0.1665],\n",
      "        [-0.9630],\n",
      "        [-0.9630],\n",
      "        [ 0.3319],\n",
      "        [ 0.8680],\n",
      "        [-0.9630],\n",
      "        [ 0.3319],\n",
      "        [ 0.3319],\n",
      "        [-0.1665],\n",
      "        [-0.1665],\n",
      "        [-0.9630],\n",
      "        [-0.1665],\n",
      "        [-0.0185],\n",
      "        [-0.6706],\n",
      "        [-0.1665],\n",
      "        [-0.9630],\n",
      "        [-0.9630],\n",
      "        [ 0.3319],\n",
      "        [ 0.3319],\n",
      "        [ 0.3319],\n",
      "        [ 0.3319],\n",
      "        [-0.1665],\n",
      "        [-0.1665],\n",
      "        [-0.9630]], dtype=torch.float64)\n",
      "Finished episode 535 Average rewards:  63.4\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2590537   1.0717974   0.87385356  1.9922777  -0.08343918  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.891055  0.7079467]\n",
      "tensor([[-0.2140],\n",
      "        [ 0.0238],\n",
      "        [ 0.0238],\n",
      "        [ 0.0238],\n",
      "        [ 0.0238],\n",
      "        [ 0.0238],\n",
      "        [ 0.0238],\n",
      "        [-0.6342],\n",
      "        [-0.6342],\n",
      "        [ 0.0238],\n",
      "        [ 0.8534],\n",
      "        [-0.9562],\n",
      "        [-0.2140],\n",
      "        [-0.9562],\n",
      "        [-0.9562],\n",
      "        [ 0.3751],\n",
      "        [ 0.3751],\n",
      "        [ 0.3751],\n",
      "        [ 0.3751],\n",
      "        [ 0.3751],\n",
      "        [-0.2140],\n",
      "        [-0.2140],\n",
      "        [-0.9562],\n",
      "        [-0.9562],\n",
      "        [ 0.3751],\n",
      "        [ 0.3751],\n",
      "        [ 0.3751],\n",
      "        [-0.2140],\n",
      "        [ 0.0238],\n",
      "        [ 0.0238],\n",
      "        [ 0.0238],\n",
      "        [-0.2140],\n",
      "        [ 0.0238],\n",
      "        [ 0.0238],\n",
      "        [ 0.0238],\n",
      "        [-0.6342],\n",
      "        [ 0.8534],\n",
      "        [-0.9562],\n",
      "        [-0.9562],\n",
      "        [-0.9562],\n",
      "        [ 0.3751],\n",
      "        [ 0.8534],\n",
      "        [-0.9562],\n",
      "        [-0.9562],\n",
      "        [-0.9562],\n",
      "        [ 0.3751],\n",
      "        [ 0.3751],\n",
      "        [ 0.3751],\n",
      "        [ 0.3751],\n",
      "        [ 0.3751],\n",
      "        [ 0.3751]], dtype=torch.float64)\n",
      "Finished episode 540 Average rewards:  39.0\n",
      "Monitored episode 50 Average Monitored rewards:  54.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2551314   1.0709444   0.8798435   1.9924502  -0.07399549  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.89508    0.71393657]\n",
      "tensor([[-0.1760],\n",
      "        [-0.1760],\n",
      "        [-0.0054],\n",
      "        [ 0.8523],\n",
      "        [ 0.8523],\n",
      "        [-0.9495],\n",
      "        [-0.9495],\n",
      "        [-0.9495],\n",
      "        [ 0.3370],\n",
      "        [-0.9495],\n",
      "        [ 0.8523],\n",
      "        [-0.9495],\n",
      "        [-0.9495],\n",
      "        [-0.9495],\n",
      "        [-0.9495],\n",
      "        [ 0.3370],\n",
      "        [ 0.3370],\n",
      "        [ 0.3370],\n",
      "        [ 0.3370],\n",
      "        [ 0.3370],\n",
      "        [ 0.8523],\n",
      "        [ 0.8523],\n",
      "        [-0.9495],\n",
      "        [-0.9495],\n",
      "        [-0.9495],\n",
      "        [ 0.3370],\n",
      "        [ 0.3370],\n",
      "        [ 0.3370],\n",
      "        [ 0.3370],\n",
      "        [-0.9495],\n",
      "        [-0.1760],\n",
      "        [-0.9495],\n",
      "        [-0.9495],\n",
      "        [-0.9495],\n",
      "        [-0.9495],\n",
      "        [-0.9495],\n",
      "        [ 0.3370],\n",
      "        [ 0.3370],\n",
      "        [ 0.3370],\n",
      "        [ 0.3370],\n",
      "        [ 0.8523],\n",
      "        [ 0.8523],\n",
      "        [-0.9495],\n",
      "        [-0.9495],\n",
      "        [-0.9495],\n",
      "        [-0.9495],\n",
      "        [ 0.3370],\n",
      "        [ 0.3370],\n",
      "        [ 0.3370],\n",
      "        [-0.1760]], dtype=torch.float64)\n",
      "Finished episode 545 Average rewards:  103.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2439922   1.0669309   0.8639373   1.9926891  -0.09986616  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.90685976 0.6980371 ]\n",
      "tensor([[-0.1917],\n",
      "        [ 0.0214],\n",
      "        [ 0.0214],\n",
      "        [ 0.0214],\n",
      "        [ 0.0214],\n",
      "        [ 0.0214],\n",
      "        [ 0.0214],\n",
      "        [ 0.0214],\n",
      "        [ 0.0214],\n",
      "        [ 0.0214],\n",
      "        [-0.1917],\n",
      "        [-0.9316],\n",
      "        [ 0.0214],\n",
      "        [ 0.0214],\n",
      "        [ 0.0214],\n",
      "        [-0.6298],\n",
      "        [-0.6298],\n",
      "        [-0.9316],\n",
      "        [-0.9316],\n",
      "        [-0.9316],\n",
      "        [-0.1917],\n",
      "        [-0.1917],\n",
      "        [-0.1917],\n",
      "        [-0.9316],\n",
      "        [-0.9316],\n",
      "        [-0.9316],\n",
      "        [ 0.3413],\n",
      "        [ 0.0214],\n",
      "        [ 0.0214],\n",
      "        [ 0.0214],\n",
      "        [-0.1917],\n",
      "        [-0.9316],\n",
      "        [-0.1917],\n",
      "        [ 0.0214],\n",
      "        [ 0.0214],\n",
      "        [ 0.0214],\n",
      "        [ 0.0214],\n",
      "        [ 0.0214],\n",
      "        [ 0.0214],\n",
      "        [ 0.0214],\n",
      "        [ 0.8251],\n",
      "        [-0.9316],\n",
      "        [-0.9316],\n",
      "        [ 0.3413],\n",
      "        [-0.1917],\n",
      "        [-0.1917],\n",
      "        [-0.9316],\n",
      "        [-0.9316],\n",
      "        [-0.9316],\n",
      "        [-0.9316]], dtype=torch.float64)\n",
      "Finished episode 550 Average rewards:  37.2\n",
      "Monitored episode 50 Average Monitored rewards:  44.56\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2780626   1.0696377   0.89037365  1.9933153  -0.0545218   1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8729958 0.724473 ]\n",
      "tensor([[ 0.8646],\n",
      "        [-0.9557],\n",
      "        [-0.0517],\n",
      "        [ 0.8646],\n",
      "        [-0.9557],\n",
      "        [-0.9557],\n",
      "        [-0.9557],\n",
      "        [-0.9557],\n",
      "        [ 0.2642],\n",
      "        [ 0.2642],\n",
      "        [-0.1110],\n",
      "        [-0.9557],\n",
      "        [-0.1110],\n",
      "        [-0.1110],\n",
      "        [-0.0517],\n",
      "        [-0.7000],\n",
      "        [-0.7000],\n",
      "        [-0.0517],\n",
      "        [-0.0517],\n",
      "        [-0.0517],\n",
      "        [-0.1110],\n",
      "        [-0.0517],\n",
      "        [-0.7000],\n",
      "        [-0.0517],\n",
      "        [-0.0517],\n",
      "        [-0.0517],\n",
      "        [-0.0517],\n",
      "        [-0.7000],\n",
      "        [-0.7000],\n",
      "        [-0.7000],\n",
      "        [-0.1110],\n",
      "        [-0.0517],\n",
      "        [-0.0517],\n",
      "        [-0.0517],\n",
      "        [-0.0517],\n",
      "        [-0.7000],\n",
      "        [-0.0517],\n",
      "        [-0.7000],\n",
      "        [-0.0517],\n",
      "        [-0.0517],\n",
      "        [-0.1110],\n",
      "        [-0.0517],\n",
      "        [-0.0517],\n",
      "        [-0.0517],\n",
      "        [-0.7000],\n",
      "        [-0.7000],\n",
      "        [-0.0517],\n",
      "        [-0.0517],\n",
      "        [-0.0517],\n",
      "        [-0.0517]], dtype=torch.float64)\n",
      "Finished episode 555 Average rewards:  35.6\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2707021   1.0672596   0.88234997  1.9935023  -0.07677062  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88079697 0.7164524 ]\n",
      "tensor([[ 0.8135],\n",
      "        [-0.9233],\n",
      "        [-0.9233],\n",
      "        [ 0.4182],\n",
      "        [ 0.4182],\n",
      "        [ 0.4182],\n",
      "        [-0.2692],\n",
      "        [ 0.0778],\n",
      "        [ 0.0778],\n",
      "        [ 0.0778],\n",
      "        [-0.2692],\n",
      "        [ 0.0778],\n",
      "        [ 0.0778],\n",
      "        [ 0.0778],\n",
      "        [ 0.0778],\n",
      "        [ 0.0778],\n",
      "        [ 0.0778],\n",
      "        [ 0.0778],\n",
      "        [ 0.0778],\n",
      "        [ 0.0778],\n",
      "        [ 0.8135],\n",
      "        [-0.9233],\n",
      "        [-0.2692],\n",
      "        [ 0.0778],\n",
      "        [ 0.0778],\n",
      "        [ 0.0778],\n",
      "        [ 0.0778],\n",
      "        [ 0.0778],\n",
      "        [ 0.0778],\n",
      "        [ 0.0778],\n",
      "        [ 0.8135],\n",
      "        [-0.9233],\n",
      "        [-0.9233],\n",
      "        [ 0.4182],\n",
      "        [ 0.4182],\n",
      "        [-0.9233],\n",
      "        [-0.9233],\n",
      "        [ 0.4182],\n",
      "        [ 0.4182],\n",
      "        [ 0.4182],\n",
      "        [ 0.8135],\n",
      "        [ 0.0778],\n",
      "        [ 0.0778],\n",
      "        [ 0.0778],\n",
      "        [ 0.0778],\n",
      "        [ 0.0778],\n",
      "        [ 0.0778],\n",
      "        [ 0.0778],\n",
      "        [ 0.0778],\n",
      "        [ 0.0778]], dtype=torch.float64)\n",
      "Finished episode 560 Average rewards:  14.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  26.64\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2656081   1.0661849   0.8861137   1.9936137  -0.07916282  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8860346 0.7202163]\n",
      "tensor([[ 0.8489],\n",
      "        [-0.9425],\n",
      "        [-0.9425],\n",
      "        [-0.9425],\n",
      "        [-0.9425],\n",
      "        [-0.9425],\n",
      "        [-0.9425],\n",
      "        [ 0.3744],\n",
      "        [ 0.3744],\n",
      "        [ 0.3744],\n",
      "        [ 0.8489],\n",
      "        [ 0.8489],\n",
      "        [-0.9425],\n",
      "        [-0.9425],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [-0.2092],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.8489],\n",
      "        [-0.9425],\n",
      "        [-0.9425],\n",
      "        [-0.9425],\n",
      "        [-0.9425],\n",
      "        [-0.9425],\n",
      "        [ 0.3744],\n",
      "        [ 0.3744],\n",
      "        [ 0.3744],\n",
      "        [ 0.3744],\n",
      "        [ 0.8489],\n",
      "        [-0.9425],\n",
      "        [-0.9425],\n",
      "        [-0.9425],\n",
      "        [-0.9425],\n",
      "        [-0.9425],\n",
      "        [-0.9425],\n",
      "        [ 0.3744],\n",
      "        [ 0.3744],\n",
      "        [ 0.3744]], dtype=torch.float64)\n",
      "Finished episode 565 Average rewards:  60.4\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2585436   1.0651139   0.8934835   1.9937469  -0.07265544  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8931908  0.72758555]\n",
      "tensor([[ 0.8401],\n",
      "        [ 0.8401],\n",
      "        [ 0.8401],\n",
      "        [-0.9337],\n",
      "        [-0.9337],\n",
      "        [-0.9337],\n",
      "        [-0.9337],\n",
      "        [-0.1957],\n",
      "        [ 0.0083],\n",
      "        [-0.6399],\n",
      "        [ 0.8401],\n",
      "        [ 0.8401],\n",
      "        [-0.9337],\n",
      "        [-0.9337],\n",
      "        [-0.9337],\n",
      "        [-0.9337],\n",
      "        [-0.9337],\n",
      "        [ 0.3583],\n",
      "        [ 0.3583],\n",
      "        [ 0.3583],\n",
      "        [ 0.8401],\n",
      "        [ 0.0083],\n",
      "        [ 0.0083],\n",
      "        [ 0.0083],\n",
      "        [ 0.0083],\n",
      "        [ 0.0083],\n",
      "        [-0.6399],\n",
      "        [ 0.0083],\n",
      "        [ 0.0083],\n",
      "        [ 0.0083],\n",
      "        [-0.1957],\n",
      "        [ 0.0083],\n",
      "        [ 0.0083],\n",
      "        [ 0.0083],\n",
      "        [ 0.0083],\n",
      "        [ 0.0083],\n",
      "        [ 0.0083],\n",
      "        [ 0.0083],\n",
      "        [ 0.0083],\n",
      "        [-0.6399],\n",
      "        [ 0.8401],\n",
      "        [ 0.8401],\n",
      "        [ 0.8401],\n",
      "        [-0.9337],\n",
      "        [-0.9337],\n",
      "        [-0.9337],\n",
      "        [-0.9337],\n",
      "        [-0.9337],\n",
      "        [ 0.3583],\n",
      "        [ 0.3583]], dtype=torch.float64)\n",
      "Finished episode 570 Average rewards:  38.8\n",
      "Monitored episode 50 Average Monitored rewards:  34.12\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2473516   1.061989    0.880944    1.993931   -0.09142772  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9048192 0.7150498]\n",
      "tensor([[-0.1995],\n",
      "        [-0.9102],\n",
      "        [-0.9102],\n",
      "        [-0.9102],\n",
      "        [ 0.3500],\n",
      "        [ 0.3500],\n",
      "        [ 0.3500],\n",
      "        [ 0.3500],\n",
      "        [-0.1995],\n",
      "        [-0.1995],\n",
      "        [ 0.8088],\n",
      "        [-0.9102],\n",
      "        [-0.1995],\n",
      "        [-0.9102],\n",
      "        [-0.1995],\n",
      "        [ 0.0268],\n",
      "        [ 0.0268],\n",
      "        [ 0.0268],\n",
      "        [ 0.0268],\n",
      "        [-0.6172],\n",
      "        [-0.1995],\n",
      "        [ 0.0268],\n",
      "        [ 0.0268],\n",
      "        [ 0.0268],\n",
      "        [ 0.0268],\n",
      "        [ 0.0268],\n",
      "        [ 0.0268],\n",
      "        [-0.6172],\n",
      "        [-0.6172],\n",
      "        [ 0.0268],\n",
      "        [ 0.8088],\n",
      "        [ 0.0268],\n",
      "        [ 0.0268],\n",
      "        [ 0.0268],\n",
      "        [-0.6172],\n",
      "        [-0.6172],\n",
      "        [-0.9102],\n",
      "        [-0.9102],\n",
      "        [-0.9102],\n",
      "        [ 0.3500],\n",
      "        [ 0.8088],\n",
      "        [-0.9102],\n",
      "        [-0.9102],\n",
      "        [ 0.3500],\n",
      "        [ 0.3500],\n",
      "        [-0.1995],\n",
      "        [-0.9102],\n",
      "        [-0.1995],\n",
      "        [-0.9102],\n",
      "        [-0.9102]], dtype=torch.float64)\n",
      "Finished episode 575 Average rewards:  60.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2518455   1.0614665   0.8847444   1.9941655  -0.07729032  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.90050966 0.71885127]\n",
      "tensor([[ 0.8402],\n",
      "        [-0.9331],\n",
      "        [-0.9331],\n",
      "        [-0.9331],\n",
      "        [-0.9331],\n",
      "        [ 0.2874],\n",
      "        [ 0.2874],\n",
      "        [ 0.2874],\n",
      "        [ 0.2874],\n",
      "        [ 0.2874],\n",
      "        [-0.1366],\n",
      "        [-0.9331],\n",
      "        [-0.9331],\n",
      "        [-0.1366],\n",
      "        [-0.9331],\n",
      "        [-0.9331],\n",
      "        [-0.9331],\n",
      "        [-0.9331],\n",
      "        [ 0.2874],\n",
      "        [ 0.2874],\n",
      "        [ 0.8402],\n",
      "        [-0.9331],\n",
      "        [-0.9331],\n",
      "        [-0.9331],\n",
      "        [-0.9331],\n",
      "        [ 0.2874],\n",
      "        [ 0.2874],\n",
      "        [ 0.2874],\n",
      "        [ 0.2874],\n",
      "        [ 0.2874],\n",
      "        [-0.1366],\n",
      "        [-0.0264],\n",
      "        [-0.0264],\n",
      "        [-0.0264],\n",
      "        [-0.6728],\n",
      "        [-0.9331],\n",
      "        [-0.1366],\n",
      "        [-0.9331],\n",
      "        [-0.9331],\n",
      "        [-0.9331],\n",
      "        [-0.1366],\n",
      "        [-0.0264],\n",
      "        [-0.0264],\n",
      "        [-0.0264],\n",
      "        [-0.0264],\n",
      "        [-0.6728],\n",
      "        [-0.0264],\n",
      "        [-0.0264],\n",
      "        [-0.6728],\n",
      "        [-0.6728]], dtype=torch.float64)\n",
      "Finished episode 580 Average rewards:  81.6\n",
      "Monitored episode 50 Average Monitored rewards:  49.8\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2448162   1.0586373   0.8697841   1.9943029  -0.10576334  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9079577 0.7038944]\n",
      "tensor([[-0.1777],\n",
      "        [ 0.0140],\n",
      "        [ 0.0140],\n",
      "        [ 0.0140],\n",
      "        [ 0.0140],\n",
      "        [-0.6377],\n",
      "        [ 0.0140],\n",
      "        [ 0.0140],\n",
      "        [ 0.0140],\n",
      "        [ 0.0140],\n",
      "        [ 0.8199],\n",
      "        [ 0.0140],\n",
      "        [ 0.0140],\n",
      "        [ 0.0140],\n",
      "        [ 0.0140],\n",
      "        [ 0.0140],\n",
      "        [-0.6377],\n",
      "        [-0.6377],\n",
      "        [ 0.8199],\n",
      "        [-0.9227],\n",
      "        [-0.1777],\n",
      "        [ 0.0140],\n",
      "        [ 0.0140],\n",
      "        [ 0.0140],\n",
      "        [ 0.0140],\n",
      "        [ 0.0140],\n",
      "        [ 0.0140],\n",
      "        [ 0.0140],\n",
      "        [ 0.0140],\n",
      "        [ 0.0140],\n",
      "        [ 0.8199],\n",
      "        [-0.9227],\n",
      "        [-0.9227],\n",
      "        [-0.1777],\n",
      "        [ 0.0140],\n",
      "        [ 0.0140],\n",
      "        [ 0.0140],\n",
      "        [ 0.0140],\n",
      "        [ 0.0140],\n",
      "        [ 0.0140],\n",
      "        [-0.1777],\n",
      "        [-0.1777],\n",
      "        [-0.9227],\n",
      "        [-0.9227],\n",
      "        [-0.9227],\n",
      "        [-0.9227],\n",
      "        [ 0.3242],\n",
      "        [-0.9227],\n",
      "        [-0.9227],\n",
      "        [-0.9227]], dtype=torch.float64)\n",
      "Finished episode 585 Average rewards:  36.6\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2637436   1.0572156   0.8743427   1.9949038  -0.07875942  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8896024 0.7084569]\n",
      "tensor([[-0.0969],\n",
      "        [-0.9547],\n",
      "        [-0.0969],\n",
      "        [-0.0666],\n",
      "        [ 0.8703],\n",
      "        [ 0.8703],\n",
      "        [-0.9547],\n",
      "        [-0.9547],\n",
      "        [ 0.2523],\n",
      "        [-0.0969],\n",
      "        [-0.0969],\n",
      "        [-0.0666],\n",
      "        [-0.7135],\n",
      "        [-0.0666],\n",
      "        [-0.7135],\n",
      "        [-0.9547],\n",
      "        [-0.9547],\n",
      "        [-0.9547],\n",
      "        [-0.9547],\n",
      "        [-0.9547],\n",
      "        [ 0.8703],\n",
      "        [-0.9547],\n",
      "        [-0.0969],\n",
      "        [-0.0666],\n",
      "        [-0.0666],\n",
      "        [-0.0666],\n",
      "        [-0.0666],\n",
      "        [-0.7135],\n",
      "        [-0.0666],\n",
      "        [-0.7135],\n",
      "        [-0.0969],\n",
      "        [-0.0666],\n",
      "        [-0.0666],\n",
      "        [-0.7135],\n",
      "        [ 0.8703],\n",
      "        [-0.9547],\n",
      "        [-0.9547],\n",
      "        [-0.9547],\n",
      "        [-0.9547],\n",
      "        [-0.9547],\n",
      "        [ 0.8703],\n",
      "        [-0.0666],\n",
      "        [-0.0666],\n",
      "        [ 0.8703],\n",
      "        [-0.9547],\n",
      "        [-0.0969],\n",
      "        [-0.0666],\n",
      "        [-0.9547],\n",
      "        [-0.9547],\n",
      "        [-0.9547]], dtype=torch.float64)\n",
      "Finished episode 590 Average rewards:  62.4\n",
      "Monitored episode 50 Average Monitored rewards:  38.52\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2504263   1.0536587   0.85534024  1.9950558  -0.11060023  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9033986 0.6894579]\n",
      "tensor([[ 0.8533],\n",
      "        [-0.9529],\n",
      "        [-0.9529],\n",
      "        [-0.9529],\n",
      "        [-0.9529],\n",
      "        [-0.9529],\n",
      "        [ 0.3518],\n",
      "        [-0.1928],\n",
      "        [-0.1928],\n",
      "        [-0.1928],\n",
      "        [-0.1928],\n",
      "        [-0.9529],\n",
      "        [-0.9529],\n",
      "        [ 0.3518],\n",
      "        [ 0.3518],\n",
      "        [ 0.3518],\n",
      "        [-0.1928],\n",
      "        [-0.1928],\n",
      "        [-0.1928],\n",
      "        [-0.9529],\n",
      "        [-0.1928],\n",
      "        [-0.9529],\n",
      "        [-0.9529],\n",
      "        [-0.9529],\n",
      "        [ 0.3518],\n",
      "        [ 0.3518],\n",
      "        [ 0.3518],\n",
      "        [ 0.3518],\n",
      "        [ 0.3518],\n",
      "        [-0.1928],\n",
      "        [ 0.8533],\n",
      "        [ 0.8533],\n",
      "        [-0.9529],\n",
      "        [-0.9529],\n",
      "        [ 0.3518],\n",
      "        [ 0.3518],\n",
      "        [-0.1928],\n",
      "        [ 0.0109],\n",
      "        [ 0.0109],\n",
      "        [ 0.0109],\n",
      "        [ 0.8533],\n",
      "        [-0.9529],\n",
      "        [-0.9529],\n",
      "        [ 0.3518],\n",
      "        [ 0.3518],\n",
      "        [-0.1928],\n",
      "        [ 0.0109],\n",
      "        [ 0.0109],\n",
      "        [ 0.0109],\n",
      "        [ 0.0109]], dtype=torch.float64)\n",
      "Finished episode 595 Average rewards:  38.0\n",
      "len_game 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[ 1.2585977   1.0525975   0.85863733  1.9953429  -0.1012819   1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.89552146 0.6927568 ]\n",
      "tensor([[-0.0943],\n",
      "        [-0.0794],\n",
      "        [ 0.8961],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [ 0.2595],\n",
      "        [ 0.2595],\n",
      "        [ 0.2595],\n",
      "        [ 0.2595],\n",
      "        [ 0.8961],\n",
      "        [-0.9768],\n",
      "        [-0.0943],\n",
      "        [-0.0943],\n",
      "        [-0.0943],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [ 0.2595],\n",
      "        [-0.0943],\n",
      "        [-0.0794],\n",
      "        [ 0.8961],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [ 0.2595],\n",
      "        [-0.0943],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [-0.0943],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [ 0.2595],\n",
      "        [ 0.2595],\n",
      "        [ 0.2595],\n",
      "        [ 0.2595],\n",
      "        [ 0.2595],\n",
      "        [ 0.2595],\n",
      "        [ 0.8961],\n",
      "        [-0.9768],\n",
      "        [-0.0943],\n",
      "        [-0.0794],\n",
      "        [-0.7336],\n",
      "        [-0.0794],\n",
      "        [-0.0794],\n",
      "        [-0.0794],\n",
      "        [-0.7336],\n",
      "        [-0.0794]], dtype=torch.float64)\n",
      "Finished episode 600 Average rewards:  82.2\n",
      "Monitored episode 50 Average Monitored rewards:  61.36\n",
      "len_game 52\n",
      "Rot\n",
      "[ 1.2722656   1.0515436   0.8660604   1.9957844  -0.07298229  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88222295 0.7001821 ]\n",
      "tensor([[ 0.8927],\n",
      "        [ 0.8927],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [-0.1310],\n",
      "        [-0.9768],\n",
      "        [-0.1310],\n",
      "        [-0.0526],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [ 0.8927],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [ 0.3006],\n",
      "        [ 0.3006],\n",
      "        [ 0.3006],\n",
      "        [ 0.3006],\n",
      "        [-0.1310],\n",
      "        [-0.1310],\n",
      "        [-0.0526],\n",
      "        [-0.0526],\n",
      "        [-0.7133],\n",
      "        [-0.9768],\n",
      "        [-0.0526],\n",
      "        [ 0.8927],\n",
      "        [-0.9768],\n",
      "        [-0.1310],\n",
      "        [-0.1310],\n",
      "        [-0.1310],\n",
      "        [-0.0526],\n",
      "        [-0.0526],\n",
      "        [-0.7133],\n",
      "        [-0.7133],\n",
      "        [-0.7133],\n",
      "        [-0.9768],\n",
      "        [-0.1310],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [ 0.8927],\n",
      "        [ 0.8927],\n",
      "        [-0.0526],\n",
      "        [-0.0526],\n",
      "        [-0.0526],\n",
      "        [-0.0526],\n",
      "        [-0.7133],\n",
      "        [-0.7133],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [-0.1310]], dtype=torch.float64)\n",
      "Finished episode 605 Average rewards:  81.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2659665   1.0506198   0.87190664  1.9958767  -0.0722888   1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8886109  0.70602834]\n",
      "tensor([[ 0.8663],\n",
      "        [ 0.8663],\n",
      "        [-0.9687],\n",
      "        [-0.9687],\n",
      "        [-0.9687],\n",
      "        [-0.9687],\n",
      "        [ 0.3795],\n",
      "        [ 0.3795],\n",
      "        [ 0.3795],\n",
      "        [ 0.3795],\n",
      "        [-0.2188],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.8663],\n",
      "        [ 0.8663],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [-0.6466],\n",
      "        [-0.9687],\n",
      "        [-0.9687],\n",
      "        [-0.9687],\n",
      "        [-0.9687],\n",
      "        [-0.2188],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [-0.6466],\n",
      "        [-0.2188],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284]], dtype=torch.float64)\n",
      "Finished episode 610 Average rewards:  38.0\n",
      "Monitored episode 50 Average Monitored rewards:  29.26\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2607338   1.0488164   0.8639596   1.9959744  -0.09937212  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8940934  0.69808257]\n",
      "tensor([[-0.2106],\n",
      "        [-0.9560],\n",
      "        [-0.9560],\n",
      "        [-0.9560],\n",
      "        [-0.9560],\n",
      "        [ 0.3652],\n",
      "        [ 0.3652],\n",
      "        [ 0.3652],\n",
      "        [ 0.3652],\n",
      "        [ 0.3652],\n",
      "        [ 0.8502],\n",
      "        [-0.9560],\n",
      "        [ 0.0305],\n",
      "        [ 0.0305],\n",
      "        [ 0.0305],\n",
      "        [ 0.0305],\n",
      "        [ 0.0305],\n",
      "        [ 0.0305],\n",
      "        [ 0.0305],\n",
      "        [ 0.0305],\n",
      "        [-0.2106],\n",
      "        [ 0.0305],\n",
      "        [ 0.0305],\n",
      "        [-0.6413],\n",
      "        [ 0.0305],\n",
      "        [ 0.0305],\n",
      "        [ 0.0305],\n",
      "        [ 0.0305],\n",
      "        [ 0.0305],\n",
      "        [ 0.0305],\n",
      "        [-0.2106],\n",
      "        [ 0.0305],\n",
      "        [ 0.0305],\n",
      "        [ 0.0305],\n",
      "        [ 0.0305],\n",
      "        [ 0.0305],\n",
      "        [ 0.0305],\n",
      "        [ 0.0305],\n",
      "        [ 0.0305],\n",
      "        [ 0.0305],\n",
      "        [ 0.8502],\n",
      "        [-0.9560],\n",
      "        [-0.9560],\n",
      "        [ 0.3652],\n",
      "        [ 0.0305],\n",
      "        [ 0.0305],\n",
      "        [ 0.0305],\n",
      "        [ 0.0305],\n",
      "        [ 0.0305],\n",
      "        [ 0.0305]], dtype=torch.float64)\n",
      "Finished episode 615 Average rewards:  13.8\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2607754   1.0476551   0.8644501   1.9961628  -0.08868954  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8942421 0.6985741]\n",
      "tensor([[ 0.8893],\n",
      "        [-0.9730],\n",
      "        [-0.1388],\n",
      "        [-0.9730],\n",
      "        [-0.9730],\n",
      "        [ 0.3089],\n",
      "        [ 0.3089],\n",
      "        [ 0.3089],\n",
      "        [ 0.3089],\n",
      "        [-0.1388],\n",
      "        [-0.1388],\n",
      "        [-0.1388],\n",
      "        [-0.9730],\n",
      "        [-0.9730],\n",
      "        [-0.9730],\n",
      "        [-0.9730],\n",
      "        [-0.9730],\n",
      "        [-0.9730],\n",
      "        [ 0.3089],\n",
      "        [ 0.3089],\n",
      "        [-0.1388],\n",
      "        [-0.9730],\n",
      "        [-0.9730],\n",
      "        [-0.9730],\n",
      "        [-0.9730],\n",
      "        [-0.9730],\n",
      "        [-0.9730],\n",
      "        [-0.9730],\n",
      "        [-0.9730],\n",
      "        [-0.9730],\n",
      "        [-0.1388],\n",
      "        [-0.9730],\n",
      "        [-0.1388],\n",
      "        [-0.0465],\n",
      "        [-0.0465],\n",
      "        [-0.0465],\n",
      "        [-0.0465],\n",
      "        [-0.0465],\n",
      "        [-0.7080],\n",
      "        [-0.7080],\n",
      "        [ 0.8893],\n",
      "        [-0.9730],\n",
      "        [-0.1388],\n",
      "        [-0.0465],\n",
      "        [-0.0465],\n",
      "        [-0.7080],\n",
      "        [-0.7080],\n",
      "        [-0.9730],\n",
      "        [-0.9730],\n",
      "        [-0.1388]], dtype=torch.float64)\n",
      "Finished episode 620 Average rewards:  40.4\n",
      "Monitored episode 50 Average Monitored rewards:  44.54\n",
      "len_game 52\n",
      "Rot\n",
      "[ 1.2616115   1.0462823   0.8632187   1.9963712  -0.07914823  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.89363456 0.697344  ]\n",
      "tensor([[-0.1640],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [ 0.3260],\n",
      "        [ 0.3260],\n",
      "        [ 0.3260],\n",
      "        [ 0.3260],\n",
      "        [-0.1640],\n",
      "        [-0.1640],\n",
      "        [ 0.8744],\n",
      "        [-0.9686],\n",
      "        [ 0.3260],\n",
      "        [-0.1640],\n",
      "        [-0.0159],\n",
      "        [-0.0159],\n",
      "        [-0.6845],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [ 0.8744],\n",
      "        [-0.0159],\n",
      "        [-0.0159],\n",
      "        [-0.0159],\n",
      "        [ 0.8744],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [ 0.8744],\n",
      "        [ 0.8744],\n",
      "        [ 0.8744],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [ 0.3260],\n",
      "        [ 0.3260],\n",
      "        [ 0.3260],\n",
      "        [-0.1640],\n",
      "        [ 0.8744],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [ 0.3260],\n",
      "        [ 0.3260],\n",
      "        [ 0.3260],\n",
      "        [-0.9686],\n",
      "        [-0.9686]], dtype=torch.float64)\n",
      "Finished episode 625 Average rewards:  102.8\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2528518   1.0441331   0.8584216   1.9964898  -0.10475064  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.90263665 0.6925479 ]\n",
      "tensor([[ 0.8628],\n",
      "        [-0.9663],\n",
      "        [-0.9663],\n",
      "        [ 0.3429],\n",
      "        [ 0.3429],\n",
      "        [ 0.3429],\n",
      "        [-0.1876],\n",
      "        [ 0.0115],\n",
      "        [ 0.0115],\n",
      "        [ 0.0115],\n",
      "        [ 0.8628],\n",
      "        [-0.9663],\n",
      "        [-0.9663],\n",
      "        [-0.9663],\n",
      "        [-0.9663],\n",
      "        [ 0.3429],\n",
      "        [ 0.3429],\n",
      "        [ 0.3429],\n",
      "        [ 0.3429],\n",
      "        [ 0.3429],\n",
      "        [-0.1876],\n",
      "        [ 0.0115],\n",
      "        [-0.6640],\n",
      "        [-0.6640],\n",
      "        [ 0.0115],\n",
      "        [ 0.0115],\n",
      "        [ 0.0115],\n",
      "        [ 0.0115],\n",
      "        [ 0.0115],\n",
      "        [ 0.0115],\n",
      "        [-0.1876],\n",
      "        [-0.1876],\n",
      "        [ 0.0115],\n",
      "        [-0.6640],\n",
      "        [-0.9663],\n",
      "        [-0.9663],\n",
      "        [-0.9663],\n",
      "        [-0.9663],\n",
      "        [ 0.0115],\n",
      "        [ 0.0115],\n",
      "        [ 0.8628],\n",
      "        [-0.9663],\n",
      "        [-0.9663],\n",
      "        [-0.9663],\n",
      "        [ 0.3429],\n",
      "        [ 0.3429],\n",
      "        [ 0.3429],\n",
      "        [ 0.3429],\n",
      "        [-0.1876],\n",
      "        [ 0.0115]], dtype=torch.float64)\n",
      "Finished episode 630 Average rewards:  17.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  50.86\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2790632   1.0446104   0.8771707   1.9968349  -0.06614404  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8766097 0.7112976]\n",
      "tensor([[ 0.8908],\n",
      "        [-0.9752],\n",
      "        [-0.1118],\n",
      "        [-0.9752],\n",
      "        [ 0.2745],\n",
      "        [-0.1118],\n",
      "        [-0.0613],\n",
      "        [-0.0613],\n",
      "        [-0.0613],\n",
      "        [-0.0613],\n",
      "        [ 0.8908],\n",
      "        [ 0.8908],\n",
      "        [-0.9752],\n",
      "        [-0.9752],\n",
      "        [ 0.2745],\n",
      "        [ 0.2745],\n",
      "        [-0.1118],\n",
      "        [-0.1118],\n",
      "        [-0.0613],\n",
      "        [-0.0613],\n",
      "        [-0.1118],\n",
      "        [-0.0613],\n",
      "        [-0.0613],\n",
      "        [-0.0613],\n",
      "        [-0.0613],\n",
      "        [-0.0613],\n",
      "        [-0.7236],\n",
      "        [-0.0613],\n",
      "        [-0.0613],\n",
      "        [-0.0613],\n",
      "        [ 0.8908],\n",
      "        [ 0.8908],\n",
      "        [-0.9752],\n",
      "        [-0.9752],\n",
      "        [-0.9752],\n",
      "        [-0.9752],\n",
      "        [-0.9752],\n",
      "        [-0.9752],\n",
      "        [-0.9752],\n",
      "        [-0.9752],\n",
      "        [-0.1118],\n",
      "        [-0.0613],\n",
      "        [-0.0613],\n",
      "        [-0.7236],\n",
      "        [-0.0613],\n",
      "        [-0.7236],\n",
      "        [-0.0613],\n",
      "        [-0.7236],\n",
      "        [-0.9752],\n",
      "        [-0.9752]], dtype=torch.float64)\n",
      "Finished episode 635 Average rewards:  38.6\n",
      "len_game 52\n",
      "Rot\n",
      "[ 1.2692997   1.0432175   0.871713    1.9969054  -0.07302487  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88651127 0.7058404 ]\n",
      "tensor([[ 0.8539],\n",
      "        [ 0.0491],\n",
      "        [ 0.0491],\n",
      "        [ 0.0491],\n",
      "        [ 0.0491],\n",
      "        [ 0.0491],\n",
      "        [ 0.0491],\n",
      "        [ 0.0491],\n",
      "        [ 0.0491],\n",
      "        [ 0.0491],\n",
      "        [ 0.8539],\n",
      "        [-0.9559],\n",
      "        [-0.9559],\n",
      "        [-0.9559],\n",
      "        [-0.2437],\n",
      "        [-0.9559],\n",
      "        [-0.9559],\n",
      "        [ 0.4022],\n",
      "        [ 0.4022],\n",
      "        [ 0.4022],\n",
      "        [-0.2437],\n",
      "        [ 0.8539],\n",
      "        [ 0.8539],\n",
      "        [-0.9559],\n",
      "        [-0.9559],\n",
      "        [ 0.4022],\n",
      "        [-0.2437],\n",
      "        [-0.9559],\n",
      "        [-0.9559],\n",
      "        [-0.9559],\n",
      "        [-0.9559],\n",
      "        [-0.2437],\n",
      "        [ 0.0491],\n",
      "        [ 0.0491],\n",
      "        [ 0.0491],\n",
      "        [ 0.0491],\n",
      "        [ 0.0491],\n",
      "        [ 0.0491],\n",
      "        [ 0.0491],\n",
      "        [-0.6252],\n",
      "        [-0.6252],\n",
      "        [ 0.8539],\n",
      "        [ 0.0491],\n",
      "        [ 0.8539],\n",
      "        [-0.9559],\n",
      "        [-0.2437],\n",
      "        [ 0.0491],\n",
      "        [-0.6252],\n",
      "        [ 0.8539],\n",
      "        [-0.9559],\n",
      "        [-0.2437],\n",
      "        [-0.2437]], dtype=torch.float64)\n",
      "Finished episode 640 Average rewards:  59.0\n",
      "Monitored episode 50 Average Monitored rewards:  40.76\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2617987   1.0419556   0.8736825   1.99699    -0.08414298  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.894136  0.7078102]\n",
      "tensor([[-0.2135],\n",
      "        [-0.2135],\n",
      "        [-0.9602],\n",
      "        [ 0.0296],\n",
      "        [ 0.0296],\n",
      "        [ 0.0296],\n",
      "        [-0.6457],\n",
      "        [-0.6457],\n",
      "        [ 0.0296],\n",
      "        [ 0.0296],\n",
      "        [ 0.8569],\n",
      "        [-0.9602],\n",
      "        [-0.9602],\n",
      "        [-0.9602],\n",
      "        [ 0.3707],\n",
      "        [ 0.3707],\n",
      "        [-0.2135],\n",
      "        [ 0.0296],\n",
      "        [ 0.0296],\n",
      "        [ 0.0296],\n",
      "        [ 0.8569],\n",
      "        [-0.9602],\n",
      "        [-0.9602],\n",
      "        [-0.9602],\n",
      "        [ 0.3707],\n",
      "        [ 0.3707],\n",
      "        [ 0.3707],\n",
      "        [ 0.3707],\n",
      "        [ 0.3707],\n",
      "        [-0.9602],\n",
      "        [ 0.8569],\n",
      "        [-0.9602],\n",
      "        [ 0.0296],\n",
      "        [ 0.0296],\n",
      "        [ 0.0296],\n",
      "        [ 0.0296],\n",
      "        [ 0.0296],\n",
      "        [ 0.0296],\n",
      "        [ 0.0296],\n",
      "        [ 0.0296],\n",
      "        [ 0.8569],\n",
      "        [-0.9602],\n",
      "        [-0.9602],\n",
      "        [-0.9602],\n",
      "        [-0.9602],\n",
      "        [-0.9602],\n",
      "        [ 0.3707],\n",
      "        [ 0.3707],\n",
      "        [ 0.3707],\n",
      "        [ 0.3707]], dtype=torch.float64)\n",
      "Finished episode 645 Average rewards:  38.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2804723   1.0416714   0.8901086   1.9973171  -0.04162405  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8756648 0.7242368]\n",
      "tensor([[ 0.8605],\n",
      "        [-0.9565],\n",
      "        [-0.0021],\n",
      "        [-0.0021],\n",
      "        [-0.0021],\n",
      "        [-0.6702],\n",
      "        [-0.9565],\n",
      "        [-0.9565],\n",
      "        [-0.9565],\n",
      "        [ 0.3346],\n",
      "        [-0.1759],\n",
      "        [-0.9565],\n",
      "        [-0.9565],\n",
      "        [-0.9565],\n",
      "        [ 0.3346],\n",
      "        [ 0.3346],\n",
      "        [-0.1759],\n",
      "        [-0.0021],\n",
      "        [-0.0021],\n",
      "        [-0.6702],\n",
      "        [-0.1759],\n",
      "        [-0.9565],\n",
      "        [-0.1759],\n",
      "        [-0.9565],\n",
      "        [-0.0021],\n",
      "        [-0.0021],\n",
      "        [-0.6702],\n",
      "        [-0.0021],\n",
      "        [-0.0021],\n",
      "        [-0.6702],\n",
      "        [-0.1759],\n",
      "        [-0.0021],\n",
      "        [ 0.8605],\n",
      "        [ 0.8605],\n",
      "        [ 0.8605],\n",
      "        [-0.9565],\n",
      "        [-0.9565],\n",
      "        [ 0.3346],\n",
      "        [-0.1759],\n",
      "        [-0.1759],\n",
      "        [-0.1759],\n",
      "        [-0.9565],\n",
      "        [-0.0021],\n",
      "        [-0.0021],\n",
      "        [-0.0021],\n",
      "        [-0.0021],\n",
      "        [-0.0021],\n",
      "        [-0.6702],\n",
      "        [-0.6702],\n",
      "        [-0.0021]], dtype=torch.float64)\n",
      "Finished episode 650 Average rewards:  16.8\n",
      "Monitored episode 50 Average Monitored rewards:  41.46\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2694399   1.0399216   0.8735425   1.997393   -0.06468768  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8868796 0.7076716]\n",
      "tensor([[ 0.7983],\n",
      "        [-0.9228],\n",
      "        [-0.2985],\n",
      "        [-0.9228],\n",
      "        [-0.9228],\n",
      "        [-0.9228],\n",
      "        [-0.2985],\n",
      "        [ 0.1192],\n",
      "        [ 0.1192],\n",
      "        [ 0.1192],\n",
      "        [-0.2985],\n",
      "        [-0.9228],\n",
      "        [-0.9228],\n",
      "        [ 0.4329],\n",
      "        [ 0.4329],\n",
      "        [ 0.4329],\n",
      "        [-0.2985],\n",
      "        [-0.2985],\n",
      "        [ 0.1192],\n",
      "        [ 0.1192],\n",
      "        [ 0.7983],\n",
      "        [-0.9228],\n",
      "        [-0.9228],\n",
      "        [-0.9228],\n",
      "        [-0.9228],\n",
      "        [ 0.4329],\n",
      "        [ 0.4329],\n",
      "        [-0.9228],\n",
      "        [-0.9228],\n",
      "        [ 0.4329],\n",
      "        [ 0.7983],\n",
      "        [-0.9228],\n",
      "        [-0.9228],\n",
      "        [-0.2985],\n",
      "        [-0.9228],\n",
      "        [-0.9228],\n",
      "        [-0.9228],\n",
      "        [-0.9228],\n",
      "        [-0.9228],\n",
      "        [-0.9228],\n",
      "        [-0.2985],\n",
      "        [-0.2985],\n",
      "        [-0.9228],\n",
      "        [-0.9228],\n",
      "        [ 0.4329],\n",
      "        [ 0.4329],\n",
      "        [-0.9228],\n",
      "        [-0.9228],\n",
      "        [-0.9228],\n",
      "        [ 0.4329]], dtype=torch.float64)\n",
      "Finished episode 655 Average rewards:  63.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2635458   1.0388244   0.8716612   1.9974581  -0.07722037  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8928827 0.7057906]\n",
      "tensor([[ 0.8425],\n",
      "        [-0.9540],\n",
      "        [-0.9540],\n",
      "        [-0.2325],\n",
      "        [ 0.0538],\n",
      "        [ 0.0538],\n",
      "        [-0.6256],\n",
      "        [-0.6256],\n",
      "        [ 0.8425],\n",
      "        [ 0.0538],\n",
      "        [-0.2325],\n",
      "        [ 0.0538],\n",
      "        [ 0.0538],\n",
      "        [ 0.0538],\n",
      "        [ 0.0538],\n",
      "        [ 0.0538],\n",
      "        [ 0.0538],\n",
      "        [ 0.0538],\n",
      "        [ 0.0538],\n",
      "        [ 0.0538],\n",
      "        [-0.2325],\n",
      "        [ 0.0538],\n",
      "        [ 0.0538],\n",
      "        [ 0.0538],\n",
      "        [ 0.0538],\n",
      "        [ 0.0538],\n",
      "        [ 0.0538],\n",
      "        [ 0.0538],\n",
      "        [ 0.0538],\n",
      "        [ 0.0538],\n",
      "        [-0.2325],\n",
      "        [-0.9540],\n",
      "        [ 0.0538],\n",
      "        [ 0.0538],\n",
      "        [ 0.0538],\n",
      "        [ 0.0538],\n",
      "        [ 0.0538],\n",
      "        [ 0.0538],\n",
      "        [-0.6256],\n",
      "        [ 0.0538],\n",
      "        [-0.2325],\n",
      "        [ 0.0538],\n",
      "        [ 0.0538],\n",
      "        [ 0.0538],\n",
      "        [-0.6256],\n",
      "        [-0.6256],\n",
      "        [ 0.0538],\n",
      "        [ 0.0538],\n",
      "        [ 0.0538],\n",
      "        [ 0.0538]], dtype=torch.float64)\n",
      "Finished episode 660 Average rewards:  -7.8\n",
      "Monitored episode 50 Average Monitored rewards:  40.94\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2532662   1.0371152   0.86817646  1.9975438  -0.0943721   1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9033122 0.7023063]\n",
      "tensor([[ 0.8552],\n",
      "        [-0.9576],\n",
      "        [-0.9576],\n",
      "        [ 0.3493],\n",
      "        [ 0.3493],\n",
      "        [ 0.3493],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.8552],\n",
      "        [-0.9576],\n",
      "        [-0.9576],\n",
      "        [ 0.3493],\n",
      "        [ 0.3493],\n",
      "        [-0.1946],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.8552],\n",
      "        [-0.9576],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [-0.6568],\n",
      "        [-0.6568],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.8552],\n",
      "        [ 0.8552],\n",
      "        [ 0.8552],\n",
      "        [-0.9576],\n",
      "        [-0.9576],\n",
      "        [-0.9576],\n",
      "        [ 0.3493],\n",
      "        [ 0.3493],\n",
      "        [-0.9576],\n",
      "        [ 0.3493],\n",
      "        [-0.1946],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [-0.6568],\n",
      "        [-0.6568],\n",
      "        [ 0.0182]], dtype=torch.float64)\n",
      "Finished episode 665 Average rewards:  14.8\n",
      "len_game 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[ 1.2763357   1.0371923   0.8818968   1.9977708  -0.06309168  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8803903 0.7160269]\n",
      "tensor([[ 0.8695],\n",
      "        [ 0.8695],\n",
      "        [-0.9613],\n",
      "        [-0.1370],\n",
      "        [-0.9613],\n",
      "        [ 0.2921],\n",
      "        [-0.1370],\n",
      "        [-0.0307],\n",
      "        [-0.0307],\n",
      "        [-0.0307],\n",
      "        [-0.1370],\n",
      "        [-0.0307],\n",
      "        [-0.6982],\n",
      "        [-0.0307],\n",
      "        [-0.6982],\n",
      "        [-0.0307],\n",
      "        [-0.0307],\n",
      "        [-0.0307],\n",
      "        [-0.0307],\n",
      "        [-0.6982],\n",
      "        [-0.1370],\n",
      "        [-0.1370],\n",
      "        [-0.9613],\n",
      "        [-0.9613],\n",
      "        [ 0.2921],\n",
      "        [ 0.2921],\n",
      "        [ 0.2921],\n",
      "        [-0.0307],\n",
      "        [-0.0307],\n",
      "        [-0.6982],\n",
      "        [-0.1370],\n",
      "        [-0.1370],\n",
      "        [-0.1370],\n",
      "        [-0.0307],\n",
      "        [ 0.8695],\n",
      "        [-0.9613],\n",
      "        [-0.1370],\n",
      "        [-0.0307],\n",
      "        [-0.0307],\n",
      "        [-0.6982],\n",
      "        [ 0.8695],\n",
      "        [-0.9613],\n",
      "        [-0.9613],\n",
      "        [ 0.2921],\n",
      "        [ 0.2921],\n",
      "        [-0.1370],\n",
      "        [-0.1370],\n",
      "        [-0.9613],\n",
      "        [-0.9613],\n",
      "        [-0.9613]], dtype=torch.float64)\n",
      "Finished episode 670 Average rewards:  17.2\n",
      "Monitored episode 50 Average Monitored rewards:  45.04\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2684038   1.036309    0.88207674  1.9978186  -0.06579505  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8883897 0.716207 ]\n",
      "tensor([[-0.2461],\n",
      "        [-0.9458],\n",
      "        [-0.9458],\n",
      "        [-0.9458],\n",
      "        [ 0.3990],\n",
      "        [ 0.3990],\n",
      "        [ 0.3990],\n",
      "        [-0.9458],\n",
      "        [-0.9458],\n",
      "        [-0.9458],\n",
      "        [-0.2461],\n",
      "        [ 0.0588],\n",
      "        [ 0.0588],\n",
      "        [ 0.0588],\n",
      "        [ 0.0588],\n",
      "        [ 0.0588],\n",
      "        [ 0.0588],\n",
      "        [ 0.0588],\n",
      "        [ 0.0588],\n",
      "        [-0.6159],\n",
      "        [-0.2461],\n",
      "        [-0.9458],\n",
      "        [-0.9458],\n",
      "        [-0.9458],\n",
      "        [-0.9458],\n",
      "        [-0.9458],\n",
      "        [-0.9458],\n",
      "        [ 0.3990],\n",
      "        [ 0.3990],\n",
      "        [ 0.3990],\n",
      "        [-0.2461],\n",
      "        [-0.2461],\n",
      "        [ 0.0588],\n",
      "        [ 0.0588],\n",
      "        [ 0.0588],\n",
      "        [ 0.0588],\n",
      "        [ 0.0588],\n",
      "        [ 0.0588],\n",
      "        [ 0.0588],\n",
      "        [-0.6159],\n",
      "        [-0.2461],\n",
      "        [ 0.0588],\n",
      "        [-0.6159],\n",
      "        [-0.9458],\n",
      "        [-0.9458],\n",
      "        [ 0.3990],\n",
      "        [ 0.3990],\n",
      "        [ 0.3990],\n",
      "        [ 0.3990],\n",
      "        [-0.2461]], dtype=torch.float64)\n",
      "Finished episode 675 Average rewards:  38.8\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2599204   1.0344955   0.86456555  1.9978837  -0.10268633  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8970498  0.69869643]\n",
      "tensor([[ 0.8319],\n",
      "        [-0.9403],\n",
      "        [-0.9403],\n",
      "        [-0.9403],\n",
      "        [ 0.3776],\n",
      "        [ 0.3776],\n",
      "        [-0.2282],\n",
      "        [-0.2282],\n",
      "        [ 0.0511],\n",
      "        [ 0.0511],\n",
      "        [-0.2282],\n",
      "        [ 0.0511],\n",
      "        [ 0.0511],\n",
      "        [-0.6223],\n",
      "        [-0.6223],\n",
      "        [ 0.0511],\n",
      "        [ 0.0511],\n",
      "        [-0.6223],\n",
      "        [-0.6223],\n",
      "        [ 0.0511],\n",
      "        [ 0.8319],\n",
      "        [-0.9403],\n",
      "        [ 0.0511],\n",
      "        [ 0.0511],\n",
      "        [ 0.0511],\n",
      "        [ 0.0511],\n",
      "        [ 0.0511],\n",
      "        [ 0.0511],\n",
      "        [ 0.0511],\n",
      "        [ 0.0511],\n",
      "        [-0.2282],\n",
      "        [-0.9403],\n",
      "        [ 0.0511],\n",
      "        [ 0.8319],\n",
      "        [-0.9403],\n",
      "        [-0.9403],\n",
      "        [-0.9403],\n",
      "        [-0.9403],\n",
      "        [-0.9403],\n",
      "        [-0.9403],\n",
      "        [ 0.8319],\n",
      "        [-0.9403],\n",
      "        [-0.2282],\n",
      "        [ 0.0511],\n",
      "        [ 0.0511],\n",
      "        [-0.6223],\n",
      "        [ 0.0511],\n",
      "        [ 0.0511],\n",
      "        [ 0.0511],\n",
      "        [ 0.0511]], dtype=torch.float64)\n",
      "Finished episode 680 Average rewards:  17.4\n",
      "Monitored episode 50 Average Monitored rewards:  42.26\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2664719  1.0338871  0.8678893  1.9980141 -0.0855957  1.8641111\n",
      "  1.7464267  0.7518858]\n",
      "Enc\n",
      "[0.89060676 0.70202047]\n",
      "tensor([[-0.1283],\n",
      "        [-0.9748],\n",
      "        [-0.1283],\n",
      "        [-0.9748],\n",
      "        [-0.9748],\n",
      "        [ 0.2972],\n",
      "        [-0.9748],\n",
      "        [-0.9748],\n",
      "        [-0.9748],\n",
      "        [-0.9748],\n",
      "        [-0.1283],\n",
      "        [-0.9748],\n",
      "        [-0.1283],\n",
      "        [-0.0539],\n",
      "        [-0.0539],\n",
      "        [-0.7194],\n",
      "        [-0.0539],\n",
      "        [-0.7194],\n",
      "        [-0.7194],\n",
      "        [-0.7194],\n",
      "        [ 0.8934],\n",
      "        [ 0.8934],\n",
      "        [ 0.8934],\n",
      "        [-0.9748],\n",
      "        [-0.9748],\n",
      "        [ 0.2972],\n",
      "        [ 0.2972],\n",
      "        [-0.1283],\n",
      "        [-0.9748],\n",
      "        [-0.9748],\n",
      "        [-0.9748],\n",
      "        [ 0.8934],\n",
      "        [-0.9748],\n",
      "        [-0.9748],\n",
      "        [-0.9748],\n",
      "        [-0.9748],\n",
      "        [-0.9748],\n",
      "        [ 0.2972],\n",
      "        [ 0.2972],\n",
      "        [-0.1283],\n",
      "        [-0.0539],\n",
      "        [ 0.8934],\n",
      "        [-0.9748],\n",
      "        [-0.9748],\n",
      "        [ 0.2972],\n",
      "        [ 0.2972],\n",
      "        [ 0.2972],\n",
      "        [ 0.2972],\n",
      "        [-0.0539],\n",
      "        [-0.9748],\n",
      "        [-0.9748]], dtype=torch.float64)\n",
      "Finished episode 685 Average rewards:  82.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2767979   1.0336502   0.8761661   1.9981396  -0.06548504  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8803671  0.71029747]\n",
      "tensor([[ 0.8757],\n",
      "        [-0.9691],\n",
      "        [-0.9691],\n",
      "        [-0.9691],\n",
      "        [-0.9691],\n",
      "        [-0.9691],\n",
      "        [-0.9691],\n",
      "        [ 0.3432],\n",
      "        [ 0.3432],\n",
      "        [ 0.3432],\n",
      "        [ 0.8757],\n",
      "        [ 0.8757],\n",
      "        [-0.9691],\n",
      "        [-0.1796],\n",
      "        [-0.0051],\n",
      "        [ 0.8757],\n",
      "        [-0.9691],\n",
      "        [-0.9691],\n",
      "        [-0.9691],\n",
      "        [ 0.3432],\n",
      "        [-0.1796],\n",
      "        [-0.9691],\n",
      "        [-0.9691],\n",
      "        [-0.9691],\n",
      "        [-0.9691],\n",
      "        [-0.9691],\n",
      "        [ 0.3432],\n",
      "        [ 0.3432],\n",
      "        [ 0.3432],\n",
      "        [ 0.3432],\n",
      "        [-0.1796],\n",
      "        [-0.9691],\n",
      "        [ 0.3432],\n",
      "        [-0.0051],\n",
      "        [-0.9691],\n",
      "        [-0.0051],\n",
      "        [ 0.8757],\n",
      "        [-0.9691],\n",
      "        [-0.1796],\n",
      "        [-0.1796],\n",
      "        [-0.1796],\n",
      "        [-0.1796],\n",
      "        [-0.0051],\n",
      "        [-0.0051],\n",
      "        [-0.6799],\n",
      "        [-0.6799],\n",
      "        [-0.6799],\n",
      "        [-0.0051],\n",
      "        [-0.6799],\n",
      "        [ 0.8757]], dtype=torch.float64)\n",
      "Finished episode 690 Average rewards:  82.2\n",
      "Monitored episode 50 Average Monitored rewards:  37.76\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2662314   1.0323192   0.87030673  1.9981935  -0.08400746  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.89104086 0.70443827]\n",
      "tensor([[ 0.8516],\n",
      "        [-0.9569],\n",
      "        [-0.2413],\n",
      "        [-0.9569],\n",
      "        [-0.9569],\n",
      "        [-0.9569],\n",
      "        [-0.9569],\n",
      "        [-0.9569],\n",
      "        [ 0.3965],\n",
      "        [ 0.3965],\n",
      "        [-0.2413],\n",
      "        [-0.9569],\n",
      "        [-0.9569],\n",
      "        [-0.9569],\n",
      "        [-0.9569],\n",
      "        [-0.9569],\n",
      "        [-0.9569],\n",
      "        [-0.9569],\n",
      "        [-0.9569],\n",
      "        [-0.9569],\n",
      "        [-0.2413],\n",
      "        [-0.9569],\n",
      "        [ 0.3965],\n",
      "        [ 0.3965],\n",
      "        [-0.2413],\n",
      "        [ 0.0524],\n",
      "        [ 0.0524],\n",
      "        [ 0.0524],\n",
      "        [ 0.0524],\n",
      "        [ 0.0524],\n",
      "        [-0.2413],\n",
      "        [-0.9569],\n",
      "        [-0.9569],\n",
      "        [ 0.3965],\n",
      "        [ 0.0524],\n",
      "        [ 0.0524],\n",
      "        [ 0.0524],\n",
      "        [ 0.0524],\n",
      "        [ 0.0524],\n",
      "        [ 0.0524],\n",
      "        [ 0.8516],\n",
      "        [-0.9569],\n",
      "        [-0.2413],\n",
      "        [-0.9569],\n",
      "        [-0.9569],\n",
      "        [-0.9569],\n",
      "        [ 0.3965],\n",
      "        [ 0.3965],\n",
      "        [-0.9569],\n",
      "        [ 0.3965]], dtype=torch.float64)\n",
      "Finished episode 695 Average rewards:  61.4\n",
      "len_game 52\n",
      "Rot\n",
      "[ 1.2840871   1.0319777   0.8778342   1.9983606  -0.05903327  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8733156 0.711966 ]\n",
      "tensor([[ 8.7077e-01],\n",
      "        [-9.6537e-01],\n",
      "        [-1.8278e-01],\n",
      "        [-3.5750e-04],\n",
      "        [-3.5750e-04],\n",
      "        [-3.5750e-04],\n",
      "        [-3.5750e-04],\n",
      "        [-6.7514e-01],\n",
      "        [-9.6537e-01],\n",
      "        [-1.8278e-01],\n",
      "        [-1.8278e-01],\n",
      "        [ 8.7077e-01],\n",
      "        [-9.6537e-01],\n",
      "        [-9.6537e-01],\n",
      "        [ 3.4471e-01],\n",
      "        [-9.6537e-01],\n",
      "        [-9.6537e-01],\n",
      "        [-9.6537e-01],\n",
      "        [ 3.4471e-01],\n",
      "        [ 3.4471e-01],\n",
      "        [ 3.4471e-01],\n",
      "        [-1.8278e-01],\n",
      "        [-9.6537e-01],\n",
      "        [-9.6537e-01],\n",
      "        [-9.6537e-01],\n",
      "        [-9.6537e-01],\n",
      "        [ 3.4471e-01],\n",
      "        [ 3.4471e-01],\n",
      "        [ 3.4471e-01],\n",
      "        [ 3.4471e-01],\n",
      "        [ 3.4471e-01],\n",
      "        [ 8.7077e-01],\n",
      "        [-9.6537e-01],\n",
      "        [-3.5750e-04],\n",
      "        [ 8.7077e-01],\n",
      "        [-9.6537e-01],\n",
      "        [-3.5750e-04],\n",
      "        [ 8.7077e-01],\n",
      "        [ 8.7077e-01],\n",
      "        [-9.6537e-01],\n",
      "        [-9.6537e-01],\n",
      "        [-1.8278e-01],\n",
      "        [ 8.7077e-01],\n",
      "        [-9.6537e-01],\n",
      "        [-1.8278e-01],\n",
      "        [-9.6537e-01],\n",
      "        [ 3.4471e-01],\n",
      "        [-1.8278e-01],\n",
      "        [-3.5750e-04],\n",
      "        [-9.6537e-01],\n",
      "        [-1.8278e-01],\n",
      "        [-3.5750e-04]], dtype=torch.float64)\n",
      "Finished episode 700 Average rewards:  39.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  26.98\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2692456   1.0301552   0.8646252   1.9984294  -0.09052319  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88830894 0.69875735]\n",
      "tensor([[ 0.8501],\n",
      "        [-0.9565],\n",
      "        [-0.9565],\n",
      "        [-0.9565],\n",
      "        [-0.9565],\n",
      "        [-0.9565],\n",
      "        [ 0.4191],\n",
      "        [ 0.4191],\n",
      "        [ 0.4191],\n",
      "        [ 0.4191],\n",
      "        [ 0.8501],\n",
      "        [-0.9565],\n",
      "        [-0.9565],\n",
      "        [-0.2658],\n",
      "        [-0.9565],\n",
      "        [-0.9565],\n",
      "        [ 0.4191],\n",
      "        [ 0.0710],\n",
      "        [ 0.0710],\n",
      "        [ 0.0710],\n",
      "        [-0.2658],\n",
      "        [-0.9565],\n",
      "        [-0.9565],\n",
      "        [-0.9565],\n",
      "        [ 0.4191],\n",
      "        [-0.2658],\n",
      "        [ 0.0710],\n",
      "        [ 0.0710],\n",
      "        [ 0.0710],\n",
      "        [ 0.0710],\n",
      "        [ 0.8501],\n",
      "        [-0.9565],\n",
      "        [-0.9565],\n",
      "        [ 0.0710],\n",
      "        [ 0.0710],\n",
      "        [ 0.0710],\n",
      "        [ 0.0710],\n",
      "        [ 0.0710],\n",
      "        [ 0.0710],\n",
      "        [ 0.0710],\n",
      "        [ 0.8501],\n",
      "        [-0.9565],\n",
      "        [-0.9565],\n",
      "        [ 0.4191],\n",
      "        [ 0.4191],\n",
      "        [ 0.4191],\n",
      "        [-0.2658],\n",
      "        [-0.2658],\n",
      "        [-0.2658],\n",
      "        [ 0.0710]], dtype=torch.float64)\n",
      "Finished episode 705 Average rewards:  17.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2912557   1.0303566   0.8850081   1.998592   -0.04569752  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8663761 0.7191403]\n",
      "tensor([[-0.1725],\n",
      "        [-0.1725],\n",
      "        [-0.0187],\n",
      "        [-0.0187],\n",
      "        [-0.0187],\n",
      "        [-0.6940],\n",
      "        [-0.6940],\n",
      "        [-0.6940],\n",
      "        [-0.6940],\n",
      "        [-0.9766],\n",
      "        [ 0.8895],\n",
      "        [-0.9766],\n",
      "        [-0.9766],\n",
      "        [-0.9766],\n",
      "        [ 0.3426],\n",
      "        [ 0.3426],\n",
      "        [ 0.3426],\n",
      "        [ 0.3426],\n",
      "        [-0.1725],\n",
      "        [-0.0187],\n",
      "        [ 0.8895],\n",
      "        [-0.9766],\n",
      "        [-0.1725],\n",
      "        [-0.0187],\n",
      "        [-0.0187],\n",
      "        [-0.6940],\n",
      "        [ 0.8895],\n",
      "        [-0.9766],\n",
      "        [-0.0187],\n",
      "        [-0.0187],\n",
      "        [-0.1725],\n",
      "        [-0.0187],\n",
      "        [-0.0187],\n",
      "        [-0.0187],\n",
      "        [-0.0187],\n",
      "        [-0.0187],\n",
      "        [-0.0187],\n",
      "        [-0.0187],\n",
      "        [-0.6940],\n",
      "        [-0.6940],\n",
      "        [-0.1725],\n",
      "        [-0.0187],\n",
      "        [-0.0187],\n",
      "        [ 0.8895],\n",
      "        [-0.9766],\n",
      "        [ 0.3426],\n",
      "        [-0.1725],\n",
      "        [-0.1725],\n",
      "        [-0.0187],\n",
      "        [-0.0187]], dtype=torch.float64)\n",
      "Finished episode 710 Average rewards:  18.0\n",
      "Monitored episode 50 Average Monitored rewards:  34.56\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2767781   1.0290996   0.8830498   1.9986467  -0.05506257  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88094336 0.71718216]\n",
      "tensor([[-0.3036],\n",
      "        [ 0.1092],\n",
      "        [ 0.1092],\n",
      "        [-0.5720],\n",
      "        [ 0.8296],\n",
      "        [ 0.8296],\n",
      "        [ 0.8296],\n",
      "        [-0.9433],\n",
      "        [-0.9433],\n",
      "        [ 0.4454],\n",
      "        [-0.3036],\n",
      "        [-0.3036],\n",
      "        [ 0.1092],\n",
      "        [ 0.1092],\n",
      "        [ 0.1092],\n",
      "        [ 0.1092],\n",
      "        [ 0.1092],\n",
      "        [ 0.1092],\n",
      "        [-0.5720],\n",
      "        [-0.5720],\n",
      "        [-0.3036],\n",
      "        [-0.9433],\n",
      "        [-0.9433],\n",
      "        [ 0.4454],\n",
      "        [ 0.4454],\n",
      "        [ 0.4454],\n",
      "        [ 0.4454],\n",
      "        [-0.3036],\n",
      "        [ 0.1092],\n",
      "        [ 0.1092],\n",
      "        [ 0.8296],\n",
      "        [-0.9433],\n",
      "        [-0.9433],\n",
      "        [-0.9433],\n",
      "        [ 0.4454],\n",
      "        [-0.3036],\n",
      "        [-0.9433],\n",
      "        [-0.3036],\n",
      "        [ 0.1092],\n",
      "        [-0.5720],\n",
      "        [ 0.8296],\n",
      "        [-0.3036],\n",
      "        [ 0.1092],\n",
      "        [ 0.1092],\n",
      "        [ 0.1092],\n",
      "        [ 0.1092],\n",
      "        [ 0.1092],\n",
      "        [ 0.1092],\n",
      "        [ 0.1092],\n",
      "        [ 0.1092],\n",
      "        [ 0.1092]], dtype=torch.float64)\n",
      "Finished episode 715 Average rewards:  36.6\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.271558    1.0284727   0.88222575  1.9986744  -0.06776856  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88620937 0.7163582 ]\n",
      "tensor([[-0.2641],\n",
      "        [ 0.0827],\n",
      "        [ 0.0827],\n",
      "        [ 0.0827],\n",
      "        [ 0.0827],\n",
      "        [ 0.0827],\n",
      "        [ 0.0827],\n",
      "        [ 0.0827],\n",
      "        [ 0.0827],\n",
      "        [ 0.0827],\n",
      "        [-0.2641],\n",
      "        [ 0.0827],\n",
      "        [ 0.0827],\n",
      "        [ 0.0827],\n",
      "        [ 0.0827],\n",
      "        [ 0.0827],\n",
      "        [ 0.0827],\n",
      "        [ 0.0827],\n",
      "        [ 0.0827],\n",
      "        [ 0.0827],\n",
      "        [-0.2641],\n",
      "        [-0.2641],\n",
      "        [-0.9409],\n",
      "        [-0.9409],\n",
      "        [-0.9409],\n",
      "        [-0.9409],\n",
      "        [-0.9409],\n",
      "        [-0.9409],\n",
      "        [ 0.4090],\n",
      "        [ 0.4090],\n",
      "        [ 0.8262],\n",
      "        [ 0.8262],\n",
      "        [-0.9409],\n",
      "        [-0.9409],\n",
      "        [-0.9409],\n",
      "        [-0.9409],\n",
      "        [-0.9409],\n",
      "        [-0.9409],\n",
      "        [ 0.4090],\n",
      "        [-0.9409],\n",
      "        [ 0.8262],\n",
      "        [ 0.8262],\n",
      "        [-0.9409],\n",
      "        [-0.2641],\n",
      "        [ 0.0827],\n",
      "        [ 0.0827],\n",
      "        [ 0.0827],\n",
      "        [ 0.0827],\n",
      "        [ 0.0827],\n",
      "        [ 0.0827]], dtype=torch.float64)\n",
      "Finished episode 720 Average rewards:  39.4\n",
      "Monitored episode 50 Average Monitored rewards:  38.6\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2615485   1.0273803   0.87247676  1.9987065  -0.08359352  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8962907 0.7066093]\n",
      "tensor([[-0.2282],\n",
      "        [ 0.0465],\n",
      "        [ 0.0465],\n",
      "        [ 0.0465],\n",
      "        [ 0.0465],\n",
      "        [ 0.0465],\n",
      "        [ 0.0465],\n",
      "        [ 0.0465],\n",
      "        [ 0.0465],\n",
      "        [ 0.0465],\n",
      "        [ 0.8397],\n",
      "        [-0.9443],\n",
      "        [-0.9443],\n",
      "        [-0.2282],\n",
      "        [ 0.0465],\n",
      "        [ 0.0465],\n",
      "        [ 0.0465],\n",
      "        [ 0.0465],\n",
      "        [-0.6289],\n",
      "        [-0.6289],\n",
      "        [-0.2282],\n",
      "        [-0.9443],\n",
      "        [-0.9443],\n",
      "        [-0.9443],\n",
      "        [-0.9443],\n",
      "        [-0.9443],\n",
      "        [-0.9443],\n",
      "        [-0.9443],\n",
      "        [ 0.3810],\n",
      "        [-0.9443],\n",
      "        [-0.2282],\n",
      "        [ 0.0465],\n",
      "        [ 0.8397],\n",
      "        [-0.9443],\n",
      "        [-0.9443],\n",
      "        [-0.9443],\n",
      "        [-0.9443],\n",
      "        [-0.9443],\n",
      "        [ 0.3810],\n",
      "        [ 0.3810],\n",
      "        [ 0.8397],\n",
      "        [-0.9443],\n",
      "        [-0.9443],\n",
      "        [ 0.3810],\n",
      "        [ 0.3810],\n",
      "        [ 0.3810],\n",
      "        [-0.9443],\n",
      "        [ 0.3810],\n",
      "        [-0.2282],\n",
      "        [-0.2282]], dtype=torch.float64)\n",
      "Finished episode 725 Average rewards:  60.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2543678   1.0265425   0.8668788   1.9987301  -0.09612803  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9035223 0.7010114]\n",
      "tensor([[ 0.8616],\n",
      "        [-0.9587],\n",
      "        [-0.1759],\n",
      "        [-0.9587],\n",
      "        [-0.9587],\n",
      "        [-0.9587],\n",
      "        [-0.9587],\n",
      "        [ 0.3319],\n",
      "        [ 0.3319],\n",
      "        [ 0.3319],\n",
      "        [ 0.8616],\n",
      "        [ 0.8616],\n",
      "        [-0.9587],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [ 0.8616],\n",
      "        [-0.9587],\n",
      "        [-0.1759],\n",
      "        [-0.1759],\n",
      "        [-0.9587],\n",
      "        [-0.9587],\n",
      "        [-0.9587],\n",
      "        [ 0.3319],\n",
      "        [ 0.3319],\n",
      "        [-0.9587],\n",
      "        [-0.1759],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [-0.6738],\n",
      "        [-0.6738],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [ 0.8616],\n",
      "        [-0.9587],\n",
      "        [-0.9587],\n",
      "        [-0.9587],\n",
      "        [ 0.3319],\n",
      "        [-0.1759],\n",
      "        [-0.9587],\n",
      "        [-0.9587],\n",
      "        [ 0.3319],\n",
      "        [-0.9587]], dtype=torch.float64)\n",
      "Finished episode 730 Average rewards:  59.8\n",
      "Monitored episode 50 Average Monitored rewards:  31.82\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2796613   1.0267317   0.8842054   1.9988592  -0.05529343  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8783004  0.71833813]\n",
      "tensor([[ 0.8755],\n",
      "        [-0.9655],\n",
      "        [-0.1340],\n",
      "        [-0.0343],\n",
      "        [-0.0343],\n",
      "        [-0.0343],\n",
      "        [-0.7057],\n",
      "        [-0.7057],\n",
      "        [-0.0343],\n",
      "        [-0.0343],\n",
      "        [-0.1340],\n",
      "        [-0.9655],\n",
      "        [-0.9655],\n",
      "        [ 0.2901],\n",
      "        [-0.1340],\n",
      "        [-0.9655],\n",
      "        [-0.1340],\n",
      "        [-0.0343],\n",
      "        [-0.7057],\n",
      "        [-0.9655],\n",
      "        [-0.1340],\n",
      "        [-0.1340],\n",
      "        [-0.0343],\n",
      "        [-0.0343],\n",
      "        [-0.0343],\n",
      "        [-0.0343],\n",
      "        [-0.7057],\n",
      "        [-0.7057],\n",
      "        [-0.7057],\n",
      "        [-0.9655],\n",
      "        [-0.1340],\n",
      "        [-0.0343],\n",
      "        [-0.0343],\n",
      "        [-0.0343],\n",
      "        [-0.0343],\n",
      "        [-0.7057],\n",
      "        [-0.0343],\n",
      "        [-0.7057],\n",
      "        [-0.0343],\n",
      "        [-0.0343],\n",
      "        [-0.1340],\n",
      "        [-0.0343],\n",
      "        [-0.0343],\n",
      "        [-0.7057],\n",
      "        [-0.0343],\n",
      "        [-0.7057],\n",
      "        [-0.7057],\n",
      "        [ 0.8755],\n",
      "        [-0.9655],\n",
      "        [-0.9655]], dtype=torch.float64)\n",
      "Finished episode 735 Average rewards:  57.4\n",
      "len_game 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[ 1.2659475   1.0253807   0.87034243  1.9989007  -0.07676712  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8921026  0.70447534]\n",
      "tensor([[-0.2675],\n",
      "        [ 0.0822],\n",
      "        [ 0.0822],\n",
      "        [ 0.0822],\n",
      "        [ 0.0822],\n",
      "        [ 0.0822],\n",
      "        [ 0.0822],\n",
      "        [-0.5973],\n",
      "        [ 0.0822],\n",
      "        [ 0.0822],\n",
      "        [ 0.8292],\n",
      "        [-0.9413],\n",
      "        [ 0.0822],\n",
      "        [ 0.0822],\n",
      "        [ 0.0822],\n",
      "        [-0.5973],\n",
      "        [-0.9413],\n",
      "        [-0.9413],\n",
      "        [-0.9413],\n",
      "        [-0.9413],\n",
      "        [ 0.8292],\n",
      "        [-0.9413],\n",
      "        [-0.9413],\n",
      "        [ 0.4142],\n",
      "        [ 0.0822],\n",
      "        [ 0.0822],\n",
      "        [-0.5973],\n",
      "        [-0.5973],\n",
      "        [-0.9413],\n",
      "        [-0.9413],\n",
      "        [ 0.8292],\n",
      "        [-0.9413],\n",
      "        [-0.2675],\n",
      "        [ 0.0822],\n",
      "        [ 0.0822],\n",
      "        [ 0.0822],\n",
      "        [ 0.0822],\n",
      "        [ 0.0822],\n",
      "        [ 0.0822],\n",
      "        [ 0.0822],\n",
      "        [-0.2675],\n",
      "        [-0.2675],\n",
      "        [-0.9413],\n",
      "        [-0.9413],\n",
      "        [-0.9413],\n",
      "        [-0.9413],\n",
      "        [-0.9413],\n",
      "        [-0.9413],\n",
      "        [ 0.4142],\n",
      "        [ 0.4142]], dtype=torch.float64)\n",
      "Finished episode 740 Average rewards:  61.0\n",
      "Monitored episode 50 Average Monitored rewards:  24.92\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2575581   1.024282    0.8564117   1.9989251  -0.10117675  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.900562  0.6905447]\n",
      "tensor([[-0.1988],\n",
      "        [-0.9622],\n",
      "        [-0.1988],\n",
      "        [ 0.0211],\n",
      "        [ 0.0211],\n",
      "        [-0.6601],\n",
      "        [ 0.8601],\n",
      "        [-0.9622],\n",
      "        [-0.1988],\n",
      "        [ 0.0211],\n",
      "        [-0.1988],\n",
      "        [-0.9622],\n",
      "        [ 0.3539],\n",
      "        [-0.1988],\n",
      "        [-0.9622],\n",
      "        [-0.9622],\n",
      "        [-0.9622],\n",
      "        [-0.9622],\n",
      "        [-0.9622],\n",
      "        [-0.9622],\n",
      "        [ 0.8601],\n",
      "        [ 0.0211],\n",
      "        [ 0.0211],\n",
      "        [ 0.0211],\n",
      "        [ 0.0211],\n",
      "        [ 0.0211],\n",
      "        [ 0.0211],\n",
      "        [ 0.0211],\n",
      "        [ 0.0211],\n",
      "        [ 0.0211],\n",
      "        [-0.1988],\n",
      "        [-0.1988],\n",
      "        [ 0.0211],\n",
      "        [ 0.0211],\n",
      "        [ 0.0211],\n",
      "        [-0.6601],\n",
      "        [ 0.0211],\n",
      "        [ 0.0211],\n",
      "        [ 0.0211],\n",
      "        [ 0.0211],\n",
      "        [-0.1988],\n",
      "        [-0.9622],\n",
      "        [-0.9622],\n",
      "        [-0.9622],\n",
      "        [-0.9622],\n",
      "        [-0.9622],\n",
      "        [ 0.3539],\n",
      "        [ 0.3539],\n",
      "        [ 0.3539],\n",
      "        [-0.9622]], dtype=torch.float64)\n",
      "Finished episode 745 Average rewards:  38.4\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2690659  1.0238202  0.8623819  1.9990107 -0.0807532  1.8641111\n",
      "  1.7464267  0.7518858]\n",
      "Enc\n",
      "[0.88912463 0.69651496]\n",
      "tensor([[ 0.8950],\n",
      "        [-0.9809],\n",
      "        [-0.1272],\n",
      "        [-0.0485],\n",
      "        [-0.7225],\n",
      "        [-0.9809],\n",
      "        [-0.1272],\n",
      "        [-0.9809],\n",
      "        [-0.9809],\n",
      "        [-0.9809],\n",
      "        [ 0.8950],\n",
      "        [ 0.8950],\n",
      "        [-0.9809],\n",
      "        [-0.9809],\n",
      "        [-0.9809],\n",
      "        [-0.9809],\n",
      "        [-0.9809],\n",
      "        [-0.9809],\n",
      "        [ 0.2905],\n",
      "        [ 0.2905],\n",
      "        [ 0.8950],\n",
      "        [-0.9809],\n",
      "        [-0.9809],\n",
      "        [ 0.2905],\n",
      "        [ 0.2905],\n",
      "        [ 0.2905],\n",
      "        [-0.1272],\n",
      "        [-0.1272],\n",
      "        [-0.9809],\n",
      "        [-0.9809],\n",
      "        [ 0.8950],\n",
      "        [-0.9809],\n",
      "        [-0.9809],\n",
      "        [-0.1272],\n",
      "        [-0.0485],\n",
      "        [-0.0485],\n",
      "        [-0.0485],\n",
      "        [-0.0485],\n",
      "        [-0.0485],\n",
      "        [-0.0485],\n",
      "        [-0.1272],\n",
      "        [-0.1272],\n",
      "        [-0.0485],\n",
      "        [-0.9809],\n",
      "        [-0.0485],\n",
      "        [-0.0485],\n",
      "        [ 0.8950],\n",
      "        [-0.9809],\n",
      "        [-0.9809],\n",
      "        [-0.9809]], dtype=torch.float64)\n",
      "Finished episode 750 Average rewards:  80.8\n",
      "Monitored episode 50 Average Monitored rewards:  40.22\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2621398   1.0230435   0.8612179   1.9990374  -0.09621363  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8960968 0.6953511]\n",
      "tensor([[ 0.8779],\n",
      "        [ 0.8779],\n",
      "        [-0.9760],\n",
      "        [-0.1945],\n",
      "        [-0.1945],\n",
      "        [ 0.0099],\n",
      "        [ 0.0099],\n",
      "        [ 0.0099],\n",
      "        [ 0.0099],\n",
      "        [ 0.0099],\n",
      "        [-0.1945],\n",
      "        [ 0.0099],\n",
      "        [ 0.0099],\n",
      "        [ 0.0099],\n",
      "        [ 0.0099],\n",
      "        [ 0.0099],\n",
      "        [ 0.0099],\n",
      "        [ 0.0099],\n",
      "        [ 0.0099],\n",
      "        [ 0.0099],\n",
      "        [-0.1945],\n",
      "        [-0.9760],\n",
      "        [-0.1945],\n",
      "        [-0.9760],\n",
      "        [-0.9760],\n",
      "        [-0.9760],\n",
      "        [ 0.3557],\n",
      "        [ 0.3557],\n",
      "        [ 0.3557],\n",
      "        [ 0.3557],\n",
      "        [-0.1945],\n",
      "        [-0.9760],\n",
      "        [-0.9760],\n",
      "        [ 0.3557],\n",
      "        [-0.1945],\n",
      "        [ 0.0099],\n",
      "        [ 0.0099],\n",
      "        [ 0.0099],\n",
      "        [ 0.0099],\n",
      "        [ 0.0099],\n",
      "        [-0.1945],\n",
      "        [ 0.0099],\n",
      "        [ 0.0099],\n",
      "        [ 0.0099],\n",
      "        [ 0.0099],\n",
      "        [ 0.0099],\n",
      "        [ 0.0099],\n",
      "        [ 0.0099],\n",
      "        [-0.6744],\n",
      "        [-0.6744]], dtype=torch.float64)\n",
      "Finished episode 755 Average rewards:  14.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2539251   1.022087    0.84934175  1.9990634  -0.10309705  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9043646 0.683475 ]\n",
      "tensor([[ 0.8911],\n",
      "        [-0.9782],\n",
      "        [ 0.3124],\n",
      "        [ 0.3124],\n",
      "        [-0.9782],\n",
      "        [ 0.3124],\n",
      "        [-0.9782],\n",
      "        [-0.9782],\n",
      "        [ 0.3124],\n",
      "        [ 0.3124],\n",
      "        [-0.1468],\n",
      "        [-0.9782],\n",
      "        [-0.9782],\n",
      "        [-0.9782],\n",
      "        [-0.9782],\n",
      "        [ 0.3124],\n",
      "        [ 0.3124],\n",
      "        [ 0.3124],\n",
      "        [ 0.3124],\n",
      "        [ 0.3124],\n",
      "        [ 0.8911],\n",
      "        [-0.9782],\n",
      "        [-0.9782],\n",
      "        [ 0.3124],\n",
      "        [ 0.3124],\n",
      "        [ 0.3124],\n",
      "        [-0.1468],\n",
      "        [-0.9782],\n",
      "        [-0.9782],\n",
      "        [ 0.3124],\n",
      "        [-0.1468],\n",
      "        [-0.9782],\n",
      "        [-0.9782],\n",
      "        [-0.9782],\n",
      "        [-0.9782],\n",
      "        [ 0.3124],\n",
      "        [ 0.3124],\n",
      "        [-0.1468],\n",
      "        [-0.9782],\n",
      "        [-0.9782],\n",
      "        [-0.1468],\n",
      "        [-0.9782],\n",
      "        [-0.9782],\n",
      "        [-0.9782],\n",
      "        [-0.9782],\n",
      "        [ 0.3124],\n",
      "        [ 0.3124],\n",
      "        [-0.1468],\n",
      "        [-0.0342],\n",
      "        [-0.7098]], dtype=torch.float64)\n",
      "Finished episode 760 Average rewards:  101.8\n",
      "Monitored episode 50 Average Monitored rewards:  50.28\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2793097   1.0219859   0.86910474  1.9991757  -0.06325033  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8790483  0.70323807]\n",
      "tensor([[ 0.8967],\n",
      "        [-0.9835],\n",
      "        [-0.0538],\n",
      "        [ 0.8967],\n",
      "        [ 0.8967],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [ 0.2756],\n",
      "        [ 0.2756],\n",
      "        [-0.1161],\n",
      "        [ 0.8967],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [ 0.2756],\n",
      "        [-0.1161],\n",
      "        [-0.0538],\n",
      "        [-0.0538],\n",
      "        [-0.7295],\n",
      "        [ 0.8967],\n",
      "        [-0.1161],\n",
      "        [-0.0538],\n",
      "        [-0.7295],\n",
      "        [-0.0538],\n",
      "        [-0.7295],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [ 0.8967],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [ 0.2756],\n",
      "        [ 0.2756],\n",
      "        [ 0.2756],\n",
      "        [-0.1161],\n",
      "        [-0.0538],\n",
      "        [-0.0538],\n",
      "        [-0.0538],\n",
      "        [ 0.8967],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [ 0.2756],\n",
      "        [-0.1161],\n",
      "        [-0.0538],\n",
      "        [-0.0538],\n",
      "        [-0.0538],\n",
      "        [-0.0538],\n",
      "        [-0.0538]], dtype=torch.float64)\n",
      "Finished episode 765 Average rewards:  59.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2680118   1.0210238   0.85810053  1.9991988  -0.08520494  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8903993 0.692234 ]\n",
      "tensor([[ 0.8605],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [ 0.4034],\n",
      "        [-0.2495],\n",
      "        [-0.2495],\n",
      "        [-0.2495],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [-0.2495],\n",
      "        [-0.9686],\n",
      "        [-0.2495],\n",
      "        [ 0.0600],\n",
      "        [ 0.0600],\n",
      "        [ 0.0600],\n",
      "        [ 0.0600],\n",
      "        [ 0.0600],\n",
      "        [ 0.0600],\n",
      "        [ 0.0600],\n",
      "        [ 0.8605],\n",
      "        [-0.9686],\n",
      "        [-0.2495],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [ 0.4034],\n",
      "        [-0.2495],\n",
      "        [-0.2495],\n",
      "        [ 0.0600],\n",
      "        [-0.2495],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [ 0.4034],\n",
      "        [ 0.4034],\n",
      "        [ 0.4034],\n",
      "        [ 0.4034],\n",
      "        [ 0.0600],\n",
      "        [ 0.0600]], dtype=torch.float64)\n",
      "Finished episode 770 Average rewards:  42.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  53.96\n",
      "len_game 52\n",
      "Rot\n",
      "[ 1.2707962   1.020413    0.8572051   1.9992473  -0.07791446  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8876661 0.6913386]\n",
      "tensor([[ 0.8862],\n",
      "        [-0.9812],\n",
      "        [-0.9812],\n",
      "        [-0.9812],\n",
      "        [ 0.3460],\n",
      "        [-0.1824],\n",
      "        [-0.1824],\n",
      "        [-0.9812],\n",
      "        [-0.9812],\n",
      "        [ 0.3460],\n",
      "        [-0.1824],\n",
      "        [-0.1824],\n",
      "        [-0.9812],\n",
      "        [-0.9812],\n",
      "        [-0.9812],\n",
      "        [-0.9812],\n",
      "        [-0.9812],\n",
      "        [-0.9812],\n",
      "        [ 0.3460],\n",
      "        [ 0.3460],\n",
      "        [ 0.3460],\n",
      "        [-0.1824],\n",
      "        [-0.9812],\n",
      "        [-0.9812],\n",
      "        [ 0.3460],\n",
      "        [ 0.3460],\n",
      "        [-0.1824],\n",
      "        [-0.9812],\n",
      "        [-0.9812],\n",
      "        [-0.9812],\n",
      "        [-0.9812],\n",
      "        [-0.1824],\n",
      "        [-0.0026],\n",
      "        [-0.6871],\n",
      "        [-0.0026],\n",
      "        [-0.6871],\n",
      "        [-0.0026],\n",
      "        [-0.0026],\n",
      "        [-0.6871],\n",
      "        [-0.9812],\n",
      "        [-0.9812],\n",
      "        [ 0.8862],\n",
      "        [-0.0026],\n",
      "        [-0.0026],\n",
      "        [-0.6871],\n",
      "        [ 0.8862],\n",
      "        [-0.9812],\n",
      "        [-0.9812],\n",
      "        [ 0.3460],\n",
      "        [ 0.3460],\n",
      "        [-0.1824],\n",
      "        [-0.1824]], dtype=torch.float64)\n",
      "Finished episode 775 Average rewards:  103.6\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2603176   1.0196651   0.85150594  1.9992651  -0.08623325  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8981778  0.68563944]\n",
      "tensor([[-0.2036],\n",
      "        [-0.2036],\n",
      "        [-0.2036],\n",
      "        [-0.9813],\n",
      "        [-0.9813],\n",
      "        [-0.9813],\n",
      "        [-0.9813],\n",
      "        [-0.9813],\n",
      "        [ 0.3639],\n",
      "        [ 0.3639],\n",
      "        [ 0.8804],\n",
      "        [-0.9813],\n",
      "        [-0.9813],\n",
      "        [-0.9813],\n",
      "        [-0.9813],\n",
      "        [ 0.3639],\n",
      "        [ 0.3639],\n",
      "        [-0.9813],\n",
      "        [-0.9813],\n",
      "        [ 0.3639],\n",
      "        [-0.2036],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [-0.6710],\n",
      "        [-0.6710],\n",
      "        [-0.6710],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [-0.2036],\n",
      "        [-0.2036],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [-0.6710],\n",
      "        [-0.6710],\n",
      "        [-0.9813],\n",
      "        [-0.9813],\n",
      "        [-0.9813],\n",
      "        [-0.2036],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182]], dtype=torch.float64)\n",
      "Finished episode 780 Average rewards:  59.2\n",
      "Monitored episode 50 Average Monitored rewards:  49.64\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2837842   1.0197875   0.8722946   1.9993397  -0.04454068  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.87474793 0.70642805]\n",
      "tensor([[-0.1673],\n",
      "        [-0.0055],\n",
      "        [-0.0055],\n",
      "        [-0.0055],\n",
      "        [-0.6922],\n",
      "        [-0.6922],\n",
      "        [-0.0055],\n",
      "        [-0.0055],\n",
      "        [-0.6922],\n",
      "        [-0.6922],\n",
      "        [ 0.8809],\n",
      "        [-0.9802],\n",
      "        [-0.0055],\n",
      "        [-0.6922],\n",
      "        [-0.0055],\n",
      "        [-0.9802],\n",
      "        [-0.9802],\n",
      "        [-0.9802],\n",
      "        [-0.9802],\n",
      "        [-0.9802],\n",
      "        [ 0.8809],\n",
      "        [ 0.8809],\n",
      "        [-0.9802],\n",
      "        [-0.9802],\n",
      "        [ 0.3232],\n",
      "        [ 0.3232],\n",
      "        [-0.1673],\n",
      "        [-0.0055],\n",
      "        [-0.0055],\n",
      "        [-0.0055],\n",
      "        [-0.1673],\n",
      "        [-0.0055],\n",
      "        [-0.0055],\n",
      "        [-0.6922],\n",
      "        [-0.0055],\n",
      "        [-0.6922],\n",
      "        [-0.6922],\n",
      "        [-0.0055],\n",
      "        [-0.6922],\n",
      "        [-0.6922],\n",
      "        [-0.1673],\n",
      "        [-0.0055],\n",
      "        [-0.0055],\n",
      "        [-0.6922],\n",
      "        [-0.6922],\n",
      "        [-0.6922],\n",
      "        [-0.6922],\n",
      "        [-0.9802],\n",
      "        [-0.9802],\n",
      "        [-0.9802]], dtype=torch.float64)\n",
      "Finished episode 785 Average rewards:  60.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2729855   1.018968    0.86800325  1.999366   -0.065282    1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88558877 0.70213675]\n",
      "tensor([[-0.2961],\n",
      "        [ 0.1133],\n",
      "        [ 0.1133],\n",
      "        [ 0.1133],\n",
      "        [ 0.1133],\n",
      "        [ 0.1133],\n",
      "        [ 0.1133],\n",
      "        [ 0.1133],\n",
      "        [ 0.1133],\n",
      "        [ 0.1133],\n",
      "        [-0.2961],\n",
      "        [-0.9599],\n",
      "        [-0.2961],\n",
      "        [ 0.1133],\n",
      "        [ 0.1133],\n",
      "        [ 0.1133],\n",
      "        [ 0.1133],\n",
      "        [ 0.1133],\n",
      "        [ 0.1133],\n",
      "        [ 0.1133],\n",
      "        [ 0.8344],\n",
      "        [-0.9599],\n",
      "        [-0.9599],\n",
      "        [-0.9599],\n",
      "        [ 0.4336],\n",
      "        [-0.2961],\n",
      "        [-0.2961],\n",
      "        [ 0.1133],\n",
      "        [ 0.1133],\n",
      "        [ 0.1133],\n",
      "        [ 0.8344],\n",
      "        [-0.9599],\n",
      "        [-0.9599],\n",
      "        [-0.9599],\n",
      "        [ 0.1133],\n",
      "        [ 0.1133],\n",
      "        [-0.5815],\n",
      "        [-0.9599],\n",
      "        [ 0.4336],\n",
      "        [-0.9599],\n",
      "        [-0.2961],\n",
      "        [-0.2961],\n",
      "        [ 0.1133],\n",
      "        [ 0.1133],\n",
      "        [ 0.1133],\n",
      "        [ 0.1133],\n",
      "        [ 0.1133],\n",
      "        [-0.5815],\n",
      "        [ 0.1133],\n",
      "        [ 0.1133]], dtype=torch.float64)\n",
      "Finished episode 790 Average rewards:  13.6\n",
      "Monitored episode 50 Average Monitored rewards:  35.78\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2623795   1.018047    0.85301924  1.9993844  -0.09145404  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8962393  0.68715274]\n",
      "tensor([[-0.2356],\n",
      "        [-0.9662],\n",
      "        [-0.9662],\n",
      "        [-0.2356],\n",
      "        [-0.2356],\n",
      "        [-0.2356],\n",
      "        [-0.9662],\n",
      "        [-0.9662],\n",
      "        [-0.9662],\n",
      "        [-0.9662],\n",
      "        [-0.2356],\n",
      "        [-0.9662],\n",
      "        [ 0.3867],\n",
      "        [ 0.3867],\n",
      "        [-0.2356],\n",
      "        [-0.2356],\n",
      "        [-0.9662],\n",
      "        [-0.9662],\n",
      "        [ 0.3867],\n",
      "        [ 0.0544],\n",
      "        [ 0.8555],\n",
      "        [-0.9662],\n",
      "        [ 0.0544],\n",
      "        [ 0.0544],\n",
      "        [ 0.0544],\n",
      "        [ 0.0544],\n",
      "        [ 0.0544],\n",
      "        [-0.6356],\n",
      "        [-0.6356],\n",
      "        [ 0.0544],\n",
      "        [-0.2356],\n",
      "        [ 0.0544],\n",
      "        [ 0.0544],\n",
      "        [ 0.0544],\n",
      "        [ 0.0544],\n",
      "        [ 0.0544],\n",
      "        [ 0.0544],\n",
      "        [-0.6356],\n",
      "        [-0.6356],\n",
      "        [-0.6356],\n",
      "        [ 0.8555],\n",
      "        [-0.9662],\n",
      "        [-0.2356],\n",
      "        [-0.2356],\n",
      "        [ 0.0544],\n",
      "        [ 0.0544],\n",
      "        [ 0.0544],\n",
      "        [ 0.0544],\n",
      "        [-0.6356],\n",
      "        [ 0.0544]], dtype=torch.float64)\n",
      "Finished episode 795 Average rewards:  17.8\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2669106  1.0180397  0.8638863  1.9994105 -0.0669853  1.8641111\n",
      "  1.7464267  0.7518858]\n",
      "Enc\n",
      "[0.89171606 0.6980198 ]\n",
      "tensor([[ 0.8905],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [ 0.3203],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [-0.1583],\n",
      "        [-0.0203],\n",
      "        [-0.0203],\n",
      "        [-0.0203],\n",
      "        [-0.0203],\n",
      "        [-0.0203],\n",
      "        [-0.0203],\n",
      "        [-0.0203],\n",
      "        [-0.7037],\n",
      "        [-0.7037],\n",
      "        [ 0.8905],\n",
      "        [ 0.8905],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [-0.1583],\n",
      "        [-0.0203],\n",
      "        [-0.0203],\n",
      "        [-0.0203],\n",
      "        [-0.0203],\n",
      "        [-0.0203],\n",
      "        [-0.0203],\n",
      "        [-0.0203],\n",
      "        [-0.0203],\n",
      "        [-0.7037],\n",
      "        [ 0.8905],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [-0.0203],\n",
      "        [ 0.8905],\n",
      "        [-0.0203],\n",
      "        [-0.9835],\n",
      "        [-0.1583],\n",
      "        [-0.9835],\n",
      "        [ 0.3203],\n",
      "        [-0.1583]], dtype=torch.float64)\n",
      "Finished episode 800 Average rewards:  62.2\n",
      "Monitored episode 50 Average Monitored rewards:  53.26\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2615266   1.0173824   0.85510397  1.9994254  -0.09317552  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.89713275 0.6892375 ]\n",
      "tensor([[-0.2226],\n",
      "        [ 0.0496],\n",
      "        [ 0.0496],\n",
      "        [ 0.0496],\n",
      "        [ 0.0496],\n",
      "        [ 0.0496],\n",
      "        [-0.6422],\n",
      "        [-0.6422],\n",
      "        [ 0.0496],\n",
      "        [ 0.0496],\n",
      "        [-0.2226],\n",
      "        [ 0.0496],\n",
      "        [ 0.0496],\n",
      "        [ 0.0496],\n",
      "        [-0.6422],\n",
      "        [ 0.0496],\n",
      "        [ 0.0496],\n",
      "        [ 0.0496],\n",
      "        [ 0.0496],\n",
      "        [ 0.0496],\n",
      "        [ 0.8530],\n",
      "        [ 0.8530],\n",
      "        [-0.9660],\n",
      "        [-0.2226],\n",
      "        [-0.2226],\n",
      "        [-0.9660],\n",
      "        [ 0.0496],\n",
      "        [ 0.0496],\n",
      "        [ 0.0496],\n",
      "        [-0.6422],\n",
      "        [ 0.8530],\n",
      "        [ 0.8530],\n",
      "        [ 0.8530],\n",
      "        [ 0.0496],\n",
      "        [ 0.0496],\n",
      "        [ 0.0496],\n",
      "        [ 0.0496],\n",
      "        [ 0.0496],\n",
      "        [ 0.0496],\n",
      "        [ 0.0496],\n",
      "        [ 0.0496],\n",
      "        [ 0.8530],\n",
      "        [-0.9660],\n",
      "        [ 0.0496],\n",
      "        [ 0.0496],\n",
      "        [ 0.0496],\n",
      "        [ 0.0496],\n",
      "        [ 0.0496],\n",
      "        [ 0.0496],\n",
      "        [-0.6422],\n",
      "        [ 0.0496]], dtype=torch.float64)\n",
      "Finished episode 805 Average rewards:  14.4\n",
      "len_game 52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[ 1.2786065   1.0174385   0.8699325   1.9994696  -0.06304412  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88007504 0.704066  ]\n",
      "tensor([[-0.1528],\n",
      "        [-0.9821],\n",
      "        [-0.9821],\n",
      "        [-0.9821],\n",
      "        [-0.9821],\n",
      "        [-0.9821],\n",
      "        [-0.9821],\n",
      "        [-0.9821],\n",
      "        [ 0.3149],\n",
      "        [-0.9821],\n",
      "        [-0.1528],\n",
      "        [-0.0252],\n",
      "        [-0.0252],\n",
      "        [-0.7068],\n",
      "        [-0.0252],\n",
      "        [ 0.8905],\n",
      "        [ 0.8905],\n",
      "        [-0.9821],\n",
      "        [-0.0252],\n",
      "        [-0.9821],\n",
      "        [-0.1528],\n",
      "        [-0.1528],\n",
      "        [-0.0252],\n",
      "        [-0.0252],\n",
      "        [-0.7068],\n",
      "        [-0.0252],\n",
      "        [-0.0252],\n",
      "        [-0.0252],\n",
      "        [-0.7068],\n",
      "        [-0.0252],\n",
      "        [ 0.8905],\n",
      "        [ 0.8905],\n",
      "        [-0.9821],\n",
      "        [-0.9821],\n",
      "        [ 0.3149],\n",
      "        [-0.1528],\n",
      "        [-0.0252],\n",
      "        [-0.7068],\n",
      "        [ 0.8905],\n",
      "        [-0.0252],\n",
      "        [ 0.8905],\n",
      "        [ 0.8905],\n",
      "        [ 0.8905],\n",
      "        [ 0.8905],\n",
      "        [-0.9821],\n",
      "        [-0.9821],\n",
      "        [ 0.3149],\n",
      "        [-0.9821],\n",
      "        [ 0.3149],\n",
      "        [ 0.3149],\n",
      "        [ 0.3149],\n",
      "        [-0.9821]], dtype=torch.float64)\n",
      "Finished episode 810 Average rewards:  62.0\n",
      "Monitored episode 50 Average Monitored rewards:  41.72\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2726605   1.0169785   0.86598325  1.9994812  -0.07759973  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8860423  0.70011675]\n",
      "tensor([[-0.2488],\n",
      "        [ 0.0609],\n",
      "        [ 0.0609],\n",
      "        [ 0.0609],\n",
      "        [ 0.0609],\n",
      "        [ 0.0609],\n",
      "        [ 0.0609],\n",
      "        [ 0.0609],\n",
      "        [ 0.0609],\n",
      "        [ 0.0609],\n",
      "        [-0.2488],\n",
      "        [-0.9672],\n",
      "        [-0.9672],\n",
      "        [-0.9672],\n",
      "        [-0.9672],\n",
      "        [-0.9672],\n",
      "        [-0.9672],\n",
      "        [-0.9672],\n",
      "        [-0.9672],\n",
      "        [-0.9672],\n",
      "        [ 0.8584],\n",
      "        [ 0.8584],\n",
      "        [-0.9672],\n",
      "        [-0.9672],\n",
      "        [-0.2488],\n",
      "        [-0.2488],\n",
      "        [ 0.0609],\n",
      "        [ 0.0609],\n",
      "        [ 0.0609],\n",
      "        [ 0.0609],\n",
      "        [ 0.8584],\n",
      "        [-0.9672],\n",
      "        [-0.9672],\n",
      "        [-0.9672],\n",
      "        [-0.9672],\n",
      "        [-0.9672],\n",
      "        [-0.9672],\n",
      "        [-0.9672],\n",
      "        [-0.9672],\n",
      "        [-0.9672],\n",
      "        [-0.2488],\n",
      "        [-0.2488],\n",
      "        [-0.2488],\n",
      "        [ 0.0609],\n",
      "        [ 0.0609],\n",
      "        [ 0.0609],\n",
      "        [ 0.0609],\n",
      "        [ 0.0609],\n",
      "        [ 0.0609],\n",
      "        [ 0.0609]], dtype=torch.float64)\n",
      "Finished episode 815 Average rewards:  42.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2629527   1.0161728   0.8567639   1.9994974  -0.10520347  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.89578587 0.69089735]\n",
      "tensor([[-0.2072],\n",
      "        [-0.9736],\n",
      "        [-0.9736],\n",
      "        [-0.9736],\n",
      "        [-0.9736],\n",
      "        [-0.9736],\n",
      "        [-0.9736],\n",
      "        [-0.9736],\n",
      "        [-0.9736],\n",
      "        [-0.9736],\n",
      "        [ 0.8754],\n",
      "        [-0.9736],\n",
      "        [-0.9736],\n",
      "        [ 0.3687],\n",
      "        [ 0.3687],\n",
      "        [-0.2072],\n",
      "        [-0.9736],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [-0.2072],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [-0.6662],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [-0.2072],\n",
      "        [-0.9736],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [ 0.8754],\n",
      "        [-0.9736],\n",
      "        [ 0.3687],\n",
      "        [-0.2072],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194]], dtype=torch.float64)\n",
      "Finished episode 820 Average rewards:  16.8\n",
      "Monitored episode 50 Average Monitored rewards:  44.96\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2562637  1.0155367  0.8497236  1.9995149 -0.1081069  1.8641111\n",
      "  1.7464267  0.7518858]\n",
      "Enc\n",
      "[0.90250117 0.68385714]\n",
      "tensor([[-0.1266],\n",
      "        [-0.0594],\n",
      "        [-0.0594],\n",
      "        [-0.7323],\n",
      "        [-0.9860],\n",
      "        [-0.1266],\n",
      "        [-0.9860],\n",
      "        [-0.9860],\n",
      "        [ 0.2991],\n",
      "        [-0.9860],\n",
      "        [ 0.9074],\n",
      "        [-0.9860],\n",
      "        [-0.9860],\n",
      "        [-0.9860],\n",
      "        [-0.9860],\n",
      "        [ 0.2991],\n",
      "        [ 0.2991],\n",
      "        [ 0.2991],\n",
      "        [ 0.2991],\n",
      "        [ 0.2991],\n",
      "        [ 0.9074],\n",
      "        [ 0.9074],\n",
      "        [-0.9860],\n",
      "        [-0.1266],\n",
      "        [-0.9860],\n",
      "        [-0.9860],\n",
      "        [ 0.2991],\n",
      "        [ 0.2991],\n",
      "        [-0.9860],\n",
      "        [-0.1266],\n",
      "        [-0.1266],\n",
      "        [-0.9860],\n",
      "        [-0.9860],\n",
      "        [-0.9860],\n",
      "        [ 0.2991],\n",
      "        [ 0.2991],\n",
      "        [ 0.2991],\n",
      "        [ 0.2991],\n",
      "        [ 0.2991],\n",
      "        [-0.1266],\n",
      "        [-0.1266],\n",
      "        [-0.9860],\n",
      "        [ 0.2991],\n",
      "        [ 0.2991],\n",
      "        [-0.1266],\n",
      "        [-0.1266],\n",
      "        [-0.9860],\n",
      "        [-0.9860],\n",
      "        [-0.9860],\n",
      "        [-0.9860]], dtype=torch.float64)\n",
      "Finished episode 825 Average rewards:  82.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2734848   1.0155826   0.8622285   1.9995474  -0.08812084  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8852984 0.6963621]\n",
      "tensor([[-0.1078],\n",
      "        [-0.9876],\n",
      "        [-0.9876],\n",
      "        [-0.9876],\n",
      "        [-0.9876],\n",
      "        [-0.9876],\n",
      "        [-0.9876],\n",
      "        [-0.9876],\n",
      "        [-0.9876],\n",
      "        [-0.9876],\n",
      "        [ 0.9065],\n",
      "        [-0.9876],\n",
      "        [-0.9876],\n",
      "        [-0.9876],\n",
      "        [ 0.2731],\n",
      "        [ 0.2731],\n",
      "        [ 0.2731],\n",
      "        [ 0.2731],\n",
      "        [-0.1078],\n",
      "        [-0.0676],\n",
      "        [ 0.9065],\n",
      "        [-0.0676],\n",
      "        [-0.0676],\n",
      "        [-0.0676],\n",
      "        [-0.0676],\n",
      "        [-0.7410],\n",
      "        [-0.0676],\n",
      "        [-0.0676],\n",
      "        [-0.0676],\n",
      "        [-0.0676],\n",
      "        [ 0.9065],\n",
      "        [-0.9876],\n",
      "        [-0.9876],\n",
      "        [-0.9876],\n",
      "        [-0.9876],\n",
      "        [-0.9876],\n",
      "        [-0.9876],\n",
      "        [ 0.2731],\n",
      "        [ 0.2731],\n",
      "        [ 0.2731],\n",
      "        [ 0.9065],\n",
      "        [-0.9876],\n",
      "        [-0.9876],\n",
      "        [ 0.2731],\n",
      "        [ 0.2731],\n",
      "        [-0.1078],\n",
      "        [-0.0676],\n",
      "        [-0.0676],\n",
      "        [-0.0676],\n",
      "        [-0.0676]], dtype=torch.float64)\n",
      "Finished episode 830 Average rewards:  39.0\n",
      "Monitored episode 50 Average Monitored rewards:  50.46\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2835205   1.0151983   0.8640781   1.9995863  -0.07063342  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8752965 0.6982117]\n",
      "tensor([[-0.1844],\n",
      "        [-0.0106],\n",
      "        [-0.0106],\n",
      "        [-0.6925],\n",
      "        [-0.6925],\n",
      "        [ 0.8944],\n",
      "        [-0.9815],\n",
      "        [-0.9815],\n",
      "        [-0.9815],\n",
      "        [-0.9815],\n",
      "        [ 0.8944],\n",
      "        [-0.9815],\n",
      "        [-0.0106],\n",
      "        [ 0.8944],\n",
      "        [-0.0106],\n",
      "        [ 0.8944],\n",
      "        [ 0.8944],\n",
      "        [-0.9815],\n",
      "        [-0.0106],\n",
      "        [-0.0106],\n",
      "        [ 0.8944],\n",
      "        [-0.9815],\n",
      "        [-0.9815],\n",
      "        [-0.9815],\n",
      "        [ 0.3556],\n",
      "        [ 0.3556],\n",
      "        [-0.1844],\n",
      "        [-0.1844],\n",
      "        [-0.9815],\n",
      "        [-0.9815],\n",
      "        [ 0.8944],\n",
      "        [-0.0106],\n",
      "        [-0.0106],\n",
      "        [-0.6925],\n",
      "        [ 0.8944],\n",
      "        [-0.9815],\n",
      "        [-0.1844],\n",
      "        [-0.0106],\n",
      "        [-0.0106],\n",
      "        [-0.0106],\n",
      "        [-0.1844],\n",
      "        [-0.9815],\n",
      "        [-0.9815],\n",
      "        [-0.9815],\n",
      "        [-0.9815],\n",
      "        [ 0.3556],\n",
      "        [ 0.3556],\n",
      "        [ 0.3556],\n",
      "        [ 0.3556],\n",
      "        [ 0.3556]], dtype=torch.float64)\n",
      "Finished episode 835 Average rewards:  82.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2709976   1.0144409   0.8530286   1.9996002  -0.09659399  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8878497 0.6871622]\n",
      "tensor([[-0.2393],\n",
      "        [-0.9795],\n",
      "        [-0.9795],\n",
      "        [ 0.4030],\n",
      "        [ 0.0394],\n",
      "        [ 0.0394],\n",
      "        [ 0.0394],\n",
      "        [ 0.0394],\n",
      "        [ 0.0394],\n",
      "        [ 0.0394],\n",
      "        [ 0.8822],\n",
      "        [ 0.0394],\n",
      "        [ 0.0394],\n",
      "        [ 0.0394],\n",
      "        [ 0.0394],\n",
      "        [ 0.0394],\n",
      "        [ 0.0394],\n",
      "        [ 0.0394],\n",
      "        [ 0.0394],\n",
      "        [ 0.0394],\n",
      "        [-0.2393],\n",
      "        [-0.9795],\n",
      "        [-0.9795],\n",
      "        [-0.9795],\n",
      "        [-0.9795],\n",
      "        [-0.9795],\n",
      "        [-0.9795],\n",
      "        [ 0.4030],\n",
      "        [ 0.4030],\n",
      "        [ 0.4030],\n",
      "        [ 0.8822],\n",
      "        [-0.9795],\n",
      "        [-0.9795],\n",
      "        [-0.2393],\n",
      "        [ 0.0394],\n",
      "        [-0.6512],\n",
      "        [-0.9795],\n",
      "        [-0.9795],\n",
      "        [-0.9795],\n",
      "        [-0.9795],\n",
      "        [-0.2393],\n",
      "        [ 0.0394],\n",
      "        [ 0.8822],\n",
      "        [-0.9795],\n",
      "        [-0.9795],\n",
      "        [ 0.4030],\n",
      "        [-0.2393],\n",
      "        [ 0.0394],\n",
      "        [ 0.0394],\n",
      "        [ 0.0394]], dtype=torch.float64)\n",
      "Finished episode 840 Average rewards:  38.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  53.46\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2934682   1.0143791   0.8686263   1.9996449  -0.06032137  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.86540544 0.70276   ]\n",
      "tensor([[-0.1606],\n",
      "        [-0.0347],\n",
      "        [-0.0347],\n",
      "        [-0.7155],\n",
      "        [-0.7155],\n",
      "        [-0.0347],\n",
      "        [-0.0347],\n",
      "        [-0.0347],\n",
      "        [-0.0347],\n",
      "        [-0.0347],\n",
      "        [-0.1606],\n",
      "        [-0.1606],\n",
      "        [-0.9905],\n",
      "        [-0.1606],\n",
      "        [-0.0347],\n",
      "        [-0.9905],\n",
      "        [-0.0347],\n",
      "        [-0.0347],\n",
      "        [-0.7155],\n",
      "        [-0.0347],\n",
      "        [-0.1606],\n",
      "        [-0.9905],\n",
      "        [-0.0347],\n",
      "        [-0.9905],\n",
      "        [-0.9905],\n",
      "        [-0.9905],\n",
      "        [-0.9905],\n",
      "        [ 0.3362],\n",
      "        [ 0.3362],\n",
      "        [ 0.3362],\n",
      "        [ 0.9088],\n",
      "        [ 0.9088],\n",
      "        [-0.9905],\n",
      "        [-0.1606],\n",
      "        [-0.0347],\n",
      "        [-0.7155],\n",
      "        [ 0.9088],\n",
      "        [-0.9905],\n",
      "        [-0.9905],\n",
      "        [-0.9905],\n",
      "        [-0.1606],\n",
      "        [-0.0347],\n",
      "        [-0.0347],\n",
      "        [-0.7155],\n",
      "        [-0.9905],\n",
      "        [-0.9905],\n",
      "        [-0.9905],\n",
      "        [-0.9905],\n",
      "        [ 0.3362],\n",
      "        [-0.0347]], dtype=torch.float64)\n",
      "Finished episode 845 Average rewards:  38.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2833922   1.0138688   0.8631744   1.9996555  -0.07756373  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8755016 0.697308 ]\n",
      "tensor([[ 0.8766],\n",
      "        [-0.9750],\n",
      "        [-0.2758],\n",
      "        [ 0.0689],\n",
      "        [ 0.0689],\n",
      "        [ 0.0689],\n",
      "        [ 0.0689],\n",
      "        [ 0.0689],\n",
      "        [ 0.0689],\n",
      "        [ 0.0689],\n",
      "        [-0.2758],\n",
      "        [ 0.0689],\n",
      "        [ 0.0689],\n",
      "        [ 0.0689],\n",
      "        [ 0.0689],\n",
      "        [ 0.0689],\n",
      "        [ 0.0689],\n",
      "        [ 0.0689],\n",
      "        [ 0.0689],\n",
      "        [ 0.0689],\n",
      "        [-0.2758],\n",
      "        [-0.2758],\n",
      "        [ 0.0689],\n",
      "        [ 0.0689],\n",
      "        [ 0.0689],\n",
      "        [ 0.0689],\n",
      "        [ 0.0689],\n",
      "        [ 0.0689],\n",
      "        [ 0.0689],\n",
      "        [ 0.0689],\n",
      "        [ 0.8766],\n",
      "        [ 0.8766],\n",
      "        [-0.9750],\n",
      "        [-0.9750],\n",
      "        [-0.9750],\n",
      "        [-0.9750],\n",
      "        [-0.2758],\n",
      "        [ 0.0689],\n",
      "        [ 0.0689],\n",
      "        [ 0.0689],\n",
      "        [ 0.8766],\n",
      "        [ 0.8766],\n",
      "        [-0.9750],\n",
      "        [-0.9750],\n",
      "        [-0.9750],\n",
      "        [-0.9750],\n",
      "        [-0.9750],\n",
      "        [ 0.4342],\n",
      "        [ 0.4342],\n",
      "        [ 0.4342]], dtype=torch.float64)\n",
      "Finished episode 850 Average rewards:  -5.8\n",
      "Monitored episode 50 Average Monitored rewards:  36.04\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2720972   1.013323    0.86203027  1.9996668  -0.09176484  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88681513 0.6961639 ]\n",
      "tensor([[-0.2238],\n",
      "        [-0.2238],\n",
      "        [-0.9819],\n",
      "        [-0.2238],\n",
      "        [ 0.0197],\n",
      "        [ 0.0197],\n",
      "        [ 0.0197],\n",
      "        [ 0.0197],\n",
      "        [ 0.0197],\n",
      "        [ 0.0197],\n",
      "        [ 0.8924],\n",
      "        [-0.9819],\n",
      "        [-0.9819],\n",
      "        [-0.9819],\n",
      "        [ 0.3942],\n",
      "        [ 0.3942],\n",
      "        [ 0.3942],\n",
      "        [ 0.3942],\n",
      "        [ 0.3942],\n",
      "        [ 0.3942],\n",
      "        [-0.2238],\n",
      "        [-0.9819],\n",
      "        [-0.9819],\n",
      "        [ 0.3942],\n",
      "        [-0.2238],\n",
      "        [ 0.0197],\n",
      "        [ 0.0197],\n",
      "        [ 0.0197],\n",
      "        [ 0.0197],\n",
      "        [ 0.0197],\n",
      "        [-0.2238],\n",
      "        [-0.9819],\n",
      "        [-0.2238],\n",
      "        [ 0.0197],\n",
      "        [ 0.0197],\n",
      "        [ 0.0197],\n",
      "        [ 0.0197],\n",
      "        [ 0.0197],\n",
      "        [ 0.0197],\n",
      "        [ 0.0197],\n",
      "        [ 0.8924],\n",
      "        [ 0.8924],\n",
      "        [-0.9819],\n",
      "        [-0.9819],\n",
      "        [-0.9819],\n",
      "        [ 0.3942],\n",
      "        [ 0.3942],\n",
      "        [ 0.3942],\n",
      "        [-0.2238],\n",
      "        [-0.9819]], dtype=torch.float64)\n",
      "Finished episode 855 Average rewards:  16.0\n",
      "len_game 53\n",
      "Rot\n",
      "[ 1.2822977   1.0130134   0.86494607  1.9996952  -0.07334881  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.87663853 0.6990797 ]\n",
      "tensor([[ 0.8977],\n",
      "        [-0.9821],\n",
      "        [-0.0209],\n",
      "        [-0.9821],\n",
      "        [-0.0209],\n",
      "        [-0.0209],\n",
      "        [-0.0209],\n",
      "        [-0.7010],\n",
      "        [-0.7010],\n",
      "        [-0.0209],\n",
      "        [ 0.8977],\n",
      "        [-0.9821],\n",
      "        [-0.0209],\n",
      "        [-0.0209],\n",
      "        [ 0.8977],\n",
      "        [-0.0209],\n",
      "        [-0.0209],\n",
      "        [-0.0209],\n",
      "        [-0.0209],\n",
      "        [-0.7010],\n",
      "        [ 0.8977],\n",
      "        [-0.0209],\n",
      "        [-0.0209],\n",
      "        [-0.0209],\n",
      "        [ 0.8977],\n",
      "        [ 0.8977],\n",
      "        [-0.0209],\n",
      "        [-0.0209],\n",
      "        [-0.7010],\n",
      "        [ 0.8977],\n",
      "        [ 0.8977],\n",
      "        [ 0.8977],\n",
      "        [-0.1736],\n",
      "        [-0.9821],\n",
      "        [-0.9821],\n",
      "        [-0.9821],\n",
      "        [ 0.3464],\n",
      "        [ 0.3464],\n",
      "        [ 0.3464],\n",
      "        [ 0.3464],\n",
      "        [-0.1736],\n",
      "        [-0.1736],\n",
      "        [-0.1736],\n",
      "        [-0.1736],\n",
      "        [-0.1736],\n",
      "        [-0.0209],\n",
      "        [-0.0209],\n",
      "        [-0.7010],\n",
      "        [-0.7010],\n",
      "        [-0.7010],\n",
      "        [-0.9821],\n",
      "        [-0.9821],\n",
      "        [-0.9821]], dtype=torch.float64)\n",
      "Finished episode 860 Average rewards:  39.0\n",
      "Monitored episode 50 Average Monitored rewards:  39.48\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2727721   1.0125269   0.8576781   1.9997028  -0.09246294  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8861806 0.6918118]\n",
      "tensor([[ 0.8836],\n",
      "        [-0.9788],\n",
      "        [-0.9788],\n",
      "        [-0.9788],\n",
      "        [ 0.3968],\n",
      "        [ 0.3968],\n",
      "        [-0.9788],\n",
      "        [-0.9788],\n",
      "        [ 0.3968],\n",
      "        [ 0.3968],\n",
      "        [-0.2315],\n",
      "        [-0.9788],\n",
      "        [-0.9788],\n",
      "        [-0.9788],\n",
      "        [-0.9788],\n",
      "        [-0.9788],\n",
      "        [-0.9788],\n",
      "        [-0.9788],\n",
      "        [ 0.3968],\n",
      "        [ 0.3968],\n",
      "        [ 0.8836],\n",
      "        [-0.9788],\n",
      "        [ 0.3968],\n",
      "        [-0.2315],\n",
      "        [ 0.0318],\n",
      "        [ 0.0318],\n",
      "        [ 0.0318],\n",
      "        [ 0.0318],\n",
      "        [ 0.0318],\n",
      "        [ 0.0318],\n",
      "        [ 0.8836],\n",
      "        [ 0.8836],\n",
      "        [ 0.8836],\n",
      "        [-0.9788],\n",
      "        [ 0.3968],\n",
      "        [ 0.0318],\n",
      "        [ 0.0318],\n",
      "        [ 0.0318],\n",
      "        [ 0.0318],\n",
      "        [ 0.0318],\n",
      "        [ 0.8836],\n",
      "        [-0.9788],\n",
      "        [-0.9788],\n",
      "        [ 0.3968],\n",
      "        [ 0.3968],\n",
      "        [ 0.3968],\n",
      "        [ 0.3968],\n",
      "        [-0.9788],\n",
      "        [-0.9788],\n",
      "        [-0.9788]], dtype=torch.float64)\n",
      "Finished episode 865 Average rewards:  61.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.279338    1.0123662   0.86128855  1.9997196  -0.07507458  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.87962717 0.69542223]\n",
      "tensor([[-0.1731],\n",
      "        [-0.0228],\n",
      "        [-0.0228],\n",
      "        [-0.7047],\n",
      "        [-0.7047],\n",
      "        [-0.7047],\n",
      "        [-0.0228],\n",
      "        [-0.0228],\n",
      "        [-0.7047],\n",
      "        [-0.0228],\n",
      "        [-0.1731],\n",
      "        [-0.0228],\n",
      "        [ 0.9028],\n",
      "        [-0.9867],\n",
      "        [-0.9867],\n",
      "        [-0.9867],\n",
      "        [-0.9867],\n",
      "        [-0.9867],\n",
      "        [-0.9867],\n",
      "        [-0.9867],\n",
      "        [ 0.9028],\n",
      "        [-0.9867],\n",
      "        [-0.9867],\n",
      "        [ 0.3472],\n",
      "        [-0.1731],\n",
      "        [-0.1731],\n",
      "        [-0.9867],\n",
      "        [-0.0228],\n",
      "        [ 0.9028],\n",
      "        [-0.9867],\n",
      "        [ 0.9028],\n",
      "        [-0.0228],\n",
      "        [-0.0228],\n",
      "        [-0.0228],\n",
      "        [-0.0228],\n",
      "        [-0.7047],\n",
      "        [-0.0228],\n",
      "        [-0.0228],\n",
      "        [-0.0228],\n",
      "        [-0.7047],\n",
      "        [ 0.9028],\n",
      "        [-0.9867],\n",
      "        [-0.9867],\n",
      "        [-0.9867],\n",
      "        [ 0.3472],\n",
      "        [ 0.3472],\n",
      "        [-0.9867],\n",
      "        [-0.9867],\n",
      "        [-0.9867],\n",
      "        [-0.9867]], dtype=torch.float64)\n",
      "Finished episode 870 Average rewards:  61.6\n",
      "Monitored episode 50 Average Monitored rewards:  29.44\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2697157   1.011925    0.85631716  1.9997271  -0.08701184  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88926286 0.69045085]\n",
      "tensor([[-0.2231],\n",
      "        [ 0.0269],\n",
      "        [ 0.0269],\n",
      "        [-0.6635],\n",
      "        [ 0.8853],\n",
      "        [ 0.8853],\n",
      "        [-0.9820],\n",
      "        [-0.9820],\n",
      "        [-0.9820],\n",
      "        [-0.9820],\n",
      "        [-0.2231],\n",
      "        [-0.2231],\n",
      "        [ 0.0269],\n",
      "        [ 0.0269],\n",
      "        [ 0.0269],\n",
      "        [-0.6635],\n",
      "        [ 0.0269],\n",
      "        [-0.6635],\n",
      "        [-0.6635],\n",
      "        [-0.6635],\n",
      "        [-0.2231],\n",
      "        [-0.2231],\n",
      "        [ 0.0269],\n",
      "        [ 0.0269],\n",
      "        [ 0.0269],\n",
      "        [ 0.0269],\n",
      "        [-0.6635],\n",
      "        [-0.6635],\n",
      "        [ 0.0269],\n",
      "        [-0.6635],\n",
      "        [-0.2231],\n",
      "        [ 0.0269],\n",
      "        [ 0.0269],\n",
      "        [ 0.0269],\n",
      "        [ 0.0269],\n",
      "        [ 0.0269],\n",
      "        [ 0.0269],\n",
      "        [ 0.0269],\n",
      "        [ 0.0269],\n",
      "        [ 0.0269],\n",
      "        [-0.2231],\n",
      "        [-0.9820],\n",
      "        [-0.9820],\n",
      "        [ 0.3878],\n",
      "        [ 0.3878],\n",
      "        [ 0.3878],\n",
      "        [-0.2231],\n",
      "        [-0.9820],\n",
      "        [-0.9820],\n",
      "        [-0.9820]], dtype=torch.float64)\n",
      "Finished episode 875 Average rewards:  39.8\n",
      "len_game 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[ 1.2803793   1.0120351   0.87437534  1.9997429  -0.05243552  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.878602 0.708509]\n",
      "tensor([[ 0.8925],\n",
      "        [-0.9849],\n",
      "        [-0.1807],\n",
      "        [-0.0072],\n",
      "        [-0.6932],\n",
      "        [-0.9849],\n",
      "        [-0.9849],\n",
      "        [ 0.3469],\n",
      "        [ 0.3469],\n",
      "        [-0.9849],\n",
      "        [-0.1807],\n",
      "        [-0.0072],\n",
      "        [-0.0072],\n",
      "        [-0.6932],\n",
      "        [-0.6932],\n",
      "        [-0.0072],\n",
      "        [-0.0072],\n",
      "        [-0.0072],\n",
      "        [-0.6932],\n",
      "        [-0.6932],\n",
      "        [ 0.8925],\n",
      "        [-0.9849],\n",
      "        [-0.0072],\n",
      "        [-0.9849],\n",
      "        [-0.9849],\n",
      "        [-0.9849],\n",
      "        [-0.9849],\n",
      "        [-0.9849],\n",
      "        [-0.9849],\n",
      "        [-0.9849],\n",
      "        [-0.1807],\n",
      "        [-0.0072],\n",
      "        [-0.0072],\n",
      "        [-0.0072],\n",
      "        [-0.0072],\n",
      "        [-0.6932],\n",
      "        [-0.6932],\n",
      "        [-0.0072],\n",
      "        [-0.6932],\n",
      "        [-0.0072],\n",
      "        [-0.1807],\n",
      "        [-0.0072],\n",
      "        [-0.0072],\n",
      "        [-0.0072],\n",
      "        [-0.6932],\n",
      "        [-0.6932],\n",
      "        [-0.0072],\n",
      "        [-0.0072],\n",
      "        [-0.0072],\n",
      "        [-0.6932]], dtype=torch.float64)\n",
      "Finished episode 880 Average rewards:  39.0\n",
      "Monitored episode 50 Average Monitored rewards:  28.98\n",
      "len_game 52\n",
      "Rot\n",
      "[ 1.269691    1.0115346   0.8565116   1.9997483  -0.07577016  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8893057 0.6906453]\n",
      "tensor([[ 0.8395],\n",
      "        [-0.9578],\n",
      "        [-0.9578],\n",
      "        [-0.9578],\n",
      "        [ 0.4181],\n",
      "        [ 0.4181],\n",
      "        [ 0.4181],\n",
      "        [-0.2745],\n",
      "        [ 0.0914],\n",
      "        [ 0.0914],\n",
      "        [-0.2745],\n",
      "        [-0.9578],\n",
      "        [-0.9578],\n",
      "        [-0.9578],\n",
      "        [-0.9578],\n",
      "        [ 0.4181],\n",
      "        [ 0.4181],\n",
      "        [ 0.4181],\n",
      "        [ 0.4181],\n",
      "        [-0.2745],\n",
      "        [-0.2745],\n",
      "        [-0.2745],\n",
      "        [-0.9578],\n",
      "        [-0.9578],\n",
      "        [-0.9578],\n",
      "        [ 0.4181],\n",
      "        [ 0.4181],\n",
      "        [ 0.4181],\n",
      "        [ 0.4181],\n",
      "        [-0.9578],\n",
      "        [-0.2745],\n",
      "        [-0.2745],\n",
      "        [-0.9578],\n",
      "        [-0.9578],\n",
      "        [ 0.4181],\n",
      "        [ 0.4181],\n",
      "        [ 0.4181],\n",
      "        [ 0.4181],\n",
      "        [ 0.4181],\n",
      "        [-0.2745],\n",
      "        [-0.9578],\n",
      "        [-0.2745],\n",
      "        [ 0.8395],\n",
      "        [-0.9578],\n",
      "        [-0.9578],\n",
      "        [-0.9578],\n",
      "        [-0.9578],\n",
      "        [-0.9578],\n",
      "        [-0.9578],\n",
      "        [ 0.4181],\n",
      "        [ 0.4181],\n",
      "        [ 0.4181]], dtype=torch.float64)\n",
      "Finished episode 885 Average rewards:  58.8\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.261663    1.0111681   0.851404    1.9997534  -0.08814407  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8973436  0.68553764]\n",
      "tensor([[-0.2066],\n",
      "        [-0.9804],\n",
      "        [-0.9804],\n",
      "        [ 0.3635],\n",
      "        [ 0.3635],\n",
      "        [ 0.3635],\n",
      "        [ 0.3635],\n",
      "        [-0.2066],\n",
      "        [-0.9804],\n",
      "        [-0.9804],\n",
      "        [-0.2066],\n",
      "        [-0.9804],\n",
      "        [-0.9804],\n",
      "        [-0.9804],\n",
      "        [-0.9804],\n",
      "        [-0.9804],\n",
      "        [ 0.3635],\n",
      "        [ 0.3635],\n",
      "        [ 0.3635],\n",
      "        [ 0.3635],\n",
      "        [-0.2066],\n",
      "        [ 0.0249],\n",
      "        [ 0.0249],\n",
      "        [ 0.0249],\n",
      "        [ 0.0249],\n",
      "        [ 0.0249],\n",
      "        [ 0.0249],\n",
      "        [ 0.0249],\n",
      "        [-0.6674],\n",
      "        [ 0.0249],\n",
      "        [-0.2066],\n",
      "        [-0.9804],\n",
      "        [-0.9804],\n",
      "        [-0.2066],\n",
      "        [-0.9804],\n",
      "        [ 0.0249],\n",
      "        [ 0.0249],\n",
      "        [ 0.0249],\n",
      "        [ 0.0249],\n",
      "        [ 0.0249],\n",
      "        [ 0.8764],\n",
      "        [-0.9804],\n",
      "        [-0.9804],\n",
      "        [-0.9804],\n",
      "        [-0.9804],\n",
      "        [-0.9804],\n",
      "        [-0.9804],\n",
      "        [-0.9804],\n",
      "        [-0.9804],\n",
      "        [ 0.3635]], dtype=torch.float64)\n",
      "Finished episode 890 Average rewards:  61.2\n",
      "Monitored episode 50 Average Monitored rewards:  48.56\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2765613   1.0111197   0.8652838   1.9997735  -0.05740282  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88245624 0.6994174 ]\n",
      "tensor([[-0.1648],\n",
      "        [-0.0104],\n",
      "        [-0.0104],\n",
      "        [-0.6977],\n",
      "        [-0.0104],\n",
      "        [-0.0104],\n",
      "        [-0.0104],\n",
      "        [-0.0104],\n",
      "        [-0.0104],\n",
      "        [-0.0104],\n",
      "        [-0.1648],\n",
      "        [-0.0104],\n",
      "        [ 0.8859],\n",
      "        [-0.9827],\n",
      "        [-0.9827],\n",
      "        [-0.9827],\n",
      "        [-0.9827],\n",
      "        [-0.9827],\n",
      "        [-0.9827],\n",
      "        [-0.9827],\n",
      "        [ 0.8859],\n",
      "        [ 0.8859],\n",
      "        [ 0.8859],\n",
      "        [ 0.8859],\n",
      "        [-0.9827],\n",
      "        [-0.9827],\n",
      "        [-0.9827],\n",
      "        [ 0.3230],\n",
      "        [ 0.3230],\n",
      "        [-0.1648],\n",
      "        [ 0.8859],\n",
      "        [-0.9827],\n",
      "        [-0.9827],\n",
      "        [-0.0104],\n",
      "        [-0.6977],\n",
      "        [-0.0104],\n",
      "        [-0.6977],\n",
      "        [ 0.8859],\n",
      "        [-0.9827],\n",
      "        [-0.9827],\n",
      "        [-0.1648],\n",
      "        [-0.1648],\n",
      "        [-0.0104],\n",
      "        [-0.6977],\n",
      "        [-0.0104],\n",
      "        [-0.0104],\n",
      "        [-0.6977],\n",
      "        [-0.6977],\n",
      "        [-0.9827],\n",
      "        [-0.1648],\n",
      "        [-0.0104]], dtype=torch.float64)\n",
      "Finished episode 895 Average rewards:  59.4\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2662823   1.0106555   0.85441035  1.9997798  -0.07797815  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.89274806 0.688544  ]\n",
      "tensor([[ 0.8515],\n",
      "        [ 0.8515],\n",
      "        [ 0.8515],\n",
      "        [-0.9691],\n",
      "        [-0.9691],\n",
      "        [ 0.0773],\n",
      "        [ 0.8515],\n",
      "        [ 0.8515],\n",
      "        [-0.9691],\n",
      "        [ 0.0773],\n",
      "        [ 0.8515],\n",
      "        [-0.9691],\n",
      "        [-0.2582],\n",
      "        [-0.2582],\n",
      "        [-0.9691],\n",
      "        [-0.9691],\n",
      "        [-0.9691],\n",
      "        [-0.9691],\n",
      "        [ 0.4043],\n",
      "        [-0.9691],\n",
      "        [ 0.8515],\n",
      "        [-0.9691],\n",
      "        [-0.2582],\n",
      "        [-0.9691],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.8515],\n",
      "        [-0.9691],\n",
      "        [-0.9691],\n",
      "        [-0.9691],\n",
      "        [-0.9691],\n",
      "        [-0.9691],\n",
      "        [-0.9691],\n",
      "        [ 0.4043],\n",
      "        [-0.9691],\n",
      "        [-0.9691],\n",
      "        [-0.2582],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773],\n",
      "        [ 0.0773]], dtype=torch.float64)\n",
      "Finished episode 900 Average rewards:  38.8\n",
      "Monitored episode 50 Average Monitored rewards:  45.48\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2536677   1.0100304   0.8461322   1.9997883  -0.10574474  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9053788 0.6802659]\n",
      "tensor([[-0.1961],\n",
      "        [ 0.0186],\n",
      "        [ 0.0186],\n",
      "        [ 0.0186],\n",
      "        [-0.6735],\n",
      "        [-0.9801],\n",
      "        [-0.9801],\n",
      "        [-0.9801],\n",
      "        [-0.9801],\n",
      "        [ 0.3515],\n",
      "        [ 0.8760],\n",
      "        [-0.9801],\n",
      "        [-0.1961],\n",
      "        [ 0.0186],\n",
      "        [ 0.0186],\n",
      "        [ 0.0186],\n",
      "        [ 0.0186],\n",
      "        [ 0.0186],\n",
      "        [ 0.0186],\n",
      "        [ 0.0186],\n",
      "        [-0.1961],\n",
      "        [-0.9801],\n",
      "        [-0.1961],\n",
      "        [ 0.0186],\n",
      "        [ 0.0186],\n",
      "        [ 0.0186],\n",
      "        [ 0.0186],\n",
      "        [ 0.0186],\n",
      "        [-0.6735],\n",
      "        [-0.6735],\n",
      "        [ 0.8760],\n",
      "        [-0.9801],\n",
      "        [-0.9801],\n",
      "        [ 0.3515],\n",
      "        [ 0.3515],\n",
      "        [ 0.3515],\n",
      "        [-0.1961],\n",
      "        [ 0.0186],\n",
      "        [ 0.0186],\n",
      "        [ 0.0186],\n",
      "        [ 0.8760],\n",
      "        [-0.9801],\n",
      "        [-0.1961],\n",
      "        [-0.9801],\n",
      "        [-0.9801],\n",
      "        [-0.9801],\n",
      "        [-0.9801],\n",
      "        [-0.9801],\n",
      "        [-0.9801],\n",
      "        [-0.9801]], dtype=torch.float64)\n",
      "Finished episode 905 Average rewards:  39.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2677662   1.0100304   0.85538375  1.9998012  -0.08278528  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8912872  0.68951744]\n",
      "tensor([[ 0.9016],\n",
      "        [-0.9865],\n",
      "        [-0.9865],\n",
      "        [-0.9865],\n",
      "        [-0.9865],\n",
      "        [ 0.2686],\n",
      "        [ 0.2686],\n",
      "        [ 0.2686],\n",
      "        [ 0.2686],\n",
      "        [ 0.2686],\n",
      "        [ 0.9016],\n",
      "        [-0.9865],\n",
      "        [ 0.2686],\n",
      "        [-0.1088],\n",
      "        [-0.9865],\n",
      "        [-0.9865],\n",
      "        [-0.0606],\n",
      "        [-0.0606],\n",
      "        [-0.7376],\n",
      "        [-0.9865],\n",
      "        [-0.1088],\n",
      "        [-0.1088],\n",
      "        [-0.0606],\n",
      "        [-0.0606],\n",
      "        [-0.0606],\n",
      "        [-0.0606],\n",
      "        [-0.0606],\n",
      "        [-0.0606],\n",
      "        [-0.0606],\n",
      "        [-0.0606],\n",
      "        [-0.1088],\n",
      "        [-0.9865],\n",
      "        [-0.9865],\n",
      "        [ 0.2686],\n",
      "        [ 0.2686],\n",
      "        [-0.9865],\n",
      "        [-0.9865],\n",
      "        [-0.9865],\n",
      "        [-0.9865],\n",
      "        [-0.9865],\n",
      "        [-0.1088],\n",
      "        [-0.0606],\n",
      "        [-0.0606],\n",
      "        [-0.0606],\n",
      "        [-0.7376],\n",
      "        [-0.0606],\n",
      "        [-0.7376],\n",
      "        [-0.7376],\n",
      "        [-0.0606],\n",
      "        [-0.0606]], dtype=torch.float64)\n",
      "Finished episode 910 Average rewards:  56.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  38.08\n",
      "len_game 52\n",
      "Rot\n",
      "[ 1.2532908  1.0094526  0.8424135  1.9998069 -0.1050811  1.8641111\n",
      "  1.7464267  0.7518858]\n",
      "Enc\n",
      "[0.90577585 0.6765472 ]\n",
      "tensor([[ 0.8846],\n",
      "        [-0.9828],\n",
      "        [-0.9828],\n",
      "        [-0.9828],\n",
      "        [-0.9828],\n",
      "        [ 0.3480],\n",
      "        [ 0.3480],\n",
      "        [-0.1873],\n",
      "        [ 0.0049],\n",
      "        [ 0.0049],\n",
      "        [-0.1873],\n",
      "        [-0.9828],\n",
      "        [-0.1873],\n",
      "        [-0.9828],\n",
      "        [ 0.3480],\n",
      "        [-0.1873],\n",
      "        [ 0.0049],\n",
      "        [ 0.0049],\n",
      "        [ 0.0049],\n",
      "        [ 0.0049],\n",
      "        [ 0.8846],\n",
      "        [-0.9828],\n",
      "        [-0.9828],\n",
      "        [ 0.3480],\n",
      "        [ 0.3480],\n",
      "        [ 0.3480],\n",
      "        [ 0.3480],\n",
      "        [-0.1873],\n",
      "        [-0.9828],\n",
      "        [-0.9828],\n",
      "        [ 0.8846],\n",
      "        [ 0.8846],\n",
      "        [-0.9828],\n",
      "        [-0.9828],\n",
      "        [ 0.3480],\n",
      "        [ 0.3480],\n",
      "        [-0.1873],\n",
      "        [-0.1873],\n",
      "        [-0.9828],\n",
      "        [-0.9828],\n",
      "        [ 0.8846],\n",
      "        [-0.9828],\n",
      "        [-0.9828],\n",
      "        [-0.9828],\n",
      "        [-0.9828],\n",
      "        [ 0.3480],\n",
      "        [ 0.3480],\n",
      "        [ 0.3480],\n",
      "        [ 0.3480],\n",
      "        [ 0.3480],\n",
      "        [-0.1873],\n",
      "        [-0.1873]], dtype=torch.float64)\n",
      "Finished episode 915 Average rewards:  38.4\n",
      "len_game 52\n",
      "Rot\n",
      "[ 1.2649684   1.0092759   0.8497295   1.9998213  -0.08838487  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8941088  0.68386316]\n",
      "tensor([[-0.1097],\n",
      "        [-0.0587],\n",
      "        [-0.7370],\n",
      "        [-0.7370],\n",
      "        [ 0.9013],\n",
      "        [-0.9873],\n",
      "        [-0.9873],\n",
      "        [-0.1097],\n",
      "        [-0.0587],\n",
      "        [-0.0587],\n",
      "        [-0.1097],\n",
      "        [-0.9873],\n",
      "        [-0.9873],\n",
      "        [-0.9873],\n",
      "        [-0.9873],\n",
      "        [-0.9873],\n",
      "        [ 0.2686],\n",
      "        [ 0.2686],\n",
      "        [ 0.2686],\n",
      "        [ 0.2686],\n",
      "        [ 0.9013],\n",
      "        [-0.9873],\n",
      "        [-0.0587],\n",
      "        [-0.0587],\n",
      "        [-0.0587],\n",
      "        [-0.7370],\n",
      "        [-0.7370],\n",
      "        [-0.0587],\n",
      "        [-0.0587],\n",
      "        [-0.0587],\n",
      "        [-0.1097],\n",
      "        [-0.0587],\n",
      "        [-0.7370],\n",
      "        [-0.7370],\n",
      "        [-0.7370],\n",
      "        [-0.0587],\n",
      "        [-0.7370],\n",
      "        [-0.9873],\n",
      "        [-0.9873],\n",
      "        [-0.9873],\n",
      "        [ 0.9013],\n",
      "        [-0.9873],\n",
      "        [-0.9873],\n",
      "        [-0.9873],\n",
      "        [ 0.2686],\n",
      "        [ 0.2686],\n",
      "        [ 0.2686],\n",
      "        [ 0.2686],\n",
      "        [ 0.2686],\n",
      "        [-0.1097],\n",
      "        [-0.1097],\n",
      "        [-0.1097]], dtype=torch.float64)\n",
      "Finished episode 920 Average rewards:  17.0\n",
      "Monitored episode 50 Average Monitored rewards:  58.72\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2661687   1.0093201   0.86382115  1.999827   -0.06008157  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8929075  0.69795483]\n",
      "tensor([[ 0.8917],\n",
      "        [-0.0110],\n",
      "        [ 0.8917],\n",
      "        [-0.9867],\n",
      "        [-0.9867],\n",
      "        [-0.9867],\n",
      "        [-0.9867],\n",
      "        [-0.9867],\n",
      "        [-0.9867],\n",
      "        [-0.9867],\n",
      "        [-0.1696],\n",
      "        [-0.9867],\n",
      "        [-0.9867],\n",
      "        [-0.9867],\n",
      "        [-0.9867],\n",
      "        [ 0.3317],\n",
      "        [ 0.3317],\n",
      "        [-0.9867],\n",
      "        [ 0.3317],\n",
      "        [ 0.3317],\n",
      "        [-0.1696],\n",
      "        [-0.0110],\n",
      "        [-0.0110],\n",
      "        [-0.0110],\n",
      "        [-0.0110],\n",
      "        [-0.0110],\n",
      "        [-0.0110],\n",
      "        [-0.6989],\n",
      "        [-0.6989],\n",
      "        [-0.6989],\n",
      "        [-0.1696],\n",
      "        [-0.0110],\n",
      "        [-0.0110],\n",
      "        [-0.0110],\n",
      "        [-0.0110],\n",
      "        [-0.0110],\n",
      "        [-0.0110],\n",
      "        [-0.0110],\n",
      "        [-0.0110],\n",
      "        [-0.6989],\n",
      "        [-0.1696],\n",
      "        [-0.1696],\n",
      "        [-0.0110],\n",
      "        [-0.0110],\n",
      "        [-0.0110],\n",
      "        [-0.0110],\n",
      "        [-0.0110],\n",
      "        [-0.6989],\n",
      "        [-0.6989],\n",
      "        [-0.6989]], dtype=torch.float64)\n",
      "Finished episode 925 Average rewards:  38.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2597226  1.0091176  0.8650454  1.9998305 -0.0640667  1.8641111\n",
      "  1.7464267  0.7518858]\n",
      "Enc\n",
      "[0.8993575 0.6991791]\n",
      "tensor([[-0.2372],\n",
      "        [ 0.0697],\n",
      "        [ 0.0697],\n",
      "        [ 0.0697],\n",
      "        [ 0.0697],\n",
      "        [-0.6266],\n",
      "        [ 0.0697],\n",
      "        [-0.6266],\n",
      "        [-0.6266],\n",
      "        [-0.6266],\n",
      "        [ 0.8409],\n",
      "        [ 0.8409],\n",
      "        [-0.9610],\n",
      "        [-0.9610],\n",
      "        [-0.9610],\n",
      "        [-0.9610],\n",
      "        [-0.9610],\n",
      "        [ 0.3780],\n",
      "        [ 0.3780],\n",
      "        [ 0.3780],\n",
      "        [-0.2372],\n",
      "        [ 0.0697],\n",
      "        [ 0.0697],\n",
      "        [ 0.0697],\n",
      "        [ 0.0697],\n",
      "        [ 0.0697],\n",
      "        [ 0.0697],\n",
      "        [ 0.0697],\n",
      "        [ 0.0697],\n",
      "        [ 0.0697],\n",
      "        [ 0.8409],\n",
      "        [-0.9610],\n",
      "        [-0.9610],\n",
      "        [ 0.0697],\n",
      "        [ 0.0697],\n",
      "        [ 0.0697],\n",
      "        [ 0.0697],\n",
      "        [ 0.0697],\n",
      "        [ 0.0697],\n",
      "        [ 0.0697],\n",
      "        [-0.2372],\n",
      "        [-0.9610],\n",
      "        [-0.9610],\n",
      "        [ 0.3780],\n",
      "        [ 0.3780],\n",
      "        [-0.9610],\n",
      "        [ 0.3780],\n",
      "        [ 0.3780],\n",
      "        [ 0.3780],\n",
      "        [-0.9610]], dtype=torch.float64)\n",
      "Finished episode 930 Average rewards:  38.2\n",
      "Monitored episode 50 Average Monitored rewards:  26.46\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.253073    1.0087117   0.8555136   1.9998357  -0.09454135  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.90601665 0.6896473 ]\n",
      "tensor([[-0.2184],\n",
      "        [ 0.0584],\n",
      "        [ 0.0584],\n",
      "        [ 0.0584],\n",
      "        [ 0.0584],\n",
      "        [ 0.0584],\n",
      "        [ 0.0584],\n",
      "        [ 0.0584],\n",
      "        [ 0.0584],\n",
      "        [ 0.0584],\n",
      "        [-0.2184],\n",
      "        [-0.9538],\n",
      "        [ 0.0584],\n",
      "        [ 0.8361],\n",
      "        [ 0.0584],\n",
      "        [ 0.0584],\n",
      "        [ 0.0584],\n",
      "        [ 0.0584],\n",
      "        [ 0.0584],\n",
      "        [ 0.0584],\n",
      "        [-0.2184],\n",
      "        [ 0.0584],\n",
      "        [ 0.0584],\n",
      "        [ 0.0584],\n",
      "        [-0.6355],\n",
      "        [-0.6355],\n",
      "        [-0.9538],\n",
      "        [ 0.0584],\n",
      "        [ 0.0584],\n",
      "        [ 0.0584],\n",
      "        [-0.2184],\n",
      "        [-0.9538],\n",
      "        [-0.2184],\n",
      "        [ 0.0584],\n",
      "        [ 0.0584],\n",
      "        [ 0.0584],\n",
      "        [ 0.0584],\n",
      "        [ 0.0584],\n",
      "        [ 0.0584],\n",
      "        [ 0.0584],\n",
      "        [-0.2184],\n",
      "        [ 0.0584],\n",
      "        [-0.6355],\n",
      "        [-0.6355],\n",
      "        [ 0.0584],\n",
      "        [ 0.0584],\n",
      "        [ 0.0584],\n",
      "        [-0.6355],\n",
      "        [-0.6355],\n",
      "        [-0.9538]], dtype=torch.float64)\n",
      "Finished episode 935 Average rewards:  15.6\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2611226   1.0087435   0.8686513   1.9998432  -0.07336117  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8979692 0.702785 ]\n",
      "tensor([[ 0.8806],\n",
      "        [-0.9745],\n",
      "        [-0.9745],\n",
      "        [-0.9745],\n",
      "        [-0.9745],\n",
      "        [-0.9745],\n",
      "        [-0.9745],\n",
      "        [ 0.2869],\n",
      "        [ 0.2869],\n",
      "        [ 0.2869],\n",
      "        [ 0.8806],\n",
      "        [-0.9745],\n",
      "        [-0.9745],\n",
      "        [-0.9745],\n",
      "        [-0.9745],\n",
      "        [ 0.2869],\n",
      "        [-0.9745],\n",
      "        [ 0.2869],\n",
      "        [ 0.2869],\n",
      "        [ 0.2869],\n",
      "        [-0.1350],\n",
      "        [-0.9745],\n",
      "        [-0.9745],\n",
      "        [-0.1350],\n",
      "        [-0.9745],\n",
      "        [-0.9745],\n",
      "        [-0.9745],\n",
      "        [-0.9745],\n",
      "        [ 0.2869],\n",
      "        [ 0.2869],\n",
      "        [-0.1350],\n",
      "        [-0.0286],\n",
      "        [-0.9745],\n",
      "        [-0.0286],\n",
      "        [-0.0286],\n",
      "        [-0.0286],\n",
      "        [-0.0286],\n",
      "        [-0.7105],\n",
      "        [-0.7105],\n",
      "        [-0.0286],\n",
      "        [-0.1350],\n",
      "        [-0.9745],\n",
      "        [-0.0286],\n",
      "        [-0.0286],\n",
      "        [-0.7105],\n",
      "        [-0.7105],\n",
      "        [ 0.8806],\n",
      "        [ 0.8806],\n",
      "        [ 0.8806],\n",
      "        [ 0.8806],\n",
      "        [ 0.8806]], dtype=torch.float64)\n",
      "Finished episode 940 Average rewards:  83.0\n",
      "Monitored episode 50 Average Monitored rewards:  15.38\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2532591   1.0084574   0.8639317   1.9998467  -0.08485781  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9058382 0.6980654]\n",
      "tensor([[ 0.8499],\n",
      "        [-0.9579],\n",
      "        [-0.1987],\n",
      "        [-0.9579],\n",
      "        [-0.9579],\n",
      "        [-0.9579],\n",
      "        [-0.9579],\n",
      "        [ 0.3454],\n",
      "        [ 0.3454],\n",
      "        [-0.1987],\n",
      "        [-0.1987],\n",
      "        [-0.9579],\n",
      "        [ 0.0319],\n",
      "        [ 0.0319],\n",
      "        [ 0.0319],\n",
      "        [ 0.0319],\n",
      "        [ 0.0319],\n",
      "        [ 0.0319],\n",
      "        [ 0.0319],\n",
      "        [ 0.0319],\n",
      "        [-0.1987],\n",
      "        [-0.9579],\n",
      "        [-0.9579],\n",
      "        [ 0.3454],\n",
      "        [-0.1987],\n",
      "        [ 0.0319],\n",
      "        [ 0.0319],\n",
      "        [ 0.0319],\n",
      "        [ 0.0319],\n",
      "        [ 0.0319],\n",
      "        [ 0.8499],\n",
      "        [-0.9579],\n",
      "        [-0.9579],\n",
      "        [-0.9579],\n",
      "        [-0.9579],\n",
      "        [-0.9579],\n",
      "        [-0.9579],\n",
      "        [-0.9579],\n",
      "        [-0.9579],\n",
      "        [-0.9579],\n",
      "        [-0.1987],\n",
      "        [ 0.0319],\n",
      "        [ 0.0319],\n",
      "        [ 0.0319],\n",
      "        [ 0.0319],\n",
      "        [ 0.0319],\n",
      "        [ 0.0319],\n",
      "        [ 0.0319],\n",
      "        [ 0.0319],\n",
      "        [-0.6554]], dtype=torch.float64)\n",
      "Finished episode 945 Average rewards:  17.6\n",
      "len_game 52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[ 1.2507204   1.0081835   0.855955    1.9998513  -0.09095054  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9083834  0.69008875]\n",
      "tensor([[ 8.6035e-01],\n",
      "        [-9.6114e-01],\n",
      "        [-9.6114e-01],\n",
      "        [-9.6114e-01],\n",
      "        [-9.6114e-01],\n",
      "        [-9.6114e-01],\n",
      "        [-9.6114e-01],\n",
      "        [-9.6114e-01],\n",
      "        [ 3.0464e-01],\n",
      "        [ 3.0464e-01],\n",
      "        [ 8.6035e-01],\n",
      "        [-9.6114e-01],\n",
      "        [-9.6114e-01],\n",
      "        [-9.6114e-01],\n",
      "        [-9.6114e-01],\n",
      "        [ 3.0464e-01],\n",
      "        [ 3.0464e-01],\n",
      "        [ 3.0464e-01],\n",
      "        [ 3.0464e-01],\n",
      "        [ 3.0464e-01],\n",
      "        [-1.5874e-01],\n",
      "        [ 8.6035e-01],\n",
      "        [-9.6114e-01],\n",
      "        [-9.6114e-01],\n",
      "        [ 3.0464e-01],\n",
      "        [ 3.0464e-01],\n",
      "        [ 3.0464e-01],\n",
      "        [ 3.0464e-01],\n",
      "        [-9.5748e-04],\n",
      "        [-9.6114e-01],\n",
      "        [ 3.0464e-01],\n",
      "        [-1.5874e-01],\n",
      "        [-1.5874e-01],\n",
      "        [-9.6114e-01],\n",
      "        [ 3.0464e-01],\n",
      "        [-1.5874e-01],\n",
      "        [-9.6114e-01],\n",
      "        [-9.6114e-01],\n",
      "        [ 3.0464e-01],\n",
      "        [-1.5874e-01],\n",
      "        [-9.6114e-01],\n",
      "        [-9.6114e-01],\n",
      "        [-1.5874e-01],\n",
      "        [-1.5874e-01],\n",
      "        [-1.5874e-01],\n",
      "        [-9.6114e-01],\n",
      "        [-9.5748e-04],\n",
      "        [ 8.6035e-01],\n",
      "        [-9.6114e-01],\n",
      "        [-9.6114e-01],\n",
      "        [-9.6114e-01],\n",
      "        [-9.6114e-01]], dtype=torch.float64)\n",
      "Finished episode 950 Average rewards:  84.6\n",
      "Monitored episode 50 Average Monitored rewards:  29.98\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2616401   1.0081409   0.8664047   1.99986    -0.07361882  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8974684 0.7005384]\n",
      "tensor([[-0.1397],\n",
      "        [-0.9692],\n",
      "        [-0.9692],\n",
      "        [-0.9692],\n",
      "        [ 0.2863],\n",
      "        [ 0.2863],\n",
      "        [ 0.2863],\n",
      "        [ 0.2863],\n",
      "        [-0.9692],\n",
      "        [-0.9692],\n",
      "        [ 0.8717],\n",
      "        [ 0.8717],\n",
      "        [-0.9692],\n",
      "        [-0.9692],\n",
      "        [-0.9692],\n",
      "        [-0.1397],\n",
      "        [-0.9692],\n",
      "        [-0.9692],\n",
      "        [-0.1397],\n",
      "        [-0.9692],\n",
      "        [ 0.8717],\n",
      "        [-0.9692],\n",
      "        [-0.9692],\n",
      "        [-0.9692],\n",
      "        [-0.9692],\n",
      "        [-0.9692],\n",
      "        [ 0.2863],\n",
      "        [ 0.2863],\n",
      "        [ 0.2863],\n",
      "        [ 0.2863],\n",
      "        [-0.1397],\n",
      "        [-0.9692],\n",
      "        [-0.9692],\n",
      "        [ 0.2863],\n",
      "        [ 0.2863],\n",
      "        [-0.1397],\n",
      "        [-0.0184],\n",
      "        [-0.0184],\n",
      "        [-0.0184],\n",
      "        [-0.0184],\n",
      "        [ 0.8717],\n",
      "        [-0.9692],\n",
      "        [-0.0184],\n",
      "        [-0.0184],\n",
      "        [-0.0184],\n",
      "        [-0.7024],\n",
      "        [-0.0184],\n",
      "        [-0.7024],\n",
      "        [-0.7024],\n",
      "        [-0.7024]], dtype=torch.float64)\n",
      "Finished episode 955 Average rewards:  81.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.252891    1.0077548   0.85406643  1.9998639  -0.10001406  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9062253 0.6882001]\n",
      "tensor([[ 0.8533],\n",
      "        [-0.9613],\n",
      "        [-0.9613],\n",
      "        [-0.9613],\n",
      "        [-0.9613],\n",
      "        [ 0.3463],\n",
      "        [ 0.3463],\n",
      "        [ 0.3463],\n",
      "        [ 0.3463],\n",
      "        [-0.9613],\n",
      "        [ 0.8533],\n",
      "        [-0.9613],\n",
      "        [ 0.0312],\n",
      "        [ 0.0312],\n",
      "        [ 0.0312],\n",
      "        [ 0.0312],\n",
      "        [ 0.0312],\n",
      "        [ 0.0312],\n",
      "        [ 0.0312],\n",
      "        [ 0.0312],\n",
      "        [-0.1989],\n",
      "        [-0.1989],\n",
      "        [-0.9613],\n",
      "        [ 0.0312],\n",
      "        [ 0.0312],\n",
      "        [ 0.0312],\n",
      "        [ 0.0312],\n",
      "        [ 0.0312],\n",
      "        [ 0.0312],\n",
      "        [-0.6575],\n",
      "        [ 0.8533],\n",
      "        [-0.9613],\n",
      "        [ 0.0312],\n",
      "        [ 0.0312],\n",
      "        [-0.6575],\n",
      "        [ 0.0312],\n",
      "        [ 0.0312],\n",
      "        [ 0.0312],\n",
      "        [ 0.0312],\n",
      "        [ 0.0312],\n",
      "        [ 0.8533],\n",
      "        [-0.9613],\n",
      "        [ 0.0312],\n",
      "        [ 0.0312],\n",
      "        [ 0.0312],\n",
      "        [ 0.0312],\n",
      "        [ 0.0312],\n",
      "        [ 0.0312],\n",
      "        [ 0.0312],\n",
      "        [-0.6575]], dtype=torch.float64)\n",
      "Finished episode 960 Average rewards:  15.8\n",
      "Monitored episode 50 Average Monitored rewards:  61.48\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2605783   1.0074935   0.8509347   1.9998729  -0.09577145  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.89854664 0.6850684 ]\n",
      "tensor([[-0.1213],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [ 0.2764],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [ 0.8891],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [ 0.2764],\n",
      "        [ 0.2764],\n",
      "        [ 0.2764],\n",
      "        [ 0.2764],\n",
      "        [-0.1213],\n",
      "        [-0.1213],\n",
      "        [ 0.8891],\n",
      "        [-0.9785],\n",
      "        [ 0.2764],\n",
      "        [-0.1213],\n",
      "        [-0.0442],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [ 0.8891],\n",
      "        [ 0.8891],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.1213],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [ 0.2764],\n",
      "        [-0.0442],\n",
      "        [-0.0442],\n",
      "        [ 0.8891],\n",
      "        [-0.9785],\n",
      "        [-0.0442],\n",
      "        [-0.0442],\n",
      "        [-0.7231],\n",
      "        [-0.9785],\n",
      "        [-0.0442],\n",
      "        [-0.0442],\n",
      "        [-0.0442],\n",
      "        [-0.7231]], dtype=torch.float64)\n",
      "Finished episode 965 Average rewards:  102.6\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2727727   1.0074775   0.85997313  1.9998804  -0.07627016  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8863561 0.6941069]\n",
      "tensor([[-0.1448],\n",
      "        [-0.0321],\n",
      "        [-0.0321],\n",
      "        [-0.0321],\n",
      "        [-0.0321],\n",
      "        [-0.0321],\n",
      "        [-0.0321],\n",
      "        [-0.0321],\n",
      "        [-0.0321],\n",
      "        [-0.0321],\n",
      "        [ 0.8954],\n",
      "        [-0.9856],\n",
      "        [-0.9856],\n",
      "        [-0.9856],\n",
      "        [ 0.3070],\n",
      "        [ 0.3070],\n",
      "        [ 0.3070],\n",
      "        [ 0.3070],\n",
      "        [-0.9856],\n",
      "        [-0.1448],\n",
      "        [ 0.8954],\n",
      "        [-0.9856],\n",
      "        [-0.1448],\n",
      "        [-0.0321],\n",
      "        [-0.0321],\n",
      "        [-0.0321],\n",
      "        [-0.7150],\n",
      "        [-0.7150],\n",
      "        [-0.0321],\n",
      "        [-0.0321],\n",
      "        [ 0.8954],\n",
      "        [ 0.8954],\n",
      "        [-0.9856],\n",
      "        [-0.1448],\n",
      "        [-0.1448],\n",
      "        [-0.9856],\n",
      "        [-0.1448],\n",
      "        [-0.9856],\n",
      "        [-0.9856],\n",
      "        [ 0.3070],\n",
      "        [-0.1448],\n",
      "        [-0.0321],\n",
      "        [-0.0321],\n",
      "        [-0.0321],\n",
      "        [-0.7150],\n",
      "        [-0.0321],\n",
      "        [-0.7150],\n",
      "        [-0.7150],\n",
      "        [-0.7150],\n",
      "        [-0.7150]], dtype=torch.float64)\n",
      "Finished episode 970 Average rewards:  14.6\n",
      "Monitored episode 50 Average Monitored rewards:  44.34\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2718804   1.0074067   0.8656787   1.9998823  -0.08358376  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88725007 0.6998124 ]\n",
      "tensor([[-0.2102],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [-0.6673],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [-0.2102],\n",
      "        [-0.2102],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [-0.2102],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [-0.2102],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [-0.6673],\n",
      "        [-0.6673],\n",
      "        [-0.6673],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [-0.2102],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236],\n",
      "        [ 0.0236]], dtype=torch.float64)\n",
      "Finished episode 975 Average rewards:  -8.6\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2638702   1.0071371   0.8611731   1.9998854  -0.10109784  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8952653 0.6953068]\n",
      "tensor([[ 0.8833],\n",
      "        [ 0.8833],\n",
      "        [ 0.8833],\n",
      "        [-0.9759],\n",
      "        [-0.1920],\n",
      "        [ 0.0027],\n",
      "        [-0.6810],\n",
      "        [ 0.0027],\n",
      "        [ 0.0027],\n",
      "        [ 0.0027],\n",
      "        [-0.1920],\n",
      "        [-0.1920],\n",
      "        [ 0.0027],\n",
      "        [ 0.0027],\n",
      "        [ 0.0027],\n",
      "        [ 0.0027],\n",
      "        [ 0.0027],\n",
      "        [ 0.0027],\n",
      "        [ 0.0027],\n",
      "        [ 0.0027],\n",
      "        [ 0.8833],\n",
      "        [-0.9759],\n",
      "        [-0.9759],\n",
      "        [-0.9759],\n",
      "        [-0.9759],\n",
      "        [-0.9759],\n",
      "        [-0.9759],\n",
      "        [-0.9759],\n",
      "        [ 0.3575],\n",
      "        [ 0.3575],\n",
      "        [ 0.8833],\n",
      "        [-0.9759],\n",
      "        [-0.9759],\n",
      "        [-0.9759],\n",
      "        [-0.9759],\n",
      "        [-0.9759],\n",
      "        [ 0.3575],\n",
      "        [ 0.3575],\n",
      "        [ 0.3575],\n",
      "        [ 0.3575],\n",
      "        [-0.1920],\n",
      "        [ 0.0027],\n",
      "        [ 0.0027],\n",
      "        [ 0.0027],\n",
      "        [ 0.0027],\n",
      "        [-0.6810],\n",
      "        [ 0.8833],\n",
      "        [ 0.8833],\n",
      "        [-0.9759],\n",
      "        [-0.9759]], dtype=torch.float64)\n",
      "Finished episode 980 Average rewards:  59.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  48.54\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2895404   1.0071905   0.8857884   1.9998993  -0.05142059  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.86960024 0.7199221 ]\n",
      "tensor([[-0.1377],\n",
      "        [-0.9817],\n",
      "        [-0.9817],\n",
      "        [-0.0473],\n",
      "        [-0.0473],\n",
      "        [-0.0473],\n",
      "        [-0.7223],\n",
      "        [-0.0473],\n",
      "        [-0.7223],\n",
      "        [-0.0473],\n",
      "        [-0.1377],\n",
      "        [-0.0473],\n",
      "        [-0.7223],\n",
      "        [-0.0473],\n",
      "        [ 0.9003],\n",
      "        [-0.9817],\n",
      "        [-0.9817],\n",
      "        [-0.9817],\n",
      "        [ 0.3079],\n",
      "        [ 0.3079],\n",
      "        [-0.1377],\n",
      "        [-0.0473],\n",
      "        [-0.0473],\n",
      "        [-0.0473],\n",
      "        [-0.0473],\n",
      "        [-0.7223],\n",
      "        [-0.7223],\n",
      "        [ 0.9003],\n",
      "        [-0.9817],\n",
      "        [-0.1377],\n",
      "        [-0.1377],\n",
      "        [ 0.9003],\n",
      "        [-0.9817],\n",
      "        [-0.0473],\n",
      "        [-0.0473],\n",
      "        [-0.7223],\n",
      "        [-0.7223],\n",
      "        [-0.9817],\n",
      "        [-0.9817],\n",
      "        [ 0.3079],\n",
      "        [ 0.3079],\n",
      "        [ 0.9003],\n",
      "        [-0.0473],\n",
      "        [-0.0473],\n",
      "        [-0.9817],\n",
      "        [-0.9817],\n",
      "        [-0.9817],\n",
      "        [-0.9817],\n",
      "        [-0.9817],\n",
      "        [ 0.3079],\n",
      "        [ 0.3079]], dtype=torch.float64)\n",
      "Finished episode 985 Average rewards:  80.8\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2764846   1.0068673   0.8743971   1.9999028  -0.07115102  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8826621  0.70853084]\n",
      "tensor([[ 0.8352],\n",
      "        [-0.9436],\n",
      "        [-0.2891],\n",
      "        [-0.9436],\n",
      "        [-0.9436],\n",
      "        [-0.9436],\n",
      "        [-0.9436],\n",
      "        [ 0.4358],\n",
      "        [ 0.4358],\n",
      "        [ 0.4358],\n",
      "        [-0.2891],\n",
      "        [ 0.0944],\n",
      "        [ 0.0944],\n",
      "        [ 0.0944],\n",
      "        [ 0.0944],\n",
      "        [-0.5885],\n",
      "        [ 0.0944],\n",
      "        [ 0.0944],\n",
      "        [ 0.0944],\n",
      "        [ 0.0944],\n",
      "        [ 0.8352],\n",
      "        [-0.9436],\n",
      "        [-0.9436],\n",
      "        [-0.9436],\n",
      "        [ 0.4358],\n",
      "        [ 0.4358],\n",
      "        [ 0.4358],\n",
      "        [-0.2891],\n",
      "        [ 0.0944],\n",
      "        [ 0.0944],\n",
      "        [ 0.8352],\n",
      "        [ 0.8352],\n",
      "        [ 0.8352],\n",
      "        [-0.9436],\n",
      "        [-0.2891],\n",
      "        [ 0.0944],\n",
      "        [ 0.0944],\n",
      "        [-0.5885],\n",
      "        [ 0.8352],\n",
      "        [-0.9436],\n",
      "        [-0.2891],\n",
      "        [ 0.8352],\n",
      "        [-0.9436],\n",
      "        [-0.2891],\n",
      "        [-0.2891],\n",
      "        [ 0.0944],\n",
      "        [ 0.0944],\n",
      "        [ 0.0944],\n",
      "        [ 0.0944],\n",
      "        [-0.5885],\n",
      "        [-0.5885]], dtype=torch.float64)\n",
      "Finished episode 990 Average rewards:  16.8\n",
      "Monitored episode 50 Average Monitored rewards:  31.42\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2688037   1.0066826   0.8667837   1.9999044  -0.08002628  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.89034593 0.7009175 ]\n",
      "tensor([[-0.2275],\n",
      "        [-0.2275],\n",
      "        [ 0.0382],\n",
      "        [ 0.0382],\n",
      "        [ 0.0382],\n",
      "        [ 0.0382],\n",
      "        [ 0.0382],\n",
      "        [ 0.0382],\n",
      "        [-0.6463],\n",
      "        [-0.6463],\n",
      "        [-0.2275],\n",
      "        [-0.9628],\n",
      "        [-0.9628],\n",
      "        [-0.9628],\n",
      "        [-0.9628],\n",
      "        [-0.9628],\n",
      "        [-0.9628],\n",
      "        [-0.9628],\n",
      "        [-0.9628],\n",
      "        [-0.9628],\n",
      "        [ 0.8625],\n",
      "        [-0.9628],\n",
      "        [-0.9628],\n",
      "        [-0.9628],\n",
      "        [-0.9628],\n",
      "        [-0.9628],\n",
      "        [-0.9628],\n",
      "        [-0.9628],\n",
      "        [-0.9628],\n",
      "        [ 0.3861],\n",
      "        [ 0.8625],\n",
      "        [-0.9628],\n",
      "        [-0.2275],\n",
      "        [-0.2275],\n",
      "        [-0.2275],\n",
      "        [-0.9628],\n",
      "        [ 0.3861],\n",
      "        [-0.9628],\n",
      "        [-0.9628],\n",
      "        [-0.9628],\n",
      "        [ 0.8625],\n",
      "        [ 0.0382],\n",
      "        [ 0.0382],\n",
      "        [ 0.0382],\n",
      "        [ 0.0382],\n",
      "        [ 0.0382],\n",
      "        [ 0.0382],\n",
      "        [ 0.0382],\n",
      "        [ 0.0382],\n",
      "        [ 0.0382]], dtype=torch.float64)\n",
      "Finished episode 995 Average rewards:  62.4\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.258831    1.0063705   0.8528315   1.9999067  -0.10360908  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9003238 0.6869653]\n",
      "tensor([[-0.1953],\n",
      "        [ 0.0129],\n",
      "        [ 0.0129],\n",
      "        [ 0.0129],\n",
      "        [ 0.0129],\n",
      "        [ 0.0129],\n",
      "        [ 0.0129],\n",
      "        [ 0.0129],\n",
      "        [ 0.0129],\n",
      "        [ 0.0129],\n",
      "        [-0.1953],\n",
      "        [ 0.0129],\n",
      "        [ 0.0129],\n",
      "        [ 0.0129],\n",
      "        [ 0.0129],\n",
      "        [-0.6722],\n",
      "        [ 0.0129],\n",
      "        [ 0.0129],\n",
      "        [ 0.0129],\n",
      "        [ 0.0129],\n",
      "        [ 0.8730],\n",
      "        [-0.9712],\n",
      "        [-0.1953],\n",
      "        [-0.1953],\n",
      "        [-0.9712],\n",
      "        [ 0.0129],\n",
      "        [ 0.0129],\n",
      "        [ 0.0129],\n",
      "        [ 0.0129],\n",
      "        [ 0.0129],\n",
      "        [-0.1953],\n",
      "        [-0.9712],\n",
      "        [ 0.3548],\n",
      "        [ 0.3548],\n",
      "        [ 0.3548],\n",
      "        [-0.1953],\n",
      "        [-0.9712],\n",
      "        [-0.9712],\n",
      "        [-0.9712],\n",
      "        [-0.9712],\n",
      "        [-0.1953],\n",
      "        [-0.9712],\n",
      "        [ 0.3548],\n",
      "        [-0.1953],\n",
      "        [ 0.0129],\n",
      "        [-0.6722],\n",
      "        [-0.9712],\n",
      "        [-0.9712],\n",
      "        [-0.9712],\n",
      "        [ 0.3548]], dtype=torch.float64)\n",
      "Finished episode 1000 Average rewards:  36.8\n",
      "Monitored episode 50 Average Monitored rewards:  60.76\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2537881   1.0061532   0.85004085  1.9999105  -0.09768532  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9053703  0.68417466]\n",
      "tensor([[ 0.9026],\n",
      "        [ 0.9026],\n",
      "        [ 0.9026],\n",
      "        [-0.9862],\n",
      "        [-0.9862],\n",
      "        [-0.9862],\n",
      "        [-0.9862],\n",
      "        [ 0.2884],\n",
      "        [ 0.2884],\n",
      "        [ 0.2884],\n",
      "        [-0.1229],\n",
      "        [ 0.9026],\n",
      "        [ 0.9026],\n",
      "        [ 0.9026],\n",
      "        [-0.0544],\n",
      "        [-0.0544],\n",
      "        [ 0.9026],\n",
      "        [-0.9862],\n",
      "        [-0.9862],\n",
      "        [-0.9862],\n",
      "        [-0.9862],\n",
      "        [-0.1229],\n",
      "        [-0.9862],\n",
      "        [-0.0544],\n",
      "        [ 0.9026],\n",
      "        [-0.9862],\n",
      "        [-0.9862],\n",
      "        [-0.9862],\n",
      "        [-0.9862],\n",
      "        [-0.9862],\n",
      "        [-0.9862],\n",
      "        [ 0.9026],\n",
      "        [ 0.9026],\n",
      "        [-0.9862],\n",
      "        [-0.1229],\n",
      "        [-0.9862],\n",
      "        [-0.9862],\n",
      "        [-0.9862],\n",
      "        [-0.9862],\n",
      "        [-0.9862],\n",
      "        [-0.9862],\n",
      "        [ 0.9026],\n",
      "        [-0.9862],\n",
      "        [ 0.2884],\n",
      "        [-0.1229],\n",
      "        [-0.1229],\n",
      "        [-0.9862],\n",
      "        [-0.9862],\n",
      "        [-0.9862],\n",
      "        [ 0.2884],\n",
      "        [ 0.2884]], dtype=torch.float64)\n",
      "Finished episode 1005 Average rewards:  85.6\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2631177   1.005928    0.8478084   1.9999171  -0.09562626  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.89604694 0.6819422 ]\n",
      "tensor([[ 0.8891],\n",
      "        [-0.9807],\n",
      "        [-0.9807],\n",
      "        [-0.1285],\n",
      "        [-0.9807],\n",
      "        [-0.1285],\n",
      "        [-0.1285],\n",
      "        [-0.1285],\n",
      "        [-0.9807],\n",
      "        [-0.9807],\n",
      "        [ 0.8891],\n",
      "        [-0.9807],\n",
      "        [-0.0375],\n",
      "        [-0.0375],\n",
      "        [-0.0375],\n",
      "        [-0.0375],\n",
      "        [-0.0375],\n",
      "        [-0.0375],\n",
      "        [-0.7195],\n",
      "        [-0.0375],\n",
      "        [ 0.8891],\n",
      "        [-0.9807],\n",
      "        [-0.0375],\n",
      "        [-0.0375],\n",
      "        [-0.7195],\n",
      "        [-0.0375],\n",
      "        [-0.0375],\n",
      "        [-0.0375],\n",
      "        [-0.0375],\n",
      "        [-0.7195],\n",
      "        [-0.1285],\n",
      "        [-0.1285],\n",
      "        [-0.9807],\n",
      "        [-0.9807],\n",
      "        [ 0.2833],\n",
      "        [ 0.2833],\n",
      "        [-0.1285],\n",
      "        [-0.9807],\n",
      "        [ 0.2833],\n",
      "        [-0.1285],\n",
      "        [ 0.8891],\n",
      "        [-0.9807],\n",
      "        [-0.1285],\n",
      "        [-0.0375],\n",
      "        [-0.0375],\n",
      "        [ 0.8891],\n",
      "        [-0.9807],\n",
      "        [-0.9807],\n",
      "        [ 0.2833],\n",
      "        [ 0.2833]], dtype=torch.float64)\n",
      "Finished episode 1010 Average rewards:  37.6\n",
      "Monitored episode 50 Average Monitored rewards:  53.66\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2869552   1.0060005   0.86838484  1.9999247  -0.05782791  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.87221193 0.70251864]\n",
      "tensor([[ 0.9000],\n",
      "        [ 0.9000],\n",
      "        [-0.9893],\n",
      "        [-0.9893],\n",
      "        [-0.9893],\n",
      "        [-0.1494],\n",
      "        [-0.0316],\n",
      "        [-0.0316],\n",
      "        [-0.7157],\n",
      "        [-0.7157],\n",
      "        [ 0.9000],\n",
      "        [-0.1494],\n",
      "        [-0.1494],\n",
      "        [-0.0316],\n",
      "        [-0.0316],\n",
      "        [-0.0316],\n",
      "        [-0.7157],\n",
      "        [-0.0316],\n",
      "        [-0.0316],\n",
      "        [-0.7157],\n",
      "        [-0.0316],\n",
      "        [-0.1494],\n",
      "        [-0.0316],\n",
      "        [-0.9893],\n",
      "        [-0.0316],\n",
      "        [-0.0316],\n",
      "        [ 0.9000],\n",
      "        [-0.9893],\n",
      "        [-0.9893],\n",
      "        [ 0.3147],\n",
      "        [ 0.3147],\n",
      "        [-0.1494],\n",
      "        [-0.0316],\n",
      "        [-0.0316],\n",
      "        [-0.0316],\n",
      "        [-0.7157],\n",
      "        [-0.0316],\n",
      "        [-0.0316],\n",
      "        [-0.0316],\n",
      "        [-0.7157],\n",
      "        [-0.0316],\n",
      "        [ 0.9000],\n",
      "        [-0.9893],\n",
      "        [-0.9893],\n",
      "        [-0.9893],\n",
      "        [-0.9893],\n",
      "        [ 0.3147],\n",
      "        [ 0.3147],\n",
      "        [ 0.3147],\n",
      "        [-0.1494],\n",
      "        [-0.9893]], dtype=torch.float64)\n",
      "Finished episode 1015 Average rewards:  38.4\n",
      "len_game 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[ 1.2801841   1.005849    0.86832947  1.9999266  -0.07130256  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8789855 0.7024632]\n",
      "tensor([[ 0.8644],\n",
      "        [ 0.8644],\n",
      "        [-0.9728],\n",
      "        [-0.2719],\n",
      "        [-0.9728],\n",
      "        [-0.2719],\n",
      "        [ 0.0762],\n",
      "        [ 0.0762],\n",
      "        [ 0.0762],\n",
      "        [ 0.0762],\n",
      "        [ 0.8644],\n",
      "        [-0.9728],\n",
      "        [-0.9728],\n",
      "        [-0.9728],\n",
      "        [-0.9728],\n",
      "        [-0.9728],\n",
      "        [-0.9728],\n",
      "        [ 0.4244],\n",
      "        [ 0.4244],\n",
      "        [ 0.4244],\n",
      "        [-0.2719],\n",
      "        [ 0.0762],\n",
      "        [ 0.0762],\n",
      "        [ 0.0762],\n",
      "        [ 0.0762],\n",
      "        [ 0.0762],\n",
      "        [ 0.0762],\n",
      "        [ 0.0762],\n",
      "        [ 0.0762],\n",
      "        [ 0.0762],\n",
      "        [ 0.8644],\n",
      "        [-0.9728],\n",
      "        [-0.9728],\n",
      "        [-0.9728],\n",
      "        [-0.9728],\n",
      "        [-0.9728],\n",
      "        [-0.9728],\n",
      "        [-0.9728],\n",
      "        [-0.9728],\n",
      "        [-0.9728],\n",
      "        [ 0.8644],\n",
      "        [-0.9728],\n",
      "        [-0.2719],\n",
      "        [-0.2719],\n",
      "        [ 0.0762],\n",
      "        [ 0.0762],\n",
      "        [ 0.0762],\n",
      "        [ 0.0762],\n",
      "        [ 0.0762],\n",
      "        [ 0.0762]], dtype=torch.float64)\n",
      "Finished episode 1020 Average rewards:  38.2\n",
      "Monitored episode 50 Average Monitored rewards:  36.52\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2715675   1.0057194   0.869408    1.999928   -0.06824451  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88760364 0.7035418 ]\n",
      "tensor([[-0.2327],\n",
      "        [-0.2327],\n",
      "        [ 0.0378],\n",
      "        [ 0.0378],\n",
      "        [ 0.0378],\n",
      "        [ 0.0378],\n",
      "        [ 0.0378],\n",
      "        [ 0.0378],\n",
      "        [ 0.0378],\n",
      "        [-0.6509],\n",
      "        [-0.2327],\n",
      "        [-0.9733],\n",
      "        [ 0.0378],\n",
      "        [ 0.0378],\n",
      "        [ 0.0378],\n",
      "        [ 0.0378],\n",
      "        [-0.6509],\n",
      "        [-0.6509],\n",
      "        [ 0.0378],\n",
      "        [ 0.0378],\n",
      "        [ 0.8746],\n",
      "        [-0.9733],\n",
      "        [-0.9733],\n",
      "        [-0.9733],\n",
      "        [-0.9733],\n",
      "        [ 0.3943],\n",
      "        [ 0.3943],\n",
      "        [-0.9733],\n",
      "        [-0.9733],\n",
      "        [-0.9733],\n",
      "        [ 0.8746],\n",
      "        [-0.9733],\n",
      "        [-0.9733],\n",
      "        [-0.9733],\n",
      "        [-0.9733],\n",
      "        [ 0.3943],\n",
      "        [ 0.3943],\n",
      "        [ 0.3943],\n",
      "        [-0.9733],\n",
      "        [-0.2327],\n",
      "        [-0.2327],\n",
      "        [ 0.0378],\n",
      "        [ 0.0378],\n",
      "        [ 0.0378],\n",
      "        [ 0.0378],\n",
      "        [ 0.0378],\n",
      "        [ 0.0378],\n",
      "        [ 0.0378],\n",
      "        [-0.6509],\n",
      "        [ 0.0378]], dtype=torch.float64)\n",
      "Finished episode 1025 Average rewards:  37.8\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2629751   1.0054965   0.8589424   1.9999299  -0.08823022  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8961993 0.6930762]\n",
      "tensor([[-0.2266],\n",
      "        [-0.9648],\n",
      "        [ 0.0466],\n",
      "        [ 0.0466],\n",
      "        [ 0.0466],\n",
      "        [-0.6430],\n",
      "        [-0.6430],\n",
      "        [-0.6430],\n",
      "        [-0.6430],\n",
      "        [ 0.8568],\n",
      "        [ 0.8568],\n",
      "        [ 0.8568],\n",
      "        [ 0.0466],\n",
      "        [ 0.0466],\n",
      "        [ 0.0466],\n",
      "        [ 0.0466],\n",
      "        [ 0.0466],\n",
      "        [ 0.0466],\n",
      "        [ 0.0466],\n",
      "        [ 0.0466],\n",
      "        [ 0.8568],\n",
      "        [-0.9648],\n",
      "        [-0.2266],\n",
      "        [-0.9648],\n",
      "        [-0.9648],\n",
      "        [-0.9648],\n",
      "        [-0.9648],\n",
      "        [-0.9648],\n",
      "        [-0.9648],\n",
      "        [-0.9648],\n",
      "        [ 0.8568],\n",
      "        [ 0.8568],\n",
      "        [-0.9648],\n",
      "        [-0.9648],\n",
      "        [-0.9648],\n",
      "        [-0.9648],\n",
      "        [-0.9648],\n",
      "        [ 0.3786],\n",
      "        [-0.9648],\n",
      "        [-0.9648],\n",
      "        [ 0.8568],\n",
      "        [-0.9648],\n",
      "        [-0.2266],\n",
      "        [ 0.0466],\n",
      "        [ 0.0466],\n",
      "        [ 0.0466],\n",
      "        [ 0.0466],\n",
      "        [-0.6430],\n",
      "        [-0.6430],\n",
      "        [-0.6430]], dtype=torch.float64)\n",
      "Finished episode 1030 Average rewards:  60.4\n",
      "Monitored episode 50 Average Monitored rewards:  51.0\n",
      "len_game 52\n",
      "Rot\n",
      "[ 1.2809602   1.0055263   0.87722874  1.9999357  -0.05148759  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.87821627 0.71136254]\n",
      "tensor([[-0.1667],\n",
      "        [-0.1667],\n",
      "        [-0.0105],\n",
      "        [-0.0105],\n",
      "        [-0.0105],\n",
      "        [-0.0105],\n",
      "        [-0.0105],\n",
      "        [-0.0105],\n",
      "        [-0.0105],\n",
      "        [-0.0105],\n",
      "        [-0.1667],\n",
      "        [-0.0105],\n",
      "        [-0.0105],\n",
      "        [-0.0105],\n",
      "        [-0.6952],\n",
      "        [ 0.8833],\n",
      "        [ 0.8833],\n",
      "        [-0.9783],\n",
      "        [-0.9783],\n",
      "        [-0.9783],\n",
      "        [-0.1667],\n",
      "        [-0.1667],\n",
      "        [-0.0105],\n",
      "        [-0.0105],\n",
      "        [-0.0105],\n",
      "        [-0.0105],\n",
      "        [-0.6952],\n",
      "        [-0.0105],\n",
      "        [-0.6952],\n",
      "        [-0.6952],\n",
      "        [-0.9783],\n",
      "        [ 0.8833],\n",
      "        [-0.9783],\n",
      "        [-0.9783],\n",
      "        [-0.9783],\n",
      "        [-0.9783],\n",
      "        [-0.9783],\n",
      "        [-0.9783],\n",
      "        [-0.9783],\n",
      "        [ 0.3263],\n",
      "        [ 0.3263],\n",
      "        [ 0.8833],\n",
      "        [ 0.8833],\n",
      "        [-0.9783],\n",
      "        [-0.9783],\n",
      "        [ 0.3263],\n",
      "        [-0.1667],\n",
      "        [-0.1667],\n",
      "        [-0.0105],\n",
      "        [-0.6952],\n",
      "        [-0.9783],\n",
      "        [-0.1667]], dtype=torch.float64)\n",
      "Finished episode 1035 Average rewards:  59.6\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2683675   1.0052526   0.86599946  1.9999384  -0.07565331  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8908128 0.7001332]\n",
      "tensor([[ 0.8353],\n",
      "        [-0.9534],\n",
      "        [ 0.0943],\n",
      "        [ 0.0943],\n",
      "        [ 0.0943],\n",
      "        [ 0.0943],\n",
      "        [ 0.0943],\n",
      "        [ 0.0943],\n",
      "        [ 0.0943],\n",
      "        [ 0.0943],\n",
      "        [-0.2772],\n",
      "        [ 0.0943],\n",
      "        [ 0.0943],\n",
      "        [ 0.0943],\n",
      "        [ 0.0943],\n",
      "        [ 0.0943],\n",
      "        [ 0.0943],\n",
      "        [ 0.0943],\n",
      "        [-0.5964],\n",
      "        [-0.5964],\n",
      "        [ 0.8353],\n",
      "        [ 0.0943],\n",
      "        [ 0.8353],\n",
      "        [ 0.8353],\n",
      "        [-0.9534],\n",
      "        [-0.2772],\n",
      "        [ 0.0943],\n",
      "        [ 0.0943],\n",
      "        [ 0.0943],\n",
      "        [ 0.0943],\n",
      "        [-0.2772],\n",
      "        [ 0.0943],\n",
      "        [ 0.0943],\n",
      "        [-0.5964],\n",
      "        [ 0.8353],\n",
      "        [-0.9534],\n",
      "        [-0.9534],\n",
      "        [-0.9534],\n",
      "        [-0.9534],\n",
      "        [ 0.4201],\n",
      "        [-0.2772],\n",
      "        [-0.9534],\n",
      "        [-0.9534],\n",
      "        [ 0.4201],\n",
      "        [ 0.0943],\n",
      "        [ 0.0943],\n",
      "        [ 0.0943],\n",
      "        [ 0.0943],\n",
      "        [ 0.0943],\n",
      "        [-0.5964]], dtype=torch.float64)\n",
      "Finished episode 1040 Average rewards:  16.8\n",
      "Monitored episode 50 Average Monitored rewards:  19.6\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2553812   1.0049199   0.8428409   1.99994    -0.11260163  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.90380347 0.6769747 ]\n",
      "tensor([[-0.2047],\n",
      "        [-0.9698],\n",
      "        [-0.9698],\n",
      "        [-0.9698],\n",
      "        [ 0.3601],\n",
      "        [ 0.3601],\n",
      "        [-0.2047],\n",
      "        [-0.9698],\n",
      "        [-0.9698],\n",
      "        [-0.9698],\n",
      "        [ 0.8667],\n",
      "        [-0.9698],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [-0.2047],\n",
      "        [-0.2047],\n",
      "        [-0.2047],\n",
      "        [-0.9698],\n",
      "        [ 0.0254],\n",
      "        [ 0.8667],\n",
      "        [ 0.8667],\n",
      "        [-0.9698],\n",
      "        [-0.9698],\n",
      "        [-0.9698],\n",
      "        [-0.2047],\n",
      "        [-0.2047],\n",
      "        [-0.9698],\n",
      "        [-0.9698],\n",
      "        [-0.9698],\n",
      "        [ 0.3601],\n",
      "        [ 0.3601],\n",
      "        [ 0.3601],\n",
      "        [-0.2047],\n",
      "        [-0.2047],\n",
      "        [ 0.8667],\n",
      "        [-0.9698],\n",
      "        [ 0.3601],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254]], dtype=torch.float64)\n",
      "Finished episode 1045 Average rewards:  37.4\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2613976   1.0049238   0.8541341   1.9999429  -0.08706826  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8977878 0.6882679]\n",
      "tensor([[-0.0950],\n",
      "        [-0.0950],\n",
      "        [-0.0800],\n",
      "        [-0.0800],\n",
      "        [-0.0800],\n",
      "        [-0.7529],\n",
      "        [-0.7529],\n",
      "        [-0.7529],\n",
      "        [-0.7529],\n",
      "        [ 0.9139],\n",
      "        [-0.0950],\n",
      "        [-0.0800],\n",
      "        [-0.0800],\n",
      "        [-0.0800],\n",
      "        [-0.0800],\n",
      "        [-0.0800],\n",
      "        [-0.7529],\n",
      "        [-0.0800],\n",
      "        [-0.0800],\n",
      "        [-0.7529],\n",
      "        [-0.0950],\n",
      "        [-0.9920],\n",
      "        [-0.9920],\n",
      "        [-0.9920],\n",
      "        [ 0.2614],\n",
      "        [ 0.2614],\n",
      "        [-0.9920],\n",
      "        [-0.9920],\n",
      "        [ 0.2614],\n",
      "        [ 0.2614],\n",
      "        [-0.0950],\n",
      "        [-0.0950],\n",
      "        [-0.9920],\n",
      "        [-0.0950],\n",
      "        [-0.0800],\n",
      "        [-0.0800],\n",
      "        [-0.7529],\n",
      "        [-0.7529],\n",
      "        [-0.7529],\n",
      "        [-0.9920],\n",
      "        [-0.9920],\n",
      "        [ 0.9139],\n",
      "        [-0.9920],\n",
      "        [-0.9920],\n",
      "        [-0.9920],\n",
      "        [-0.9920],\n",
      "        [-0.9920],\n",
      "        [-0.9920],\n",
      "        [ 0.2614],\n",
      "        [ 0.2614],\n",
      "        [ 0.2614]], dtype=torch.float64)\n",
      "Finished episode 1050 Average rewards:  60.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  47.46\n",
      "len_game 52\n",
      "Rot\n",
      "[ 1.2677804   1.0048599   0.8596073   1.9999458  -0.07681282  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8914068 0.6937411]\n",
      "tensor([[-0.1668],\n",
      "        [-0.9802],\n",
      "        [-0.9802],\n",
      "        [-0.9802],\n",
      "        [ 0.3238],\n",
      "        [ 0.3238],\n",
      "        [ 0.3238],\n",
      "        [ 0.3238],\n",
      "        [-0.1668],\n",
      "        [-0.0072],\n",
      "        [-0.1668],\n",
      "        [-0.1668],\n",
      "        [-0.0072],\n",
      "        [-0.6946],\n",
      "        [-0.0072],\n",
      "        [-0.0072],\n",
      "        [-0.0072],\n",
      "        [-0.0072],\n",
      "        [-0.6946],\n",
      "        [-0.6946],\n",
      "        [ 0.8825],\n",
      "        [-0.9802],\n",
      "        [-0.1668],\n",
      "        [-0.9802],\n",
      "        [-0.9802],\n",
      "        [ 0.3238],\n",
      "        [ 0.3238],\n",
      "        [ 0.3238],\n",
      "        [-0.1668],\n",
      "        [-0.9802],\n",
      "        [-0.1668],\n",
      "        [-0.1668],\n",
      "        [-0.1668],\n",
      "        [-0.0072],\n",
      "        [-0.0072],\n",
      "        [-0.0072],\n",
      "        [-0.0072],\n",
      "        [-0.6946],\n",
      "        [-0.0072],\n",
      "        [-0.0072],\n",
      "        [-0.6946],\n",
      "        [-0.6946],\n",
      "        [-0.1668],\n",
      "        [-0.1668],\n",
      "        [-0.9802],\n",
      "        [-0.9802],\n",
      "        [ 0.3238],\n",
      "        [ 0.3238],\n",
      "        [ 0.3238],\n",
      "        [ 0.3238],\n",
      "        [-0.1668],\n",
      "        [-0.1668]], dtype=torch.float64)\n",
      "Finished episode 1055 Average rewards:  -3.4\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2620761   1.0047196   0.84995985  1.9999466  -0.09306996  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.89711285 0.68409365]\n",
      "tensor([[-0.2011],\n",
      "        [-0.9766],\n",
      "        [-0.9766],\n",
      "        [-0.9766],\n",
      "        [-0.9766],\n",
      "        [ 0.3569],\n",
      "        [ 0.3569],\n",
      "        [ 0.3569],\n",
      "        [ 0.3569],\n",
      "        [ 0.3569],\n",
      "        [-0.2011],\n",
      "        [-0.9766],\n",
      "        [-0.9766],\n",
      "        [-0.9766],\n",
      "        [ 0.3569],\n",
      "        [-0.9766],\n",
      "        [-0.9766],\n",
      "        [ 0.3569],\n",
      "        [-0.9766],\n",
      "        [ 0.3569],\n",
      "        [-0.2011],\n",
      "        [-0.9766],\n",
      "        [ 0.3569],\n",
      "        [-0.9766],\n",
      "        [-0.9766],\n",
      "        [ 0.3569],\n",
      "        [ 0.3569],\n",
      "        [ 0.3569],\n",
      "        [ 0.3569],\n",
      "        [ 0.3569],\n",
      "        [-0.2011],\n",
      "        [-0.2011],\n",
      "        [-0.2011],\n",
      "        [ 0.0221],\n",
      "        [ 0.0221],\n",
      "        [ 0.0221],\n",
      "        [ 0.0221],\n",
      "        [ 0.0221],\n",
      "        [ 0.0221],\n",
      "        [ 0.0221],\n",
      "        [-0.2011],\n",
      "        [ 0.0221],\n",
      "        [ 0.0221],\n",
      "        [ 0.0221],\n",
      "        [ 0.0221],\n",
      "        [-0.6688],\n",
      "        [ 0.0221],\n",
      "        [ 0.0221],\n",
      "        [ 0.0221],\n",
      "        [ 0.0221]], dtype=torch.float64)\n",
      "Finished episode 1060 Average rewards:  37.2\n",
      "Monitored episode 50 Average Monitored rewards:  47.0\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2827263   1.0047294   0.8657326   1.9999515  -0.06049608  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8764648 0.6998664]\n",
      "tensor([[-0.1537],\n",
      "        [-0.9863],\n",
      "        [-0.9863],\n",
      "        [ 0.3158],\n",
      "        [ 0.3158],\n",
      "        [-0.1537],\n",
      "        [-0.9863],\n",
      "        [-0.9863],\n",
      "        [ 0.3158],\n",
      "        [-0.1537],\n",
      "        [-0.1537],\n",
      "        [-0.0243],\n",
      "        [-0.0243],\n",
      "        [-0.0243],\n",
      "        [-0.0243],\n",
      "        [-0.0243],\n",
      "        [-0.0243],\n",
      "        [-0.7095],\n",
      "        [-0.7095],\n",
      "        [-0.7095],\n",
      "        [-0.1537],\n",
      "        [-0.1537],\n",
      "        [-0.0243],\n",
      "        [-0.0243],\n",
      "        [-0.7095],\n",
      "        [-0.7095],\n",
      "        [-0.9863],\n",
      "        [ 0.3158],\n",
      "        [ 0.3158],\n",
      "        [-0.1537],\n",
      "        [ 0.8942],\n",
      "        [ 0.8942],\n",
      "        [ 0.8942],\n",
      "        [-0.9863],\n",
      "        [-0.1537],\n",
      "        [-0.0243],\n",
      "        [-0.7095],\n",
      "        [ 0.8942],\n",
      "        [-0.9863],\n",
      "        [-0.0243],\n",
      "        [ 0.8942],\n",
      "        [-0.1537],\n",
      "        [-0.1537],\n",
      "        [-0.0243],\n",
      "        [-0.0243],\n",
      "        [-0.0243],\n",
      "        [-0.0243],\n",
      "        [-0.7095],\n",
      "        [-0.0243],\n",
      "        [-0.0243],\n",
      "        [-0.0243]], dtype=torch.float64)\n",
      "Finished episode 1065 Average rewards:  37.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2694771   1.0044632   0.85410327  1.9999535  -0.09384067  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8897174 0.6882371]\n",
      "tensor([[ 0.8650],\n",
      "        [-0.9746],\n",
      "        [-0.9746],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [ 0.8650],\n",
      "        [-0.9746],\n",
      "        [-0.9746],\n",
      "        [-0.9746],\n",
      "        [ 0.4130],\n",
      "        [ 0.4130],\n",
      "        [ 0.4130],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [-0.2602],\n",
      "        [-0.9746],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [-0.6267],\n",
      "        [ 0.8650],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [ 0.8650],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [ 0.8650],\n",
      "        [-0.9746],\n",
      "        [-0.9746],\n",
      "        [ 0.4130],\n",
      "        [ 0.4130],\n",
      "        [ 0.4130],\n",
      "        [-0.2602],\n",
      "        [ 0.0687],\n",
      "        [ 0.0687],\n",
      "        [-0.6267]], dtype=torch.float64)\n",
      "Finished episode 1070 Average rewards:  -6.0\n",
      "Monitored episode 50 Average Monitored rewards:  55.3\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.277599   1.0044523  0.8695073  1.9999566 -0.0651504  1.8641111\n",
      "  1.7464267  0.7518858]\n",
      "Enc\n",
      "[0.88159657 0.7036411 ]\n",
      "tensor([[ 0.9029],\n",
      "        [-0.9887],\n",
      "        [-0.9887],\n",
      "        [-0.9887],\n",
      "        [-0.9887],\n",
      "        [-0.9887],\n",
      "        [-0.9887],\n",
      "        [ 0.3356],\n",
      "        [ 0.3356],\n",
      "        [ 0.3356],\n",
      "        [ 0.9029],\n",
      "        [ 0.9029],\n",
      "        [-0.9887],\n",
      "        [-0.9887],\n",
      "        [ 0.3356],\n",
      "        [ 0.3356],\n",
      "        [-0.0265],\n",
      "        [-0.0265],\n",
      "        [-0.0265],\n",
      "        [-0.7098],\n",
      "        [ 0.9029],\n",
      "        [-0.9887],\n",
      "        [-0.1643],\n",
      "        [-0.0265],\n",
      "        [-0.0265],\n",
      "        [-0.7098],\n",
      "        [-0.7098],\n",
      "        [-0.9887],\n",
      "        [-0.9887],\n",
      "        [-0.9887],\n",
      "        [ 0.9029],\n",
      "        [-0.9887],\n",
      "        [-0.9887],\n",
      "        [-0.9887],\n",
      "        [ 0.3356],\n",
      "        [ 0.3356],\n",
      "        [ 0.3356],\n",
      "        [ 0.3356],\n",
      "        [ 0.3356],\n",
      "        [-0.1643],\n",
      "        [-0.1643],\n",
      "        [-0.0265],\n",
      "        [-0.0265],\n",
      "        [-0.0265],\n",
      "        [-0.0265],\n",
      "        [-0.0265],\n",
      "        [-0.0265],\n",
      "        [-0.7098],\n",
      "        [-0.0265],\n",
      "        [-0.0265]], dtype=torch.float64)\n",
      "Finished episode 1075 Average rewards:  39.8\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2700096   1.0043489   0.8646658   1.9999572  -0.07126836  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88918686 0.6987996 ]\n",
      "tensor([[-0.2425],\n",
      "        [ 0.0554],\n",
      "        [ 0.0554],\n",
      "        [ 0.0554],\n",
      "        [ 0.0554],\n",
      "        [ 0.0554],\n",
      "        [ 0.0554],\n",
      "        [ 0.0554],\n",
      "        [ 0.0554],\n",
      "        [ 0.0554],\n",
      "        [-0.2425],\n",
      "        [-0.9682],\n",
      "        [-0.9682],\n",
      "        [-0.9682],\n",
      "        [ 0.3964],\n",
      "        [ 0.3964],\n",
      "        [ 0.3964],\n",
      "        [-0.9682],\n",
      "        [-0.9682],\n",
      "        [-0.9682],\n",
      "        [ 0.8607],\n",
      "        [-0.9682],\n",
      "        [-0.9682],\n",
      "        [ 0.3964],\n",
      "        [ 0.3964],\n",
      "        [ 0.3964],\n",
      "        [-0.9682],\n",
      "        [ 0.3964],\n",
      "        [ 0.3964],\n",
      "        [-0.2425],\n",
      "        [ 0.8607],\n",
      "        [-0.9682],\n",
      "        [-0.9682],\n",
      "        [-0.9682],\n",
      "        [-0.9682],\n",
      "        [ 0.3964],\n",
      "        [-0.9682],\n",
      "        [ 0.3964],\n",
      "        [ 0.3964],\n",
      "        [ 0.3964],\n",
      "        [ 0.8607],\n",
      "        [-0.9682],\n",
      "        [-0.2425],\n",
      "        [-0.9682],\n",
      "        [-0.9682],\n",
      "        [-0.9682],\n",
      "        [ 0.3964],\n",
      "        [ 0.3964],\n",
      "        [ 0.3964],\n",
      "        [-0.2425],\n",
      "        [-0.2425]], dtype=torch.float64)\n",
      "Finished episode 1080 Average rewards:  59.4\n",
      "Monitored episode 50 Average Monitored rewards:  29.52\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2594242   1.0041642   0.858569    1.9999584  -0.08898075  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.89977413 0.69270283]\n",
      "tensor([[ 0.8637],\n",
      "        [ 0.8637],\n",
      "        [ 0.8637],\n",
      "        [ 0.8637],\n",
      "        [-0.9707],\n",
      "        [-0.9707],\n",
      "        [ 0.3706],\n",
      "        [ 0.3706],\n",
      "        [-0.2173],\n",
      "        [ 0.0380],\n",
      "        [ 0.8637],\n",
      "        [-0.9707],\n",
      "        [-0.9707],\n",
      "        [ 0.0380],\n",
      "        [ 0.0380],\n",
      "        [ 0.0380],\n",
      "        [ 0.0380],\n",
      "        [ 0.0380],\n",
      "        [ 0.0380],\n",
      "        [ 0.0380],\n",
      "        [-0.2173],\n",
      "        [ 0.0380],\n",
      "        [ 0.0380],\n",
      "        [ 0.0380],\n",
      "        [ 0.0380],\n",
      "        [ 0.0380],\n",
      "        [ 0.0380],\n",
      "        [ 0.0380],\n",
      "        [ 0.0380],\n",
      "        [ 0.0380],\n",
      "        [ 0.8637],\n",
      "        [-0.9707],\n",
      "        [-0.9707],\n",
      "        [-0.9707],\n",
      "        [ 0.3706],\n",
      "        [ 0.3706],\n",
      "        [-0.2173],\n",
      "        [ 0.0380],\n",
      "        [ 0.0380],\n",
      "        [ 0.0380],\n",
      "        [ 0.8637],\n",
      "        [ 0.8637],\n",
      "        [-0.9707],\n",
      "        [-0.9707],\n",
      "        [-0.9707],\n",
      "        [-0.9707],\n",
      "        [-0.9707],\n",
      "        [-0.9707],\n",
      "        [-0.9707],\n",
      "        [-0.9707]], dtype=torch.float64)\n",
      "Finished episode 1085 Average rewards:  18.0\n",
      "len_game 53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[ 1.2680202   1.0040759   0.8645823   1.9999615  -0.07290374  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8911802 0.6987161]\n",
      "tensor([[-0.1590],\n",
      "        [-0.9757],\n",
      "        [-0.9757],\n",
      "        [ 0.3150],\n",
      "        [ 0.3150],\n",
      "        [ 0.3150],\n",
      "        [-0.1590],\n",
      "        [-0.9757],\n",
      "        [-0.1590],\n",
      "        [-0.0126],\n",
      "        [ 0.8796],\n",
      "        [-0.9757],\n",
      "        [-0.1590],\n",
      "        [-0.0126],\n",
      "        [-0.9757],\n",
      "        [-0.9757],\n",
      "        [-0.9757],\n",
      "        [-0.9757],\n",
      "        [-0.9757],\n",
      "        [-0.9757],\n",
      "        [-0.1590],\n",
      "        [-0.9757],\n",
      "        [ 0.3150],\n",
      "        [-0.1590],\n",
      "        [-0.0126],\n",
      "        [-0.0126],\n",
      "        [-0.0126],\n",
      "        [-0.0126],\n",
      "        [-0.6971],\n",
      "        [-0.6971],\n",
      "        [ 0.8796],\n",
      "        [ 0.8796],\n",
      "        [-0.0126],\n",
      "        [-0.0126],\n",
      "        [ 0.8796],\n",
      "        [-0.9757],\n",
      "        [-0.9757],\n",
      "        [ 0.3150],\n",
      "        [ 0.3150],\n",
      "        [ 0.3150],\n",
      "        [-0.1590],\n",
      "        [-0.1590],\n",
      "        [-0.1590],\n",
      "        [-0.9757],\n",
      "        [-0.9757],\n",
      "        [ 0.3150],\n",
      "        [-0.9757],\n",
      "        [-0.9757],\n",
      "        [ 0.3150],\n",
      "        [ 0.3150],\n",
      "        [ 0.3150],\n",
      "        [ 0.3150],\n",
      "        [-0.1590]], dtype=torch.float64)\n",
      "Finished episode 1090 Average rewards:  39.6\n",
      "Monitored episode 50 Average Monitored rewards:  33.84\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2608174  1.0039786  0.8646738  1.9999622 -0.0756664  1.8641111\n",
      "  1.7464267  0.7518858]\n",
      "Enc\n",
      "[0.8983838  0.69880754]\n",
      "tensor([[-0.2105],\n",
      "        [-0.9698],\n",
      "        [ 0.3633],\n",
      "        [ 0.0333],\n",
      "        [ 0.8634],\n",
      "        [-0.9698],\n",
      "        [-0.9698],\n",
      "        [-0.9698],\n",
      "        [-0.9698],\n",
      "        [-0.9698],\n",
      "        [ 0.8634],\n",
      "        [-0.9698],\n",
      "        [-0.9698],\n",
      "        [-0.9698],\n",
      "        [ 0.3633],\n",
      "        [ 0.3633],\n",
      "        [ 0.3633],\n",
      "        [ 0.3633],\n",
      "        [ 0.3633],\n",
      "        [-0.9698],\n",
      "        [-0.2105],\n",
      "        [ 0.0333],\n",
      "        [ 0.0333],\n",
      "        [ 0.0333],\n",
      "        [ 0.0333],\n",
      "        [ 0.0333],\n",
      "        [ 0.0333],\n",
      "        [ 0.0333],\n",
      "        [-0.6571],\n",
      "        [-0.6571],\n",
      "        [-0.2105],\n",
      "        [ 0.0333],\n",
      "        [ 0.0333],\n",
      "        [ 0.0333],\n",
      "        [ 0.0333],\n",
      "        [ 0.0333],\n",
      "        [ 0.0333],\n",
      "        [ 0.0333],\n",
      "        [ 0.0333],\n",
      "        [ 0.0333],\n",
      "        [-0.2105],\n",
      "        [-0.9698],\n",
      "        [-0.2105],\n",
      "        [-0.2105],\n",
      "        [ 0.0333],\n",
      "        [ 0.0333],\n",
      "        [ 0.0333],\n",
      "        [ 0.0333],\n",
      "        [ 0.0333],\n",
      "        [ 0.0333]], dtype=torch.float64)\n",
      "Finished episode 1095 Average rewards:  16.4\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2560943   1.0038534   0.8597756   1.9999632  -0.09609938  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9031082 0.6939094]\n",
      "tensor([[-0.1928],\n",
      "        [-0.9636],\n",
      "        [-0.9636],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.8568],\n",
      "        [-0.9636],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [-0.6635],\n",
      "        [ 0.0254],\n",
      "        [-0.6635],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [-0.1928],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [-0.1928],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [-0.6635],\n",
      "        [-0.6635],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [-0.6635],\n",
      "        [-0.6635],\n",
      "        [-0.1928],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254],\n",
      "        [-0.6635],\n",
      "        [-0.6635],\n",
      "        [ 0.0254],\n",
      "        [ 0.0254]], dtype=torch.float64)\n",
      "Finished episode 1100 Average rewards:  -7.4\n",
      "Monitored episode 50 Average Monitored rewards:  60.8\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.26452     1.0038997   0.8740835   1.9999644  -0.07460145  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8946824  0.70821726]\n",
      "tensor([[-0.1363],\n",
      "        [-0.1363],\n",
      "        [-0.0330],\n",
      "        [-0.0330],\n",
      "        [-0.0330],\n",
      "        [-0.0330],\n",
      "        [-0.0330],\n",
      "        [-0.0330],\n",
      "        [-0.0330],\n",
      "        [-0.7123],\n",
      "        [-0.1363],\n",
      "        [-0.9751],\n",
      "        [-0.9751],\n",
      "        [ 0.2930],\n",
      "        [ 0.2930],\n",
      "        [-0.1363],\n",
      "        [-0.9751],\n",
      "        [-0.9751],\n",
      "        [ 0.2930],\n",
      "        [ 0.2930],\n",
      "        [ 0.8843],\n",
      "        [-0.9751],\n",
      "        [-0.1363],\n",
      "        [-0.9751],\n",
      "        [-0.9751],\n",
      "        [-0.9751],\n",
      "        [-0.9751],\n",
      "        [ 0.2930],\n",
      "        [ 0.2930],\n",
      "        [ 0.2930],\n",
      "        [ 0.8843],\n",
      "        [-0.9751],\n",
      "        [-0.9751],\n",
      "        [-0.9751],\n",
      "        [-0.9751],\n",
      "        [-0.9751],\n",
      "        [-0.9751],\n",
      "        [-0.9751],\n",
      "        [ 0.2930],\n",
      "        [ 0.2930],\n",
      "        [-0.1363],\n",
      "        [-0.0330],\n",
      "        [-0.0330],\n",
      "        [-0.0330],\n",
      "        [-0.0330],\n",
      "        [-0.7123],\n",
      "        [-0.7123],\n",
      "        [-0.7123],\n",
      "        [-0.0330],\n",
      "        [-0.7123]], dtype=torch.float64)\n",
      "Finished episode 1105 Average rewards:  62.6\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2551268   1.0037676   0.8708546   1.9999652  -0.08457659  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9040767 0.7049884]\n",
      "tensor([[-0.2011],\n",
      "        [ 0.0284],\n",
      "        [ 0.8511],\n",
      "        [-0.9551],\n",
      "        [-0.9551],\n",
      "        [ 0.3520],\n",
      "        [ 0.3520],\n",
      "        [-0.2011],\n",
      "        [-0.9551],\n",
      "        [-0.9551],\n",
      "        [ 0.8511],\n",
      "        [ 0.0284],\n",
      "        [ 0.8511],\n",
      "        [-0.9551],\n",
      "        [-0.9551],\n",
      "        [-0.9551],\n",
      "        [ 0.3520],\n",
      "        [ 0.3520],\n",
      "        [ 0.3520],\n",
      "        [ 0.3520],\n",
      "        [ 0.8511],\n",
      "        [-0.9551],\n",
      "        [-0.9551],\n",
      "        [-0.9551],\n",
      "        [-0.9551],\n",
      "        [-0.9551],\n",
      "        [-0.9551],\n",
      "        [-0.9551],\n",
      "        [-0.9551],\n",
      "        [-0.9551],\n",
      "        [ 0.8511],\n",
      "        [-0.9551],\n",
      "        [-0.9551],\n",
      "        [-0.9551],\n",
      "        [-0.9551],\n",
      "        [-0.9551],\n",
      "        [-0.9551],\n",
      "        [-0.9551],\n",
      "        [-0.9551],\n",
      "        [-0.9551],\n",
      "        [ 0.8511],\n",
      "        [-0.9551],\n",
      "        [-0.9551],\n",
      "        [-0.9551],\n",
      "        [ 0.3520],\n",
      "        [ 0.3520],\n",
      "        [-0.2011],\n",
      "        [-0.2011],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284]], dtype=torch.float64)\n",
      "Finished episode 1110 Average rewards:  85.2\n",
      "Monitored episode 50 Average Monitored rewards:  49.24\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2721622   1.003803    0.8858076   1.9999673  -0.05910828  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88704205 0.7199414 ]\n",
      "tensor([[ 8.5626e-01],\n",
      "        [ 8.5626e-01],\n",
      "        [-4.8942e-05],\n",
      "        [-4.8942e-05],\n",
      "        [-4.8942e-05],\n",
      "        [-4.8942e-05],\n",
      "        [-6.8008e-01],\n",
      "        [-4.8942e-05],\n",
      "        [-6.8008e-01],\n",
      "        [-4.8942e-05],\n",
      "        [ 8.5626e-01],\n",
      "        [-9.5526e-01],\n",
      "        [-9.5526e-01],\n",
      "        [-9.5526e-01],\n",
      "        [-9.5526e-01],\n",
      "        [-9.5526e-01],\n",
      "        [-9.5526e-01],\n",
      "        [-9.5526e-01],\n",
      "        [-9.5526e-01],\n",
      "        [-9.5526e-01],\n",
      "        [-1.6243e-01],\n",
      "        [-4.8942e-05],\n",
      "        [-4.8942e-05],\n",
      "        [-6.8008e-01],\n",
      "        [-6.8008e-01],\n",
      "        [-4.8942e-05],\n",
      "        [-4.8942e-05],\n",
      "        [-6.8008e-01],\n",
      "        [-6.8008e-01],\n",
      "        [-4.8942e-05],\n",
      "        [-1.6243e-01],\n",
      "        [-9.5526e-01],\n",
      "        [-9.5526e-01],\n",
      "        [ 3.1028e-01],\n",
      "        [ 3.1028e-01],\n",
      "        [ 3.1028e-01],\n",
      "        [-1.6243e-01],\n",
      "        [-4.8942e-05],\n",
      "        [-4.8942e-05],\n",
      "        [-4.8942e-05],\n",
      "        [ 8.5626e-01],\n",
      "        [-9.5526e-01],\n",
      "        [-9.5526e-01],\n",
      "        [-9.5526e-01],\n",
      "        [-9.5526e-01],\n",
      "        [-9.5526e-01],\n",
      "        [ 3.1028e-01],\n",
      "        [ 3.1028e-01],\n",
      "        [ 3.1028e-01],\n",
      "        [ 3.1028e-01]], dtype=torch.float64)\n",
      "Finished episode 1115 Average rewards:  40.6\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2618023   1.0036491   0.88220626  1.9999684  -0.07843577  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8974033  0.71634007]\n",
      "tensor([[ 0.8222],\n",
      "        [-0.9344],\n",
      "        [-0.9344],\n",
      "        [-0.9344],\n",
      "        [ 0.3925],\n",
      "        [ 0.3925],\n",
      "        [ 0.3925],\n",
      "        [ 0.0726],\n",
      "        [ 0.0726],\n",
      "        [ 0.0726],\n",
      "        [ 0.8222],\n",
      "        [ 0.8222],\n",
      "        [-0.9344],\n",
      "        [-0.9344],\n",
      "        [ 0.0726],\n",
      "        [ 0.8222],\n",
      "        [-0.9344],\n",
      "        [-0.9344],\n",
      "        [-0.9344],\n",
      "        [ 0.3925],\n",
      "        [ 0.8222],\n",
      "        [-0.9344],\n",
      "        [-0.2480],\n",
      "        [-0.9344],\n",
      "        [-0.9344],\n",
      "        [-0.9344],\n",
      "        [-0.9344],\n",
      "        [-0.9344],\n",
      "        [ 0.3925],\n",
      "        [-0.9344],\n",
      "        [-0.2480],\n",
      "        [-0.2480],\n",
      "        [ 0.0726],\n",
      "        [ 0.0726],\n",
      "        [ 0.0726],\n",
      "        [ 0.0726],\n",
      "        [ 0.0726],\n",
      "        [ 0.0726],\n",
      "        [ 0.0726],\n",
      "        [ 0.0726],\n",
      "        [ 0.8222],\n",
      "        [-0.9344],\n",
      "        [-0.9344],\n",
      "        [ 0.3925],\n",
      "        [ 0.3925],\n",
      "        [-0.2480],\n",
      "        [ 0.0726],\n",
      "        [ 0.0726],\n",
      "        [ 0.0726],\n",
      "        [ 0.0726]], dtype=torch.float64)\n",
      "Finished episode 1120 Average rewards:  38.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  44.58\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.25101     1.003469    0.8694209   1.9999694  -0.10178274  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.90819716 0.7035547 ]\n",
      "tensor([[ 0.8429],\n",
      "        [-0.9419],\n",
      "        [-0.9419],\n",
      "        [-0.9419],\n",
      "        [-0.9419],\n",
      "        [-0.9419],\n",
      "        [ 0.3388],\n",
      "        [ 0.3388],\n",
      "        [ 0.3388],\n",
      "        [-0.1878],\n",
      "        [ 0.8429],\n",
      "        [-0.9419],\n",
      "        [ 0.0175],\n",
      "        [ 0.0175],\n",
      "        [ 0.0175],\n",
      "        [ 0.0175],\n",
      "        [ 0.0175],\n",
      "        [ 0.0175],\n",
      "        [ 0.0175],\n",
      "        [ 0.0175],\n",
      "        [-0.1878],\n",
      "        [ 0.0175],\n",
      "        [ 0.0175],\n",
      "        [ 0.0175],\n",
      "        [ 0.0175],\n",
      "        [ 0.0175],\n",
      "        [-0.6570],\n",
      "        [ 0.8429],\n",
      "        [-0.9419],\n",
      "        [-0.9419],\n",
      "        [ 0.8429],\n",
      "        [-0.9419],\n",
      "        [-0.9419],\n",
      "        [-0.9419],\n",
      "        [-0.9419],\n",
      "        [-0.9419],\n",
      "        [ 0.3388],\n",
      "        [-0.9419],\n",
      "        [-0.9419],\n",
      "        [-0.9419],\n",
      "        [-0.1878],\n",
      "        [-0.9419],\n",
      "        [ 0.3388],\n",
      "        [-0.1878],\n",
      "        [-0.1878],\n",
      "        [-0.9419],\n",
      "        [-0.1878],\n",
      "        [ 0.0175],\n",
      "        [ 0.0175],\n",
      "        [ 0.0175]], dtype=torch.float64)\n",
      "Finished episode 1125 Average rewards:  38.8\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2532446   1.0034145   0.8709108   1.9999706  -0.09109335  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.90596324 0.70504457]\n",
      "tensor([[-0.1137],\n",
      "        [-0.9630],\n",
      "        [-0.9630],\n",
      "        [ 0.2671],\n",
      "        [ 0.2671],\n",
      "        [ 0.2671],\n",
      "        [ 0.2671],\n",
      "        [-0.1137],\n",
      "        [-0.0492],\n",
      "        [ 0.8773],\n",
      "        [ 0.8773],\n",
      "        [ 0.8773],\n",
      "        [-0.0492],\n",
      "        [-0.0492],\n",
      "        [-0.0492],\n",
      "        [-0.0492],\n",
      "        [-0.0492],\n",
      "        [-0.7192],\n",
      "        [-0.7192],\n",
      "        [-0.7192],\n",
      "        [ 0.8773],\n",
      "        [-0.9630],\n",
      "        [-0.9630],\n",
      "        [ 0.2671],\n",
      "        [-0.1137],\n",
      "        [-0.0492],\n",
      "        [-0.9630],\n",
      "        [-0.9630],\n",
      "        [-0.9630],\n",
      "        [-0.9630],\n",
      "        [ 0.8773],\n",
      "        [-0.9630],\n",
      "        [-0.9630],\n",
      "        [-0.9630],\n",
      "        [ 0.2671],\n",
      "        [ 0.2671],\n",
      "        [-0.9630],\n",
      "        [-0.9630],\n",
      "        [ 0.2671],\n",
      "        [ 0.2671],\n",
      "        [ 0.8773],\n",
      "        [-0.9630],\n",
      "        [-0.9630],\n",
      "        [-0.9630],\n",
      "        [ 0.2671],\n",
      "        [ 0.2671],\n",
      "        [ 0.2671],\n",
      "        [ 0.2671],\n",
      "        [-0.9630],\n",
      "        [ 0.2671]], dtype=torch.float64)\n",
      "Finished episode 1130 Average rewards:  60.6\n",
      "Monitored episode 50 Average Monitored rewards:  51.94\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2656157   1.0033141   0.8702798   1.9999732  -0.07563237  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8935941  0.70441353]\n",
      "tensor([[ 0.8634],\n",
      "        [-0.9572],\n",
      "        [-0.1436],\n",
      "        [-0.0187],\n",
      "        [ 0.8634],\n",
      "        [-0.9572],\n",
      "        [-0.1436],\n",
      "        [-0.1436],\n",
      "        [-0.1436],\n",
      "        [-0.9572],\n",
      "        [-0.1436],\n",
      "        [-0.0187],\n",
      "        [-0.6947],\n",
      "        [-0.6947],\n",
      "        [-0.0187],\n",
      "        [-0.0187],\n",
      "        [-0.6947],\n",
      "        [ 0.8634],\n",
      "        [-0.9572],\n",
      "        [-0.9572],\n",
      "        [ 0.8634],\n",
      "        [-0.9572],\n",
      "        [ 0.2934],\n",
      "        [-0.1436],\n",
      "        [-0.9572],\n",
      "        [-0.1436],\n",
      "        [-0.9572],\n",
      "        [-0.9572],\n",
      "        [-0.9572],\n",
      "        [-0.9572],\n",
      "        [ 0.8634],\n",
      "        [-0.9572],\n",
      "        [-0.9572],\n",
      "        [-0.9572],\n",
      "        [ 0.2934],\n",
      "        [ 0.2934],\n",
      "        [-0.1436],\n",
      "        [-0.9572],\n",
      "        [-0.1436],\n",
      "        [-0.0187],\n",
      "        [-0.1436],\n",
      "        [-0.9572],\n",
      "        [ 0.2934],\n",
      "        [-0.1436],\n",
      "        [-0.1436],\n",
      "        [-0.0187],\n",
      "        [-0.6947],\n",
      "        [-0.0187],\n",
      "        [-0.6947],\n",
      "        [-0.9572]], dtype=torch.float64)\n",
      "Finished episode 1135 Average rewards:  82.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2570167   1.0031946   0.8640532   1.9999738  -0.08882216  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.90219396 0.698187  ]\n",
      "tensor([[-0.2004],\n",
      "        [ 0.0255],\n",
      "        [ 0.0255],\n",
      "        [ 0.0255],\n",
      "        [ 0.0255],\n",
      "        [ 0.0255],\n",
      "        [ 0.0255],\n",
      "        [ 0.0255],\n",
      "        [ 0.0255],\n",
      "        [ 0.0255],\n",
      "        [ 0.8584],\n",
      "        [-0.9620],\n",
      "        [ 0.0255],\n",
      "        [ 0.0255],\n",
      "        [ 0.0255],\n",
      "        [ 0.0255],\n",
      "        [ 0.0255],\n",
      "        [ 0.0255],\n",
      "        [ 0.0255],\n",
      "        [-0.6599],\n",
      "        [-0.2004],\n",
      "        [-0.2004],\n",
      "        [ 0.0255],\n",
      "        [ 0.0255],\n",
      "        [ 0.0255],\n",
      "        [ 0.0255],\n",
      "        [ 0.0255],\n",
      "        [ 0.0255],\n",
      "        [-0.6599],\n",
      "        [ 0.0255],\n",
      "        [-0.2004],\n",
      "        [-0.9620],\n",
      "        [-0.9620],\n",
      "        [-0.9620],\n",
      "        [-0.9620],\n",
      "        [-0.9620],\n",
      "        [ 0.3531],\n",
      "        [ 0.3531],\n",
      "        [ 0.3531],\n",
      "        [ 0.3531],\n",
      "        [-0.2004],\n",
      "        [ 0.0255],\n",
      "        [ 0.0255],\n",
      "        [-0.6599],\n",
      "        [ 0.8584],\n",
      "        [ 0.8584],\n",
      "        [-0.9620],\n",
      "        [-0.9620],\n",
      "        [-0.9620],\n",
      "        [-0.9620]], dtype=torch.float64)\n",
      "Finished episode 1140 Average rewards:  35.8\n",
      "Monitored episode 50 Average Monitored rewards:  58.06\n",
      "len_game 52\n",
      "Rot\n",
      "[ 1.2705768   1.0031245   0.8672525   1.9999759  -0.07461493  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8886353  0.70138633]\n",
      "tensor([[ 0.8718],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [ 0.3083],\n",
      "        [-0.1554],\n",
      "        [-0.1554],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [ 0.8718],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [ 0.3083],\n",
      "        [ 0.3083],\n",
      "        [ 0.3083],\n",
      "        [ 0.3083],\n",
      "        [ 0.3083],\n",
      "        [-0.1554],\n",
      "        [-0.1554],\n",
      "        [ 0.8718],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [-0.1554],\n",
      "        [-0.1554],\n",
      "        [-0.0122],\n",
      "        [-0.0122],\n",
      "        [-0.0122],\n",
      "        [-0.0122],\n",
      "        [-0.0122],\n",
      "        [ 0.8718],\n",
      "        [-0.0122],\n",
      "        [-0.0122],\n",
      "        [-0.0122],\n",
      "        [-0.0122],\n",
      "        [-0.0122],\n",
      "        [-0.6939],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [ 0.3083],\n",
      "        [-0.1554],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [ 0.3083],\n",
      "        [ 0.3083],\n",
      "        [ 0.3083],\n",
      "        [ 0.3083],\n",
      "        [-0.1554],\n",
      "        [-0.0122],\n",
      "        [ 0.8718]], dtype=torch.float64)\n",
      "Finished episode 1145 Average rewards:  81.6\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2646502   1.003066    0.87059814  1.9999763  -0.07840484  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.89456224 0.70473194]\n",
      "tensor([[ 0.8671],\n",
      "        [-0.9697],\n",
      "        [-0.2105],\n",
      "        [-0.9697],\n",
      "        [-0.9697],\n",
      "        [-0.9697],\n",
      "        [-0.9697],\n",
      "        [-0.9697],\n",
      "        [-0.9697],\n",
      "        [-0.9697],\n",
      "        [ 0.8671],\n",
      "        [-0.9697],\n",
      "        [-0.9697],\n",
      "        [-0.9697],\n",
      "        [-0.9697],\n",
      "        [-0.9697],\n",
      "        [-0.9697],\n",
      "        [-0.9697],\n",
      "        [-0.9697],\n",
      "        [-0.9697],\n",
      "        [-0.2105],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [-0.2105],\n",
      "        [-0.9697],\n",
      "        [-0.9697],\n",
      "        [ 0.3671],\n",
      "        [ 0.3671],\n",
      "        [ 0.3671],\n",
      "        [-0.2105],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.8671],\n",
      "        [-0.9697],\n",
      "        [-0.9697],\n",
      "        [-0.9697],\n",
      "        [-0.9697],\n",
      "        [-0.9697],\n",
      "        [ 0.3671],\n",
      "        [ 0.3671],\n",
      "        [ 0.3671],\n",
      "        [ 0.3671]], dtype=torch.float64)\n",
      "Finished episode 1150 Average rewards:  63.2\n",
      "Monitored episode 50 Average Monitored rewards:  42.8\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2564187  1.0029297  0.8636831  1.9999771 -0.1035003  1.8641111\n",
      "  1.7464267  0.7518858]\n",
      "Enc\n",
      "[0.9027948 0.6978169]\n",
      "tensor([[-0.1924],\n",
      "        [ 0.0176],\n",
      "        [ 0.0176],\n",
      "        [ 0.0176],\n",
      "        [ 0.0176],\n",
      "        [ 0.0176],\n",
      "        [ 0.0176],\n",
      "        [ 0.0176],\n",
      "        [-0.6661],\n",
      "        [-0.6661],\n",
      "        [-0.1924],\n",
      "        [-0.1924],\n",
      "        [-0.9621],\n",
      "        [-0.9621],\n",
      "        [ 0.3464],\n",
      "        [ 0.3464],\n",
      "        [-0.1924],\n",
      "        [ 0.0176],\n",
      "        [ 0.0176],\n",
      "        [ 0.0176],\n",
      "        [-0.1924],\n",
      "        [ 0.0176],\n",
      "        [ 0.0176],\n",
      "        [ 0.0176],\n",
      "        [ 0.0176],\n",
      "        [-0.6661],\n",
      "        [-0.6661],\n",
      "        [-0.6661],\n",
      "        [-0.9621],\n",
      "        [-0.9621],\n",
      "        [-0.1924],\n",
      "        [ 0.0176],\n",
      "        [ 0.0176],\n",
      "        [ 0.0176],\n",
      "        [ 0.0176],\n",
      "        [ 0.0176],\n",
      "        [ 0.0176],\n",
      "        [ 0.0176],\n",
      "        [ 0.0176],\n",
      "        [ 0.0176],\n",
      "        [ 0.8609],\n",
      "        [ 0.8609],\n",
      "        [ 0.8609],\n",
      "        [ 0.8609],\n",
      "        [-0.9621],\n",
      "        [-0.1924],\n",
      "        [-0.1924],\n",
      "        [-0.1924],\n",
      "        [ 0.0176],\n",
      "        [ 0.0176]], dtype=torch.float64)\n",
      "Finished episode 1155 Average rewards:  36.8\n",
      "len_game 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[ 1.2792931   1.0029598   0.88299924  1.9999793  -0.06078246  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8799211  0.71713305]\n",
      "tensor([[-0.1189],\n",
      "        [-0.0541],\n",
      "        [-0.0541],\n",
      "        [ 0.8920],\n",
      "        [-0.9751],\n",
      "        [-0.9751],\n",
      "        [-0.9751],\n",
      "        [ 0.2810],\n",
      "        [-0.1189],\n",
      "        [-0.9751],\n",
      "        [ 0.8920],\n",
      "        [ 0.8920],\n",
      "        [ 0.8920],\n",
      "        [-0.9751],\n",
      "        [-0.9751],\n",
      "        [-0.9751],\n",
      "        [ 0.2810],\n",
      "        [ 0.2810],\n",
      "        [-0.0541],\n",
      "        [-0.0541],\n",
      "        [ 0.8920],\n",
      "        [-0.9751],\n",
      "        [-0.1189],\n",
      "        [-0.0541],\n",
      "        [-0.7263],\n",
      "        [-0.9751],\n",
      "        [-0.0541],\n",
      "        [ 0.8920],\n",
      "        [ 0.8920],\n",
      "        [-0.9751],\n",
      "        [-0.1189],\n",
      "        [-0.0541],\n",
      "        [-0.0541],\n",
      "        [-0.0541],\n",
      "        [-0.0541],\n",
      "        [-0.0541],\n",
      "        [-0.0541],\n",
      "        [-0.7263],\n",
      "        [-0.7263],\n",
      "        [-0.7263],\n",
      "        [-0.1189],\n",
      "        [-0.1189],\n",
      "        [-0.0541],\n",
      "        [-0.0541],\n",
      "        [-0.7263],\n",
      "        [-0.7263],\n",
      "        [-0.7263],\n",
      "        [-0.7263],\n",
      "        [-0.0541],\n",
      "        [-0.0541]], dtype=torch.float64)\n",
      "Finished episode 1160 Average rewards:  37.4\n",
      "Monitored episode 50 Average Monitored rewards:  39.96\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2717851   1.0028453   0.87050754  1.9999799  -0.08957671  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88743   0.7046413]\n",
      "tensor([[ 0.8394],\n",
      "        [-0.9464],\n",
      "        [-0.9464],\n",
      "        [-0.9464],\n",
      "        [-0.9464],\n",
      "        [ 0.4055],\n",
      "        [ 0.4055],\n",
      "        [ 0.4055],\n",
      "        [-0.2546],\n",
      "        [ 0.0679],\n",
      "        [ 0.8394],\n",
      "        [-0.9464],\n",
      "        [-0.2546],\n",
      "        [-0.2546],\n",
      "        [ 0.0679],\n",
      "        [ 0.0679],\n",
      "        [ 0.0679],\n",
      "        [ 0.0679],\n",
      "        [ 0.0679],\n",
      "        [ 0.0679],\n",
      "        [ 0.8394],\n",
      "        [ 0.0679],\n",
      "        [ 0.0679],\n",
      "        [ 0.0679],\n",
      "        [ 0.0679],\n",
      "        [ 0.0679],\n",
      "        [ 0.0679],\n",
      "        [ 0.0679],\n",
      "        [ 0.0679],\n",
      "        [ 0.0679],\n",
      "        [-0.2546],\n",
      "        [ 0.0679],\n",
      "        [ 0.0679],\n",
      "        [ 0.0679],\n",
      "        [ 0.0679],\n",
      "        [ 0.0679],\n",
      "        [ 0.0679],\n",
      "        [ 0.0679],\n",
      "        [ 0.0679],\n",
      "        [ 0.0679],\n",
      "        [ 0.8394],\n",
      "        [-0.9464],\n",
      "        [ 0.0679],\n",
      "        [ 0.0679],\n",
      "        [ 0.0679],\n",
      "        [ 0.0679],\n",
      "        [ 0.0679],\n",
      "        [ 0.0679],\n",
      "        [ 0.0679],\n",
      "        [ 0.0679]], dtype=torch.float64)\n",
      "Finished episode 1165 Average rewards:  -9.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2787915   1.0028473   0.88286984  1.9999807  -0.06706288  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8804238  0.71700364]\n",
      "tensor([[-0.1780],\n",
      "        [-0.0143],\n",
      "        [-0.0143],\n",
      "        [-0.6916],\n",
      "        [-0.0143],\n",
      "        [-0.0143],\n",
      "        [-0.0143],\n",
      "        [-0.0143],\n",
      "        [-0.6916],\n",
      "        [-0.0143],\n",
      "        [ 0.8865],\n",
      "        [-0.9717],\n",
      "        [-0.9717],\n",
      "        [-0.9717],\n",
      "        [-0.9717],\n",
      "        [-0.9717],\n",
      "        [-0.9717],\n",
      "        [-0.9717],\n",
      "        [-0.9717],\n",
      "        [ 0.3483],\n",
      "        [-0.1780],\n",
      "        [-0.1780],\n",
      "        [-0.0143],\n",
      "        [-0.0143],\n",
      "        [-0.6916],\n",
      "        [-0.9717],\n",
      "        [-0.9717],\n",
      "        [-0.9717],\n",
      "        [ 0.3483],\n",
      "        [-0.9717],\n",
      "        [ 0.8865],\n",
      "        [-0.9717],\n",
      "        [-0.9717],\n",
      "        [-0.9717],\n",
      "        [-0.9717],\n",
      "        [-0.9717],\n",
      "        [-0.9717],\n",
      "        [ 0.3483],\n",
      "        [-0.9717],\n",
      "        [-0.9717],\n",
      "        [ 0.8865],\n",
      "        [ 0.8865],\n",
      "        [-0.9717],\n",
      "        [-0.9717],\n",
      "        [-0.9717],\n",
      "        [ 0.3483],\n",
      "        [ 0.3483],\n",
      "        [ 0.3483],\n",
      "        [ 0.3483],\n",
      "        [-0.1780]], dtype=torch.float64)\n",
      "Finished episode 1170 Average rewards:  64.4\n",
      "Monitored episode 50 Average Monitored rewards:  36.0\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2729529   1.0028087   0.88679355  1.999981   -0.06377584  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88626266 0.72092736]\n",
      "tensor([[ 0.8483],\n",
      "        [-0.9488],\n",
      "        [-0.9488],\n",
      "        [-0.9488],\n",
      "        [-0.9488],\n",
      "        [-0.9488],\n",
      "        [ 0.3966],\n",
      "        [ 0.3966],\n",
      "        [ 0.3966],\n",
      "        [ 0.3966],\n",
      "        [-0.2400],\n",
      "        [ 0.0500],\n",
      "        [ 0.0500],\n",
      "        [ 0.0500],\n",
      "        [ 0.0500],\n",
      "        [ 0.0500],\n",
      "        [ 0.0500],\n",
      "        [ 0.0500],\n",
      "        [ 0.0500],\n",
      "        [ 0.0500],\n",
      "        [-0.2400],\n",
      "        [-0.2400],\n",
      "        [ 0.0500],\n",
      "        [ 0.0500],\n",
      "        [ 0.0500],\n",
      "        [ 0.0500],\n",
      "        [-0.6296],\n",
      "        [ 0.0500],\n",
      "        [ 0.0500],\n",
      "        [-0.6296],\n",
      "        [ 0.8483],\n",
      "        [-0.9488],\n",
      "        [-0.9488],\n",
      "        [-0.9488],\n",
      "        [-0.9488],\n",
      "        [ 0.3966],\n",
      "        [ 0.3966],\n",
      "        [ 0.3966],\n",
      "        [ 0.3966],\n",
      "        [ 0.3966],\n",
      "        [-0.2400],\n",
      "        [ 0.8483],\n",
      "        [-0.9488],\n",
      "        [-0.2400],\n",
      "        [-0.9488],\n",
      "        [-0.9488],\n",
      "        [-0.9488],\n",
      "        [ 0.3966],\n",
      "        [-0.9488],\n",
      "        [-0.9488],\n",
      "        [-0.9488]], dtype=torch.float64)\n",
      "Finished episode 1175 Average rewards:  38.4\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2653326  1.0027007  0.8769167  1.9999816 -0.0886983  1.8641111\n",
      "  1.7464267  0.7518858]\n",
      "Enc\n",
      "[0.8938838 0.7110505]\n",
      "tensor([[-0.2387],\n",
      "        [ 0.0593],\n",
      "        [ 0.0593],\n",
      "        [ 0.0593],\n",
      "        [ 0.0593],\n",
      "        [ 0.0593],\n",
      "        [ 0.0593],\n",
      "        [-0.6180],\n",
      "        [-0.6180],\n",
      "        [-0.6180],\n",
      "        [ 0.8293],\n",
      "        [ 0.8293],\n",
      "        [-0.9358],\n",
      "        [ 0.0593],\n",
      "        [ 0.0593],\n",
      "        [ 0.0593],\n",
      "        [ 0.0593],\n",
      "        [ 0.0593],\n",
      "        [ 0.0593],\n",
      "        [ 0.0593],\n",
      "        [ 0.0593],\n",
      "        [-0.2387],\n",
      "        [-0.9358],\n",
      "        [-0.2387],\n",
      "        [ 0.0593],\n",
      "        [ 0.0593],\n",
      "        [ 0.0593],\n",
      "        [ 0.0593],\n",
      "        [ 0.0593],\n",
      "        [ 0.0593],\n",
      "        [ 0.0593],\n",
      "        [-0.2387],\n",
      "        [-0.9358],\n",
      "        [-0.9358],\n",
      "        [-0.9358],\n",
      "        [-0.9358],\n",
      "        [ 0.3879],\n",
      "        [ 0.3879],\n",
      "        [ 0.3879],\n",
      "        [-0.9358],\n",
      "        [-0.9358],\n",
      "        [-0.2387],\n",
      "        [-0.9358],\n",
      "        [-0.2387],\n",
      "        [ 0.0593],\n",
      "        [ 0.0593],\n",
      "        [ 0.0593],\n",
      "        [ 0.0593],\n",
      "        [ 0.0593],\n",
      "        [ 0.0593],\n",
      "        [ 0.0593]], dtype=torch.float64)\n",
      "Finished episode 1180 Average rewards:  37.0\n",
      "Monitored episode 50 Average Monitored rewards:  47.46\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2851046   1.0027094   0.89408535  1.9999833  -0.04988535  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8741123 0.7282191]\n",
      "tensor([[ 0.8697],\n",
      "        [ 0.8697],\n",
      "        [-0.9586],\n",
      "        [-0.9586],\n",
      "        [-0.9586],\n",
      "        [ 0.3320],\n",
      "        [ 0.3320],\n",
      "        [ 0.3320],\n",
      "        [-0.9586],\n",
      "        [-0.9586],\n",
      "        [-0.1694],\n",
      "        [-0.9586],\n",
      "        [ 0.3320],\n",
      "        [-0.1694],\n",
      "        [-0.0118],\n",
      "        [-0.0118],\n",
      "        [-0.0118],\n",
      "        [-0.0118],\n",
      "        [-0.6850],\n",
      "        [-0.6850],\n",
      "        [ 0.8697],\n",
      "        [-0.9586],\n",
      "        [-0.1694],\n",
      "        [-0.1694],\n",
      "        [-0.0118],\n",
      "        [-0.0118],\n",
      "        [-0.0118],\n",
      "        [-0.6850],\n",
      "        [-0.6850],\n",
      "        [-0.0118],\n",
      "        [-0.1694],\n",
      "        [-0.9586],\n",
      "        [-0.0118],\n",
      "        [-0.0118],\n",
      "        [-0.0118],\n",
      "        [-0.0118],\n",
      "        [-0.6850],\n",
      "        [-0.6850],\n",
      "        [-0.6850],\n",
      "        [ 0.8697],\n",
      "        [-0.1694],\n",
      "        [-0.9586],\n",
      "        [-0.9586],\n",
      "        [-0.9586],\n",
      "        [ 0.3320],\n",
      "        [ 0.3320],\n",
      "        [ 0.3320],\n",
      "        [ 0.3320],\n",
      "        [-0.1694],\n",
      "        [-0.0118]], dtype=torch.float64)\n",
      "Finished episode 1185 Average rewards:  17.8\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2765087   1.0026257   0.8872131   1.9999838  -0.06556249  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8827088  0.72134686]\n",
      "tensor([[ 0.8124],\n",
      "        [-0.9232],\n",
      "        [-0.9232],\n",
      "        [-0.9232],\n",
      "        [-0.9232],\n",
      "        [-0.9232],\n",
      "        [ 0.4295],\n",
      "        [ 0.4295],\n",
      "        [ 0.4295],\n",
      "        [ 0.4295],\n",
      "        [ 0.8124],\n",
      "        [-0.9232],\n",
      "        [-0.9232],\n",
      "        [-0.2863],\n",
      "        [ 0.0989],\n",
      "        [ 0.0989],\n",
      "        [ 0.0989],\n",
      "        [-0.5761],\n",
      "        [ 0.0989],\n",
      "        [-0.5761],\n",
      "        [ 0.8124],\n",
      "        [-0.2863],\n",
      "        [-0.9232],\n",
      "        [-0.9232],\n",
      "        [-0.9232],\n",
      "        [-0.9232],\n",
      "        [-0.9232],\n",
      "        [ 0.4295],\n",
      "        [ 0.4295],\n",
      "        [ 0.4295],\n",
      "        [ 0.4295],\n",
      "        [ 0.8124],\n",
      "        [-0.9232],\n",
      "        [-0.2863],\n",
      "        [-0.2863],\n",
      "        [ 0.0989],\n",
      "        [ 0.0989],\n",
      "        [ 0.0989],\n",
      "        [ 0.0989],\n",
      "        [ 0.0989],\n",
      "        [ 0.0989],\n",
      "        [-0.2863],\n",
      "        [ 0.0989],\n",
      "        [ 0.0989],\n",
      "        [ 0.0989],\n",
      "        [ 0.0989],\n",
      "        [ 0.0989],\n",
      "        [ 0.0989],\n",
      "        [ 0.0989],\n",
      "        [ 0.0989],\n",
      "        [ 0.0989]], dtype=torch.float64)\n",
      "Finished episode 1190 Average rewards:  58.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  36.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2669115   1.0025531   0.8804556   1.999984   -0.06664553  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.89230645 0.7145894 ]\n",
      "tensor([[ 0.8364],\n",
      "        [-0.9386],\n",
      "        [-0.9386],\n",
      "        [-0.2400],\n",
      "        [ 0.0543],\n",
      "        [ 0.0543],\n",
      "        [-0.6219],\n",
      "        [-0.6219],\n",
      "        [-0.6219],\n",
      "        [ 0.0543],\n",
      "        [-0.2400],\n",
      "        [ 0.0543],\n",
      "        [ 0.0543],\n",
      "        [ 0.0543],\n",
      "        [ 0.0543],\n",
      "        [ 0.0543],\n",
      "        [ 0.0543],\n",
      "        [ 0.0543],\n",
      "        [ 0.0543],\n",
      "        [-0.6219],\n",
      "        [ 0.8364],\n",
      "        [-0.9386],\n",
      "        [-0.9386],\n",
      "        [-0.9386],\n",
      "        [ 0.3935],\n",
      "        [ 0.3935],\n",
      "        [ 0.3935],\n",
      "        [ 0.3935],\n",
      "        [ 0.3935],\n",
      "        [ 0.3935],\n",
      "        [ 0.8364],\n",
      "        [-0.9386],\n",
      "        [-0.9386],\n",
      "        [-0.9386],\n",
      "        [-0.9386],\n",
      "        [-0.9386],\n",
      "        [ 0.3935],\n",
      "        [-0.9386],\n",
      "        [-0.9386],\n",
      "        [ 0.3935],\n",
      "        [-0.2400],\n",
      "        [-0.9386],\n",
      "        [ 0.3935],\n",
      "        [ 0.3935],\n",
      "        [-0.9386],\n",
      "        [-0.9386],\n",
      "        [-0.9386],\n",
      "        [-0.9386],\n",
      "        [-0.9386],\n",
      "        [-0.9386]], dtype=torch.float64)\n",
      "Finished episode 1195 Average rewards:  61.6\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2624501   1.0025201   0.885355    1.9999844  -0.06699122  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.896768   0.71948874]\n",
      "tensor([[ 0.8342],\n",
      "        [-0.9430],\n",
      "        [-0.9430],\n",
      "        [ 0.3699],\n",
      "        [ 0.3699],\n",
      "        [-0.2232],\n",
      "        [-0.9430],\n",
      "        [-0.9430],\n",
      "        [ 0.3699],\n",
      "        [ 0.3699],\n",
      "        [ 0.8342],\n",
      "        [-0.9430],\n",
      "        [-0.2232],\n",
      "        [-0.9430],\n",
      "        [-0.9430],\n",
      "        [-0.9430],\n",
      "        [-0.9430],\n",
      "        [-0.9430],\n",
      "        [-0.9430],\n",
      "        [-0.9430],\n",
      "        [ 0.8342],\n",
      "        [-0.9430],\n",
      "        [-0.9430],\n",
      "        [-0.9430],\n",
      "        [-0.9430],\n",
      "        [-0.9430],\n",
      "        [ 0.3699],\n",
      "        [ 0.3699],\n",
      "        [ 0.3699],\n",
      "        [ 0.3699],\n",
      "        [-0.2232],\n",
      "        [-0.2232],\n",
      "        [ 0.0512],\n",
      "        [ 0.0512],\n",
      "        [ 0.0512],\n",
      "        [ 0.0512],\n",
      "        [ 0.0512],\n",
      "        [ 0.0512],\n",
      "        [ 0.0512],\n",
      "        [ 0.0512],\n",
      "        [-0.2232],\n",
      "        [-0.2232],\n",
      "        [ 0.0512],\n",
      "        [ 0.0512],\n",
      "        [ 0.0512],\n",
      "        [ 0.0512],\n",
      "        [ 0.0512],\n",
      "        [ 0.0512],\n",
      "        [ 0.0512],\n",
      "        [ 0.0512]], dtype=torch.float64)\n",
      "Finished episode 1200 Average rewards:  61.0\n",
      "Monitored episode 50 Average Monitored rewards:  29.18\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2562522   1.0024781   0.8878531   1.9999846  -0.06413349  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9029661 0.7219869]\n",
      "tensor([[-0.2156],\n",
      "        [-0.2156],\n",
      "        [-0.2156],\n",
      "        [ 0.0502],\n",
      "        [ 0.0502],\n",
      "        [ 0.0502],\n",
      "        [ 0.0502],\n",
      "        [ 0.0502],\n",
      "        [ 0.0502],\n",
      "        [-0.6271],\n",
      "        [ 0.8212],\n",
      "        [-0.9297],\n",
      "        [-0.9297],\n",
      "        [-0.9297],\n",
      "        [-0.9297],\n",
      "        [ 0.3586],\n",
      "        [-0.9297],\n",
      "        [-0.9297],\n",
      "        [-0.9297],\n",
      "        [ 0.3586],\n",
      "        [ 0.8212],\n",
      "        [-0.9297],\n",
      "        [-0.2156],\n",
      "        [-0.9297],\n",
      "        [-0.2156],\n",
      "        [-0.9297],\n",
      "        [-0.9297],\n",
      "        [-0.9297],\n",
      "        [ 0.3586],\n",
      "        [ 0.3586],\n",
      "        [-0.2156],\n",
      "        [ 0.0502],\n",
      "        [ 0.0502],\n",
      "        [ 0.0502],\n",
      "        [ 0.0502],\n",
      "        [ 0.0502],\n",
      "        [ 0.0502],\n",
      "        [ 0.0502],\n",
      "        [ 0.0502],\n",
      "        [-0.6271],\n",
      "        [ 0.8212],\n",
      "        [-0.9297],\n",
      "        [ 0.3586],\n",
      "        [-0.2156],\n",
      "        [-0.9297],\n",
      "        [-0.9297],\n",
      "        [-0.9297],\n",
      "        [ 0.3586],\n",
      "        [-0.9297],\n",
      "        [-0.9297]], dtype=torch.float64)\n",
      "Finished episode 1205 Average rewards:  60.8\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2504995   1.0023757   0.8731541   1.999985   -0.09592947  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.90871936 0.7072879 ]\n",
      "tensor([[ 0.8033],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [-0.6178],\n",
      "        [-0.6178],\n",
      "        [ 0.0583],\n",
      "        [-0.6178],\n",
      "        [-0.6178],\n",
      "        [ 0.8033],\n",
      "        [-0.2129],\n",
      "        [-0.9148],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [-0.6178],\n",
      "        [-0.6178],\n",
      "        [ 0.8033],\n",
      "        [-0.9148],\n",
      "        [-0.9148],\n",
      "        [-0.9148],\n",
      "        [ 0.3478],\n",
      "        [ 0.3478],\n",
      "        [ 0.3478],\n",
      "        [ 0.3478],\n",
      "        [-0.2129],\n",
      "        [ 0.0583],\n",
      "        [ 0.8033],\n",
      "        [-0.9148],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [-0.6178],\n",
      "        [-0.6178],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [ 0.8033],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [ 0.0583],\n",
      "        [-0.6178],\n",
      "        [-0.6178]], dtype=torch.float64)\n",
      "Finished episode 1210 Average rewards:  16.4\n",
      "Monitored episode 50 Average Monitored rewards:  49.34\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2790743   1.0024077   0.890474    1.9999863  -0.06095047  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88014513 0.7246078 ]\n",
      "tensor([[-0.1271],\n",
      "        [-0.0325],\n",
      "        [-0.0325],\n",
      "        [-0.7039],\n",
      "        [-0.9542],\n",
      "        [-0.9542],\n",
      "        [-0.9542],\n",
      "        [ 0.2763],\n",
      "        [ 0.2763],\n",
      "        [ 0.2763],\n",
      "        [-0.1271],\n",
      "        [-0.0325],\n",
      "        [-0.0325],\n",
      "        [-0.7039],\n",
      "        [ 0.8644],\n",
      "        [-0.9542],\n",
      "        [-0.1271],\n",
      "        [-0.1271],\n",
      "        [-0.9542],\n",
      "        [-0.9542],\n",
      "        [-0.1271],\n",
      "        [-0.1271],\n",
      "        [-0.0325],\n",
      "        [-0.7039],\n",
      "        [-0.0325],\n",
      "        [-0.7039],\n",
      "        [-0.0325],\n",
      "        [-0.0325],\n",
      "        [-0.0325],\n",
      "        [-0.7039],\n",
      "        [-0.1271],\n",
      "        [-0.0325],\n",
      "        [-0.7039],\n",
      "        [-0.0325],\n",
      "        [-0.0325],\n",
      "        [-0.7039],\n",
      "        [-0.0325],\n",
      "        [-0.7039],\n",
      "        [-0.0325],\n",
      "        [-0.0325],\n",
      "        [ 0.8644],\n",
      "        [-0.0325],\n",
      "        [-0.0325],\n",
      "        [-0.0325],\n",
      "        [-0.7039],\n",
      "        [-0.7039],\n",
      "        [-0.0325],\n",
      "        [-0.0325],\n",
      "        [-0.7039],\n",
      "        [ 0.8644],\n",
      "        [ 0.8644]], dtype=torch.float64)\n",
      "Finished episode 1215 Average rewards:  57.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2738771   1.0023657   0.89154303  1.9999866  -0.06809368  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8853425  0.72567683]\n",
      "tensor([[-0.2539],\n",
      "        [-0.9318],\n",
      "        [-0.9318],\n",
      "        [-0.9318],\n",
      "        [-0.9318],\n",
      "        [-0.9318],\n",
      "        [ 0.4049],\n",
      "        [ 0.4049],\n",
      "        [ 0.4049],\n",
      "        [ 0.4049],\n",
      "        [-0.2539],\n",
      "        [-0.9318],\n",
      "        [ 0.0674],\n",
      "        [ 0.0674],\n",
      "        [ 0.0674],\n",
      "        [ 0.0674],\n",
      "        [-0.6074],\n",
      "        [ 0.0674],\n",
      "        [ 0.0674],\n",
      "        [ 0.0674],\n",
      "        [ 0.8276],\n",
      "        [-0.9318],\n",
      "        [-0.9318],\n",
      "        [ 0.4049],\n",
      "        [ 0.4049],\n",
      "        [ 0.4049],\n",
      "        [ 0.4049],\n",
      "        [ 0.4049],\n",
      "        [-0.9318],\n",
      "        [-0.9318],\n",
      "        [-0.2539],\n",
      "        [-0.2539],\n",
      "        [ 0.0674],\n",
      "        [-0.6074],\n",
      "        [ 0.0674],\n",
      "        [ 0.0674],\n",
      "        [ 0.0674],\n",
      "        [ 0.0674],\n",
      "        [ 0.0674],\n",
      "        [ 0.0674],\n",
      "        [ 0.8276],\n",
      "        [-0.9318],\n",
      "        [-0.9318],\n",
      "        [ 0.4049],\n",
      "        [ 0.4049],\n",
      "        [ 0.4049],\n",
      "        [-0.9318],\n",
      "        [ 0.4049],\n",
      "        [-0.9318],\n",
      "        [-0.9318]], dtype=torch.float64)\n",
      "Finished episode 1220 Average rewards:  59.4\n",
      "Monitored episode 50 Average Monitored rewards:  20.56\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2642684   1.0022643   0.87705576  1.999987   -0.09351531  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8949518  0.71118957]\n",
      "tensor([[-0.2304],\n",
      "        [ 0.0470],\n",
      "        [ 0.0470],\n",
      "        [ 0.0470],\n",
      "        [ 0.0470],\n",
      "        [ 0.0470],\n",
      "        [ 0.0470],\n",
      "        [ 0.0470],\n",
      "        [ 0.0470],\n",
      "        [ 0.0470],\n",
      "        [ 0.8296],\n",
      "        [-0.9292],\n",
      "        [-0.2304],\n",
      "        [-0.9292],\n",
      "        [-0.2304],\n",
      "        [-0.9292],\n",
      "        [ 0.0470],\n",
      "        [ 0.0470],\n",
      "        [ 0.0470],\n",
      "        [ 0.0470],\n",
      "        [ 0.8296],\n",
      "        [ 0.8296],\n",
      "        [-0.9292],\n",
      "        [-0.9292],\n",
      "        [-0.2304],\n",
      "        [ 0.0470],\n",
      "        [ 0.0470],\n",
      "        [ 0.0470],\n",
      "        [ 0.0470],\n",
      "        [ 0.0470],\n",
      "        [ 0.8296],\n",
      "        [-0.9292],\n",
      "        [-0.9292],\n",
      "        [-0.9292],\n",
      "        [-0.9292],\n",
      "        [-0.9292],\n",
      "        [-0.9292],\n",
      "        [-0.9292],\n",
      "        [-0.9292],\n",
      "        [-0.9292],\n",
      "        [-0.2304],\n",
      "        [-0.9292],\n",
      "        [-0.9292],\n",
      "        [-0.9292],\n",
      "        [-0.9292],\n",
      "        [-0.9292],\n",
      "        [ 0.3841],\n",
      "        [ 0.3841],\n",
      "        [ 0.3841],\n",
      "        [-0.9292]], dtype=torch.float64)\n",
      "Finished episode 1225 Average rewards:  41.0\n",
      "len_game 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[ 1.264302    1.0022432   0.88261896  1.9999874  -0.076169    1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8949183  0.71675277]\n",
      "tensor([[-0.1563],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [ 0.8749],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [-0.0256],\n",
      "        [-0.0256],\n",
      "        [-0.0256],\n",
      "        [-0.0256],\n",
      "        [-0.0256],\n",
      "        [-0.6956],\n",
      "        [-0.6956],\n",
      "        [ 0.8749],\n",
      "        [-0.0256],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [ 0.3213],\n",
      "        [ 0.3213],\n",
      "        [ 0.3213],\n",
      "        [ 0.3213],\n",
      "        [ 0.3213],\n",
      "        [-0.1563],\n",
      "        [-0.0256],\n",
      "        [-0.0256],\n",
      "        [-0.0256],\n",
      "        [-0.0256],\n",
      "        [-0.0256],\n",
      "        [-0.0256],\n",
      "        [-0.0256],\n",
      "        [-0.6956],\n",
      "        [-0.6956],\n",
      "        [ 0.8749],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [ 0.3213]], dtype=torch.float64)\n",
      "Finished episode 1230 Average rewards:  63.0\n",
      "Monitored episode 50 Average Monitored rewards:  31.06\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2591985   1.0021726   0.87779814  1.9999877  -0.09710355  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9000222  0.71193194]\n",
      "tensor([[-0.1971],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [-0.1971],\n",
      "        [-0.9423],\n",
      "        [-0.9423],\n",
      "        [ 0.3489],\n",
      "        [-0.1971],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [-0.1971],\n",
      "        [-0.9423],\n",
      "        [-0.1971],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [-0.1971],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.8424],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240],\n",
      "        [ 0.0240]], dtype=torch.float64)\n",
      "Finished episode 1235 Average rewards:  -8.6\n",
      "len_game 52\n",
      "Rot\n",
      "[ 1.2746027   1.0021515   0.8866951   1.9999888  -0.07026124  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8846187  0.72082883]\n",
      "tensor([[-0.1392],\n",
      "        [-0.0358],\n",
      "        [-0.7030],\n",
      "        [-0.9566],\n",
      "        [-0.9566],\n",
      "        [-0.9566],\n",
      "        [-0.9566],\n",
      "        [ 0.3005],\n",
      "        [ 0.3005],\n",
      "        [ 0.3005],\n",
      "        [-0.1392],\n",
      "        [-0.1392],\n",
      "        [-0.0358],\n",
      "        [-0.7030],\n",
      "        [ 0.8724],\n",
      "        [-0.9566],\n",
      "        [-0.9566],\n",
      "        [-0.9566],\n",
      "        [-0.9566],\n",
      "        [-0.9566],\n",
      "        [-0.9566],\n",
      "        [-0.1392],\n",
      "        [-0.0358],\n",
      "        [-0.0358],\n",
      "        [ 0.8724],\n",
      "        [-0.9566],\n",
      "        [ 0.3005],\n",
      "        [ 0.3005],\n",
      "        [-0.1392],\n",
      "        [-0.0358],\n",
      "        [-0.0358],\n",
      "        [-0.1392],\n",
      "        [-0.1392],\n",
      "        [-0.1392],\n",
      "        [-0.0358],\n",
      "        [-0.7030],\n",
      "        [-0.7030],\n",
      "        [-0.9566],\n",
      "        [-0.0358],\n",
      "        [-0.0358],\n",
      "        [-0.7030],\n",
      "        [ 0.8724],\n",
      "        [-0.1392],\n",
      "        [-0.9566],\n",
      "        [-0.9566],\n",
      "        [-0.9566],\n",
      "        [-0.9566],\n",
      "        [ 0.3005],\n",
      "        [ 0.3005],\n",
      "        [ 0.3005],\n",
      "        [ 0.3005],\n",
      "        [ 0.3005]], dtype=torch.float64)\n",
      "Finished episode 1240 Average rewards:  60.8\n",
      "Monitored episode 50 Average Monitored rewards:  29.9\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2689371   1.002096    0.88279873  1.999989   -0.08568299  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8902846  0.71693254]\n",
      "tensor([[ 0.8417],\n",
      "        [-0.9403],\n",
      "        [ 0.0409],\n",
      "        [ 0.0409],\n",
      "        [ 0.0409],\n",
      "        [ 0.0409],\n",
      "        [ 0.0409],\n",
      "        [ 0.0409],\n",
      "        [ 0.0409],\n",
      "        [ 0.0409],\n",
      "        [-0.2266],\n",
      "        [-0.9403],\n",
      "        [-0.9403],\n",
      "        [-0.9403],\n",
      "        [-0.9403],\n",
      "        [ 0.3828],\n",
      "        [ 0.3828],\n",
      "        [ 0.3828],\n",
      "        [ 0.3828],\n",
      "        [ 0.3828],\n",
      "        [-0.2266],\n",
      "        [ 0.0409],\n",
      "        [ 0.0409],\n",
      "        [ 0.0409],\n",
      "        [ 0.0409],\n",
      "        [ 0.0409],\n",
      "        [ 0.0409],\n",
      "        [ 0.0409],\n",
      "        [-0.6336],\n",
      "        [-0.6336],\n",
      "        [ 0.8417],\n",
      "        [-0.9403],\n",
      "        [-0.9403],\n",
      "        [-0.9403],\n",
      "        [-0.9403],\n",
      "        [ 0.3828],\n",
      "        [ 0.3828],\n",
      "        [ 0.3828],\n",
      "        [ 0.3828],\n",
      "        [-0.2266],\n",
      "        [-0.2266],\n",
      "        [-0.2266],\n",
      "        [-0.2266],\n",
      "        [ 0.0409],\n",
      "        [ 0.0409],\n",
      "        [ 0.0409],\n",
      "        [ 0.0409],\n",
      "        [ 0.0409],\n",
      "        [ 0.0409],\n",
      "        [ 0.0409]], dtype=torch.float64)\n",
      "Finished episode 1245 Average rewards:  16.0\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2701877   1.0020505   0.8837585   1.9999896  -0.07462009  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8890344 0.7178922]\n",
      "tensor([[ 0.8624],\n",
      "        [ 0.8624],\n",
      "        [-0.9502],\n",
      "        [-0.9502],\n",
      "        [-0.9502],\n",
      "        [ 0.3465],\n",
      "        [-0.9502],\n",
      "        [-0.9502],\n",
      "        [-0.9502],\n",
      "        [ 0.3465],\n",
      "        [-0.1824],\n",
      "        [-0.9502],\n",
      "        [-0.9502],\n",
      "        [-0.9502],\n",
      "        [ 0.3465],\n",
      "        [ 0.3465],\n",
      "        [ 0.3465],\n",
      "        [ 0.3465],\n",
      "        [ 0.3465],\n",
      "        [-0.1824],\n",
      "        [-0.1824],\n",
      "        [-0.0032],\n",
      "        [-0.6732],\n",
      "        [-0.9502],\n",
      "        [-0.0032],\n",
      "        [-0.0032],\n",
      "        [-0.6732],\n",
      "        [ 0.8624],\n",
      "        [ 0.8624],\n",
      "        [-0.9502],\n",
      "        [ 0.8624],\n",
      "        [ 0.8624],\n",
      "        [-0.9502],\n",
      "        [-0.9502],\n",
      "        [-0.9502],\n",
      "        [ 0.3465],\n",
      "        [ 0.3465],\n",
      "        [ 0.3465],\n",
      "        [-0.1824],\n",
      "        [-0.9502],\n",
      "        [-0.1824],\n",
      "        [-0.0032],\n",
      "        [ 0.8624],\n",
      "        [-0.9502],\n",
      "        [-0.9502],\n",
      "        [ 0.3465],\n",
      "        [ 0.3465],\n",
      "        [-0.1824],\n",
      "        [-0.1824],\n",
      "        [-0.1824],\n",
      "        [-0.1824]], dtype=torch.float64)\n",
      "Finished episode 1250 Average rewards:  81.0\n",
      "Monitored episode 50 Average Monitored rewards:  35.58\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2659359   1.0020182   0.884021    1.9999899  -0.07969647  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.89328635 0.7181547 ]\n",
      "tensor([[-0.2099],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.8466],\n",
      "        [-0.9446],\n",
      "        [-0.9446],\n",
      "        [-0.9446],\n",
      "        [-0.9446],\n",
      "        [ 0.3661],\n",
      "        [ 0.3661],\n",
      "        [-0.9446],\n",
      "        [-0.9446],\n",
      "        [ 0.3661],\n",
      "        [-0.2099],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [-0.2099],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [-0.6467],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.0284],\n",
      "        [-0.2099],\n",
      "        [-0.2099],\n",
      "        [-0.9446],\n",
      "        [-0.9446],\n",
      "        [-0.9446],\n",
      "        [ 0.3661],\n",
      "        [ 0.3661],\n",
      "        [-0.2099],\n",
      "        [-0.9446],\n",
      "        [-0.9446]], dtype=torch.float64)\n",
      "Finished episode 1255 Average rewards:  36.6\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2571087   1.0019457   0.8746586   1.99999    -0.09344747  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9021139 0.7087924]\n",
      "tensor([[-0.1915],\n",
      "        [-0.9432],\n",
      "        [-0.9432],\n",
      "        [ 0.3477],\n",
      "        [ 0.3477],\n",
      "        [ 0.3477],\n",
      "        [ 0.3477],\n",
      "        [-0.9432],\n",
      "        [-0.9432],\n",
      "        [ 0.3477],\n",
      "        [-0.1915],\n",
      "        [ 0.8480],\n",
      "        [-0.9432],\n",
      "        [-0.9432],\n",
      "        [-0.9432],\n",
      "        [ 0.3477],\n",
      "        [ 0.3477],\n",
      "        [ 0.3477],\n",
      "        [ 0.3477],\n",
      "        [-0.1915],\n",
      "        [-0.9432],\n",
      "        [-0.1915],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.8480],\n",
      "        [-0.9432],\n",
      "        [-0.1915],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [-0.6583],\n",
      "        [-0.6583],\n",
      "        [-0.9432],\n",
      "        [-0.1915],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [-0.6583],\n",
      "        [-0.6583],\n",
      "        [-0.6583],\n",
      "        [ 0.8480]], dtype=torch.float64)\n",
      "Finished episode 1260 Average rewards:  58.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  65.66\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2669184   1.0019397   0.88033485  1.9999905  -0.07784137  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.89230436 0.71446866]\n",
      "tensor([[ 0.8682],\n",
      "        [-0.9575],\n",
      "        [-0.9575],\n",
      "        [-0.9575],\n",
      "        [-0.9575],\n",
      "        [-0.9575],\n",
      "        [-0.9575],\n",
      "        [-0.9575],\n",
      "        [-0.9575],\n",
      "        [-0.9575],\n",
      "        [ 0.8682],\n",
      "        [-0.9575],\n",
      "        [-0.0254],\n",
      "        [-0.9575],\n",
      "        [-0.1444],\n",
      "        [-0.0254],\n",
      "        [-0.0254],\n",
      "        [-0.0254],\n",
      "        [-0.6973],\n",
      "        [-0.0254],\n",
      "        [-0.1444],\n",
      "        [-0.0254],\n",
      "        [-0.0254],\n",
      "        [-0.6973],\n",
      "        [-0.6973],\n",
      "        [-0.0254],\n",
      "        [-0.0254],\n",
      "        [-0.0254],\n",
      "        [-0.0254],\n",
      "        [-0.0254],\n",
      "        [ 0.8682],\n",
      "        [ 0.8682],\n",
      "        [-0.9575],\n",
      "        [-0.9575],\n",
      "        [-0.9575],\n",
      "        [ 0.3006],\n",
      "        [ 0.3006],\n",
      "        [ 0.3006],\n",
      "        [ 0.3006],\n",
      "        [ 0.3006],\n",
      "        [-0.1444],\n",
      "        [-0.9575],\n",
      "        [-0.9575],\n",
      "        [-0.9575],\n",
      "        [-0.9575],\n",
      "        [ 0.3006],\n",
      "        [ 0.3006],\n",
      "        [-0.9575],\n",
      "        [-0.9575],\n",
      "        [-0.9575]], dtype=torch.float64)\n",
      "Finished episode 1265 Average rewards:  62.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2556258   1.0018456   0.8613606   1.9999906  -0.10249057  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9035974 0.6954944]\n",
      "tensor([[ 0.8516],\n",
      "        [-0.9494],\n",
      "        [-0.9494],\n",
      "        [-0.9494],\n",
      "        [-0.9494],\n",
      "        [-0.9494],\n",
      "        [ 0.3531],\n",
      "        [ 0.3531],\n",
      "        [ 0.3531],\n",
      "        [-0.1973],\n",
      "        [-0.1973],\n",
      "        [-0.9494],\n",
      "        [-0.9494],\n",
      "        [-0.9494],\n",
      "        [-0.9494],\n",
      "        [-0.9494],\n",
      "        [-0.9494],\n",
      "        [-0.9494],\n",
      "        [-0.9494],\n",
      "        [-0.9494],\n",
      "        [-0.1973],\n",
      "        [-0.1973],\n",
      "        [-0.9494],\n",
      "        [-0.9494],\n",
      "        [-0.9494],\n",
      "        [-0.9494],\n",
      "        [ 0.3531],\n",
      "        [ 0.3531],\n",
      "        [ 0.3531],\n",
      "        [ 0.3531],\n",
      "        [-0.1973],\n",
      "        [-0.9494],\n",
      "        [-0.9494],\n",
      "        [ 0.3531],\n",
      "        [ 0.3531],\n",
      "        [-0.1973],\n",
      "        [ 0.0192],\n",
      "        [ 0.0192],\n",
      "        [ 0.0192],\n",
      "        [ 0.0192],\n",
      "        [-0.1973],\n",
      "        [-0.9494],\n",
      "        [-0.9494],\n",
      "        [ 0.3531],\n",
      "        [ 0.3531],\n",
      "        [ 0.3531],\n",
      "        [-0.1973],\n",
      "        [-0.9494],\n",
      "        [-0.9494],\n",
      "        [-0.9494]], dtype=torch.float64)\n",
      "Finished episode 1270 Average rewards:  62.2\n",
      "Monitored episode 50 Average Monitored rewards:  32.66\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2792592   1.0018451   0.8739867   1.9999915  -0.07542176  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8799644 0.7081205]\n",
      "tensor([[-0.1200],\n",
      "        [-0.0512],\n",
      "        [-0.0512],\n",
      "        [-0.7254],\n",
      "        [-0.0512],\n",
      "        [-0.0512],\n",
      "        [-0.0512],\n",
      "        [-0.7254],\n",
      "        [-0.7254],\n",
      "        [-0.0512],\n",
      "        [-0.1200],\n",
      "        [-0.9763],\n",
      "        [-0.1200],\n",
      "        [-0.9763],\n",
      "        [-0.9763],\n",
      "        [-0.9763],\n",
      "        [-0.9763],\n",
      "        [ 0.2803],\n",
      "        [ 0.2803],\n",
      "        [ 0.2803],\n",
      "        [ 0.8914],\n",
      "        [-0.0512],\n",
      "        [ 0.8914],\n",
      "        [ 0.8914],\n",
      "        [-0.9763],\n",
      "        [-0.9763],\n",
      "        [-0.0512],\n",
      "        [-0.0512],\n",
      "        [-0.0512],\n",
      "        [-0.0512],\n",
      "        [ 0.8914],\n",
      "        [-0.9763],\n",
      "        [-0.1200],\n",
      "        [-0.9763],\n",
      "        [-0.0512],\n",
      "        [-0.0512],\n",
      "        [-0.7254],\n",
      "        [-0.0512],\n",
      "        [-0.0512],\n",
      "        [-0.7254],\n",
      "        [ 0.8914],\n",
      "        [-0.9763],\n",
      "        [-0.9763],\n",
      "        [ 0.2803],\n",
      "        [-0.1200],\n",
      "        [-0.9763],\n",
      "        [-0.1200],\n",
      "        [-0.0512],\n",
      "        [-0.0512],\n",
      "        [-0.0512]], dtype=torch.float64)\n",
      "Finished episode 1275 Average rewards:  16.4\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2664768   1.001753    0.8660173   1.9999918  -0.09605195  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8927473 0.7001511]\n",
      "tensor([[ 0.8729],\n",
      "        [ 0.8729],\n",
      "        [-0.9663],\n",
      "        [-0.9663],\n",
      "        [ 0.0261],\n",
      "        [ 0.0261],\n",
      "        [ 0.0261],\n",
      "        [ 0.0261],\n",
      "        [ 0.0261],\n",
      "        [ 0.0261],\n",
      "        [-0.2221],\n",
      "        [-0.2221],\n",
      "        [ 0.0261],\n",
      "        [ 0.0261],\n",
      "        [ 0.0261],\n",
      "        [-0.6568],\n",
      "        [ 0.0261],\n",
      "        [ 0.0261],\n",
      "        [-0.6568],\n",
      "        [-0.6568],\n",
      "        [-0.2221],\n",
      "        [ 0.0261],\n",
      "        [ 0.0261],\n",
      "        [ 0.0261],\n",
      "        [ 0.0261],\n",
      "        [ 0.0261],\n",
      "        [ 0.0261],\n",
      "        [ 0.0261],\n",
      "        [ 0.0261],\n",
      "        [ 0.0261],\n",
      "        [ 0.8729],\n",
      "        [-0.9663],\n",
      "        [-0.9663],\n",
      "        [-0.2221],\n",
      "        [-0.2221],\n",
      "        [-0.9663],\n",
      "        [-0.2221],\n",
      "        [ 0.0261],\n",
      "        [ 0.0261],\n",
      "        [-0.6568],\n",
      "        [-0.2221],\n",
      "        [-0.9663],\n",
      "        [-0.9663],\n",
      "        [-0.9663],\n",
      "        [ 0.3869],\n",
      "        [ 0.3869],\n",
      "        [ 0.3869],\n",
      "        [-0.2221],\n",
      "        [ 0.0261],\n",
      "        [ 0.0261]], dtype=torch.float64)\n",
      "Finished episode 1280 Average rewards:  -5.6\n",
      "Monitored episode 50 Average Monitored rewards:  46.38\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2691095   1.0017083   0.86550343  1.9999923  -0.08547032  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8901149 0.6996372]\n",
      "tensor([[-0.1541],\n",
      "        [-0.0328],\n",
      "        [-0.0328],\n",
      "        [-0.0328],\n",
      "        [-0.0328],\n",
      "        [-0.0328],\n",
      "        [-0.7089],\n",
      "        [-0.7089],\n",
      "        [-0.0328],\n",
      "        [-0.7089],\n",
      "        [ 0.8929],\n",
      "        [-0.9765],\n",
      "        [-0.9765],\n",
      "        [-0.1541],\n",
      "        [-0.1541],\n",
      "        [-0.9765],\n",
      "        [-0.9765],\n",
      "        [-0.9765],\n",
      "        [ 0.3236],\n",
      "        [ 0.3236],\n",
      "        [ 0.8929],\n",
      "        [-0.9765],\n",
      "        [-0.0328],\n",
      "        [ 0.8929],\n",
      "        [-0.0328],\n",
      "        [ 0.8929],\n",
      "        [-0.9765],\n",
      "        [-0.1541],\n",
      "        [-0.9765],\n",
      "        [-0.1541],\n",
      "        [-0.1541],\n",
      "        [-0.1541],\n",
      "        [-0.9765],\n",
      "        [ 0.3236],\n",
      "        [ 0.3236],\n",
      "        [-0.9765],\n",
      "        [-0.9765],\n",
      "        [-0.9765],\n",
      "        [ 0.3236],\n",
      "        [ 0.3236],\n",
      "        [-0.1541],\n",
      "        [-0.0328],\n",
      "        [-0.7089],\n",
      "        [ 0.8929],\n",
      "        [-0.9765],\n",
      "        [-0.9765],\n",
      "        [-0.9765],\n",
      "        [-0.9765],\n",
      "        [-0.9765],\n",
      "        [-0.9765]], dtype=torch.float64)\n",
      "Finished episode 1285 Average rewards:  62.8\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2846303   1.0016934   0.87312573  1.9999928  -0.06159057  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.87459433 0.70725954]\n",
      "tensor([[-0.1832],\n",
      "        [-0.0026],\n",
      "        [-0.0026],\n",
      "        [-0.0026],\n",
      "        [-0.0026],\n",
      "        [-0.6856],\n",
      "        [-0.6856],\n",
      "        [-0.9751],\n",
      "        [-0.9751],\n",
      "        [-0.9751],\n",
      "        [-0.1832],\n",
      "        [-0.0026],\n",
      "        [-0.0026],\n",
      "        [-0.0026],\n",
      "        [-0.6856],\n",
      "        [-0.0026],\n",
      "        [-0.0026],\n",
      "        [-0.0026],\n",
      "        [-0.0026],\n",
      "        [-0.0026],\n",
      "        [ 0.8824],\n",
      "        [-0.9751],\n",
      "        [-0.9751],\n",
      "        [-0.9751],\n",
      "        [-0.9751],\n",
      "        [-0.9751],\n",
      "        [ 0.3473],\n",
      "        [ 0.3473],\n",
      "        [ 0.3473],\n",
      "        [ 0.3473],\n",
      "        [-0.1832],\n",
      "        [-0.0026],\n",
      "        [-0.6856],\n",
      "        [-0.0026],\n",
      "        [ 0.8824],\n",
      "        [-0.9751],\n",
      "        [-0.0026],\n",
      "        [ 0.8824],\n",
      "        [-0.9751],\n",
      "        [-0.0026],\n",
      "        [-0.1832],\n",
      "        [-0.9751],\n",
      "        [-0.9751],\n",
      "        [-0.9751],\n",
      "        [ 0.3473],\n",
      "        [ 0.3473],\n",
      "        [ 0.3473],\n",
      "        [ 0.3473],\n",
      "        [-0.1832],\n",
      "        [-0.9751]], dtype=torch.float64)\n",
      "Finished episode 1290 Average rewards:  59.6\n",
      "Monitored episode 50 Average Monitored rewards:  37.84\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2760867   1.0016488   0.8746404   1.999993   -0.06767244  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8831381  0.70877415]\n",
      "tensor([[-0.2605],\n",
      "        [ 0.0656],\n",
      "        [ 0.0656],\n",
      "        [ 0.0656],\n",
      "        [ 0.0656],\n",
      "        [ 0.0656],\n",
      "        [ 0.0656],\n",
      "        [ 0.0656],\n",
      "        [ 0.0656],\n",
      "        [ 0.0656],\n",
      "        [-0.2605],\n",
      "        [ 0.0656],\n",
      "        [ 0.0656],\n",
      "        [ 0.0656],\n",
      "        [ 0.0656],\n",
      "        [-0.6245],\n",
      "        [-0.6245],\n",
      "        [-0.6245],\n",
      "        [ 0.0656],\n",
      "        [ 0.0656],\n",
      "        [-0.2605],\n",
      "        [-0.9661],\n",
      "        [ 0.0656],\n",
      "        [ 0.0656],\n",
      "        [ 0.0656],\n",
      "        [ 0.0656],\n",
      "        [ 0.0656],\n",
      "        [ 0.0656],\n",
      "        [ 0.0656],\n",
      "        [-0.6245],\n",
      "        [ 0.8613],\n",
      "        [ 0.8613],\n",
      "        [-0.9661],\n",
      "        [-0.9661],\n",
      "        [-0.9661],\n",
      "        [ 0.4155],\n",
      "        [ 0.4155],\n",
      "        [ 0.4155],\n",
      "        [ 0.4155],\n",
      "        [-0.2605],\n",
      "        [-0.2605],\n",
      "        [-0.2605],\n",
      "        [-0.2605],\n",
      "        [-0.9661],\n",
      "        [ 0.0656],\n",
      "        [ 0.0656],\n",
      "        [ 0.0656],\n",
      "        [ 0.0656],\n",
      "        [ 0.0656],\n",
      "        [ 0.0656],\n",
      "        [ 0.0656]], dtype=torch.float64)\n",
      "Finished episode 1295 Average rewards:  14.8\n",
      "len_game 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[ 1.2676464   1.001592    0.8649464   1.9999932  -0.08612395  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.89157856 0.6990802 ]\n",
      "tensor([[ 0.8565],\n",
      "        [ 0.0482],\n",
      "        [ 0.0482],\n",
      "        [ 0.0482],\n",
      "        [ 0.0482],\n",
      "        [-0.6380],\n",
      "        [ 0.8565],\n",
      "        [-0.9609],\n",
      "        [-0.9609],\n",
      "        [-0.9609],\n",
      "        [-0.2346],\n",
      "        [-0.9609],\n",
      "        [-0.9609],\n",
      "        [-0.9609],\n",
      "        [-0.9609],\n",
      "        [-0.9609],\n",
      "        [-0.9609],\n",
      "        [-0.9609],\n",
      "        [-0.9609],\n",
      "        [-0.9609],\n",
      "        [-0.2346],\n",
      "        [ 0.0482],\n",
      "        [-0.6380],\n",
      "        [ 0.0482],\n",
      "        [ 0.0482],\n",
      "        [ 0.0482],\n",
      "        [ 0.0482],\n",
      "        [ 0.0482],\n",
      "        [ 0.0482],\n",
      "        [ 0.0482],\n",
      "        [-0.2346],\n",
      "        [-0.2346],\n",
      "        [-0.9609],\n",
      "        [-0.9609],\n",
      "        [-0.9609],\n",
      "        [ 0.3897],\n",
      "        [ 0.3897],\n",
      "        [ 0.3897],\n",
      "        [ 0.3897],\n",
      "        [ 0.3897],\n",
      "        [ 0.8565],\n",
      "        [-0.9609],\n",
      "        [-0.9609],\n",
      "        [-0.9609],\n",
      "        [-0.9609],\n",
      "        [-0.9609],\n",
      "        [-0.9609],\n",
      "        [-0.9609],\n",
      "        [-0.9609],\n",
      "        [ 0.3897]], dtype=torch.float64)\n",
      "Finished episode 1300 Average rewards:  84.2\n",
      "Monitored episode 50 Average Monitored rewards:  47.1\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2743003   1.0015681   0.87167203  1.9999937  -0.06073271  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88492495 0.70580584]\n",
      "tensor([[ 0.8818],\n",
      "        [ 0.8818],\n",
      "        [-0.9750],\n",
      "        [-0.9750],\n",
      "        [-0.9750],\n",
      "        [-0.9750],\n",
      "        [ 0.3424],\n",
      "        [ 0.3424],\n",
      "        [-0.9750],\n",
      "        [-0.9750],\n",
      "        [ 0.8818],\n",
      "        [-0.9750],\n",
      "        [-0.9750],\n",
      "        [-0.9750],\n",
      "        [-0.9750],\n",
      "        [ 0.3424],\n",
      "        [-0.9750],\n",
      "        [-0.9750],\n",
      "        [-0.9750],\n",
      "        [ 0.3424],\n",
      "        [ 0.8818],\n",
      "        [-0.9750],\n",
      "        [-0.0044],\n",
      "        [-0.0044],\n",
      "        [-0.6874],\n",
      "        [-0.6874],\n",
      "        [-0.9750],\n",
      "        [-0.1793],\n",
      "        [-0.0044],\n",
      "        [-0.0044],\n",
      "        [-0.1793],\n",
      "        [-0.9750],\n",
      "        [ 0.3424],\n",
      "        [-0.9750],\n",
      "        [-0.9750],\n",
      "        [ 0.3424],\n",
      "        [-0.9750],\n",
      "        [ 0.3424],\n",
      "        [-0.0044],\n",
      "        [-0.9750],\n",
      "        [-0.1793],\n",
      "        [-0.0044],\n",
      "        [-0.0044],\n",
      "        [-0.0044],\n",
      "        [-0.6874],\n",
      "        [-0.6874],\n",
      "        [ 0.8818],\n",
      "        [-0.9750],\n",
      "        [-0.1793],\n",
      "        [-0.1793]], dtype=torch.float64)\n",
      "Finished episode 1305 Average rewards:  102.6\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2685832   1.0015436   0.8758535   1.9999938  -0.05992055  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8906422 0.7099873]\n",
      "tensor([[-0.2475],\n",
      "        [ 0.0680],\n",
      "        [ 0.0680],\n",
      "        [ 0.0680],\n",
      "        [ 0.0680],\n",
      "        [ 0.0680],\n",
      "        [ 0.0680],\n",
      "        [ 0.0680],\n",
      "        [ 0.0680],\n",
      "        [-0.6234],\n",
      "        [-0.2475],\n",
      "        [ 0.0680],\n",
      "        [ 0.0680],\n",
      "        [ 0.0680],\n",
      "        [ 0.0680],\n",
      "        [ 0.0680],\n",
      "        [ 0.0680],\n",
      "        [ 0.0680],\n",
      "        [ 0.0680],\n",
      "        [ 0.0680],\n",
      "        [ 0.8467],\n",
      "        [ 0.8467],\n",
      "        [-0.9605],\n",
      "        [ 0.0680],\n",
      "        [ 0.0680],\n",
      "        [ 0.0680],\n",
      "        [ 0.0680],\n",
      "        [ 0.0680],\n",
      "        [-0.6234],\n",
      "        [ 0.0680],\n",
      "        [ 0.8467],\n",
      "        [-0.9605],\n",
      "        [-0.9605],\n",
      "        [-0.9605],\n",
      "        [-0.9605],\n",
      "        [-0.9605],\n",
      "        [-0.9605],\n",
      "        [-0.9605],\n",
      "        [-0.9605],\n",
      "        [-0.9605],\n",
      "        [ 0.8467],\n",
      "        [ 0.8467],\n",
      "        [-0.9605],\n",
      "        [-0.9605],\n",
      "        [-0.9605],\n",
      "        [-0.9605],\n",
      "        [ 0.3950],\n",
      "        [ 0.3950],\n",
      "        [ 0.3950],\n",
      "        [ 0.3950]], dtype=torch.float64)\n",
      "Finished episode 1310 Average rewards:  39.4\n",
      "Monitored episode 50 Average Monitored rewards:  40.26\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.260125    1.0014633   0.86307347  1.999994   -0.10060637  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8991007 0.6972073]\n",
      "tensor([[-0.2410],\n",
      "        [ 0.0703],\n",
      "        [ 0.0703],\n",
      "        [ 0.0703],\n",
      "        [ 0.0703],\n",
      "        [ 0.0703],\n",
      "        [-0.6183],\n",
      "        [-0.6183],\n",
      "        [ 0.8318],\n",
      "        [-0.9481],\n",
      "        [ 0.8318],\n",
      "        [-0.9481],\n",
      "        [-0.9481],\n",
      "        [ 0.3835],\n",
      "        [-0.2410],\n",
      "        [-0.9481],\n",
      "        [ 0.0703],\n",
      "        [ 0.0703],\n",
      "        [ 0.0703],\n",
      "        [ 0.0703],\n",
      "        [-0.2410],\n",
      "        [-0.9481],\n",
      "        [ 0.0703],\n",
      "        [ 0.0703],\n",
      "        [-0.6183],\n",
      "        [-0.6183],\n",
      "        [ 0.0703],\n",
      "        [ 0.0703],\n",
      "        [ 0.0703],\n",
      "        [ 0.0703],\n",
      "        [-0.2410],\n",
      "        [ 0.0703],\n",
      "        [ 0.0703],\n",
      "        [-0.6183],\n",
      "        [ 0.0703],\n",
      "        [ 0.0703],\n",
      "        [ 0.0703],\n",
      "        [ 0.0703],\n",
      "        [ 0.0703],\n",
      "        [ 0.0703],\n",
      "        [ 0.8318],\n",
      "        [-0.9481],\n",
      "        [-0.9481],\n",
      "        [ 0.3835],\n",
      "        [ 0.3835],\n",
      "        [ 0.3835],\n",
      "        [-0.2410],\n",
      "        [ 0.0703],\n",
      "        [ 0.0703],\n",
      "        [ 0.0703]], dtype=torch.float64)\n",
      "Finished episode 1315 Average rewards:  16.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2602822   1.0014347   0.8625295   1.9999943  -0.09717226  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8989438 0.6966633]\n",
      "tensor([[ 0.8934],\n",
      "        [-0.9773],\n",
      "        [-0.0458],\n",
      "        [-0.0458],\n",
      "        [-0.0458],\n",
      "        [-0.0458],\n",
      "        [-0.0458],\n",
      "        [-0.7205],\n",
      "        [-0.7205],\n",
      "        [-0.9773],\n",
      "        [ 0.8934],\n",
      "        [-0.9773],\n",
      "        [-0.9773],\n",
      "        [-0.9773],\n",
      "        [-0.9773],\n",
      "        [-0.9773],\n",
      "        [ 0.2973],\n",
      "        [ 0.2973],\n",
      "        [ 0.2973],\n",
      "        [ 0.2973],\n",
      "        [-0.1324],\n",
      "        [-0.1324],\n",
      "        [-0.9773],\n",
      "        [-0.9773],\n",
      "        [-0.9773],\n",
      "        [-0.9773],\n",
      "        [-0.9773],\n",
      "        [-0.9773],\n",
      "        [ 0.2973],\n",
      "        [ 0.2973],\n",
      "        [-0.1324],\n",
      "        [-0.9773],\n",
      "        [-0.9773],\n",
      "        [-0.9773],\n",
      "        [ 0.2973],\n",
      "        [ 0.2973],\n",
      "        [ 0.2973],\n",
      "        [ 0.2973],\n",
      "        [ 0.2973],\n",
      "        [-0.9773],\n",
      "        [ 0.8934],\n",
      "        [-0.9773],\n",
      "        [-0.1324],\n",
      "        [-0.9773],\n",
      "        [-0.9773],\n",
      "        [-0.9773],\n",
      "        [ 0.2973],\n",
      "        [ 0.2973],\n",
      "        [ 0.2973],\n",
      "        [-0.9773]], dtype=torch.float64)\n",
      "Finished episode 1320 Average rewards:  82.0\n",
      "Monitored episode 50 Average Monitored rewards:  58.02\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2589266   1.0013752   0.84914744  1.9999944  -0.10914334  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9002996  0.68328124]\n",
      "tensor([[-0.1409],\n",
      "        [-0.9766],\n",
      "        [-0.9766],\n",
      "        [ 0.3036],\n",
      "        [-0.1409],\n",
      "        [-0.9766],\n",
      "        [-0.9766],\n",
      "        [-0.9766],\n",
      "        [-0.9766],\n",
      "        [-0.9766],\n",
      "        [-0.1409],\n",
      "        [-0.9766],\n",
      "        [-0.9766],\n",
      "        [-0.9766],\n",
      "        [-0.9766],\n",
      "        [-0.9766],\n",
      "        [ 0.3036],\n",
      "        [ 0.3036],\n",
      "        [ 0.3036],\n",
      "        [ 0.3036],\n",
      "        [-0.1409],\n",
      "        [-0.0360],\n",
      "        [ 0.8894],\n",
      "        [-0.9766],\n",
      "        [ 0.3036],\n",
      "        [-0.0360],\n",
      "        [ 0.8894],\n",
      "        [-0.0360],\n",
      "        [-0.0360],\n",
      "        [-0.0360],\n",
      "        [-0.1409],\n",
      "        [-0.9766],\n",
      "        [-0.9766],\n",
      "        [-0.9766],\n",
      "        [ 0.3036],\n",
      "        [ 0.3036],\n",
      "        [-0.9766],\n",
      "        [-0.9766],\n",
      "        [-0.9766],\n",
      "        [-0.9766],\n",
      "        [-0.1409],\n",
      "        [-0.9766],\n",
      "        [-0.9766],\n",
      "        [-0.9766],\n",
      "        [ 0.3036],\n",
      "        [ 0.3036],\n",
      "        [ 0.3036],\n",
      "        [ 0.3036],\n",
      "        [ 0.3036],\n",
      "        [-0.1409]], dtype=torch.float64)\n",
      "Finished episode 1325 Average rewards:  82.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2823246   1.0013816   0.8674539   1.999995   -0.06953476  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8769018 0.7015877]\n",
      "tensor([[ 0.9118],\n",
      "        [-0.9905],\n",
      "        [-0.0701],\n",
      "        [-0.0701],\n",
      "        [-0.0701],\n",
      "        [-0.0701],\n",
      "        [-0.0701],\n",
      "        [-0.0701],\n",
      "        [-0.0701],\n",
      "        [-0.0701],\n",
      "        [ 0.9118],\n",
      "        [-0.9905],\n",
      "        [-0.0701],\n",
      "        [-0.9905],\n",
      "        [-0.1097],\n",
      "        [-0.0701],\n",
      "        [ 0.9118],\n",
      "        [ 0.9118],\n",
      "        [ 0.9118],\n",
      "        [-0.0701],\n",
      "        [ 0.9118],\n",
      "        [-0.9905],\n",
      "        [-0.1097],\n",
      "        [-0.0701],\n",
      "        [-0.7444],\n",
      "        [-0.9905],\n",
      "        [-0.9905],\n",
      "        [ 0.2789],\n",
      "        [-0.9905],\n",
      "        [ 0.2789],\n",
      "        [-0.1097],\n",
      "        [-0.0701],\n",
      "        [-0.0701],\n",
      "        [-0.0701],\n",
      "        [-0.0701],\n",
      "        [-0.7444],\n",
      "        [-0.7444],\n",
      "        [-0.7444],\n",
      "        [-0.0701],\n",
      "        [-0.7444],\n",
      "        [-0.1097],\n",
      "        [-0.0701],\n",
      "        [-0.0701],\n",
      "        [-0.7444],\n",
      "        [-0.7444],\n",
      "        [-0.7444],\n",
      "        [-0.9905],\n",
      "        [-0.9905],\n",
      "        [-0.1097],\n",
      "        [-0.0701]], dtype=torch.float64)\n",
      "Finished episode 1330 Average rewards:  17.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  42.62\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2716428   1.0013185   0.8586833   1.9999951  -0.09475575  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88758373 0.6928171 ]\n",
      "tensor([[ 0.8759],\n",
      "        [ 0.8759],\n",
      "        [-0.9750],\n",
      "        [-0.2398],\n",
      "        [ 0.0429],\n",
      "        [ 0.0429],\n",
      "        [ 0.0429],\n",
      "        [ 0.0429],\n",
      "        [ 0.0429],\n",
      "        [ 0.0429],\n",
      "        [-0.2398],\n",
      "        [ 0.0429],\n",
      "        [ 0.0429],\n",
      "        [ 0.0429],\n",
      "        [ 0.0429],\n",
      "        [ 0.0429],\n",
      "        [ 0.0429],\n",
      "        [ 0.0429],\n",
      "        [ 0.0429],\n",
      "        [ 0.0429],\n",
      "        [ 0.8759],\n",
      "        [-0.9750],\n",
      "        [-0.9750],\n",
      "        [-0.2398],\n",
      "        [ 0.0429],\n",
      "        [ 0.0429],\n",
      "        [ 0.0429],\n",
      "        [ 0.0429],\n",
      "        [ 0.0429],\n",
      "        [ 0.0429],\n",
      "        [ 0.8759],\n",
      "        [-0.9750],\n",
      "        [-0.9750],\n",
      "        [-0.9750],\n",
      "        [-0.9750],\n",
      "        [-0.9750],\n",
      "        [-0.9750],\n",
      "        [-0.9750],\n",
      "        [ 0.4012],\n",
      "        [ 0.4012],\n",
      "        [ 0.8759],\n",
      "        [-0.9750],\n",
      "        [-0.9750],\n",
      "        [ 0.0429],\n",
      "        [ 0.0429],\n",
      "        [ 0.0429],\n",
      "        [ 0.0429],\n",
      "        [-0.6474],\n",
      "        [-0.6474],\n",
      "        [ 0.8759]], dtype=torch.float64)\n",
      "Finished episode 1335 Average rewards:  36.6\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.3007408   1.0013449   0.8800852   1.9999956  -0.05367611  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8584858 0.714219 ]\n",
      "tensor([[ 0.9038],\n",
      "        [-0.0291],\n",
      "        [-0.0291],\n",
      "        [-0.7099],\n",
      "        [-0.7099],\n",
      "        [-0.0291],\n",
      "        [-0.0291],\n",
      "        [-0.7099],\n",
      "        [-0.0291],\n",
      "        [-0.7099],\n",
      "        [-0.1658],\n",
      "        [-0.0291],\n",
      "        [-0.0291],\n",
      "        [-0.0291],\n",
      "        [-0.0291],\n",
      "        [-0.7099],\n",
      "        [-0.0291],\n",
      "        [-0.0291],\n",
      "        [-0.0291],\n",
      "        [-0.7099],\n",
      "        [ 0.9038],\n",
      "        [ 0.9038],\n",
      "        [ 0.9038],\n",
      "        [-0.9861],\n",
      "        [-0.1658],\n",
      "        [-0.0291],\n",
      "        [-0.0291],\n",
      "        [-0.7099],\n",
      "        [-0.0291],\n",
      "        [-0.0291],\n",
      "        [ 0.9038],\n",
      "        [-0.9861],\n",
      "        [-0.1658],\n",
      "        [-0.1658],\n",
      "        [-0.0291],\n",
      "        [-0.9861],\n",
      "        [-0.0291],\n",
      "        [-0.0291],\n",
      "        [-0.0291],\n",
      "        [-0.7099],\n",
      "        [-0.1658],\n",
      "        [-0.1658],\n",
      "        [-0.0291],\n",
      "        [-0.7099],\n",
      "        [-0.0291],\n",
      "        [-0.0291],\n",
      "        [-0.7099],\n",
      "        [-0.7099],\n",
      "        [-0.7099],\n",
      "        [-0.7099],\n",
      "        [ 0.9038]], dtype=torch.float64)\n",
      "Finished episode 1340 Average rewards:  16.0\n",
      "Monitored episode 50 Average Monitored rewards:  36.12\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2899352   1.0012978   0.86484414  1.9999957  -0.07003508  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.86929166 0.69897795]\n",
      "tensor([[-0.2994],\n",
      "        [-0.9577],\n",
      "        [-0.9577],\n",
      "        [-0.9577],\n",
      "        [ 0.4524],\n",
      "        [ 0.4524],\n",
      "        [ 0.4524],\n",
      "        [-0.9577],\n",
      "        [-0.9577],\n",
      "        [-0.9577],\n",
      "        [ 0.8624],\n",
      "        [-0.9577],\n",
      "        [-0.9577],\n",
      "        [-0.9577],\n",
      "        [ 0.4524],\n",
      "        [ 0.4524],\n",
      "        [ 0.4524],\n",
      "        [ 0.4524],\n",
      "        [-0.9577],\n",
      "        [-0.2994],\n",
      "        [-0.2994],\n",
      "        [ 0.8624],\n",
      "        [-0.9577],\n",
      "        [ 0.0881],\n",
      "        [ 0.0881],\n",
      "        [ 0.0881],\n",
      "        [ 0.0881],\n",
      "        [ 0.0881],\n",
      "        [-0.5995],\n",
      "        [-0.5995],\n",
      "        [-0.9577],\n",
      "        [-0.2994],\n",
      "        [ 0.0881],\n",
      "        [ 0.0881],\n",
      "        [ 0.0881],\n",
      "        [ 0.0881],\n",
      "        [ 0.0881],\n",
      "        [ 0.0881],\n",
      "        [ 0.0881],\n",
      "        [ 0.0881],\n",
      "        [ 0.0881],\n",
      "        [-0.2994],\n",
      "        [ 0.0881],\n",
      "        [ 0.0881],\n",
      "        [ 0.0881],\n",
      "        [-0.5995],\n",
      "        [-0.5995],\n",
      "        [ 0.8624],\n",
      "        [ 0.0881],\n",
      "        [ 0.0881],\n",
      "        [ 0.0881]], dtype=torch.float64)\n",
      "Finished episode 1345 Average rewards:  39.0\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2823639   1.0012677   0.8616626   1.9999957  -0.07866684  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.87686306 0.69579643]\n",
      "tensor([[ 0.8893],\n",
      "        [-0.9806],\n",
      "        [-0.9806],\n",
      "        [-0.9806],\n",
      "        [ 0.4170],\n",
      "        [-0.2500],\n",
      "        [-0.9806],\n",
      "        [-0.9806],\n",
      "        [ 0.4170],\n",
      "        [ 0.4170],\n",
      "        [-0.2500],\n",
      "        [ 0.8893],\n",
      "        [ 0.8893],\n",
      "        [-0.9806],\n",
      "        [-0.2500],\n",
      "        [-0.9806],\n",
      "        [-0.9806],\n",
      "        [-0.9806],\n",
      "        [-0.9806],\n",
      "        [ 0.4170],\n",
      "        [ 0.4170],\n",
      "        [-0.2500],\n",
      "        [ 0.0415],\n",
      "        [ 0.0415],\n",
      "        [ 0.0415],\n",
      "        [-0.6502],\n",
      "        [-0.6502],\n",
      "        [ 0.0415],\n",
      "        [ 0.0415],\n",
      "        [ 0.0415],\n",
      "        [ 0.0415],\n",
      "        [-0.2500],\n",
      "        [-0.9806],\n",
      "        [-0.9806],\n",
      "        [-0.9806],\n",
      "        [-0.9806],\n",
      "        [-0.9806],\n",
      "        [-0.9806],\n",
      "        [-0.9806],\n",
      "        [-0.9806],\n",
      "        [-0.9806],\n",
      "        [-0.2500],\n",
      "        [ 0.0415],\n",
      "        [ 0.0415],\n",
      "        [ 0.0415],\n",
      "        [ 0.0415],\n",
      "        [ 0.0415],\n",
      "        [ 0.0415],\n",
      "        [-0.6502],\n",
      "        [ 0.0415],\n",
      "        [ 0.0415]], dtype=torch.float64)\n",
      "Finished episode 1350 Average rewards:  40.6\n",
      "Monitored episode 50 Average Monitored rewards:  32.38\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2727664   1.0012262   0.8573019   1.999996   -0.08935911  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8864608  0.69143564]\n",
      "tensor([[ 0.8940],\n",
      "        [-0.9837],\n",
      "        [-0.9837],\n",
      "        [-0.9837],\n",
      "        [-0.9837],\n",
      "        [-0.9837],\n",
      "        [-0.9837],\n",
      "        [-0.9837],\n",
      "        [ 0.3900],\n",
      "        [ 0.3900],\n",
      "        [-0.2197],\n",
      "        [-0.2197],\n",
      "        [-0.9837],\n",
      "        [-0.9837],\n",
      "        [-0.9837],\n",
      "        [-0.9837],\n",
      "        [-0.9837],\n",
      "        [-0.9837],\n",
      "        [-0.9837],\n",
      "        [-0.9837],\n",
      "        [-0.2197],\n",
      "        [ 0.0169],\n",
      "        [ 0.0169],\n",
      "        [ 0.0169],\n",
      "        [ 0.0169],\n",
      "        [ 0.0169],\n",
      "        [ 0.0169],\n",
      "        [ 0.0169],\n",
      "        [ 0.0169],\n",
      "        [ 0.0169],\n",
      "        [-0.2197],\n",
      "        [ 0.0169],\n",
      "        [ 0.0169],\n",
      "        [ 0.0169],\n",
      "        [ 0.0169],\n",
      "        [ 0.0169],\n",
      "        [ 0.0169],\n",
      "        [ 0.0169],\n",
      "        [ 0.0169],\n",
      "        [ 0.0169],\n",
      "        [ 0.8940],\n",
      "        [-0.9837],\n",
      "        [-0.2197],\n",
      "        [-0.9837],\n",
      "        [ 0.0169],\n",
      "        [ 0.0169],\n",
      "        [ 0.0169],\n",
      "        [-0.6722],\n",
      "        [-0.9837],\n",
      "        [-0.9837]], dtype=torch.float64)\n",
      "Finished episode 1355 Average rewards:  61.6\n",
      "len_game 53\n",
      "Rot\n",
      "[ 1.2958217   1.0012363   0.8766386   1.9999963  -0.05408409  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8634055 0.7107724]\n",
      "tensor([[-0.1801],\n",
      "        [-0.0137],\n",
      "        [ 0.8992],\n",
      "        [-0.9865],\n",
      "        [-0.9865],\n",
      "        [-0.1801],\n",
      "        [-0.0137],\n",
      "        [-0.0137],\n",
      "        [ 0.8992],\n",
      "        [-0.0137],\n",
      "        [ 0.8992],\n",
      "        [-0.1801],\n",
      "        [-0.0137],\n",
      "        [ 0.8992],\n",
      "        [-0.9865],\n",
      "        [-0.9865],\n",
      "        [-0.9865],\n",
      "        [-0.9865],\n",
      "        [ 0.3513],\n",
      "        [ 0.3513],\n",
      "        [ 0.3513],\n",
      "        [-0.1801],\n",
      "        [-0.0137],\n",
      "        [-0.0137],\n",
      "        [-0.0137],\n",
      "        [-0.0137],\n",
      "        [-0.0137],\n",
      "        [-0.0137],\n",
      "        [-0.6986],\n",
      "        [-0.0137],\n",
      "        [-0.0137],\n",
      "        [-0.1801],\n",
      "        [-0.0137],\n",
      "        [-0.0137],\n",
      "        [-0.0137],\n",
      "        [-0.0137],\n",
      "        [-0.0137],\n",
      "        [-0.6986],\n",
      "        [-0.6986],\n",
      "        [-0.6986],\n",
      "        [-0.6986],\n",
      "        [ 0.8992],\n",
      "        [ 0.8992],\n",
      "        [ 0.8992],\n",
      "        [ 0.8992],\n",
      "        [-0.9865],\n",
      "        [-0.1801],\n",
      "        [-0.0137],\n",
      "        [-0.9865],\n",
      "        [-0.9865],\n",
      "        [-0.9865],\n",
      "        [ 0.3513],\n",
      "        [ 0.3513]], dtype=torch.float64)\n",
      "Finished episode 1360 Average rewards:  79.0\n",
      "Monitored episode 50 Average Monitored rewards:  26.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2805997   1.0011698   0.86643535  1.9999965  -0.08408166  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8786277  0.70056915]\n",
      "tensor([[ 0.8613],\n",
      "        [-0.9630],\n",
      "        [-0.9630],\n",
      "        [-0.9630],\n",
      "        [ 0.4440],\n",
      "        [-0.2919],\n",
      "        [-0.2919],\n",
      "        [ 0.0870],\n",
      "        [ 0.0870],\n",
      "        [ 0.0870],\n",
      "        [ 0.8613],\n",
      "        [-0.9630],\n",
      "        [-0.9630],\n",
      "        [ 0.4440],\n",
      "        [-0.9630],\n",
      "        [ 0.4440],\n",
      "        [ 0.0870],\n",
      "        [ 0.0870],\n",
      "        [ 0.0870],\n",
      "        [ 0.0870],\n",
      "        [-0.2919],\n",
      "        [ 0.0870],\n",
      "        [ 0.0870],\n",
      "        [ 0.0870],\n",
      "        [-0.6034],\n",
      "        [-0.6034],\n",
      "        [ 0.8613],\n",
      "        [-0.9630],\n",
      "        [-0.9630],\n",
      "        [ 0.4440],\n",
      "        [ 0.8613],\n",
      "        [ 0.8613],\n",
      "        [ 0.0870],\n",
      "        [ 0.0870],\n",
      "        [ 0.0870],\n",
      "        [ 0.0870],\n",
      "        [ 0.0870],\n",
      "        [ 0.0870],\n",
      "        [ 0.0870],\n",
      "        [ 0.0870],\n",
      "        [-0.2919],\n",
      "        [-0.2919],\n",
      "        [ 0.0870],\n",
      "        [ 0.0870],\n",
      "        [ 0.0870],\n",
      "        [ 0.0870],\n",
      "        [ 0.0870],\n",
      "        [ 0.0870],\n",
      "        [ 0.0870],\n",
      "        [-0.6034]], dtype=torch.float64)\n",
      "Finished episode 1365 Average rewards:  16.6\n",
      "len_game 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[ 1.2725477   1.0011281   0.86224365  1.9999967  -0.10295194  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8866799  0.69637746]\n",
      "tensor([[-0.2048],\n",
      "        [-0.9787],\n",
      "        [-0.9787],\n",
      "        [-0.2048],\n",
      "        [-0.9787],\n",
      "        [-0.9787],\n",
      "        [-0.9787],\n",
      "        [-0.9787],\n",
      "        [-0.9787],\n",
      "        [ 0.3788],\n",
      "        [-0.2048],\n",
      "        [-0.9787],\n",
      "        [-0.2048],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [-0.6819],\n",
      "        [-0.6819],\n",
      "        [-0.6819],\n",
      "        [ 0.8945],\n",
      "        [ 0.8945],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [ 0.8945],\n",
      "        [-0.9787],\n",
      "        [ 0.3788],\n",
      "        [-0.2048],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [-0.2048],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [-0.6819],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014],\n",
      "        [ 0.0014]], dtype=torch.float64)\n",
      "Finished episode 1370 Average rewards:  37.2\n",
      "Monitored episode 50 Average Monitored rewards:  65.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2599691   1.0010781   0.8481867   1.9999967  -0.11882854  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.89925855 0.6823205 ]\n",
      "tensor([[-0.1483],\n",
      "        [-0.9844],\n",
      "        [-0.9844],\n",
      "        [-0.9844],\n",
      "        [ 0.3305],\n",
      "        [ 0.3305],\n",
      "        [ 0.3305],\n",
      "        [ 0.3305],\n",
      "        [ 0.3305],\n",
      "        [-0.1483],\n",
      "        [-0.1483],\n",
      "        [-0.9844],\n",
      "        [-0.9844],\n",
      "        [-0.9844],\n",
      "        [-0.9844],\n",
      "        [ 0.3305],\n",
      "        [ 0.3305],\n",
      "        [ 0.3305],\n",
      "        [ 0.3305],\n",
      "        [ 0.3305],\n",
      "        [-0.1483],\n",
      "        [-0.9844],\n",
      "        [-0.9844],\n",
      "        [-0.9844],\n",
      "        [ 0.3305],\n",
      "        [ 0.3305],\n",
      "        [-0.1483],\n",
      "        [-0.1483],\n",
      "        [-0.9844],\n",
      "        [-0.9844],\n",
      "        [ 0.9124],\n",
      "        [-0.9844],\n",
      "        [-0.9844],\n",
      "        [-0.9844],\n",
      "        [-0.9844],\n",
      "        [-0.9844],\n",
      "        [ 0.3305],\n",
      "        [ 0.3305],\n",
      "        [ 0.3305],\n",
      "        [-0.9844],\n",
      "        [-0.1483],\n",
      "        [-0.9844],\n",
      "        [ 0.3305],\n",
      "        [-0.1483],\n",
      "        [-0.9844],\n",
      "        [-0.9844],\n",
      "        [-0.9844],\n",
      "        [ 0.3305],\n",
      "        [ 0.3305],\n",
      "        [-0.1483]], dtype=torch.float64)\n",
      "Finished episode 1375 Average rewards:  61.0\n",
      "len_game 52\n",
      "Rot\n",
      "[ 1.2520301   1.0010517   0.84632045  1.9999967  -0.11837257  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9071976  0.68045425]\n",
      "tensor([[-0.0882],\n",
      "        [-0.0977],\n",
      "        [-0.0977],\n",
      "        [-0.0977],\n",
      "        [-0.0977],\n",
      "        [-0.0977],\n",
      "        [-0.0977],\n",
      "        [-0.7646],\n",
      "        [-0.0977],\n",
      "        [-0.7646],\n",
      "        [-0.0882],\n",
      "        [-0.9941],\n",
      "        [-0.9941],\n",
      "        [-0.9941],\n",
      "        [ 0.2653],\n",
      "        [ 0.2653],\n",
      "        [-0.0882],\n",
      "        [-0.9941],\n",
      "        [-0.9941],\n",
      "        [-0.0882],\n",
      "        [-0.0882],\n",
      "        [-0.9941],\n",
      "        [-0.9941],\n",
      "        [ 0.2653],\n",
      "        [ 0.2653],\n",
      "        [ 0.2653],\n",
      "        [ 0.2653],\n",
      "        [ 0.2653],\n",
      "        [-0.0882],\n",
      "        [-0.9941],\n",
      "        [-0.0882],\n",
      "        [ 0.9253],\n",
      "        [-0.9941],\n",
      "        [-0.9941],\n",
      "        [ 0.2653],\n",
      "        [-0.9941],\n",
      "        [-0.9941],\n",
      "        [-0.9941],\n",
      "        [-0.9941],\n",
      "        [ 0.2653],\n",
      "        [ 0.2653],\n",
      "        [ 0.9253],\n",
      "        [ 0.9253],\n",
      "        [-0.9941],\n",
      "        [-0.9941],\n",
      "        [-0.9941],\n",
      "        [ 0.2653],\n",
      "        [ 0.2653],\n",
      "        [ 0.2653],\n",
      "        [ 0.2653],\n",
      "        [ 0.2653],\n",
      "        [-0.0882]], dtype=torch.float64)\n",
      "Finished episode 1380 Average rewards:  79.4\n",
      "Monitored episode 50 Average Monitored rewards:  49.16\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2654083   1.0010684   0.8618809   1.9999968  -0.09176142  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8938196 0.6960147]\n",
      "tensor([[-0.0747],\n",
      "        [-0.0964],\n",
      "        [-0.0964],\n",
      "        [-0.0964],\n",
      "        [-0.0964],\n",
      "        [-0.0964],\n",
      "        [-0.0964],\n",
      "        [-0.0964],\n",
      "        [-0.7641],\n",
      "        [-0.0964],\n",
      "        [ 0.9159],\n",
      "        [-0.9904],\n",
      "        [-0.9904],\n",
      "        [-0.9904],\n",
      "        [-0.9904],\n",
      "        [-0.9904],\n",
      "        [ 0.2396],\n",
      "        [ 0.2396],\n",
      "        [ 0.2396],\n",
      "        [ 0.2396],\n",
      "        [-0.0747],\n",
      "        [-0.9904],\n",
      "        [-0.9904],\n",
      "        [-0.9904],\n",
      "        [-0.9904],\n",
      "        [ 0.2396],\n",
      "        [ 0.2396],\n",
      "        [ 0.2396],\n",
      "        [ 0.2396],\n",
      "        [ 0.2396],\n",
      "        [-0.0747],\n",
      "        [-0.0964],\n",
      "        [-0.0964],\n",
      "        [-0.0964],\n",
      "        [ 0.9159],\n",
      "        [-0.9904],\n",
      "        [-0.9904],\n",
      "        [-0.9904],\n",
      "        [-0.9904],\n",
      "        [ 0.2396],\n",
      "        [-0.0747],\n",
      "        [-0.0964],\n",
      "        [-0.0964],\n",
      "        [-0.0964],\n",
      "        [-0.0964],\n",
      "        [-0.0964],\n",
      "        [-0.0964],\n",
      "        [-0.0964],\n",
      "        [-0.7641],\n",
      "        [-0.0964]], dtype=torch.float64)\n",
      "Finished episode 1385 Average rewards:  57.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2775295   1.0010673   0.8723954   1.999997   -0.06918287  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88169837 0.70652914]\n",
      "tensor([[ 0.8893],\n",
      "        [-0.9788],\n",
      "        [-0.9788],\n",
      "        [-0.9788],\n",
      "        [ 0.3274],\n",
      "        [ 0.3274],\n",
      "        [ 0.3274],\n",
      "        [ 0.3274],\n",
      "        [-0.1624],\n",
      "        [-0.1624],\n",
      "        [-0.1624],\n",
      "        [-0.0205],\n",
      "        [-0.0205],\n",
      "        [-0.7017],\n",
      "        [-0.0205],\n",
      "        [-0.0205],\n",
      "        [-0.0205],\n",
      "        [-0.0205],\n",
      "        [-0.7017],\n",
      "        [-0.7017],\n",
      "        [-0.1624],\n",
      "        [-0.0205],\n",
      "        [-0.0205],\n",
      "        [-0.0205],\n",
      "        [-0.7017],\n",
      "        [-0.0205],\n",
      "        [-0.0205],\n",
      "        [-0.7017],\n",
      "        [-0.7017],\n",
      "        [-0.7017],\n",
      "        [ 0.8893],\n",
      "        [-0.9788],\n",
      "        [-0.9788],\n",
      "        [-0.1624],\n",
      "        [-0.1624],\n",
      "        [-0.0205],\n",
      "        [-0.0205],\n",
      "        [-0.7017],\n",
      "        [-0.0205],\n",
      "        [-0.7017],\n",
      "        [-0.1624],\n",
      "        [-0.9788],\n",
      "        [ 0.3274],\n",
      "        [-0.1624],\n",
      "        [-0.9788],\n",
      "        [-0.9788],\n",
      "        [-0.9788],\n",
      "        [-0.9788],\n",
      "        [-0.9788],\n",
      "        [ 0.3274]], dtype=torch.float64)\n",
      "Finished episode 1390 Average rewards:  17.4\n",
      "Monitored episode 50 Average Monitored rewards:  37.68\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2689036   1.0010328   0.8664151   1.999997   -0.08088866  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8903243 0.7005489]\n",
      "tensor([[ 0.8634],\n",
      "        [-0.9657],\n",
      "        [-0.2334],\n",
      "        [ 0.0439],\n",
      "        [ 0.0439],\n",
      "        [ 0.0439],\n",
      "        [ 0.0439],\n",
      "        [ 0.0439],\n",
      "        [ 0.0439],\n",
      "        [ 0.0439],\n",
      "        [-0.2334],\n",
      "        [ 0.0439],\n",
      "        [ 0.0439],\n",
      "        [ 0.0439],\n",
      "        [ 0.0439],\n",
      "        [ 0.0439],\n",
      "        [ 0.0439],\n",
      "        [ 0.0439],\n",
      "        [ 0.0439],\n",
      "        [ 0.0439],\n",
      "        [ 0.8634],\n",
      "        [-0.9657],\n",
      "        [ 0.0439],\n",
      "        [ 0.0439],\n",
      "        [ 0.0439],\n",
      "        [ 0.0439],\n",
      "        [ 0.0439],\n",
      "        [-0.6432],\n",
      "        [-0.6432],\n",
      "        [ 0.0439],\n",
      "        [ 0.8634],\n",
      "        [ 0.8634],\n",
      "        [ 0.8634],\n",
      "        [-0.9657],\n",
      "        [-0.9657],\n",
      "        [ 0.3910],\n",
      "        [-0.9657],\n",
      "        [-0.9657],\n",
      "        [-0.9657],\n",
      "        [-0.9657],\n",
      "        [-0.2334],\n",
      "        [ 0.0439],\n",
      "        [ 0.0439],\n",
      "        [ 0.0439],\n",
      "        [ 0.0439],\n",
      "        [ 0.0439],\n",
      "        [ 0.0439],\n",
      "        [ 0.0439],\n",
      "        [ 0.0439],\n",
      "        [ 0.0439]], dtype=torch.float64)\n",
      "Finished episode 1395 Average rewards:  14.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2617851   1.00101     0.87063503  1.999997   -0.08304703  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8974428 0.7047688]\n",
      "tensor([[ 0.8748],\n",
      "        [ 0.8748],\n",
      "        [-0.9721],\n",
      "        [-0.9721],\n",
      "        [-0.1934],\n",
      "        [-0.9721],\n",
      "        [-0.9721],\n",
      "        [-0.9721],\n",
      "        [ 0.3536],\n",
      "        [ 0.3536],\n",
      "        [-0.1934],\n",
      "        [-0.9721],\n",
      "        [-0.1934],\n",
      "        [ 0.0105],\n",
      "        [ 0.0105],\n",
      "        [ 0.0105],\n",
      "        [ 0.0105],\n",
      "        [ 0.0105],\n",
      "        [ 0.0105],\n",
      "        [ 0.0105],\n",
      "        [-0.1934],\n",
      "        [ 0.0105],\n",
      "        [ 0.0105],\n",
      "        [ 0.0105],\n",
      "        [ 0.0105],\n",
      "        [ 0.0105],\n",
      "        [ 0.0105],\n",
      "        [ 0.0105],\n",
      "        [ 0.0105],\n",
      "        [ 0.0105],\n",
      "        [ 0.8748],\n",
      "        [-0.9721],\n",
      "        [-0.9721],\n",
      "        [-0.9721],\n",
      "        [-0.9721],\n",
      "        [-0.9721],\n",
      "        [-0.9721],\n",
      "        [-0.9721],\n",
      "        [ 0.3536],\n",
      "        [ 0.3536],\n",
      "        [-0.1934],\n",
      "        [ 0.0105],\n",
      "        [-0.6746],\n",
      "        [-0.9721],\n",
      "        [-0.9721],\n",
      "        [-0.9721],\n",
      "        [ 0.3536],\n",
      "        [ 0.3536],\n",
      "        [ 0.3536],\n",
      "        [ 0.3536]], dtype=torch.float64)\n",
      "Finished episode 1400 Average rewards:  38.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  32.5\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.252113    1.0009731   0.86991197  1.9999971  -0.09106125  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9071151 0.7040458]\n",
      "tensor([[-0.1769],\n",
      "        [ 0.0043],\n",
      "        [ 0.0043],\n",
      "        [ 0.0043],\n",
      "        [ 0.0043],\n",
      "        [ 0.0043],\n",
      "        [ 0.0043],\n",
      "        [ 0.0043],\n",
      "        [ 0.0043],\n",
      "        [-0.6768],\n",
      "        [-0.1769],\n",
      "        [-0.1769],\n",
      "        [ 0.0043],\n",
      "        [ 0.0043],\n",
      "        [ 0.0043],\n",
      "        [ 0.0043],\n",
      "        [ 0.0043],\n",
      "        [ 0.0043],\n",
      "        [ 0.0043],\n",
      "        [ 0.0043],\n",
      "        [ 0.8637],\n",
      "        [-0.9618],\n",
      "        [-0.9618],\n",
      "        [-0.9618],\n",
      "        [ 0.3313],\n",
      "        [ 0.3313],\n",
      "        [ 0.3313],\n",
      "        [ 0.3313],\n",
      "        [ 0.3313],\n",
      "        [-0.1769],\n",
      "        [-0.1769],\n",
      "        [ 0.0043],\n",
      "        [ 0.0043],\n",
      "        [-0.6768],\n",
      "        [-0.9618],\n",
      "        [-0.1769],\n",
      "        [-0.9618],\n",
      "        [-0.9618],\n",
      "        [ 0.3313],\n",
      "        [ 0.3313],\n",
      "        [-0.1769],\n",
      "        [-0.9618],\n",
      "        [-0.9618],\n",
      "        [ 0.3313],\n",
      "        [-0.1769],\n",
      "        [ 0.0043],\n",
      "        [ 0.0043],\n",
      "        [ 0.0043],\n",
      "        [-0.6768],\n",
      "        [-0.6768]], dtype=torch.float64)\n",
      "Finished episode 1405 Average rewards:  37.0\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2743433  1.0009815  0.8873771  1.9999974 -0.052471   1.8641111\n",
      "  1.7464267  0.7518858]\n",
      "Enc\n",
      "[0.8848849 0.7215109]\n",
      "tensor([[-0.1417],\n",
      "        [-0.0185],\n",
      "        [-0.6954],\n",
      "        [-0.9571],\n",
      "        [-0.1417],\n",
      "        [-0.9571],\n",
      "        [-0.9571],\n",
      "        [-0.0185],\n",
      "        [-0.6954],\n",
      "        [-0.9571],\n",
      "        [ 0.8627],\n",
      "        [-0.0185],\n",
      "        [-0.0185],\n",
      "        [-0.0185],\n",
      "        [-0.0185],\n",
      "        [-0.6954],\n",
      "        [-0.6954],\n",
      "        [-0.0185],\n",
      "        [-0.6954],\n",
      "        [-0.6954],\n",
      "        [ 0.8627],\n",
      "        [-0.9571],\n",
      "        [ 0.2900],\n",
      "        [-0.1417],\n",
      "        [-0.0185],\n",
      "        [-0.0185],\n",
      "        [-0.0185],\n",
      "        [-0.0185],\n",
      "        [-0.0185],\n",
      "        [-0.0185],\n",
      "        [-0.1417],\n",
      "        [-0.0185],\n",
      "        [-0.6954],\n",
      "        [-0.0185],\n",
      "        [-0.0185],\n",
      "        [-0.0185],\n",
      "        [-0.6954],\n",
      "        [-0.6954],\n",
      "        [-0.6954],\n",
      "        [-0.0185],\n",
      "        [-0.1417],\n",
      "        [-0.9571],\n",
      "        [-0.1417],\n",
      "        [-0.0185],\n",
      "        [-0.0185],\n",
      "        [-0.0185],\n",
      "        [-0.0185],\n",
      "        [-0.6954],\n",
      "        [-0.6954],\n",
      "        [-0.6954],\n",
      "        [ 0.8627]], dtype=torch.float64)\n",
      "Finished episode 1410 Average rewards:  36.4\n",
      "Monitored episode 50 Average Monitored rewards:  29.6\n",
      "len_game 52\n",
      "Rot\n",
      "[ 1.2614043   1.0009303   0.8672689   1.9999976  -0.07942339  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8978239 0.7014027]\n",
      "tensor([[ 0.8122],\n",
      "        [ 0.8122],\n",
      "        [ 0.8122],\n",
      "        [-0.9297],\n",
      "        [-0.9297],\n",
      "        [-0.9297],\n",
      "        [-0.9297],\n",
      "        [-0.9297],\n",
      "        [ 0.4059],\n",
      "        [ 0.4059],\n",
      "        [ 0.8122],\n",
      "        [ 0.8122],\n",
      "        [-0.9297],\n",
      "        [-0.9297],\n",
      "        [-0.9297],\n",
      "        [ 0.4059],\n",
      "        [-0.2659],\n",
      "        [-0.2659],\n",
      "        [ 0.0915],\n",
      "        [ 0.0915],\n",
      "        [-0.2659],\n",
      "        [-0.2659],\n",
      "        [-0.9297],\n",
      "        [-0.9297],\n",
      "        [ 0.4059],\n",
      "        [-0.9297],\n",
      "        [-0.9297],\n",
      "        [-0.9297],\n",
      "        [-0.9297],\n",
      "        [-0.9297],\n",
      "        [ 0.8122],\n",
      "        [-0.9297],\n",
      "        [-0.9297],\n",
      "        [ 0.0915],\n",
      "        [ 0.0915],\n",
      "        [ 0.0915],\n",
      "        [ 0.0915],\n",
      "        [ 0.0915],\n",
      "        [ 0.0915],\n",
      "        [ 0.0915],\n",
      "        [-0.2659],\n",
      "        [-0.9297],\n",
      "        [-0.9297],\n",
      "        [ 0.4059],\n",
      "        [-0.2659],\n",
      "        [ 0.0915],\n",
      "        [-0.5897],\n",
      "        [-0.9297],\n",
      "        [-0.9297],\n",
      "        [-0.2659],\n",
      "        [-0.2659],\n",
      "        [-0.2659]], dtype=torch.float64)\n",
      "Finished episode 1415 Average rewards:  59.8\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2533914   1.000907    0.86875427  1.9999976  -0.08287942  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9058369 0.7028881]\n",
      "tensor([[ 0.8611],\n",
      "        [-0.9636],\n",
      "        [-0.9636],\n",
      "        [-0.9636],\n",
      "        [ 0.3362],\n",
      "        [ 0.3362],\n",
      "        [ 0.3362],\n",
      "        [-0.1849],\n",
      "        [-0.9636],\n",
      "        [-0.9636],\n",
      "        [ 0.8611],\n",
      "        [-0.9636],\n",
      "        [-0.9636],\n",
      "        [-0.9636],\n",
      "        [-0.9636],\n",
      "        [-0.9636],\n",
      "        [ 0.3362],\n",
      "        [ 0.3362],\n",
      "        [ 0.3362],\n",
      "        [ 0.3362],\n",
      "        [ 0.8611],\n",
      "        [ 0.8611],\n",
      "        [ 0.8611],\n",
      "        [ 0.8611],\n",
      "        [-0.9636],\n",
      "        [-0.1849],\n",
      "        [-0.9636],\n",
      "        [-0.9636],\n",
      "        [ 0.3362],\n",
      "        [ 0.3362],\n",
      "        [-0.1849],\n",
      "        [ 0.8611],\n",
      "        [-0.9636],\n",
      "        [-0.9636],\n",
      "        [-0.1849],\n",
      "        [ 0.0147],\n",
      "        [ 0.0147],\n",
      "        [-0.6707],\n",
      "        [-0.6707],\n",
      "        [ 0.0147],\n",
      "        [ 0.0147],\n",
      "        [-0.1849],\n",
      "        [-0.1849],\n",
      "        [-0.9636],\n",
      "        [-0.9636],\n",
      "        [-0.9636],\n",
      "        [-0.9636],\n",
      "        [ 0.3362],\n",
      "        [ 0.3362],\n",
      "        [ 0.3362],\n",
      "        [ 0.3362]], dtype=torch.float64)\n",
      "Finished episode 1420 Average rewards:  61.8\n",
      "Monitored episode 50 Average Monitored rewards:  51.06\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2452291   1.0008761   0.8599161   1.9999976  -0.09429107  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9139992 0.6940499]\n",
      "tensor([[-0.1637],\n",
      "        [ 0.0048],\n",
      "        [ 0.0048],\n",
      "        [ 0.0048],\n",
      "        [ 0.0048],\n",
      "        [-0.6777],\n",
      "        [ 0.8532],\n",
      "        [ 0.8532],\n",
      "        [-0.9546],\n",
      "        [-0.1637],\n",
      "        [ 0.8532],\n",
      "        [-0.9546],\n",
      "        [-0.9546],\n",
      "        [-0.9546],\n",
      "        [-0.9546],\n",
      "        [-0.9546],\n",
      "        [-0.9546],\n",
      "        [-0.9546],\n",
      "        [ 0.3083],\n",
      "        [ 0.3083],\n",
      "        [-0.1637],\n",
      "        [-0.9546],\n",
      "        [-0.9546],\n",
      "        [-0.9546],\n",
      "        [ 0.3083],\n",
      "        [ 0.3083],\n",
      "        [ 0.3083],\n",
      "        [ 0.3083],\n",
      "        [ 0.3083],\n",
      "        [ 0.3083],\n",
      "        [-0.1637],\n",
      "        [ 0.8532],\n",
      "        [-0.9546],\n",
      "        [-0.9546],\n",
      "        [ 0.3083],\n",
      "        [-0.1637],\n",
      "        [-0.9546],\n",
      "        [-0.1637],\n",
      "        [-0.9546],\n",
      "        [-0.9546],\n",
      "        [-0.9546],\n",
      "        [ 0.8532],\n",
      "        [-0.9546],\n",
      "        [-0.9546],\n",
      "        [-0.9546],\n",
      "        [-0.9546],\n",
      "        [-0.9546],\n",
      "        [-0.9546],\n",
      "        [-0.9546],\n",
      "        [-0.9546],\n",
      "        [-0.9546]], dtype=torch.float64)\n",
      "Finished episode 1425 Average rewards:  83.4\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2607324   1.0008957   0.8770245   1.9999977  -0.06464512  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.898496  0.7111583]\n",
      "tensor([[-0.1221],\n",
      "        [-0.0278],\n",
      "        [-0.0278],\n",
      "        [-0.0278],\n",
      "        [-0.0278],\n",
      "        [-0.0278],\n",
      "        [-0.0278],\n",
      "        [-0.7083],\n",
      "        [-0.7083],\n",
      "        [-0.7083],\n",
      "        [ 0.8660],\n",
      "        [-0.9609],\n",
      "        [-0.9609],\n",
      "        [ 0.2631],\n",
      "        [ 0.2631],\n",
      "        [ 0.2631],\n",
      "        [-0.1221],\n",
      "        [-0.9609],\n",
      "        [-0.9609],\n",
      "        [ 0.2631],\n",
      "        [-0.1221],\n",
      "        [-0.1221],\n",
      "        [-0.0278],\n",
      "        [-0.0278],\n",
      "        [-0.0278],\n",
      "        [-0.7083],\n",
      "        [-0.0278],\n",
      "        [-0.0278],\n",
      "        [-0.0278],\n",
      "        [-0.0278],\n",
      "        [ 0.8660],\n",
      "        [-0.9609],\n",
      "        [-0.9609],\n",
      "        [-0.9609],\n",
      "        [-0.9609],\n",
      "        [-0.9609],\n",
      "        [-0.9609],\n",
      "        [-0.9609],\n",
      "        [ 0.2631],\n",
      "        [ 0.2631],\n",
      "        [-0.1221],\n",
      "        [-0.0278],\n",
      "        [-0.0278],\n",
      "        [-0.7083],\n",
      "        [-0.0278],\n",
      "        [-0.0278],\n",
      "        [-0.0278],\n",
      "        [-0.0278],\n",
      "        [-0.0278],\n",
      "        [-0.7083]], dtype=torch.float64)\n",
      "Finished episode 1430 Average rewards:  40.4\n",
      "Monitored episode 50 Average Monitored rewards:  31.22\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2544856   1.000862    0.8669988   1.9999977  -0.08947755  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9047428  0.70113254]\n",
      "tensor([[-0.2185],\n",
      "        [-0.9398],\n",
      "        [-0.9398],\n",
      "        [-0.2185],\n",
      "        [-0.9398],\n",
      "        [-0.9398],\n",
      "        [ 0.3580],\n",
      "        [-0.2185],\n",
      "        [ 0.0569],\n",
      "        [ 0.0569],\n",
      "        [-0.2185],\n",
      "        [ 0.0569],\n",
      "        [ 0.0569],\n",
      "        [ 0.0569],\n",
      "        [ 0.0569],\n",
      "        [ 0.0569],\n",
      "        [ 0.0569],\n",
      "        [-0.6288],\n",
      "        [ 0.0569],\n",
      "        [ 0.0569],\n",
      "        [-0.2185],\n",
      "        [-0.2185],\n",
      "        [ 0.0569],\n",
      "        [ 0.0569],\n",
      "        [ 0.0569],\n",
      "        [ 0.0569],\n",
      "        [-0.6288],\n",
      "        [ 0.0569],\n",
      "        [ 0.0569],\n",
      "        [ 0.0569],\n",
      "        [ 0.8260],\n",
      "        [-0.9398],\n",
      "        [-0.2185],\n",
      "        [ 0.0569],\n",
      "        [ 0.0569],\n",
      "        [ 0.0569],\n",
      "        [ 0.0569],\n",
      "        [ 0.0569],\n",
      "        [ 0.0569],\n",
      "        [ 0.0569],\n",
      "        [-0.2185],\n",
      "        [-0.9398],\n",
      "        [-0.9398],\n",
      "        [-0.9398],\n",
      "        [-0.9398],\n",
      "        [-0.9398],\n",
      "        [-0.9398],\n",
      "        [-0.9398],\n",
      "        [-0.9398],\n",
      "        [-0.9398]], dtype=torch.float64)\n",
      "Finished episode 1435 Average rewards:  15.4\n",
      "len_game 51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[ 1.2628635   1.0008442   0.86961365  1.9999979  -0.07165808  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8963649  0.70374745]\n",
      "tensor([[-0.1496],\n",
      "        [-0.1496],\n",
      "        [-0.0140],\n",
      "        [-0.0140],\n",
      "        [-0.0140],\n",
      "        [-0.0140],\n",
      "        [-0.0140],\n",
      "        [-0.6937],\n",
      "        [-0.6937],\n",
      "        [-0.6937],\n",
      "        [ 0.8665],\n",
      "        [ 0.8665],\n",
      "        [-0.9623],\n",
      "        [-0.9623],\n",
      "        [-0.9623],\n",
      "        [-0.9623],\n",
      "        [-0.9623],\n",
      "        [-0.9623],\n",
      "        [-0.9623],\n",
      "        [-0.9623],\n",
      "        [ 0.8665],\n",
      "        [ 0.8665],\n",
      "        [-0.9623],\n",
      "        [-0.0140],\n",
      "        [-0.0140],\n",
      "        [-0.0140],\n",
      "        [ 0.8665],\n",
      "        [-0.0140],\n",
      "        [-0.9623],\n",
      "        [-0.9623],\n",
      "        [ 0.8665],\n",
      "        [-0.9623],\n",
      "        [-0.9623],\n",
      "        [ 0.2998],\n",
      "        [-0.1496],\n",
      "        [-0.9623],\n",
      "        [-0.9623],\n",
      "        [ 0.2998],\n",
      "        [ 0.2998],\n",
      "        [-0.1496],\n",
      "        [-0.1496],\n",
      "        [ 0.8665],\n",
      "        [ 0.8665],\n",
      "        [ 0.8665],\n",
      "        [-0.9623],\n",
      "        [-0.0140],\n",
      "        [-0.9623],\n",
      "        [-0.1496],\n",
      "        [-0.9623],\n",
      "        [-0.1496],\n",
      "        [-0.9623]], dtype=torch.float64)\n",
      "Finished episode 1440 Average rewards:  82.2\n",
      "Monitored episode 50 Average Monitored rewards:  52.52\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2542785   1.0008034   0.8572359   1.9999979  -0.10054284  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.90495   0.6913697]\n",
      "tensor([[-0.2054],\n",
      "        [-0.2054],\n",
      "        [ 0.0369],\n",
      "        [ 0.0369],\n",
      "        [ 0.0369],\n",
      "        [ 0.0369],\n",
      "        [-0.6510],\n",
      "        [ 0.0369],\n",
      "        [ 0.0369],\n",
      "        [ 0.0369],\n",
      "        [ 0.8489],\n",
      "        [-0.9576],\n",
      "        [ 0.0369],\n",
      "        [ 0.0369],\n",
      "        [ 0.0369],\n",
      "        [ 0.0369],\n",
      "        [ 0.0369],\n",
      "        [ 0.0369],\n",
      "        [ 0.0369],\n",
      "        [ 0.0369],\n",
      "        [-0.2054],\n",
      "        [ 0.0369],\n",
      "        [ 0.0369],\n",
      "        [ 0.0369],\n",
      "        [ 0.0369],\n",
      "        [ 0.0369],\n",
      "        [ 0.0369],\n",
      "        [ 0.0369],\n",
      "        [ 0.0369],\n",
      "        [ 0.0369],\n",
      "        [-0.2054],\n",
      "        [ 0.0369],\n",
      "        [ 0.0369],\n",
      "        [-0.6510],\n",
      "        [-0.9576],\n",
      "        [-0.9576],\n",
      "        [-0.9576],\n",
      "        [-0.9576],\n",
      "        [-0.9576],\n",
      "        [-0.9576],\n",
      "        [ 0.8489],\n",
      "        [-0.9576],\n",
      "        [-0.9576],\n",
      "        [ 0.0369],\n",
      "        [ 0.0369],\n",
      "        [ 0.0369],\n",
      "        [ 0.0369],\n",
      "        [ 0.0369],\n",
      "        [ 0.0369],\n",
      "        [ 0.0369]], dtype=torch.float64)\n",
      "Finished episode 1445 Average rewards:  16.4\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2649437  1.0008031  0.8649142  1.999998  -0.0860288  1.8641111\n",
      "  1.7464267  0.7518858]\n",
      "Enc\n",
      "[0.8942849 0.699048 ]\n",
      "tensor([[ 0.8899],\n",
      "        [ 0.8899],\n",
      "        [-0.9778],\n",
      "        [-0.0456],\n",
      "        [-0.0456],\n",
      "        [-0.0456],\n",
      "        [-0.0456],\n",
      "        [-0.7232],\n",
      "        [-0.0456],\n",
      "        [-0.0456],\n",
      "        [-0.1224],\n",
      "        [-0.9778],\n",
      "        [-0.9778],\n",
      "        [-0.9778],\n",
      "        [-0.9778],\n",
      "        [ 0.2796],\n",
      "        [ 0.2796],\n",
      "        [ 0.2796],\n",
      "        [ 0.2796],\n",
      "        [-0.9778],\n",
      "        [ 0.8899],\n",
      "        [-0.9778],\n",
      "        [-0.9778],\n",
      "        [-0.9778],\n",
      "        [-0.9778],\n",
      "        [-0.9778],\n",
      "        [-0.9778],\n",
      "        [-0.9778],\n",
      "        [-0.9778],\n",
      "        [-0.9778],\n",
      "        [-0.1224],\n",
      "        [-0.9778],\n",
      "        [-0.0456],\n",
      "        [-0.0456],\n",
      "        [-0.0456],\n",
      "        [-0.7232],\n",
      "        [-0.0456],\n",
      "        [-0.0456],\n",
      "        [-0.0456],\n",
      "        [-0.0456],\n",
      "        [ 0.8899],\n",
      "        [-0.9778],\n",
      "        [-0.9778],\n",
      "        [-0.9778],\n",
      "        [-0.9778],\n",
      "        [-0.9778],\n",
      "        [-0.9778],\n",
      "        [ 0.2796],\n",
      "        [ 0.2796],\n",
      "        [ 0.2796]], dtype=torch.float64)\n",
      "Finished episode 1450 Average rewards:  59.4\n",
      "Monitored episode 50 Average Monitored rewards:  45.38\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2782454   1.0007973   0.87715816  1.9999982  -0.0566329   1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88098335 0.7112919 ]\n",
      "tensor([[-0.1751],\n",
      "        [-0.0042],\n",
      "        [-0.0042],\n",
      "        [-0.0042],\n",
      "        [-0.0042],\n",
      "        [-0.6872],\n",
      "        [-0.0042],\n",
      "        [-0.0042],\n",
      "        [-0.6872],\n",
      "        [-0.6872],\n",
      "        [ 0.8780],\n",
      "        [-0.9729],\n",
      "        [-0.9729],\n",
      "        [-0.9729],\n",
      "        [-0.0042],\n",
      "        [-0.0042],\n",
      "        [-0.0042],\n",
      "        [-0.0042],\n",
      "        [-0.0042],\n",
      "        [-0.6872],\n",
      "        [ 0.8780],\n",
      "        [-0.9729],\n",
      "        [-0.1751],\n",
      "        [-0.9729],\n",
      "        [-0.1751],\n",
      "        [-0.0042],\n",
      "        [-0.0042],\n",
      "        [-0.0042],\n",
      "        [-0.6872],\n",
      "        [-0.6872],\n",
      "        [ 0.8780],\n",
      "        [-0.9729],\n",
      "        [-0.9729],\n",
      "        [-0.1751],\n",
      "        [-0.9729],\n",
      "        [-0.9729],\n",
      "        [-0.9729],\n",
      "        [ 0.3352],\n",
      "        [ 0.3352],\n",
      "        [ 0.3352],\n",
      "        [-0.1751],\n",
      "        [ 0.8780],\n",
      "        [-0.0042],\n",
      "        [-0.0042],\n",
      "        [ 0.8780],\n",
      "        [-0.9729],\n",
      "        [-0.9729],\n",
      "        [ 0.3352],\n",
      "        [-0.1751],\n",
      "        [-0.1751],\n",
      "        [-0.1751]], dtype=torch.float64)\n",
      "Finished episode 1455 Average rewards:  37.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2731315   1.0007784   0.8757332   1.9999982  -0.07208902  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8860973 0.709867 ]\n",
      "tensor([[-0.2622],\n",
      "        [-0.2622],\n",
      "        [ 0.0797],\n",
      "        [ 0.0797],\n",
      "        [-0.6092],\n",
      "        [-0.6092],\n",
      "        [-0.6092],\n",
      "        [-0.6092],\n",
      "        [ 0.0797],\n",
      "        [ 0.0797],\n",
      "        [-0.2622],\n",
      "        [ 0.0797],\n",
      "        [ 0.0797],\n",
      "        [ 0.0797],\n",
      "        [-0.6092],\n",
      "        [ 0.0797],\n",
      "        [ 0.0797],\n",
      "        [ 0.0797],\n",
      "        [ 0.0797],\n",
      "        [ 0.0797],\n",
      "        [-0.2622],\n",
      "        [-0.9537],\n",
      "        [-0.9537],\n",
      "        [-0.9537],\n",
      "        [-0.9537],\n",
      "        [-0.9537],\n",
      "        [-0.9537],\n",
      "        [-0.9537],\n",
      "        [-0.9537],\n",
      "        [-0.9537],\n",
      "        [-0.2622],\n",
      "        [ 0.0797],\n",
      "        [ 0.0797],\n",
      "        [ 0.0797],\n",
      "        [ 0.0797],\n",
      "        [-0.6092],\n",
      "        [-0.6092],\n",
      "        [ 0.0797],\n",
      "        [ 0.0797],\n",
      "        [ 0.0797],\n",
      "        [ 0.8395],\n",
      "        [-0.9537],\n",
      "        [-0.9537],\n",
      "        [ 0.4085],\n",
      "        [ 0.4085],\n",
      "        [-0.2622],\n",
      "        [-0.2622],\n",
      "        [ 0.0797],\n",
      "        [ 0.0797],\n",
      "        [ 0.0797]], dtype=torch.float64)\n",
      "Finished episode 1460 Average rewards:  17.8\n",
      "Monitored episode 50 Average Monitored rewards:  47.38\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2655861   1.0007557   0.8713881   1.9999982  -0.08423024  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.89364266 0.7055219 ]\n",
      "tensor([[-0.2202],\n",
      "        [-0.9589],\n",
      "        [-0.9589],\n",
      "        [ 0.3769],\n",
      "        [ 0.3769],\n",
      "        [ 0.3769],\n",
      "        [ 0.3769],\n",
      "        [-0.9589],\n",
      "        [ 0.3769],\n",
      "        [-0.9589],\n",
      "        [ 0.8576],\n",
      "        [-0.9589],\n",
      "        [-0.9589],\n",
      "        [-0.9589],\n",
      "        [-0.9589],\n",
      "        [-0.9589],\n",
      "        [ 0.3769],\n",
      "        [-0.9589],\n",
      "        [-0.9589],\n",
      "        [ 0.3769],\n",
      "        [ 0.8576],\n",
      "        [ 0.0356],\n",
      "        [ 0.0356],\n",
      "        [ 0.0356],\n",
      "        [ 0.0356],\n",
      "        [ 0.0356],\n",
      "        [ 0.0356],\n",
      "        [-0.6476],\n",
      "        [-0.6476],\n",
      "        [ 0.0356],\n",
      "        [ 0.8576],\n",
      "        [-0.9589],\n",
      "        [-0.2202],\n",
      "        [-0.9589],\n",
      "        [-0.9589],\n",
      "        [ 0.3769],\n",
      "        [ 0.3769],\n",
      "        [-0.2202],\n",
      "        [ 0.0356],\n",
      "        [ 0.0356],\n",
      "        [-0.2202],\n",
      "        [-0.9589],\n",
      "        [ 0.0356],\n",
      "        [ 0.0356],\n",
      "        [ 0.0356],\n",
      "        [ 0.0356],\n",
      "        [ 0.0356],\n",
      "        [ 0.0356],\n",
      "        [ 0.0356],\n",
      "        [ 0.0356]], dtype=torch.float64)\n",
      "Finished episode 1465 Average rewards:  38.4\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.257132    1.0007304   0.8666658   1.9999982  -0.09409125  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9020968 0.7007995]\n",
      "tensor([[ 0.8700],\n",
      "        [-0.9647],\n",
      "        [-0.9647],\n",
      "        [-0.9647],\n",
      "        [-0.9647],\n",
      "        [ 0.3397],\n",
      "        [ 0.3397],\n",
      "        [ 0.3397],\n",
      "        [ 0.3397],\n",
      "        [-0.9647],\n",
      "        [ 0.8700],\n",
      "        [-0.9647],\n",
      "        [-0.9647],\n",
      "        [-0.9647],\n",
      "        [-0.9647],\n",
      "        [-0.9647],\n",
      "        [-0.9647],\n",
      "        [-0.9647],\n",
      "        [-0.9647],\n",
      "        [-0.9647],\n",
      "        [ 0.8700],\n",
      "        [-0.9647],\n",
      "        [-0.1803],\n",
      "        [ 0.0010],\n",
      "        [ 0.0010],\n",
      "        [ 0.0010],\n",
      "        [-0.6790],\n",
      "        [-0.6790],\n",
      "        [-0.6790],\n",
      "        [ 0.0010],\n",
      "        [-0.1803],\n",
      "        [ 0.0010],\n",
      "        [ 0.0010],\n",
      "        [ 0.0010],\n",
      "        [ 0.0010],\n",
      "        [-0.6790],\n",
      "        [-0.6790],\n",
      "        [-0.6790],\n",
      "        [ 0.0010],\n",
      "        [ 0.0010],\n",
      "        [-0.1803],\n",
      "        [ 0.0010],\n",
      "        [ 0.0010],\n",
      "        [ 0.0010],\n",
      "        [ 0.0010],\n",
      "        [-0.6790],\n",
      "        [ 0.8700],\n",
      "        [ 0.8700],\n",
      "        [ 0.8700],\n",
      "        [-0.9647]], dtype=torch.float64)\n",
      "Finished episode 1470 Average rewards:  63.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  48.9\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2764298   1.0007303   0.8804165   1.9999983  -0.06446283  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8827991 0.7145503]\n",
      "tensor([[ 0.8773],\n",
      "        [-0.9680],\n",
      "        [-0.9680],\n",
      "        [ 0.2996],\n",
      "        [ 0.2996],\n",
      "        [-0.1429],\n",
      "        [-0.1429],\n",
      "        [-0.0272],\n",
      "        [-0.0272],\n",
      "        [-0.0272],\n",
      "        [-0.1429],\n",
      "        [-0.0272],\n",
      "        [-0.7042],\n",
      "        [-0.9680],\n",
      "        [-0.9680],\n",
      "        [ 0.2996],\n",
      "        [-0.9680],\n",
      "        [-0.9680],\n",
      "        [-0.9680],\n",
      "        [-0.9680],\n",
      "        [-0.1429],\n",
      "        [-0.9680],\n",
      "        [-0.1429],\n",
      "        [-0.0272],\n",
      "        [-0.0272],\n",
      "        [-0.0272],\n",
      "        [-0.0272],\n",
      "        [-0.7042],\n",
      "        [-0.0272],\n",
      "        [-0.0272],\n",
      "        [ 0.8773],\n",
      "        [-0.9680],\n",
      "        [-0.1429],\n",
      "        [-0.1429],\n",
      "        [-0.1429],\n",
      "        [-0.9680],\n",
      "        [-0.9680],\n",
      "        [-0.9680],\n",
      "        [ 0.2996],\n",
      "        [ 0.2996],\n",
      "        [-0.1429],\n",
      "        [-0.0272],\n",
      "        [-0.0272],\n",
      "        [-0.7042],\n",
      "        [-0.7042],\n",
      "        [-0.0272],\n",
      "        [-0.0272],\n",
      "        [-0.0272],\n",
      "        [-0.7042],\n",
      "        [-0.0272]], dtype=torch.float64)\n",
      "Finished episode 1475 Average rewards:  38.2\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2698923   1.0007143   0.8732438   1.9999983  -0.07222635  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88933665 0.7073776 ]\n",
      "tensor([[-0.2423],\n",
      "        [-0.9505],\n",
      "        [-0.9505],\n",
      "        [-0.9505],\n",
      "        [ 0.3947],\n",
      "        [ 0.3947],\n",
      "        [-0.9505],\n",
      "        [ 0.3947],\n",
      "        [ 0.3947],\n",
      "        [ 0.3947],\n",
      "        [-0.2423],\n",
      "        [-0.2423],\n",
      "        [ 0.0574],\n",
      "        [ 0.0574],\n",
      "        [ 0.0574],\n",
      "        [ 0.0574],\n",
      "        [ 0.0574],\n",
      "        [ 0.0574],\n",
      "        [ 0.0574],\n",
      "        [ 0.0574],\n",
      "        [ 0.0574],\n",
      "        [ 0.8446],\n",
      "        [-0.9505],\n",
      "        [-0.9505],\n",
      "        [-0.9505],\n",
      "        [-0.9505],\n",
      "        [-0.9505],\n",
      "        [-0.9505],\n",
      "        [-0.9505],\n",
      "        [ 0.3947],\n",
      "        [-0.9505],\n",
      "        [ 0.8446],\n",
      "        [-0.9505],\n",
      "        [-0.2423],\n",
      "        [-0.9505],\n",
      "        [-0.9505],\n",
      "        [-0.9505],\n",
      "        [-0.9505],\n",
      "        [-0.9505],\n",
      "        [-0.9505],\n",
      "        [-0.9505],\n",
      "        [-0.2423],\n",
      "        [-0.9505],\n",
      "        [-0.9505],\n",
      "        [-0.9505],\n",
      "        [-0.9505],\n",
      "        [-0.9505],\n",
      "        [-0.9505],\n",
      "        [ 0.3947],\n",
      "        [ 0.3947],\n",
      "        [-0.9505]], dtype=torch.float64)\n",
      "Finished episode 1480 Average rewards:  64.6\n",
      "Monitored episode 50 Average Monitored rewards:  22.88\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2572793   1.000674    0.86026406  1.9999983  -0.10179469  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9019498  0.69439787]\n",
      "tensor([[ 0.8562],\n",
      "        [-0.9601],\n",
      "        [-0.2149],\n",
      "        [ 0.0353],\n",
      "        [ 0.0353],\n",
      "        [ 0.0353],\n",
      "        [ 0.0353],\n",
      "        [ 0.0353],\n",
      "        [ 0.0353],\n",
      "        [ 0.0353],\n",
      "        [-0.2149],\n",
      "        [-0.9601],\n",
      "        [ 0.3689],\n",
      "        [-0.9601],\n",
      "        [-0.9601],\n",
      "        [-0.9601],\n",
      "        [ 0.3689],\n",
      "        [ 0.3689],\n",
      "        [ 0.3689],\n",
      "        [-0.2149],\n",
      "        [-0.2149],\n",
      "        [-0.2149],\n",
      "        [-0.9601],\n",
      "        [-0.9601],\n",
      "        [ 0.3689],\n",
      "        [ 0.3689],\n",
      "        [ 0.3689],\n",
      "        [-0.2149],\n",
      "        [ 0.0353],\n",
      "        [ 0.0353],\n",
      "        [-0.2149],\n",
      "        [-0.9601],\n",
      "        [ 0.3689],\n",
      "        [ 0.3689],\n",
      "        [ 0.0353],\n",
      "        [ 0.0353],\n",
      "        [ 0.0353],\n",
      "        [ 0.0353],\n",
      "        [ 0.0353],\n",
      "        [-0.6498],\n",
      "        [ 0.8562],\n",
      "        [-0.9601],\n",
      "        [-0.9601],\n",
      "        [-0.9601],\n",
      "        [ 0.3689],\n",
      "        [ 0.3689],\n",
      "        [ 0.3689],\n",
      "        [ 0.3689],\n",
      "        [-0.2149],\n",
      "        [ 0.0353]], dtype=torch.float64)\n",
      "Finished episode 1485 Average rewards:  17.0\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2752264   1.0006667   0.86820614  1.9999985  -0.08021303  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8840028 0.7023399]\n",
      "tensor([[ 0.8935],\n",
      "        [-0.9784],\n",
      "        [-0.9784],\n",
      "        [-0.0492],\n",
      "        [-0.0492],\n",
      "        [-0.7245],\n",
      "        [-0.0492],\n",
      "        [-0.7245],\n",
      "        [-0.0492],\n",
      "        [-0.0492],\n",
      "        [ 0.8935],\n",
      "        [-0.9784],\n",
      "        [-0.9784],\n",
      "        [-0.9784],\n",
      "        [-0.9784],\n",
      "        [-0.9784],\n",
      "        [ 0.2866],\n",
      "        [ 0.2866],\n",
      "        [ 0.2866],\n",
      "        [ 0.2866],\n",
      "        [-0.1246],\n",
      "        [-0.9784],\n",
      "        [ 0.2866],\n",
      "        [ 0.2866],\n",
      "        [-0.1246],\n",
      "        [-0.9784],\n",
      "        [-0.9784],\n",
      "        [-0.9784],\n",
      "        [-0.9784],\n",
      "        [ 0.2866],\n",
      "        [ 0.8935],\n",
      "        [-0.9784],\n",
      "        [ 0.2866],\n",
      "        [-0.1246],\n",
      "        [-0.0492],\n",
      "        [-0.0492],\n",
      "        [-0.7245],\n",
      "        [-0.7245],\n",
      "        [-0.0492],\n",
      "        [-0.0492],\n",
      "        [ 0.8935],\n",
      "        [-0.0492],\n",
      "        [ 0.8935],\n",
      "        [-0.9784],\n",
      "        [-0.0492],\n",
      "        [ 0.8935],\n",
      "        [ 0.8935],\n",
      "        [-0.0492],\n",
      "        [ 0.8935],\n",
      "        [-0.9784],\n",
      "        [-0.1246]], dtype=torch.float64)\n",
      "Finished episode 1490 Average rewards:  37.4\n",
      "Monitored episode 50 Average Monitored rewards:  33.4\n",
      "len_game 52\n",
      "Rot\n",
      "[ 1.2651498   1.0006375   0.85928166  1.9999985  -0.10183351  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8940794 0.6934154]\n",
      "tensor([[-0.2050],\n",
      "        [-0.9737],\n",
      "        [-0.2050],\n",
      "        [-0.9737],\n",
      "        [ 0.0124],\n",
      "        [ 0.0124],\n",
      "        [ 0.0124],\n",
      "        [ 0.0124],\n",
      "        [ 0.0124],\n",
      "        [-0.6719],\n",
      "        [ 0.8806],\n",
      "        [ 0.8806],\n",
      "        [ 0.8806],\n",
      "        [-0.9737],\n",
      "        [-0.9737],\n",
      "        [-0.9737],\n",
      "        [ 0.3707],\n",
      "        [ 0.3707],\n",
      "        [ 0.3707],\n",
      "        [ 0.3707],\n",
      "        [-0.2050],\n",
      "        [-0.9737],\n",
      "        [ 0.8806],\n",
      "        [-0.9737],\n",
      "        [-0.2050],\n",
      "        [ 0.0124],\n",
      "        [ 0.0124],\n",
      "        [ 0.0124],\n",
      "        [ 0.0124],\n",
      "        [ 0.0124],\n",
      "        [ 0.0124],\n",
      "        [ 0.0124],\n",
      "        [-0.2050],\n",
      "        [ 0.0124],\n",
      "        [ 0.0124],\n",
      "        [ 0.0124],\n",
      "        [ 0.0124],\n",
      "        [ 0.0124],\n",
      "        [ 0.0124],\n",
      "        [ 0.0124],\n",
      "        [ 0.0124],\n",
      "        [ 0.0124],\n",
      "        [-0.2050],\n",
      "        [-0.9737],\n",
      "        [-0.9737],\n",
      "        [-0.9737],\n",
      "        [ 0.3707],\n",
      "        [ 0.3707],\n",
      "        [ 0.3707],\n",
      "        [ 0.3707],\n",
      "        [ 0.3707],\n",
      "        [ 0.0124]], dtype=torch.float64)\n",
      "Finished episode 1495 Average rewards:  36.6\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2886194   1.0006425   0.8757048   1.9999987  -0.06791765  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8706099 0.7098386]\n",
      "tensor([[ 0.9043],\n",
      "        [ 0.9043],\n",
      "        [-0.0493],\n",
      "        [ 0.9043],\n",
      "        [-0.9844],\n",
      "        [-0.0493],\n",
      "        [-0.0493],\n",
      "        [-0.0493],\n",
      "        [-0.0493],\n",
      "        [-0.0493],\n",
      "        [ 0.9043],\n",
      "        [-0.9844],\n",
      "        [-0.9844],\n",
      "        [-0.9844],\n",
      "        [-0.9844],\n",
      "        [-0.9844],\n",
      "        [-0.9844],\n",
      "        [ 0.3104],\n",
      "        [-0.9844],\n",
      "        [-0.9844],\n",
      "        [-0.1381],\n",
      "        [-0.0493],\n",
      "        [-0.7250],\n",
      "        [-0.0493],\n",
      "        [-0.7250],\n",
      "        [ 0.9043],\n",
      "        [-0.9844],\n",
      "        [-0.9844],\n",
      "        [-0.1381],\n",
      "        [-0.9844],\n",
      "        [ 0.9043],\n",
      "        [-0.9844],\n",
      "        [ 0.3104],\n",
      "        [-0.1381],\n",
      "        [-0.0493],\n",
      "        [-0.0493],\n",
      "        [-0.7250],\n",
      "        [-0.7250],\n",
      "        [-0.0493],\n",
      "        [-0.0493],\n",
      "        [-0.1381],\n",
      "        [-0.0493],\n",
      "        [-0.0493],\n",
      "        [-0.0493],\n",
      "        [-0.7250],\n",
      "        [-0.0493],\n",
      "        [-0.0493],\n",
      "        [-0.0493],\n",
      "        [-0.0493],\n",
      "        [-0.0493]], dtype=torch.float64)\n",
      "Finished episode 1500 Average rewards:  36.0\n",
      "Monitored episode 50 Average Monitored rewards:  26.56\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2789683  1.0006225  0.872418   1.9999987 -0.0793347  1.8641111\n",
      "  1.7464267  0.7518858]\n",
      "Enc\n",
      "[0.88026094 0.7065518 ]\n",
      "tensor([[ 0.8725],\n",
      "        [-0.9651],\n",
      "        [-0.9651],\n",
      "        [-0.9651],\n",
      "        [-0.9651],\n",
      "        [-0.9651],\n",
      "        [ 0.4165],\n",
      "        [ 0.4165],\n",
      "        [ 0.4165],\n",
      "        [ 0.4165],\n",
      "        [-0.2526],\n",
      "        [-0.9651],\n",
      "        [ 0.4165],\n",
      "        [ 0.4165],\n",
      "        [-0.2526],\n",
      "        [-0.9651],\n",
      "        [ 0.4165],\n",
      "        [-0.2526],\n",
      "        [-0.9651],\n",
      "        [-0.9651],\n",
      "        [ 0.8725],\n",
      "        [ 0.8725],\n",
      "        [-0.9651],\n",
      "        [-0.9651],\n",
      "        [-0.9651],\n",
      "        [ 0.4165],\n",
      "        [-0.2526],\n",
      "        [-0.2526],\n",
      "        [ 0.0475],\n",
      "        [ 0.0475],\n",
      "        [-0.2526],\n",
      "        [ 0.0475],\n",
      "        [ 0.0475],\n",
      "        [ 0.0475],\n",
      "        [ 0.0475],\n",
      "        [ 0.0475],\n",
      "        [-0.6377],\n",
      "        [ 0.0475],\n",
      "        [ 0.0475],\n",
      "        [ 0.0475],\n",
      "        [-0.2526],\n",
      "        [-0.2526],\n",
      "        [-0.2526],\n",
      "        [ 0.0475],\n",
      "        [ 0.0475],\n",
      "        [ 0.0475],\n",
      "        [ 0.0475],\n",
      "        [ 0.0475],\n",
      "        [ 0.0475],\n",
      "        [ 0.0475]], dtype=torch.float64)\n",
      "Finished episode 1505 Average rewards:  37.0\n",
      "len_game 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[ 1.2698047   1.0005955   0.8654144   1.9999987  -0.10530207  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8894247 0.6995482]\n",
      "tensor([[ 0.8797],\n",
      "        [ 0.8797],\n",
      "        [ 0.8797],\n",
      "        [ 0.8797],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [-0.2129],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [-0.2129],\n",
      "        [-0.2129],\n",
      "        [-0.9694],\n",
      "        [-0.9694],\n",
      "        [ 0.3810],\n",
      "        [ 0.3810],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [-0.2129],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [-0.2129],\n",
      "        [-0.9694],\n",
      "        [ 0.3810],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [ 0.0150],\n",
      "        [-0.6670],\n",
      "        [-0.6670],\n",
      "        [ 0.0150]], dtype=torch.float64)\n",
      "Finished episode 1510 Average rewards:  -7.0\n",
      "Monitored episode 50 Average Monitored rewards:  53.6\n",
      "len_game 52\n",
      "Rot\n",
      "[ 1.2737372   1.000584    0.866257    1.9999987  -0.09261723  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88549227 0.7003908 ]\n",
      "tensor([[-0.1380],\n",
      "        [-0.9807],\n",
      "        [-0.1380],\n",
      "        [-0.1380],\n",
      "        [-0.0592],\n",
      "        [-0.0592],\n",
      "        [-0.0592],\n",
      "        [-0.7292],\n",
      "        [-0.0592],\n",
      "        [-0.7292],\n",
      "        [-0.1380],\n",
      "        [-0.9807],\n",
      "        [-0.9807],\n",
      "        [-0.9807],\n",
      "        [ 0.3188],\n",
      "        [ 0.3188],\n",
      "        [ 0.3188],\n",
      "        [ 0.3188],\n",
      "        [ 0.3188],\n",
      "        [-0.1380],\n",
      "        [-0.1380],\n",
      "        [-0.0592],\n",
      "        [-0.0592],\n",
      "        [-0.0592],\n",
      "        [-0.0592],\n",
      "        [-0.0592],\n",
      "        [-0.0592],\n",
      "        [-0.7292],\n",
      "        [-0.7292],\n",
      "        [-0.7292],\n",
      "        [ 0.9093],\n",
      "        [ 0.9093],\n",
      "        [ 0.9093],\n",
      "        [-0.9807],\n",
      "        [-0.1380],\n",
      "        [-0.9807],\n",
      "        [-0.9807],\n",
      "        [-0.9807],\n",
      "        [-0.9807],\n",
      "        [ 0.3188],\n",
      "        [-0.1380],\n",
      "        [-0.9807],\n",
      "        [ 0.9093],\n",
      "        [-0.9807],\n",
      "        [-0.9807],\n",
      "        [-0.1380],\n",
      "        [-0.1380],\n",
      "        [-0.9807],\n",
      "        [-0.9807],\n",
      "        [-0.9807],\n",
      "        [ 0.3188],\n",
      "        [ 0.3188]], dtype=torch.float64)\n",
      "Finished episode 1515 Average rewards:  60.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2764201   1.0005816   0.87579435  1.9999987  -0.07686077  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88280946 0.70992815]\n",
      "tensor([[ 0.8973],\n",
      "        [ 0.8973],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [ 0.3491],\n",
      "        [ 0.3491],\n",
      "        [ 0.3491],\n",
      "        [-0.1742],\n",
      "        [ 0.8973],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.1742],\n",
      "        [-0.9785],\n",
      "        [ 0.3491],\n",
      "        [-0.1742],\n",
      "        [-0.0230],\n",
      "        [-0.7012],\n",
      "        [-0.0230],\n",
      "        [-0.0230],\n",
      "        [-0.7012],\n",
      "        [ 0.8973],\n",
      "        [ 0.8973],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [ 0.3491],\n",
      "        [ 0.3491],\n",
      "        [ 0.3491],\n",
      "        [ 0.3491],\n",
      "        [ 0.3491],\n",
      "        [-0.1742],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [ 0.3491],\n",
      "        [ 0.3491],\n",
      "        [ 0.3491],\n",
      "        [ 0.3491]], dtype=torch.float64)\n",
      "Finished episode 1520 Average rewards:  104.4\n",
      "Monitored episode 50 Average Monitored rewards:  45.4\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.265734    1.0005621   0.8752321   1.9999987  -0.08121325  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.89349556 0.7093659 ]\n",
      "tensor([[-0.2145],\n",
      "        [-0.2145],\n",
      "        [-0.2145],\n",
      "        [ 0.0220],\n",
      "        [ 0.0220],\n",
      "        [ 0.0220],\n",
      "        [ 0.0220],\n",
      "        [-0.6588],\n",
      "        [ 0.0220],\n",
      "        [ 0.0220],\n",
      "        [-0.2145],\n",
      "        [ 0.0220],\n",
      "        [ 0.0220],\n",
      "        [-0.6588],\n",
      "        [-0.6588],\n",
      "        [-0.6588],\n",
      "        [-0.9626],\n",
      "        [-0.9626],\n",
      "        [ 0.3782],\n",
      "        [-0.2145],\n",
      "        [-0.2145],\n",
      "        [-0.9626],\n",
      "        [ 0.0220],\n",
      "        [ 0.0220],\n",
      "        [ 0.0220],\n",
      "        [ 0.0220],\n",
      "        [ 0.0220],\n",
      "        [ 0.0220],\n",
      "        [-0.6588],\n",
      "        [ 0.0220],\n",
      "        [ 0.8689],\n",
      "        [ 0.8689],\n",
      "        [-0.9626],\n",
      "        [-0.9626],\n",
      "        [-0.9626],\n",
      "        [-0.9626],\n",
      "        [ 0.3782],\n",
      "        [ 0.3782],\n",
      "        [ 0.3782],\n",
      "        [-0.2145],\n",
      "        [-0.2145],\n",
      "        [-0.2145],\n",
      "        [ 0.0220],\n",
      "        [ 0.0220],\n",
      "        [ 0.0220],\n",
      "        [ 0.0220],\n",
      "        [ 0.0220],\n",
      "        [ 0.0220],\n",
      "        [ 0.0220],\n",
      "        [ 0.0220],\n",
      "        [ 0.0220]], dtype=torch.float64)\n",
      "Finished episode 1525 Average rewards:  15.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2590609   1.0005481   0.8776616   1.9999987  -0.08663062  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.90016866 0.7117954 ]\n",
      "tensor([[-0.1876],\n",
      "        [ 0.0096],\n",
      "        [ 0.0096],\n",
      "        [ 0.0096],\n",
      "        [ 0.0096],\n",
      "        [ 0.0096],\n",
      "        [ 0.0096],\n",
      "        [ 0.0096],\n",
      "        [ 0.0096],\n",
      "        [ 0.0096],\n",
      "        [-0.1876],\n",
      "        [-0.9581],\n",
      "        [-0.1876],\n",
      "        [ 0.0096],\n",
      "        [ 0.0096],\n",
      "        [ 0.0096],\n",
      "        [ 0.0096],\n",
      "        [ 0.0096],\n",
      "        [ 0.0096],\n",
      "        [ 0.0096],\n",
      "        [ 0.8614],\n",
      "        [-0.9581],\n",
      "        [-0.9581],\n",
      "        [-0.9581],\n",
      "        [-0.9581],\n",
      "        [-0.9581],\n",
      "        [-0.9581],\n",
      "        [ 0.3448],\n",
      "        [ 0.3448],\n",
      "        [ 0.3448],\n",
      "        [-0.1876],\n",
      "        [-0.9581],\n",
      "        [-0.9581],\n",
      "        [ 0.3448],\n",
      "        [ 0.3448],\n",
      "        [ 0.3448],\n",
      "        [ 0.0096],\n",
      "        [ 0.0096],\n",
      "        [ 0.0096],\n",
      "        [ 0.0096],\n",
      "        [-0.1876],\n",
      "        [ 0.0096],\n",
      "        [ 0.0096],\n",
      "        [ 0.0096],\n",
      "        [ 0.0096],\n",
      "        [ 0.0096],\n",
      "        [ 0.0096],\n",
      "        [ 0.0096],\n",
      "        [-0.6693],\n",
      "        [-0.6693]], dtype=torch.float64)\n",
      "Finished episode 1530 Average rewards:  14.6\n",
      "Monitored episode 50 Average Monitored rewards:  52.98\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2685297   1.000542    0.8830483   1.9999988  -0.07153782  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8906999  0.71718204]\n",
      "tensor([[-0.1640],\n",
      "        [-0.1640],\n",
      "        [-0.9513],\n",
      "        [-0.9513],\n",
      "        [ 0.3178],\n",
      "        [ 0.3178],\n",
      "        [ 0.3178],\n",
      "        [ 0.3178],\n",
      "        [-0.0059],\n",
      "        [-0.0059],\n",
      "        [-0.1640],\n",
      "        [-0.0059],\n",
      "        [-0.9513],\n",
      "        [-0.1640],\n",
      "        [-0.9513],\n",
      "        [ 0.3178],\n",
      "        [-0.1640],\n",
      "        [-0.0059],\n",
      "        [ 0.8573],\n",
      "        [-0.9513],\n",
      "        [ 0.8573],\n",
      "        [-0.9513],\n",
      "        [-0.9513],\n",
      "        [-0.9513],\n",
      "        [ 0.3178],\n",
      "        [-0.9513],\n",
      "        [-0.9513],\n",
      "        [-0.9513],\n",
      "        [-0.9513],\n",
      "        [-0.9513],\n",
      "        [ 0.8573],\n",
      "        [-0.9513],\n",
      "        [-0.9513],\n",
      "        [-0.9513],\n",
      "        [-0.1640],\n",
      "        [-0.1640],\n",
      "        [-0.9513],\n",
      "        [-0.9513],\n",
      "        [-0.9513],\n",
      "        [ 0.3178],\n",
      "        [ 0.8573],\n",
      "        [-0.9513],\n",
      "        [-0.9513],\n",
      "        [-0.9513],\n",
      "        [-0.9513],\n",
      "        [-0.9513],\n",
      "        [-0.9513],\n",
      "        [-0.9513],\n",
      "        [-0.9513],\n",
      "        [ 0.3178]], dtype=torch.float64)\n",
      "Finished episode 1535 Average rewards:  83.6\n",
      "len_game 52\n",
      "Rot\n",
      "[ 1.2557286   1.0005103   0.85815364  1.9999988  -0.10384049  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.90350103 0.69228745]\n",
      "tensor([[ 0.8406],\n",
      "        [-0.9429],\n",
      "        [ 0.3665],\n",
      "        [-0.2144],\n",
      "        [-0.9429],\n",
      "        [-0.9429],\n",
      "        [-0.9429],\n",
      "        [-0.9429],\n",
      "        [-0.9429],\n",
      "        [-0.9429],\n",
      "        [ 0.8406],\n",
      "        [-0.9429],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [-0.6401],\n",
      "        [-0.6401],\n",
      "        [-0.9429],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.8406],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.8406],\n",
      "        [-0.9429],\n",
      "        [-0.9429],\n",
      "        [-0.2144],\n",
      "        [-0.9429],\n",
      "        [-0.2144],\n",
      "        [-0.9429],\n",
      "        [-0.9429],\n",
      "        [ 0.3665],\n",
      "        [ 0.3665],\n",
      "        [-0.2144],\n",
      "        [-0.2144],\n",
      "        [ 0.8406],\n",
      "        [-0.9429],\n",
      "        [-0.2144],\n",
      "        [-0.9429],\n",
      "        [-0.9429],\n",
      "        [-0.2144],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372],\n",
      "        [ 0.0372]], dtype=torch.float64)\n",
      "Finished episode 1540 Average rewards:  17.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  55.3\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2788231   1.0005188   0.8811503   1.9999989  -0.06245934  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88040656 0.7152841 ]\n",
      "tensor([[-0.1169],\n",
      "        [-0.0550],\n",
      "        [-0.0550],\n",
      "        [-0.0550],\n",
      "        [-0.0550],\n",
      "        [-0.0550],\n",
      "        [-0.0550],\n",
      "        [-0.7298],\n",
      "        [-0.7298],\n",
      "        [-0.7298],\n",
      "        [-0.1169],\n",
      "        [-0.9799],\n",
      "        [-0.9799],\n",
      "        [-0.9799],\n",
      "        [-0.1169],\n",
      "        [-0.0550],\n",
      "        [-0.7298],\n",
      "        [-0.0550],\n",
      "        [-0.0550],\n",
      "        [-0.0550],\n",
      "        [ 0.8957],\n",
      "        [-0.9799],\n",
      "        [-0.9799],\n",
      "        [-0.9799],\n",
      "        [ 0.2782],\n",
      "        [ 0.2782],\n",
      "        [ 0.2782],\n",
      "        [-0.1169],\n",
      "        [-0.0550],\n",
      "        [-0.0550],\n",
      "        [ 0.8957],\n",
      "        [-0.9799],\n",
      "        [-0.9799],\n",
      "        [-0.9799],\n",
      "        [-0.9799],\n",
      "        [-0.9799],\n",
      "        [ 0.2782],\n",
      "        [ 0.2782],\n",
      "        [ 0.2782],\n",
      "        [ 0.2782],\n",
      "        [ 0.8957],\n",
      "        [-0.9799],\n",
      "        [ 0.2782],\n",
      "        [-0.1169],\n",
      "        [-0.0550],\n",
      "        [-0.7298],\n",
      "        [-0.0550],\n",
      "        [-0.7298],\n",
      "        [-0.0550],\n",
      "        [-0.0550]], dtype=torch.float64)\n",
      "Finished episode 1545 Average rewards:  17.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2726002   1.0005051   0.8766308   1.9999989  -0.07970605  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8866296 0.7107646]\n",
      "tensor([[ 0.8439],\n",
      "        [-0.9500],\n",
      "        [-0.9500],\n",
      "        [ 0.4024],\n",
      "        [-0.9500],\n",
      "        [-0.9500],\n",
      "        [ 0.4024],\n",
      "        [ 0.4024],\n",
      "        [ 0.4024],\n",
      "        [-0.9500],\n",
      "        [-0.2502],\n",
      "        [-0.9500],\n",
      "        [-0.9500],\n",
      "        [-0.9500],\n",
      "        [-0.9500],\n",
      "        [-0.9500],\n",
      "        [ 0.4024],\n",
      "        [ 0.4024],\n",
      "        [ 0.4024],\n",
      "        [ 0.4024],\n",
      "        [-0.2502],\n",
      "        [-0.9500],\n",
      "        [-0.9500],\n",
      "        [-0.9500],\n",
      "        [-0.9500],\n",
      "        [-0.9500],\n",
      "        [-0.9500],\n",
      "        [-0.9500],\n",
      "        [ 0.4024],\n",
      "        [ 0.4024],\n",
      "        [ 0.8439],\n",
      "        [-0.9500],\n",
      "        [ 0.0631],\n",
      "        [ 0.0631],\n",
      "        [ 0.0631],\n",
      "        [ 0.0631],\n",
      "        [ 0.0631],\n",
      "        [ 0.0631],\n",
      "        [ 0.0631],\n",
      "        [ 0.0631],\n",
      "        [ 0.8439],\n",
      "        [-0.9500],\n",
      "        [-0.2502],\n",
      "        [ 0.0631],\n",
      "        [ 0.0631],\n",
      "        [ 0.0631],\n",
      "        [ 0.0631],\n",
      "        [ 0.0631],\n",
      "        [ 0.0631],\n",
      "        [ 0.0631]], dtype=torch.float64)\n",
      "Finished episode 1550 Average rewards:  62.0\n",
      "Monitored episode 50 Average Monitored rewards:  13.32\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2633027   1.0004888   0.8717109   1.9999989  -0.08813215  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.89592695 0.7058447 ]\n",
      "tensor([[ 0.8669],\n",
      "        [-0.9602],\n",
      "        [-0.9602],\n",
      "        [-0.9602],\n",
      "        [-0.9602],\n",
      "        [-0.9602],\n",
      "        [-0.9602],\n",
      "        [-0.9602],\n",
      "        [ 0.3648],\n",
      "        [ 0.3648],\n",
      "        [-0.2020],\n",
      "        [-0.2020],\n",
      "        [-0.2020],\n",
      "        [-0.2020],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [-0.6647],\n",
      "        [-0.6647],\n",
      "        [ 0.8669],\n",
      "        [ 0.8669],\n",
      "        [-0.9602],\n",
      "        [-0.9602],\n",
      "        [-0.9602],\n",
      "        [ 0.3648],\n",
      "        [ 0.3648],\n",
      "        [ 0.3648],\n",
      "        [ 0.3648],\n",
      "        [ 0.3648],\n",
      "        [-0.2020],\n",
      "        [-0.2020],\n",
      "        [-0.9602],\n",
      "        [-0.9602],\n",
      "        [-0.2020],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [-0.2020],\n",
      "        [-0.9602],\n",
      "        [-0.9602],\n",
      "        [-0.9602],\n",
      "        [-0.9602],\n",
      "        [-0.9602],\n",
      "        [ 0.3648],\n",
      "        [-0.9602],\n",
      "        [ 0.3648],\n",
      "        [ 0.3648]], dtype=torch.float64)\n",
      "Finished episode 1555 Average rewards:  80.4\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2788997   1.000479    0.87450635  1.999999   -0.06942867  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88033015 0.70864016]\n",
      "tensor([[ 0.8721],\n",
      "        [-0.0102],\n",
      "        [-0.9643],\n",
      "        [-0.9643],\n",
      "        [ 0.3273],\n",
      "        [ 0.3273],\n",
      "        [-0.9643],\n",
      "        [-0.9643],\n",
      "        [-0.9643],\n",
      "        [-0.9643],\n",
      "        [-0.1674],\n",
      "        [-0.1674],\n",
      "        [-0.1674],\n",
      "        [-0.9643],\n",
      "        [-0.9643],\n",
      "        [-0.1674],\n",
      "        [-0.1674],\n",
      "        [-0.9643],\n",
      "        [-0.9643],\n",
      "        [-0.9643],\n",
      "        [-0.1674],\n",
      "        [-0.9643],\n",
      "        [-0.9643],\n",
      "        [ 0.3273],\n",
      "        [ 0.3273],\n",
      "        [ 0.3273],\n",
      "        [-0.1674],\n",
      "        [-0.0102],\n",
      "        [-0.0102],\n",
      "        [-0.0102],\n",
      "        [ 0.8721],\n",
      "        [-0.9643],\n",
      "        [-0.1674],\n",
      "        [-0.0102],\n",
      "        [-0.0102],\n",
      "        [-0.0102],\n",
      "        [-0.0102],\n",
      "        [-0.0102],\n",
      "        [-0.0102],\n",
      "        [-0.6876],\n",
      "        [ 0.8721],\n",
      "        [-0.9643],\n",
      "        [-0.9643],\n",
      "        [-0.9643],\n",
      "        [ 0.3273],\n",
      "        [-0.9643],\n",
      "        [ 0.3273],\n",
      "        [-0.1674],\n",
      "        [-0.0102],\n",
      "        [-0.0102]], dtype=torch.float64)\n",
      "Finished episode 1560 Average rewards:  37.4\n",
      "Monitored episode 50 Average Monitored rewards:  45.58\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2686756   1.000463    0.869282    1.999999   -0.07964689  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8905542 0.7034158]\n",
      "tensor([[ 0.8632],\n",
      "        [-0.9635],\n",
      "        [-0.9635],\n",
      "        [-0.2349],\n",
      "        [ 0.0432],\n",
      "        [ 0.8632],\n",
      "        [-0.9635],\n",
      "        [-0.9635],\n",
      "        [-0.9635],\n",
      "        [ 0.3938],\n",
      "        [ 0.8632],\n",
      "        [-0.9635],\n",
      "        [-0.9635],\n",
      "        [ 0.3938],\n",
      "        [-0.2349],\n",
      "        [-0.2349],\n",
      "        [-0.9635],\n",
      "        [-0.9635],\n",
      "        [-0.9635],\n",
      "        [-0.2349],\n",
      "        [-0.2349],\n",
      "        [ 0.0432],\n",
      "        [ 0.0432],\n",
      "        [ 0.0432],\n",
      "        [ 0.0432],\n",
      "        [ 0.0432],\n",
      "        [ 0.0432],\n",
      "        [ 0.0432],\n",
      "        [ 0.0432],\n",
      "        [ 0.0432],\n",
      "        [-0.2349],\n",
      "        [-0.9635],\n",
      "        [-0.2349],\n",
      "        [ 0.0432],\n",
      "        [ 0.0432],\n",
      "        [ 0.0432],\n",
      "        [ 0.0432],\n",
      "        [ 0.0432],\n",
      "        [ 0.0432],\n",
      "        [ 0.0432],\n",
      "        [ 0.8632],\n",
      "        [ 0.8632],\n",
      "        [-0.9635],\n",
      "        [-0.9635],\n",
      "        [ 0.3938],\n",
      "        [ 0.3938],\n",
      "        [ 0.3938],\n",
      "        [ 0.3938],\n",
      "        [-0.2349],\n",
      "        [-0.9635]], dtype=torch.float64)\n",
      "Finished episode 1565 Average rewards:  37.4\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2600733   1.0004483   0.86395234  1.999999   -0.09074935  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8991565  0.69808614]\n",
      "tensor([[ 0.8698],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [ 0.3549],\n",
      "        [ 0.3549],\n",
      "        [ 0.3549],\n",
      "        [-0.1959],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [ 0.3549],\n",
      "        [ 0.3549],\n",
      "        [ 0.3549],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [ 0.8698],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [ 0.3549],\n",
      "        [ 0.3549],\n",
      "        [ 0.3549],\n",
      "        [ 0.3549],\n",
      "        [ 0.3549],\n",
      "        [-0.1959],\n",
      "        [ 0.0141],\n",
      "        [ 0.8698],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [ 0.3549],\n",
      "        [ 0.3549],\n",
      "        [ 0.3549],\n",
      "        [-0.1959],\n",
      "        [ 0.0141],\n",
      "        [ 0.0141],\n",
      "        [ 0.0141],\n",
      "        [ 0.0141],\n",
      "        [ 0.0141],\n",
      "        [-0.6699],\n",
      "        [-0.6699],\n",
      "        [-0.6699],\n",
      "        [-0.9679]], dtype=torch.float64)\n",
      "Finished episode 1570 Average rewards:  61.8\n",
      "Monitored episode 50 Average Monitored rewards:  53.98\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2701902   1.0004499   0.879684    1.999999   -0.06211709  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8890396 0.7138177]\n",
      "tensor([[ 0.8789],\n",
      "        [ 0.8789],\n",
      "        [ 0.8789],\n",
      "        [ 0.8789],\n",
      "        [-0.9720],\n",
      "        [-0.9720],\n",
      "        [-0.9720],\n",
      "        [-0.9720],\n",
      "        [-0.9720],\n",
      "        [ 0.3138],\n",
      "        [-0.1558],\n",
      "        [-0.9720],\n",
      "        [-0.0177],\n",
      "        [ 0.8789],\n",
      "        [-0.0177],\n",
      "        [-0.0177],\n",
      "        [-0.0177],\n",
      "        [-0.0177],\n",
      "        [-0.0177],\n",
      "        [-0.0177],\n",
      "        [-0.1558],\n",
      "        [-0.1558],\n",
      "        [-0.0177],\n",
      "        [-0.6983],\n",
      "        [-0.9720],\n",
      "        [-0.9720],\n",
      "        [-0.9720],\n",
      "        [ 0.3138],\n",
      "        [ 0.3138],\n",
      "        [-0.9720],\n",
      "        [-0.1558],\n",
      "        [-0.9720],\n",
      "        [-0.9720],\n",
      "        [-0.9720],\n",
      "        [-0.9720],\n",
      "        [-0.9720],\n",
      "        [-0.9720],\n",
      "        [ 0.3138],\n",
      "        [ 0.3138],\n",
      "        [ 0.3138],\n",
      "        [-0.1558],\n",
      "        [-0.1558],\n",
      "        [-0.0177],\n",
      "        [-0.0177],\n",
      "        [-0.0177],\n",
      "        [-0.0177],\n",
      "        [-0.6983],\n",
      "        [-0.6983],\n",
      "        [-0.0177],\n",
      "        [-0.6983]], dtype=torch.float64)\n",
      "Finished episode 1575 Average rewards:  60.6\n",
      "len_game 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[ 1.2579821   1.0004287   0.8696402   1.999999   -0.07994641  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9012477 0.7037739]\n",
      "tensor([[ 0.8329],\n",
      "        [ 0.8329],\n",
      "        [-0.9450],\n",
      "        [-0.9450],\n",
      "        [-0.9450],\n",
      "        [-0.9450],\n",
      "        [-0.9450],\n",
      "        [ 0.3840],\n",
      "        [ 0.3840],\n",
      "        [ 0.3840],\n",
      "        [ 0.8329],\n",
      "        [-0.9450],\n",
      "        [-0.2384],\n",
      "        [ 0.0641],\n",
      "        [-0.6205],\n",
      "        [-0.9450],\n",
      "        [-0.2384],\n",
      "        [-0.9450],\n",
      "        [-0.9450],\n",
      "        [-0.9450],\n",
      "        [ 0.8329],\n",
      "        [-0.9450],\n",
      "        [ 0.0641],\n",
      "        [ 0.0641],\n",
      "        [ 0.0641],\n",
      "        [ 0.0641],\n",
      "        [ 0.0641],\n",
      "        [ 0.0641],\n",
      "        [ 0.0641],\n",
      "        [ 0.0641],\n",
      "        [-0.2384],\n",
      "        [ 0.0641],\n",
      "        [-0.6205],\n",
      "        [-0.6205],\n",
      "        [ 0.8329],\n",
      "        [-0.9450],\n",
      "        [ 0.0641],\n",
      "        [ 0.0641],\n",
      "        [ 0.0641],\n",
      "        [ 0.0641],\n",
      "        [-0.2384],\n",
      "        [-0.9450],\n",
      "        [ 0.0641],\n",
      "        [ 0.0641],\n",
      "        [ 0.0641],\n",
      "        [ 0.0641],\n",
      "        [-0.6205],\n",
      "        [-0.6205],\n",
      "        [-0.9450],\n",
      "        [ 0.0641]], dtype=torch.float64)\n",
      "Finished episode 1580 Average rewards:  38.6\n",
      "Monitored episode 50 Average Monitored rewards:  35.68\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2504096   1.0004132   0.8663187   1.999999   -0.09566443  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9088202 0.7004525]\n",
      "tensor([[ 0.8546],\n",
      "        [-0.9572],\n",
      "        [-0.9572],\n",
      "        [-0.9572],\n",
      "        [-0.9572],\n",
      "        [-0.9572],\n",
      "        [-0.9572],\n",
      "        [-0.9572],\n",
      "        [-0.9572],\n",
      "        [-0.9572],\n",
      "        [-0.1781],\n",
      "        [ 0.0132],\n",
      "        [ 0.0132],\n",
      "        [ 0.0132],\n",
      "        [ 0.0132],\n",
      "        [-0.6704],\n",
      "        [ 0.0132],\n",
      "        [ 0.0132],\n",
      "        [ 0.0132],\n",
      "        [ 0.0132],\n",
      "        [ 0.8546],\n",
      "        [-0.9572],\n",
      "        [-0.9572],\n",
      "        [-0.9572],\n",
      "        [-0.9572],\n",
      "        [-0.9572],\n",
      "        [ 0.3261],\n",
      "        [ 0.3261],\n",
      "        [ 0.3261],\n",
      "        [ 0.3261],\n",
      "        [ 0.8546],\n",
      "        [-0.9572],\n",
      "        [ 0.0132],\n",
      "        [ 0.0132],\n",
      "        [ 0.0132],\n",
      "        [-0.6704],\n",
      "        [-0.9572],\n",
      "        [-0.9572],\n",
      "        [ 0.0132],\n",
      "        [ 0.0132],\n",
      "        [-0.1781],\n",
      "        [-0.9572],\n",
      "        [-0.9572],\n",
      "        [-0.9572],\n",
      "        [ 0.3261],\n",
      "        [-0.1781],\n",
      "        [ 0.0132],\n",
      "        [ 0.0132],\n",
      "        [ 0.0132],\n",
      "        [ 0.0132]], dtype=torch.float64)\n",
      "Finished episode 1585 Average rewards:  39.6\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2879784   1.0004214   0.891399    1.9999993  -0.04360355  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8712514 0.7255328]\n",
      "tensor([[-0.1276],\n",
      "        [-0.1276],\n",
      "        [-0.0317],\n",
      "        [-0.0317],\n",
      "        [-0.0317],\n",
      "        [-0.7079],\n",
      "        [-0.0317],\n",
      "        [-0.0317],\n",
      "        [-0.7079],\n",
      "        [-0.7079],\n",
      "        [ 0.8705],\n",
      "        [ 0.8705],\n",
      "        [-0.9622],\n",
      "        [-0.1276],\n",
      "        [-0.0317],\n",
      "        [-0.0317],\n",
      "        [-0.0317],\n",
      "        [-0.7079],\n",
      "        [-0.0317],\n",
      "        [-0.7079],\n",
      "        [ 0.8705],\n",
      "        [-0.0317],\n",
      "        [-0.9622],\n",
      "        [ 0.2765],\n",
      "        [-0.1276],\n",
      "        [-0.1276],\n",
      "        [-0.0317],\n",
      "        [-0.7079],\n",
      "        [-0.9622],\n",
      "        [-0.1276],\n",
      "        [-0.1276],\n",
      "        [-0.9622],\n",
      "        [-0.1276],\n",
      "        [-0.1276],\n",
      "        [-0.0317],\n",
      "        [-0.7079],\n",
      "        [-0.9622],\n",
      "        [-0.0317],\n",
      "        [-0.0317],\n",
      "        [-0.7079],\n",
      "        [ 0.8705],\n",
      "        [ 0.8705],\n",
      "        [-0.9622],\n",
      "        [-0.1276],\n",
      "        [-0.9622],\n",
      "        [-0.1276],\n",
      "        [-0.0317],\n",
      "        [-0.0317],\n",
      "        [-0.0317],\n",
      "        [-0.0317]], dtype=torch.float64)\n",
      "Finished episode 1590 Average rewards:  -4.6\n",
      "Monitored episode 50 Average Monitored rewards:  40.38\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2776213   1.0004054   0.88388836  1.9999993  -0.0624258   1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8816085  0.71802217]\n",
      "tensor([[-0.3034],\n",
      "        [ 0.1167],\n",
      "        [ 0.1167],\n",
      "        [ 0.1167],\n",
      "        [ 0.1167],\n",
      "        [ 0.1167],\n",
      "        [ 0.1167],\n",
      "        [ 0.1167],\n",
      "        [ 0.1167],\n",
      "        [ 0.1167],\n",
      "        [-0.3034],\n",
      "        [ 0.1167],\n",
      "        [-0.5633],\n",
      "        [ 0.1167],\n",
      "        [-0.5633],\n",
      "        [-0.9284],\n",
      "        [-0.3034],\n",
      "        [ 0.1167],\n",
      "        [ 0.1167],\n",
      "        [-0.5633],\n",
      "        [ 0.8113],\n",
      "        [-0.9284],\n",
      "        [-0.9284],\n",
      "        [-0.9284],\n",
      "        [-0.3034],\n",
      "        [ 0.1167],\n",
      "        [ 0.1167],\n",
      "        [ 0.1167],\n",
      "        [ 0.1167],\n",
      "        [ 0.1167],\n",
      "        [-0.3034],\n",
      "        [ 0.1167],\n",
      "        [ 0.1167],\n",
      "        [ 0.1167],\n",
      "        [ 0.1167],\n",
      "        [ 0.1167],\n",
      "        [ 0.1167],\n",
      "        [ 0.1167],\n",
      "        [-0.5633],\n",
      "        [ 0.1167],\n",
      "        [ 0.8113],\n",
      "        [-0.9284],\n",
      "        [-0.3034],\n",
      "        [ 0.1167],\n",
      "        [ 0.1167],\n",
      "        [ 0.1167],\n",
      "        [ 0.1167],\n",
      "        [ 0.1167],\n",
      "        [-0.5633],\n",
      "        [-0.5633]], dtype=torch.float64)\n",
      "Finished episode 1595 Average rewards:  -6.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2686337  1.0003902  0.8763747  1.9999993 -0.0849431  1.8641111\n",
      "  1.7464267  0.7518858]\n",
      "Enc\n",
      "[0.89059603 0.7105085 ]\n",
      "tensor([[ 0.8382],\n",
      "        [-0.9443],\n",
      "        [-0.9443],\n",
      "        [ 0.3999],\n",
      "        [ 0.3999],\n",
      "        [-0.2486],\n",
      "        [-0.9443],\n",
      "        [-0.2486],\n",
      "        [-0.9443],\n",
      "        [-0.9443],\n",
      "        [ 0.8382],\n",
      "        [ 0.8382],\n",
      "        [-0.9443],\n",
      "        [-0.9443],\n",
      "        [ 0.3999],\n",
      "        [ 0.3999],\n",
      "        [ 0.3999],\n",
      "        [-0.2486],\n",
      "        [ 0.0632],\n",
      "        [ 0.0632],\n",
      "        [-0.2486],\n",
      "        [ 0.0632],\n",
      "        [-0.6175],\n",
      "        [ 0.0632],\n",
      "        [ 0.0632],\n",
      "        [ 0.0632],\n",
      "        [ 0.0632],\n",
      "        [ 0.0632],\n",
      "        [ 0.0632],\n",
      "        [ 0.0632],\n",
      "        [ 0.8382],\n",
      "        [-0.9443],\n",
      "        [ 0.3999],\n",
      "        [ 0.3999],\n",
      "        [-0.2486],\n",
      "        [-0.9443],\n",
      "        [ 0.3999],\n",
      "        [-0.2486],\n",
      "        [ 0.0632],\n",
      "        [ 0.0632],\n",
      "        [-0.2486],\n",
      "        [ 0.0632],\n",
      "        [ 0.0632],\n",
      "        [ 0.0632],\n",
      "        [ 0.0632],\n",
      "        [ 0.0632],\n",
      "        [ 0.0632],\n",
      "        [ 0.0632],\n",
      "        [ 0.0632],\n",
      "        [ 0.0632]], dtype=torch.float64)\n",
      "Finished episode 1600 Average rewards:  15.4\n",
      "Monitored episode 50 Average Monitored rewards:  49.02\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2867556   1.0003856   0.8853471   1.9999993  -0.05005491  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8724743  0.71948093]\n",
      "tensor([[ 0.8694],\n",
      "        [-0.9601],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.6769],\n",
      "        [-0.6769],\n",
      "        [-0.0011],\n",
      "        [ 0.8694],\n",
      "        [-0.9601],\n",
      "        [-0.9601],\n",
      "        [-0.1836],\n",
      "        [-0.9601],\n",
      "        [-0.9601],\n",
      "        [-0.1836],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.6769],\n",
      "        [-0.9601],\n",
      "        [-0.1836],\n",
      "        [ 0.8694],\n",
      "        [-0.9601],\n",
      "        [-0.1836],\n",
      "        [-0.0011],\n",
      "        [-0.6769],\n",
      "        [-0.6769],\n",
      "        [-0.9601],\n",
      "        [-0.1836],\n",
      "        [-0.0011],\n",
      "        [-0.6769],\n",
      "        [ 0.8694],\n",
      "        [-0.9601],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.6769],\n",
      "        [-0.6769],\n",
      "        [ 0.8694],\n",
      "        [ 0.8694],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.6769],\n",
      "        [-0.6769],\n",
      "        [-0.6769]], dtype=torch.float64)\n",
      "Finished episode 1605 Average rewards:  19.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2768964   1.0003741   0.87169045  1.9999993  -0.05915074  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8823335 0.7058242]\n",
      "tensor([[ 0.8298],\n",
      "        [-0.9426],\n",
      "        [-0.9426],\n",
      "        [-0.9426],\n",
      "        [-0.9426],\n",
      "        [-0.9426],\n",
      "        [ 0.4323],\n",
      "        [ 0.4323],\n",
      "        [ 0.4323],\n",
      "        [-0.2882],\n",
      "        [ 0.8298],\n",
      "        [-0.9426],\n",
      "        [-0.9426],\n",
      "        [-0.9426],\n",
      "        [ 0.4323],\n",
      "        [ 0.4323],\n",
      "        [ 0.4323],\n",
      "        [ 0.4323],\n",
      "        [ 0.4323],\n",
      "        [-0.2882],\n",
      "        [-0.2882],\n",
      "        [ 0.0984],\n",
      "        [ 0.0984],\n",
      "        [ 0.0984],\n",
      "        [ 0.0984],\n",
      "        [ 0.0984],\n",
      "        [ 0.0984],\n",
      "        [ 0.0984],\n",
      "        [ 0.0984],\n",
      "        [ 0.0984],\n",
      "        [ 0.8298],\n",
      "        [-0.9426],\n",
      "        [-0.9426],\n",
      "        [ 0.4323],\n",
      "        [-0.9426],\n",
      "        [-0.9426],\n",
      "        [-0.9426],\n",
      "        [-0.9426],\n",
      "        [ 0.4323],\n",
      "        [ 0.4323],\n",
      "        [-0.2882],\n",
      "        [-0.2882],\n",
      "        [-0.9426],\n",
      "        [ 0.4323],\n",
      "        [ 0.4323],\n",
      "        [-0.2882],\n",
      "        [-0.2882],\n",
      "        [-0.9426],\n",
      "        [ 0.4323],\n",
      "        [-0.2882]], dtype=torch.float64)\n",
      "Finished episode 1610 Average rewards:  58.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  42.16\n",
      "len_game 53\n",
      "Rot\n",
      "[ 1.2689943  1.0003614  0.8654287  1.9999993 -0.0792356  1.8641111\n",
      "  1.7464267  0.7518858]\n",
      "Enc\n",
      "[0.8902356  0.69956243]\n",
      "tensor([[ 0.8481],\n",
      "        [ 0.0725],\n",
      "        [ 0.0725],\n",
      "        [ 0.0725],\n",
      "        [ 0.0725],\n",
      "        [ 0.0725],\n",
      "        [ 0.0725],\n",
      "        [ 0.0725],\n",
      "        [ 0.0725],\n",
      "        [ 0.0725],\n",
      "        [ 0.8481],\n",
      "        [ 0.8481],\n",
      "        [-0.9620],\n",
      "        [-0.9620],\n",
      "        [-0.9620],\n",
      "        [-0.9620],\n",
      "        [ 0.4026],\n",
      "        [ 0.4026],\n",
      "        [ 0.4026],\n",
      "        [ 0.4026],\n",
      "        [-0.2548],\n",
      "        [-0.2548],\n",
      "        [-0.2548],\n",
      "        [-0.9620],\n",
      "        [-0.9620],\n",
      "        [-0.9620],\n",
      "        [ 0.4026],\n",
      "        [ 0.4026],\n",
      "        [ 0.4026],\n",
      "        [-0.2548],\n",
      "        [-0.2548],\n",
      "        [-0.2548],\n",
      "        [ 0.8481],\n",
      "        [-0.9620],\n",
      "        [-0.9620],\n",
      "        [ 0.4026],\n",
      "        [-0.2548],\n",
      "        [ 0.0725],\n",
      "        [ 0.0725],\n",
      "        [ 0.0725],\n",
      "        [ 0.0725],\n",
      "        [-0.6196],\n",
      "        [-0.2548],\n",
      "        [ 0.0725],\n",
      "        [ 0.0725],\n",
      "        [ 0.0725],\n",
      "        [ 0.0725],\n",
      "        [ 0.0725],\n",
      "        [ 0.0725],\n",
      "        [-0.6196],\n",
      "        [-0.6196],\n",
      "        [-0.6196],\n",
      "        [ 0.8481]], dtype=torch.float64)\n",
      "Finished episode 1615 Average rewards:  37.4\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2614223   1.000347    0.85798573  1.9999993  -0.10347477  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8978077  0.69211954]\n",
      "tensor([[-0.1974],\n",
      "        [-0.9726],\n",
      "        [ 0.3563],\n",
      "        [-0.1974],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [ 0.3563],\n",
      "        [ 0.3563],\n",
      "        [ 0.8734],\n",
      "        [-0.9726],\n",
      "        [ 0.0152],\n",
      "        [ 0.0152],\n",
      "        [ 0.0152],\n",
      "        [-0.6714],\n",
      "        [-0.6714],\n",
      "        [ 0.0152],\n",
      "        [ 0.0152],\n",
      "        [ 0.0152],\n",
      "        [-0.1974],\n",
      "        [ 0.0152],\n",
      "        [ 0.0152],\n",
      "        [ 0.0152],\n",
      "        [ 0.0152],\n",
      "        [ 0.0152],\n",
      "        [ 0.0152],\n",
      "        [ 0.0152],\n",
      "        [ 0.0152],\n",
      "        [ 0.0152],\n",
      "        [-0.1974],\n",
      "        [ 0.0152],\n",
      "        [ 0.0152],\n",
      "        [ 0.0152],\n",
      "        [ 0.0152],\n",
      "        [ 0.0152],\n",
      "        [ 0.0152],\n",
      "        [ 0.0152],\n",
      "        [ 0.0152],\n",
      "        [ 0.0152],\n",
      "        [-0.1974],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [ 0.3563],\n",
      "        [ 0.3563],\n",
      "        [-0.1974],\n",
      "        [ 0.0152],\n",
      "        [ 0.0152],\n",
      "        [ 0.0152]], dtype=torch.float64)\n",
      "Finished episode 1620 Average rewards:  15.6\n",
      "Monitored episode 50 Average Monitored rewards:  48.82\n",
      "len_game 53\n",
      "Rot\n",
      "[ 1.2650008   1.0003372   0.85927904  1.9999993  -0.0924139   1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8942291  0.69341284]\n",
      "tensor([[-0.1277],\n",
      "        [-0.9840],\n",
      "        [-0.9840],\n",
      "        [ 0.2964],\n",
      "        [ 0.2964],\n",
      "        [-0.1277],\n",
      "        [-0.0540],\n",
      "        [-0.7291],\n",
      "        [ 0.9027],\n",
      "        [-0.9840],\n",
      "        [-0.1277],\n",
      "        [-0.9840],\n",
      "        [-0.9840],\n",
      "        [-0.9840],\n",
      "        [ 0.2964],\n",
      "        [ 0.2964],\n",
      "        [-0.1277],\n",
      "        [-0.0540],\n",
      "        [ 0.9027],\n",
      "        [-0.9840],\n",
      "        [-0.1277],\n",
      "        [ 0.9027],\n",
      "        [-0.9840],\n",
      "        [ 0.2964],\n",
      "        [-0.1277],\n",
      "        [-0.9840],\n",
      "        [-0.9840],\n",
      "        [-0.9840],\n",
      "        [-0.9840],\n",
      "        [ 0.2964],\n",
      "        [ 0.2964],\n",
      "        [-0.1277],\n",
      "        [-0.9840],\n",
      "        [-0.9840],\n",
      "        [-0.1277],\n",
      "        [-0.1277],\n",
      "        [-0.9840],\n",
      "        [-0.9840],\n",
      "        [-0.9840],\n",
      "        [-0.9840],\n",
      "        [ 0.2964],\n",
      "        [ 0.9027],\n",
      "        [-0.9840],\n",
      "        [-0.0540],\n",
      "        [-0.0540],\n",
      "        [-0.0540],\n",
      "        [-0.7291],\n",
      "        [-0.7291],\n",
      "        [-0.0540],\n",
      "        [ 0.9027],\n",
      "        [-0.9840],\n",
      "        [-0.1277],\n",
      "        [-0.1277]], dtype=torch.float64)\n",
      "Finished episode 1625 Average rewards:  101.8\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2763764   1.0003374   0.8781582   1.9999993  -0.06320043  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8828536 0.712292 ]\n",
      "tensor([[ 0.8917],\n",
      "        [-0.9813],\n",
      "        [-0.9813],\n",
      "        [ 0.3252],\n",
      "        [ 0.3252],\n",
      "        [-0.1601],\n",
      "        [-0.0224],\n",
      "        [-0.0224],\n",
      "        [-0.0224],\n",
      "        [-0.0224],\n",
      "        [ 0.8917],\n",
      "        [ 0.8917],\n",
      "        [-0.9813],\n",
      "        [-0.9813],\n",
      "        [ 0.3252],\n",
      "        [ 0.3252],\n",
      "        [ 0.3252],\n",
      "        [ 0.3252],\n",
      "        [ 0.3252],\n",
      "        [-0.1601],\n",
      "        [ 0.8917],\n",
      "        [ 0.8917],\n",
      "        [ 0.8917],\n",
      "        [-0.9813],\n",
      "        [-0.9813],\n",
      "        [-0.9813],\n",
      "        [-0.9813],\n",
      "        [ 0.3252],\n",
      "        [ 0.3252],\n",
      "        [ 0.3252],\n",
      "        [ 0.8917],\n",
      "        [-0.9813],\n",
      "        [-0.9813],\n",
      "        [-0.9813],\n",
      "        [ 0.3252],\n",
      "        [ 0.3252],\n",
      "        [-0.1601],\n",
      "        [-0.0224],\n",
      "        [ 0.8917],\n",
      "        [-0.9813],\n",
      "        [ 0.8917],\n",
      "        [-0.9813],\n",
      "        [-0.0224],\n",
      "        [-0.9813],\n",
      "        [-0.1601],\n",
      "        [-0.9813],\n",
      "        [-0.9813],\n",
      "        [ 0.3252],\n",
      "        [ 0.3252],\n",
      "        [-0.1601]], dtype=torch.float64)\n",
      "Finished episode 1630 Average rewards:  38.6\n",
      "Monitored episode 50 Average Monitored rewards:  32.06\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2694017   1.0003289   0.87380874  1.9999993  -0.07548375  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88982826 0.70794255]\n",
      "tensor([[ 0.8457],\n",
      "        [-0.9536],\n",
      "        [ 0.0610],\n",
      "        [ 0.0610],\n",
      "        [ 0.0610],\n",
      "        [ 0.0610],\n",
      "        [ 0.0610],\n",
      "        [ 0.0610],\n",
      "        [ 0.0610],\n",
      "        [ 0.0610],\n",
      "        [ 0.8457],\n",
      "        [-0.9536],\n",
      "        [-0.9536],\n",
      "        [-0.9536],\n",
      "        [ 0.3962],\n",
      "        [ 0.3962],\n",
      "        [-0.2450],\n",
      "        [-0.9536],\n",
      "        [-0.9536],\n",
      "        [-0.9536],\n",
      "        [-0.2450],\n",
      "        [-0.9536],\n",
      "        [-0.9536],\n",
      "        [ 0.3962],\n",
      "        [ 0.3962],\n",
      "        [ 0.3962],\n",
      "        [-0.2450],\n",
      "        [-0.2450],\n",
      "        [-0.9536],\n",
      "        [-0.2450],\n",
      "        [ 0.8457],\n",
      "        [-0.9536],\n",
      "        [-0.9536],\n",
      "        [-0.9536],\n",
      "        [-0.9536],\n",
      "        [-0.9536],\n",
      "        [ 0.3962],\n",
      "        [ 0.3962],\n",
      "        [ 0.3962],\n",
      "        [ 0.3962],\n",
      "        [-0.2450],\n",
      "        [-0.9536],\n",
      "        [-0.9536],\n",
      "        [-0.9536],\n",
      "        [-0.9536],\n",
      "        [ 0.3962],\n",
      "        [-0.9536],\n",
      "        [ 0.3962],\n",
      "        [ 0.3962],\n",
      "        [ 0.3962]], dtype=torch.float64)\n",
      "Finished episode 1635 Average rewards:  61.8\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2647473   1.0003197   0.86876434  1.9999993  -0.09381749  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8944828  0.70289814]\n",
      "tensor([[ 0.8597],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [-0.6571],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [-0.2067],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [-0.6571],\n",
      "        [-0.6571],\n",
      "        [-0.6571],\n",
      "        [-0.9604],\n",
      "        [-0.9604],\n",
      "        [ 0.8597],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [-0.2067],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [-0.6571],\n",
      "        [ 0.0260],\n",
      "        [-0.2067],\n",
      "        [-0.2067],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260],\n",
      "        [ 0.0260]], dtype=torch.float64)\n",
      "Finished episode 1640 Average rewards:  13.2\n",
      "Monitored episode 50 Average Monitored rewards:  60.24\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2844344   1.0003172   0.88101083  1.9999993  -0.05712974  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.87479556 0.71514463]\n",
      "tensor([[-0.1564],\n",
      "        [-0.9715],\n",
      "        [-0.9715],\n",
      "        [-0.1564],\n",
      "        [-0.0264],\n",
      "        [-0.0264],\n",
      "        [-0.0264],\n",
      "        [-0.0264],\n",
      "        [-0.7023],\n",
      "        [-0.7023],\n",
      "        [ 0.8851],\n",
      "        [ 0.8851],\n",
      "        [ 0.8851],\n",
      "        [-0.9715],\n",
      "        [-0.1564],\n",
      "        [-0.0264],\n",
      "        [-0.0264],\n",
      "        [-0.0264],\n",
      "        [-0.0264],\n",
      "        [-0.7023],\n",
      "        [-0.1564],\n",
      "        [-0.0264],\n",
      "        [-0.7023],\n",
      "        [-0.9715],\n",
      "        [-0.0264],\n",
      "        [-0.0264],\n",
      "        [-0.0264],\n",
      "        [-0.0264],\n",
      "        [-0.7023],\n",
      "        [-0.7023],\n",
      "        [-0.1564],\n",
      "        [-0.1564],\n",
      "        [-0.0264],\n",
      "        [-0.7023],\n",
      "        [-0.9715],\n",
      "        [-0.9715],\n",
      "        [-0.9715],\n",
      "        [-0.9715],\n",
      "        [-0.9715],\n",
      "        [-0.9715],\n",
      "        [ 0.8851],\n",
      "        [-0.9715],\n",
      "        [-0.1564],\n",
      "        [-0.1564],\n",
      "        [-0.9715],\n",
      "        [ 0.3222],\n",
      "        [-0.1564],\n",
      "        [-0.1564],\n",
      "        [-0.0264],\n",
      "        [-0.0264]], dtype=torch.float64)\n",
      "Finished episode 1645 Average rewards:  18.8\n",
      "len_game 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[ 1.2729579   1.0003046   0.870289    1.9999993  -0.07350883  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88627213 0.70442283]\n",
      "tensor([[ 0.8439],\n",
      "        [-0.9518],\n",
      "        [ 0.4202],\n",
      "        [-0.2699],\n",
      "        [-0.2699],\n",
      "        [-0.2699],\n",
      "        [-0.9518],\n",
      "        [-0.9518],\n",
      "        [-0.9518],\n",
      "        [-0.9518],\n",
      "        [ 0.8439],\n",
      "        [ 0.0783],\n",
      "        [ 0.0783],\n",
      "        [-0.6072],\n",
      "        [-0.6072],\n",
      "        [-0.9518],\n",
      "        [-0.2699],\n",
      "        [-0.9518],\n",
      "        [-0.2699],\n",
      "        [-0.9518],\n",
      "        [ 0.8439],\n",
      "        [-0.9518],\n",
      "        [-0.9518],\n",
      "        [-0.9518],\n",
      "        [-0.9518],\n",
      "        [-0.9518],\n",
      "        [ 0.4202],\n",
      "        [ 0.4202],\n",
      "        [ 0.4202],\n",
      "        [ 0.4202],\n",
      "        [-0.2699],\n",
      "        [-0.9518],\n",
      "        [-0.2699],\n",
      "        [ 0.0783],\n",
      "        [-0.6072],\n",
      "        [ 0.0783],\n",
      "        [ 0.0783],\n",
      "        [ 0.0783],\n",
      "        [ 0.0783],\n",
      "        [ 0.0783],\n",
      "        [-0.2699],\n",
      "        [ 0.0783],\n",
      "        [ 0.0783],\n",
      "        [ 0.0783],\n",
      "        [ 0.0783],\n",
      "        [ 0.0783],\n",
      "        [-0.6072],\n",
      "        [-0.6072],\n",
      "        [-0.6072],\n",
      "        [ 0.0783]], dtype=torch.float64)\n",
      "Finished episode 1650 Average rewards:  60.8\n",
      "Monitored episode 50 Average Monitored rewards:  39.68\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2710977   1.000301    0.8716819   1.9999993  -0.08145128  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88813233 0.70581573]\n",
      "tensor([[-0.2167],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [-0.2167],\n",
      "        [-0.9672],\n",
      "        [-0.9672],\n",
      "        [-0.9672],\n",
      "        [-0.9672],\n",
      "        [-0.9672],\n",
      "        [-0.9672],\n",
      "        [-0.9672],\n",
      "        [-0.9672],\n",
      "        [-0.9672],\n",
      "        [-0.2167],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [-0.2167],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [-0.2167],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [-0.6549],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316],\n",
      "        [ 0.0316]], dtype=torch.float64)\n",
      "Finished episode 1655 Average rewards:  16.2\n",
      "len_game 52\n",
      "Rot\n",
      "[ 1.2610382  1.0002877  0.8631662  1.9999993 -0.1029285  1.8641111\n",
      "  1.7464267  0.7518858]\n",
      "Enc\n",
      "[0.89819187 0.6973    ]\n",
      "tensor([[-0.1956],\n",
      "        [ 0.0089],\n",
      "        [ 0.0089],\n",
      "        [ 0.0089],\n",
      "        [ 0.0089],\n",
      "        [ 0.0089],\n",
      "        [ 0.0089],\n",
      "        [ 0.0089],\n",
      "        [ 0.0089],\n",
      "        [ 0.0089],\n",
      "        [ 0.8731],\n",
      "        [ 0.0089],\n",
      "        [ 0.0089],\n",
      "        [ 0.0089],\n",
      "        [-0.6724],\n",
      "        [ 0.8731],\n",
      "        [-0.9671],\n",
      "        [-0.9671],\n",
      "        [ 0.3584],\n",
      "        [-0.1956],\n",
      "        [-0.1956],\n",
      "        [-0.1956],\n",
      "        [-0.1956],\n",
      "        [ 0.0089],\n",
      "        [ 0.0089],\n",
      "        [ 0.0089],\n",
      "        [ 0.0089],\n",
      "        [-0.6724],\n",
      "        [-0.6724],\n",
      "        [ 0.0089],\n",
      "        [ 0.0089],\n",
      "        [ 0.0089],\n",
      "        [-0.1956],\n",
      "        [-0.9671],\n",
      "        [-0.9671],\n",
      "        [-0.9671],\n",
      "        [ 0.3584],\n",
      "        [ 0.3584],\n",
      "        [-0.1956],\n",
      "        [ 0.0089],\n",
      "        [ 0.0089],\n",
      "        [ 0.0089],\n",
      "        [-0.1956],\n",
      "        [-0.9671],\n",
      "        [-0.9671],\n",
      "        [-0.9671],\n",
      "        [-0.9671],\n",
      "        [ 0.3584],\n",
      "        [ 0.3584],\n",
      "        [ 0.3584],\n",
      "        [ 0.3584],\n",
      "        [-0.1956]], dtype=torch.float64)\n",
      "Finished episode 1660 Average rewards:  36.0\n",
      "Monitored episode 50 Average Monitored rewards:  48.76\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2841809   1.0002917   0.88559806  1.9999993  -0.06289236  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.87504923 0.71973187]\n",
      "tensor([[-0.1284],\n",
      "        [-0.9787],\n",
      "        [-0.1284],\n",
      "        [-0.0524],\n",
      "        [-0.7254],\n",
      "        [-0.0524],\n",
      "        [-0.0524],\n",
      "        [-0.0524],\n",
      "        [-0.0524],\n",
      "        [-0.0524],\n",
      "        [ 0.8976],\n",
      "        [-0.0524],\n",
      "        [ 0.8976],\n",
      "        [ 0.8976],\n",
      "        [-0.9787],\n",
      "        [-0.9787],\n",
      "        [-0.9787],\n",
      "        [ 0.2962],\n",
      "        [-0.9787],\n",
      "        [ 0.2962],\n",
      "        [ 0.8976],\n",
      "        [ 0.8976],\n",
      "        [-0.9787],\n",
      "        [-0.9787],\n",
      "        [-0.9787],\n",
      "        [ 0.2962],\n",
      "        [ 0.2962],\n",
      "        [ 0.2962],\n",
      "        [ 0.2962],\n",
      "        [-0.1284],\n",
      "        [-0.1284],\n",
      "        [-0.1284],\n",
      "        [-0.0524],\n",
      "        [-0.0524],\n",
      "        [-0.0524],\n",
      "        [-0.0524],\n",
      "        [-0.7254],\n",
      "        [ 0.8976],\n",
      "        [-0.9787],\n",
      "        [-0.0524],\n",
      "        [-0.1284],\n",
      "        [-0.1284],\n",
      "        [-0.1284],\n",
      "        [-0.0524],\n",
      "        [ 0.8976],\n",
      "        [-0.9787],\n",
      "        [-0.9787],\n",
      "        [-0.9787],\n",
      "        [ 0.2962],\n",
      "        [ 0.2962]], dtype=torch.float64)\n",
      "Finished episode 1665 Average rewards:  59.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2756447   1.0002829   0.876745    1.9999993  -0.07971004  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8835855 0.7108788]\n",
      "tensor([[-0.2570],\n",
      "        [-0.9451],\n",
      "        [-0.9451],\n",
      "        [-0.9451],\n",
      "        [ 0.4131],\n",
      "        [ 0.4131],\n",
      "        [ 0.4131],\n",
      "        [-0.9451],\n",
      "        [ 0.4131],\n",
      "        [ 0.4131],\n",
      "        [-0.2570],\n",
      "        [-0.2570],\n",
      "        [-0.9451],\n",
      "        [-0.9451],\n",
      "        [-0.9451],\n",
      "        [-0.9451],\n",
      "        [-0.9451],\n",
      "        [ 0.4131],\n",
      "        [ 0.4131],\n",
      "        [ 0.4131],\n",
      "        [ 0.8454],\n",
      "        [-0.9451],\n",
      "        [-0.9451],\n",
      "        [-0.9451],\n",
      "        [-0.9451],\n",
      "        [ 0.4131],\n",
      "        [ 0.4131],\n",
      "        [ 0.4131],\n",
      "        [ 0.4131],\n",
      "        [ 0.4131],\n",
      "        [-0.2570],\n",
      "        [-0.9451],\n",
      "        [-0.2570],\n",
      "        [ 0.0619],\n",
      "        [-0.6170],\n",
      "        [-0.6170],\n",
      "        [ 0.0619],\n",
      "        [ 0.0619],\n",
      "        [ 0.0619],\n",
      "        [ 0.0619],\n",
      "        [-0.2570],\n",
      "        [-0.9451],\n",
      "        [-0.2570],\n",
      "        [-0.9451],\n",
      "        [-0.2570],\n",
      "        [-0.2570],\n",
      "        [-0.9451],\n",
      "        [-0.9451],\n",
      "        [-0.9451],\n",
      "        [-0.9451]], dtype=torch.float64)\n",
      "Finished episode 1670 Average rewards:  82.8\n",
      "Monitored episode 50 Average Monitored rewards:  40.78\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.26559     1.0002737   0.87211716  1.9999993  -0.0884275   1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8936402  0.70625097]\n",
      "tensor([[-0.2068],\n",
      "        [-0.9617],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [-0.6646],\n",
      "        [-0.6646],\n",
      "        [ 0.0139],\n",
      "        [ 0.8707],\n",
      "        [-0.9617],\n",
      "        [-0.9617],\n",
      "        [-0.9617],\n",
      "        [ 0.3724],\n",
      "        [ 0.3724],\n",
      "        [ 0.3724],\n",
      "        [ 0.3724],\n",
      "        [ 0.3724],\n",
      "        [-0.9617],\n",
      "        [-0.2068],\n",
      "        [-0.2068],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [ 0.0139],\n",
      "        [-0.2068],\n",
      "        [-0.2068],\n",
      "        [-0.9617],\n",
      "        [-0.9617],\n",
      "        [-0.2068],\n",
      "        [-0.9617],\n",
      "        [-0.9617],\n",
      "        [ 0.3724],\n",
      "        [ 0.3724],\n",
      "        [-0.2068],\n",
      "        [-0.2068],\n",
      "        [-0.9617],\n",
      "        [ 0.0139],\n",
      "        [ 0.8707],\n",
      "        [ 0.8707],\n",
      "        [-0.9617],\n",
      "        [-0.9617],\n",
      "        [-0.9617],\n",
      "        [-0.9617],\n",
      "        [ 0.3724]], dtype=torch.float64)\n",
      "Finished episode 1675 Average rewards:  37.4\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2737371   1.0002714   0.87856805  1.9999993  -0.07061014  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8854931  0.71270186]\n",
      "tensor([[ 0.8752],\n",
      "        [-0.0110],\n",
      "        [-0.0110],\n",
      "        [-0.0110],\n",
      "        [-0.0110],\n",
      "        [-0.0110],\n",
      "        [-0.6880],\n",
      "        [-0.6880],\n",
      "        [-0.6880],\n",
      "        [-0.0110],\n",
      "        [-0.1705],\n",
      "        [-0.0110],\n",
      "        [-0.6880],\n",
      "        [-0.9656],\n",
      "        [-0.9656],\n",
      "        [ 0.3331],\n",
      "        [ 0.3331],\n",
      "        [-0.1705],\n",
      "        [-0.9656],\n",
      "        [-0.9656],\n",
      "        [-0.1705],\n",
      "        [-0.0110],\n",
      "        [-0.0110],\n",
      "        [-0.0110],\n",
      "        [-0.0110],\n",
      "        [-0.6880],\n",
      "        [-0.6880],\n",
      "        [-0.6880],\n",
      "        [-0.6880],\n",
      "        [-0.0110],\n",
      "        [ 0.8752],\n",
      "        [-0.9656],\n",
      "        [-0.9656],\n",
      "        [ 0.3331],\n",
      "        [ 0.3331],\n",
      "        [-0.1705],\n",
      "        [-0.9656],\n",
      "        [-0.9656],\n",
      "        [-0.9656],\n",
      "        [-0.9656],\n",
      "        [ 0.8752],\n",
      "        [-0.9656],\n",
      "        [-0.0110],\n",
      "        [ 0.8752],\n",
      "        [-0.9656],\n",
      "        [-0.9656],\n",
      "        [-0.9656],\n",
      "        [ 0.3331],\n",
      "        [ 0.3331],\n",
      "        [ 0.3331],\n",
      "        [-0.1705]], dtype=torch.float64)\n",
      "Finished episode 1680 Average rewards:  40.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  40.54\n",
      "len_game 52\n",
      "Rot\n",
      "[ 1.2628052   1.0002606   0.8663318   1.9999993  -0.08721735  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8964249 0.7004656]\n",
      "tensor([[-0.2245],\n",
      "        [ 0.0399],\n",
      "        [ 0.8526],\n",
      "        [-0.9543],\n",
      "        [-0.9543],\n",
      "        [-0.9543],\n",
      "        [-0.9543],\n",
      "        [-0.9543],\n",
      "        [ 0.3803],\n",
      "        [ 0.3803],\n",
      "        [ 0.8526],\n",
      "        [-0.9543],\n",
      "        [ 0.0399],\n",
      "        [ 0.8526],\n",
      "        [-0.9543],\n",
      "        [-0.9543],\n",
      "        [ 0.3803],\n",
      "        [ 0.3803],\n",
      "        [ 0.3803],\n",
      "        [-0.2245],\n",
      "        [-0.2245],\n",
      "        [ 0.0399],\n",
      "        [ 0.0399],\n",
      "        [ 0.0399],\n",
      "        [ 0.0399],\n",
      "        [ 0.0399],\n",
      "        [ 0.0399],\n",
      "        [ 0.0399],\n",
      "        [ 0.0399],\n",
      "        [ 0.0399],\n",
      "        [ 0.8526],\n",
      "        [-0.9543],\n",
      "        [-0.2245],\n",
      "        [-0.9543],\n",
      "        [-0.9543],\n",
      "        [ 0.3803],\n",
      "        [ 0.3803],\n",
      "        [ 0.3803],\n",
      "        [ 0.3803],\n",
      "        [ 0.3803],\n",
      "        [-0.2245],\n",
      "        [-0.2245],\n",
      "        [-0.2245],\n",
      "        [-0.2245],\n",
      "        [-0.9543],\n",
      "        [-0.9543],\n",
      "        [-0.9543],\n",
      "        [-0.9543],\n",
      "        [-0.9543],\n",
      "        [-0.9543],\n",
      "        [-0.9543],\n",
      "        [-0.9543]], dtype=torch.float64)\n",
      "Finished episode 1685 Average rewards:  80.4\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2747291   1.0002569   0.87754023  1.9999993  -0.0567509   1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88450104 0.71167403]\n",
      "tensor([[ 0.8755],\n",
      "        [-0.9701],\n",
      "        [-0.9701],\n",
      "        [-0.0076],\n",
      "        [-0.9701],\n",
      "        [-0.9701],\n",
      "        [ 0.3274],\n",
      "        [ 0.3274],\n",
      "        [-0.1688],\n",
      "        [-0.0076],\n",
      "        [ 0.8755],\n",
      "        [ 0.8755],\n",
      "        [-0.9701],\n",
      "        [-0.9701],\n",
      "        [-0.9701],\n",
      "        [ 0.3274],\n",
      "        [ 0.3274],\n",
      "        [-0.0076],\n",
      "        [-0.9701],\n",
      "        [-0.1688],\n",
      "        [ 0.8755],\n",
      "        [-0.0076],\n",
      "        [-0.0076],\n",
      "        [-0.6890],\n",
      "        [-0.6890],\n",
      "        [ 0.8755],\n",
      "        [-0.9701],\n",
      "        [-0.9701],\n",
      "        [-0.9701],\n",
      "        [-0.9701],\n",
      "        [ 0.8755],\n",
      "        [-0.9701],\n",
      "        [-0.9701],\n",
      "        [-0.9701],\n",
      "        [ 0.3274],\n",
      "        [ 0.3274],\n",
      "        [ 0.3274],\n",
      "        [ 0.3274],\n",
      "        [ 0.3274],\n",
      "        [-0.9701],\n",
      "        [ 0.8755],\n",
      "        [-0.9701],\n",
      "        [-0.9701],\n",
      "        [ 0.3274],\n",
      "        [-0.1688],\n",
      "        [-0.0076],\n",
      "        [-0.0076],\n",
      "        [-0.6890],\n",
      "        [-0.6890],\n",
      "        [-0.0076]], dtype=torch.float64)\n",
      "Finished episode 1690 Average rewards:  40.0\n",
      "Monitored episode 50 Average Monitored rewards:  27.92\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2631743   1.0002447   0.86966944  1.9999993  -0.08294721  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8960558  0.70380324]\n",
      "tensor([[ 0.8339],\n",
      "        [ 0.8339],\n",
      "        [ 0.8339],\n",
      "        [-0.9500],\n",
      "        [-0.9500],\n",
      "        [ 0.4011],\n",
      "        [ 0.4011],\n",
      "        [-0.2570],\n",
      "        [-0.2570],\n",
      "        [-0.9500],\n",
      "        [-0.2570],\n",
      "        [-0.9500],\n",
      "        [-0.9500],\n",
      "        [-0.9500],\n",
      "        [-0.9500],\n",
      "        [ 0.4011],\n",
      "        [ 0.4011],\n",
      "        [ 0.4011],\n",
      "        [ 0.4011],\n",
      "        [ 0.4011],\n",
      "        [ 0.8339],\n",
      "        [ 0.8339],\n",
      "        [-0.9500],\n",
      "        [-0.9500],\n",
      "        [ 0.4011],\n",
      "        [-0.2570],\n",
      "        [ 0.0794],\n",
      "        [ 0.0794],\n",
      "        [ 0.0794],\n",
      "        [ 0.0794],\n",
      "        [-0.2570],\n",
      "        [-0.9500],\n",
      "        [ 0.4011],\n",
      "        [-0.2570],\n",
      "        [ 0.0794],\n",
      "        [ 0.0794],\n",
      "        [ 0.0794],\n",
      "        [ 0.0794],\n",
      "        [ 0.0794],\n",
      "        [ 0.0794],\n",
      "        [ 0.8339],\n",
      "        [-0.9500],\n",
      "        [-0.9500],\n",
      "        [-0.9500],\n",
      "        [-0.9500],\n",
      "        [ 0.4011],\n",
      "        [ 0.4011],\n",
      "        [-0.2570],\n",
      "        [ 0.0794],\n",
      "        [ 0.0794]], dtype=torch.float64)\n",
      "Finished episode 1695 Average rewards:  38.0\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2543701   1.0002341   0.85850745  1.9999993  -0.10485542  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.90486    0.69264126]\n",
      "tensor([[ 0.8666],\n",
      "        [-0.9643],\n",
      "        [-0.9643],\n",
      "        [ 0.3352],\n",
      "        [-0.1794],\n",
      "        [-0.9643],\n",
      "        [-0.9643],\n",
      "        [-0.9643],\n",
      "        [ 0.3352],\n",
      "        [ 0.3352],\n",
      "        [-0.1794],\n",
      "        [ 0.8666],\n",
      "        [-0.9643],\n",
      "        [-0.9643],\n",
      "        [ 0.3352],\n",
      "        [-0.1794],\n",
      "        [-0.9643],\n",
      "        [-0.9643],\n",
      "        [ 0.3352],\n",
      "        [-0.1794],\n",
      "        [-0.1794],\n",
      "        [ 0.8666],\n",
      "        [-0.9643],\n",
      "        [-0.1794],\n",
      "        [ 0.0046],\n",
      "        [ 0.0046],\n",
      "        [ 0.0046],\n",
      "        [ 0.0046],\n",
      "        [ 0.0046],\n",
      "        [ 0.0046],\n",
      "        [ 0.0046],\n",
      "        [-0.1794],\n",
      "        [ 0.0046],\n",
      "        [ 0.0046],\n",
      "        [ 0.0046],\n",
      "        [ 0.0046],\n",
      "        [ 0.0046],\n",
      "        [ 0.0046],\n",
      "        [ 0.0046],\n",
      "        [ 0.0046],\n",
      "        [ 0.0046],\n",
      "        [-0.1794],\n",
      "        [-0.1794],\n",
      "        [-0.1794],\n",
      "        [-0.1794],\n",
      "        [ 0.0046],\n",
      "        [ 0.0046],\n",
      "        [ 0.0046],\n",
      "        [ 0.0046],\n",
      "        [ 0.0046],\n",
      "        [ 0.0046]], dtype=torch.float64)\n",
      "Finished episode 1700 Average rewards:  15.2\n",
      "Monitored episode 50 Average Monitored rewards:  46.46\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2476851   1.0002257   0.84981626  1.9999993  -0.10820017  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9115451  0.68395007]\n",
      "tensor([[ 0.8951],\n",
      "        [-0.9789],\n",
      "        [-0.9789],\n",
      "        [-0.9789],\n",
      "        [ 0.2721],\n",
      "        [ 0.2721],\n",
      "        [ 0.2721],\n",
      "        [ 0.2721],\n",
      "        [ 0.2721],\n",
      "        [-0.1120],\n",
      "        [ 0.8951],\n",
      "        [-0.9789],\n",
      "        [-0.1120],\n",
      "        [-0.0579],\n",
      "        [-0.0579],\n",
      "        [-0.0579],\n",
      "        [-0.0579],\n",
      "        [-0.7318],\n",
      "        [-0.7318],\n",
      "        [-0.7318],\n",
      "        [ 0.8951],\n",
      "        [-0.9789],\n",
      "        [-0.9789],\n",
      "        [-0.9789],\n",
      "        [ 0.2721],\n",
      "        [-0.9789],\n",
      "        [-0.9789],\n",
      "        [-0.9789],\n",
      "        [-0.9789],\n",
      "        [-0.9789],\n",
      "        [ 0.8951],\n",
      "        [-0.9789],\n",
      "        [-0.9789],\n",
      "        [ 0.2721],\n",
      "        [ 0.2721],\n",
      "        [-0.9789],\n",
      "        [-0.9789],\n",
      "        [ 0.2721],\n",
      "        [ 0.2721],\n",
      "        [-0.1120],\n",
      "        [-0.1120],\n",
      "        [-0.9789],\n",
      "        [-0.9789],\n",
      "        [ 0.2721],\n",
      "        [ 0.2721],\n",
      "        [ 0.2721],\n",
      "        [-0.9789],\n",
      "        [-0.9789],\n",
      "        [ 0.2721],\n",
      "        [ 0.2721],\n",
      "        [-0.1120]], dtype=torch.float64)\n",
      "Finished episode 1705 Average rewards:  40.6\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2709917   1.000229    0.8681079   1.9999993  -0.07376772  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88823843 0.7022417 ]\n",
      "tensor([[-0.0920],\n",
      "        [-0.0675],\n",
      "        [-0.7422],\n",
      "        [-0.7422],\n",
      "        [-0.0675],\n",
      "        [-0.0675],\n",
      "        [-0.0675],\n",
      "        [-0.7422],\n",
      "        [-0.0675],\n",
      "        [-0.7422],\n",
      "        [-0.0920],\n",
      "        [-0.0675],\n",
      "        [ 0.8955],\n",
      "        [-0.0675],\n",
      "        [-0.0675],\n",
      "        [-0.0675],\n",
      "        [-0.7422],\n",
      "        [-0.0675],\n",
      "        [-0.0675],\n",
      "        [-0.7422],\n",
      "        [ 0.8955],\n",
      "        [-0.9801],\n",
      "        [-0.9801],\n",
      "        [-0.9801],\n",
      "        [-0.9801],\n",
      "        [-0.9801],\n",
      "        [-0.9801],\n",
      "        [-0.9801],\n",
      "        [-0.9801],\n",
      "        [-0.9801],\n",
      "        [ 0.8955],\n",
      "        [-0.9801],\n",
      "        [-0.0920],\n",
      "        [-0.0920],\n",
      "        [-0.9801],\n",
      "        [-0.9801],\n",
      "        [-0.0675],\n",
      "        [-0.0675],\n",
      "        [-0.7422],\n",
      "        [-0.0675],\n",
      "        [-0.0920],\n",
      "        [-0.9801],\n",
      "        [-0.9801],\n",
      "        [ 0.2444],\n",
      "        [ 0.2444],\n",
      "        [ 0.2444],\n",
      "        [-0.0675],\n",
      "        [-0.0675],\n",
      "        [-0.0675],\n",
      "        [ 0.8955]], dtype=torch.float64)\n",
      "Finished episode 1710 Average rewards:  39.0\n",
      "Monitored episode 50 Average Monitored rewards:  26.52\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2662764   1.000224    0.86971444  1.9999993  -0.08324628  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8929538  0.70384824]\n",
      "tensor([[-0.2131],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [-0.6570],\n",
      "        [-0.6570],\n",
      "        [-0.9686],\n",
      "        [-0.9686],\n",
      "        [-0.2131],\n",
      "        [-0.2131],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [-0.2131],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [-0.2131],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [-0.2131],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309],\n",
      "        [ 0.0309]], dtype=torch.float64)\n",
      "Finished episode 1715 Average rewards:  12.0\n",
      "len_game 52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[ 1.2559861   1.0002154   0.86332214  1.9999993  -0.0949724   1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9032441  0.69745594]\n",
      "tensor([[ 0.8713],\n",
      "        [ 0.8713],\n",
      "        [ 0.0038],\n",
      "        [ 0.0038],\n",
      "        [-0.6779],\n",
      "        [-0.9670],\n",
      "        [-0.9670],\n",
      "        [ 0.3431],\n",
      "        [ 0.3431],\n",
      "        [ 0.3431],\n",
      "        [-0.1837],\n",
      "        [ 0.8713],\n",
      "        [-0.9670],\n",
      "        [-0.9670],\n",
      "        [-0.9670],\n",
      "        [-0.9670],\n",
      "        [ 0.3431],\n",
      "        [ 0.3431],\n",
      "        [ 0.3431],\n",
      "        [ 0.3431],\n",
      "        [ 0.3431],\n",
      "        [ 0.8713],\n",
      "        [ 0.8713],\n",
      "        [-0.9670],\n",
      "        [-0.9670],\n",
      "        [ 0.3431],\n",
      "        [-0.9670],\n",
      "        [ 0.3431],\n",
      "        [ 0.3431],\n",
      "        [ 0.3431],\n",
      "        [ 0.3431],\n",
      "        [-0.1837],\n",
      "        [ 0.8713],\n",
      "        [-0.9670],\n",
      "        [-0.9670],\n",
      "        [ 0.3431],\n",
      "        [-0.9670],\n",
      "        [-0.9670],\n",
      "        [ 0.3431],\n",
      "        [-0.9670],\n",
      "        [-0.1837],\n",
      "        [ 0.0038],\n",
      "        [ 0.8713],\n",
      "        [ 0.0038],\n",
      "        [ 0.0038],\n",
      "        [ 0.0038],\n",
      "        [ 0.0038],\n",
      "        [ 0.0038],\n",
      "        [ 0.0038],\n",
      "        [ 0.0038],\n",
      "        [ 0.0038],\n",
      "        [ 0.0038]], dtype=torch.float64)\n",
      "Finished episode 1720 Average rewards:  17.6\n",
      "Monitored episode 50 Average Monitored rewards:  47.1\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.276501    1.0002185   0.8843982   1.9999993  -0.05505008  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8827292 0.718532 ]\n",
      "tensor([[ 0.8799],\n",
      "        [-0.9710],\n",
      "        [-0.9710],\n",
      "        [-0.9710],\n",
      "        [ 0.2946],\n",
      "        [ 0.2946],\n",
      "        [ 0.2946],\n",
      "        [ 0.2946],\n",
      "        [ 0.2946],\n",
      "        [-0.9710],\n",
      "        [-0.1388],\n",
      "        [-0.1388],\n",
      "        [-0.0297],\n",
      "        [-0.0297],\n",
      "        [-0.7080],\n",
      "        [ 0.8799],\n",
      "        [ 0.8799],\n",
      "        [-0.9710],\n",
      "        [-0.9710],\n",
      "        [ 0.2946],\n",
      "        [ 0.8799],\n",
      "        [ 0.8799],\n",
      "        [-0.9710],\n",
      "        [-0.1388],\n",
      "        [-0.1388],\n",
      "        [-0.0297],\n",
      "        [-0.0297],\n",
      "        [-0.7080],\n",
      "        [-0.9710],\n",
      "        [-0.1388],\n",
      "        [ 0.8799],\n",
      "        [-0.9710],\n",
      "        [-0.1388],\n",
      "        [-0.9710],\n",
      "        [-0.9710],\n",
      "        [-0.9710],\n",
      "        [-0.9710],\n",
      "        [-0.9710],\n",
      "        [-0.9710],\n",
      "        [ 0.2946],\n",
      "        [-0.1388],\n",
      "        [-0.1388],\n",
      "        [-0.1388],\n",
      "        [-0.1388],\n",
      "        [-0.0297],\n",
      "        [-0.0297],\n",
      "        [-0.7080],\n",
      "        [-0.0297],\n",
      "        [-0.0297],\n",
      "        [-0.0297]], dtype=torch.float64)\n",
      "Finished episode 1725 Average rewards:  62.0\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2674408   1.00021     0.86777735  1.9999993  -0.07777987  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8917894  0.70191115]\n",
      "tensor([[-0.2633],\n",
      "        [-0.9389],\n",
      "        [-0.9389],\n",
      "        [ 0.4070],\n",
      "        [ 0.4070],\n",
      "        [ 0.0842],\n",
      "        [ 0.8242],\n",
      "        [-0.9389],\n",
      "        [-0.9389],\n",
      "        [ 0.4070],\n",
      "        [-0.2633],\n",
      "        [ 0.8242],\n",
      "        [ 0.0842],\n",
      "        [ 0.0842],\n",
      "        [ 0.0842],\n",
      "        [ 0.0842],\n",
      "        [ 0.0842],\n",
      "        [ 0.0842],\n",
      "        [ 0.0842],\n",
      "        [ 0.0842],\n",
      "        [ 0.0842],\n",
      "        [-0.2633],\n",
      "        [ 0.0842],\n",
      "        [ 0.0842],\n",
      "        [ 0.0842],\n",
      "        [ 0.0842],\n",
      "        [ 0.0842],\n",
      "        [ 0.0842],\n",
      "        [ 0.0842],\n",
      "        [ 0.0842],\n",
      "        [ 0.0842],\n",
      "        [-0.2633],\n",
      "        [-0.9389],\n",
      "        [-0.9389],\n",
      "        [-0.9389],\n",
      "        [ 0.4070],\n",
      "        [-0.9389],\n",
      "        [-0.9389],\n",
      "        [-0.9389],\n",
      "        [-0.9389],\n",
      "        [-0.9389],\n",
      "        [-0.2633],\n",
      "        [ 0.0842],\n",
      "        [ 0.0842],\n",
      "        [ 0.0842],\n",
      "        [-0.5990],\n",
      "        [ 0.8242],\n",
      "        [ 0.8242],\n",
      "        [-0.9389],\n",
      "        [-0.9389],\n",
      "        [-0.9389]], dtype=torch.float64)\n",
      "Finished episode 1730 Average rewards:  60.0\n",
      "Monitored episode 50 Average Monitored rewards:  29.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2560617   1.0001996   0.8591339   1.9999993  -0.09924089  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9031685  0.69326764]\n",
      "tensor([[ 0.8668],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [ 0.3545],\n",
      "        [ 0.3545],\n",
      "        [-0.1983],\n",
      "        [-0.1983],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [-0.1983],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [-0.1983],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [ 0.3545],\n",
      "        [ 0.3545],\n",
      "        [-0.1983],\n",
      "        [-0.1983],\n",
      "        [-0.1983],\n",
      "        [ 0.0194],\n",
      "        [-0.1983],\n",
      "        [-0.1983],\n",
      "        [ 0.0194],\n",
      "        [-0.6666],\n",
      "        [ 0.8668],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [-0.1983],\n",
      "        [-0.9679],\n",
      "        [-0.1983],\n",
      "        [-0.1983],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [ 0.0194],\n",
      "        [-0.6666],\n",
      "        [ 0.0194]], dtype=torch.float64)\n",
      "Finished episode 1735 Average rewards:  14.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2653823   1.0001996   0.8716752   1.9999993  -0.07524902  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8938479  0.70580894]\n",
      "tensor([[ 0.8892],\n",
      "        [-0.9772],\n",
      "        [-0.9772],\n",
      "        [-0.1286],\n",
      "        [-0.9772],\n",
      "        [-0.1286],\n",
      "        [-0.0419],\n",
      "        [-0.0419],\n",
      "        [-0.0419],\n",
      "        [-0.0419],\n",
      "        [ 0.8892],\n",
      "        [ 0.8892],\n",
      "        [-0.9772],\n",
      "        [-0.9772],\n",
      "        [-0.9772],\n",
      "        [-0.9772],\n",
      "        [-0.9772],\n",
      "        [-0.9772],\n",
      "        [-0.9772],\n",
      "        [ 0.2873],\n",
      "        [-0.1286],\n",
      "        [-0.9772],\n",
      "        [-0.1286],\n",
      "        [-0.9772],\n",
      "        [-0.1286],\n",
      "        [-0.1286],\n",
      "        [-0.0419],\n",
      "        [ 0.8892],\n",
      "        [-0.9772],\n",
      "        [-0.1286],\n",
      "        [ 0.8892],\n",
      "        [-0.9772],\n",
      "        [-0.9772],\n",
      "        [-0.9772],\n",
      "        [-0.9772],\n",
      "        [-0.9772],\n",
      "        [ 0.2873],\n",
      "        [ 0.2873],\n",
      "        [ 0.2873],\n",
      "        [ 0.2873],\n",
      "        [ 0.8892],\n",
      "        [ 0.8892],\n",
      "        [-0.9772],\n",
      "        [-0.9772],\n",
      "        [-0.9772],\n",
      "        [-0.9772],\n",
      "        [ 0.2873],\n",
      "        [ 0.2873],\n",
      "        [ 0.2873],\n",
      "        [ 0.2873]], dtype=torch.float64)\n",
      "Finished episode 1740 Average rewards:  62.8\n",
      "Monitored episode 50 Average Monitored rewards:  34.22\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.255222    1.0001901   0.8606685   1.9999993  -0.09836107  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9040082 0.6948023]\n",
      "tensor([[-0.2009],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [ 0.3531],\n",
      "        [ 0.3531],\n",
      "        [ 0.3531],\n",
      "        [-0.9597],\n",
      "        [ 0.3531],\n",
      "        [-0.2009],\n",
      "        [ 0.0266],\n",
      "        [ 0.0266],\n",
      "        [ 0.0266],\n",
      "        [ 0.0266],\n",
      "        [ 0.0266],\n",
      "        [-0.6581],\n",
      "        [-0.6581],\n",
      "        [-0.6581],\n",
      "        [-0.6581],\n",
      "        [ 0.8560],\n",
      "        [ 0.8560],\n",
      "        [ 0.0266],\n",
      "        [ 0.0266],\n",
      "        [ 0.0266],\n",
      "        [-0.6581],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [-0.2009],\n",
      "        [-0.9597],\n",
      "        [ 0.3531],\n",
      "        [ 0.3531],\n",
      "        [-0.2009],\n",
      "        [ 0.0266],\n",
      "        [ 0.0266],\n",
      "        [ 0.0266],\n",
      "        [ 0.0266],\n",
      "        [ 0.0266],\n",
      "        [-0.2009],\n",
      "        [-0.2009],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [-0.9597],\n",
      "        [ 0.3531]], dtype=torch.float64)\n",
      "Finished episode 1745 Average rewards:  81.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2726216   1.0001899   0.8715958   1.9999993  -0.07760519  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8866085 0.7057296]\n",
      "tensor([[-0.1293],\n",
      "        [-0.9746],\n",
      "        [-0.0394],\n",
      "        [ 0.8857],\n",
      "        [ 0.8857],\n",
      "        [-0.9746],\n",
      "        [-0.9746],\n",
      "        [-0.9746],\n",
      "        [ 0.2863],\n",
      "        [ 0.2863],\n",
      "        [ 0.8857],\n",
      "        [ 0.8857],\n",
      "        [-0.9746],\n",
      "        [-0.0394],\n",
      "        [-0.0394],\n",
      "        [-0.7168],\n",
      "        [ 0.8857],\n",
      "        [-0.9746],\n",
      "        [-0.9746],\n",
      "        [-0.9746],\n",
      "        [ 0.8857],\n",
      "        [-0.0394],\n",
      "        [-0.0394],\n",
      "        [-0.7168],\n",
      "        [-0.0394],\n",
      "        [-0.7168],\n",
      "        [-0.0394],\n",
      "        [-0.7168],\n",
      "        [-0.0394],\n",
      "        [-0.0394],\n",
      "        [-0.1293],\n",
      "        [-0.0394],\n",
      "        [ 0.8857],\n",
      "        [ 0.8857],\n",
      "        [-0.0394],\n",
      "        [-0.0394],\n",
      "        [-0.0394],\n",
      "        [-0.0394],\n",
      "        [-0.7168],\n",
      "        [-0.0394],\n",
      "        [ 0.8857],\n",
      "        [-0.9746],\n",
      "        [-0.1293],\n",
      "        [-0.9746],\n",
      "        [-0.9746],\n",
      "        [-0.1293],\n",
      "        [-0.9746],\n",
      "        [-0.9746],\n",
      "        [-0.9746],\n",
      "        [ 0.2863]], dtype=torch.float64)\n",
      "Finished episode 1750 Average rewards:  61.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  49.28\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2698306   1.0001876   0.8738937   1.9999993  -0.08261239  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8893995 0.7080275]\n",
      "tensor([[-0.2069],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.8698],\n",
      "        [-0.9668],\n",
      "        [-0.2069],\n",
      "        [-0.9668],\n",
      "        [-0.9668],\n",
      "        [ 0.3678],\n",
      "        [ 0.3678],\n",
      "        [ 0.3678],\n",
      "        [ 0.3678],\n",
      "        [ 0.3678],\n",
      "        [-0.2069],\n",
      "        [-0.2069],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [-0.2069],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [-0.2069],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199],\n",
      "        [ 0.0199]], dtype=torch.float64)\n",
      "Finished episode 1755 Average rewards:  -8.6\n",
      "len_game 52\n",
      "Rot\n",
      "[ 1.260841    1.0001812   0.8675489   1.9999993  -0.09546433  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8983891 0.7016827]\n",
      "tensor([[ 0.8706],\n",
      "        [ 0.8706],\n",
      "        [ 0.8706],\n",
      "        [-0.9637],\n",
      "        [-0.9637],\n",
      "        [-0.9637],\n",
      "        [ 0.3535],\n",
      "        [ 0.3535],\n",
      "        [ 0.3535],\n",
      "        [-0.1909],\n",
      "        [ 0.8706],\n",
      "        [ 0.0056],\n",
      "        [ 0.0056],\n",
      "        [ 0.0056],\n",
      "        [ 0.0056],\n",
      "        [ 0.0056],\n",
      "        [ 0.0056],\n",
      "        [ 0.0056],\n",
      "        [ 0.0056],\n",
      "        [ 0.0056],\n",
      "        [ 0.8706],\n",
      "        [-0.9637],\n",
      "        [-0.9637],\n",
      "        [-0.9637],\n",
      "        [ 0.3535],\n",
      "        [ 0.3535],\n",
      "        [ 0.3535],\n",
      "        [ 0.3535],\n",
      "        [ 0.3535],\n",
      "        [-0.1909],\n",
      "        [ 0.8706],\n",
      "        [ 0.8706],\n",
      "        [ 0.0056],\n",
      "        [ 0.0056],\n",
      "        [ 0.0056],\n",
      "        [ 0.0056],\n",
      "        [ 0.0056],\n",
      "        [ 0.0056],\n",
      "        [ 0.0056],\n",
      "        [ 0.0056],\n",
      "        [ 0.8706],\n",
      "        [-0.9637],\n",
      "        [-0.9637],\n",
      "        [ 0.3535],\n",
      "        [-0.1909],\n",
      "        [-0.9637],\n",
      "        [-0.1909],\n",
      "        [ 0.0056],\n",
      "        [-0.6735],\n",
      "        [ 0.8706],\n",
      "        [ 0.8706],\n",
      "        [ 0.8706]], dtype=torch.float64)\n",
      "Finished episode 1760 Average rewards:  15.2\n",
      "Monitored episode 50 Average Monitored rewards:  55.76\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2710854   1.0001807   0.8757604   1.9999993  -0.07672494  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88814473 0.7098942 ]\n",
      "tensor([[ 0.8834],\n",
      "        [-0.9708],\n",
      "        [-0.9708],\n",
      "        [-0.9708],\n",
      "        [-0.9708],\n",
      "        [ 0.3082],\n",
      "        [-0.9708],\n",
      "        [-0.9708],\n",
      "        [ 0.3082],\n",
      "        [ 0.3082],\n",
      "        [-0.1459],\n",
      "        [-0.9708],\n",
      "        [-0.9708],\n",
      "        [-0.9708],\n",
      "        [-0.9708],\n",
      "        [ 0.3082],\n",
      "        [-0.9708],\n",
      "        [-0.9708],\n",
      "        [-0.9708],\n",
      "        [-0.9708],\n",
      "        [-0.1459],\n",
      "        [-0.1459],\n",
      "        [-0.0311],\n",
      "        [-0.0311],\n",
      "        [-0.0311],\n",
      "        [-0.0311],\n",
      "        [-0.0311],\n",
      "        [-0.7067],\n",
      "        [-0.0311],\n",
      "        [-0.0311],\n",
      "        [ 0.8834],\n",
      "        [-0.9708],\n",
      "        [ 0.3082],\n",
      "        [-0.1459],\n",
      "        [-0.9708],\n",
      "        [-0.1459],\n",
      "        [-0.1459],\n",
      "        [-0.1459],\n",
      "        [-0.1459],\n",
      "        [-0.1459],\n",
      "        [-0.1459],\n",
      "        [-0.1459],\n",
      "        [-0.9708],\n",
      "        [-0.1459],\n",
      "        [-0.0311],\n",
      "        [-0.0311],\n",
      "        [-0.0311],\n",
      "        [-0.0311],\n",
      "        [-0.0311],\n",
      "        [-0.0311]], dtype=torch.float64)\n",
      "Finished episode 1765 Average rewards:  36.6\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2588016   1.0001714   0.86369354  1.9999993  -0.09850677  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.90042853 0.69782734]\n",
      "tensor([[ 0.8616],\n",
      "        [-0.9594],\n",
      "        [ 0.0224],\n",
      "        [ 0.0224],\n",
      "        [ 0.0224],\n",
      "        [ 0.0224],\n",
      "        [ 0.0224],\n",
      "        [ 0.0224],\n",
      "        [ 0.0224],\n",
      "        [ 0.0224],\n",
      "        [ 0.8616],\n",
      "        [-0.9594],\n",
      "        [ 0.0224],\n",
      "        [ 0.0224],\n",
      "        [ 0.0224],\n",
      "        [ 0.0224],\n",
      "        [ 0.0224],\n",
      "        [ 0.0224],\n",
      "        [ 0.0224],\n",
      "        [-0.6585],\n",
      "        [-0.2065],\n",
      "        [ 0.0224],\n",
      "        [ 0.0224],\n",
      "        [ 0.0224],\n",
      "        [-0.6585],\n",
      "        [-0.6585],\n",
      "        [-0.6585],\n",
      "        [-0.9594],\n",
      "        [-0.2065],\n",
      "        [ 0.0224],\n",
      "        [ 0.8616],\n",
      "        [-0.9594],\n",
      "        [-0.9594],\n",
      "        [-0.2065],\n",
      "        [ 0.0224],\n",
      "        [ 0.0224],\n",
      "        [ 0.0224],\n",
      "        [ 0.0224],\n",
      "        [ 0.0224],\n",
      "        [ 0.0224],\n",
      "        [ 0.8616],\n",
      "        [ 0.8616],\n",
      "        [-0.9594],\n",
      "        [-0.9594],\n",
      "        [-0.9594],\n",
      "        [-0.9594],\n",
      "        [ 0.3653],\n",
      "        [ 0.3653],\n",
      "        [ 0.3653],\n",
      "        [ 0.3653]], dtype=torch.float64)\n",
      "Finished episode 1770 Average rewards:  16.6\n",
      "Monitored episode 50 Average Monitored rewards:  57.98\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2889514   1.000172    0.88081956  1.9999994  -0.06127981  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8702788  0.71495336]\n",
      "tensor([[ 0.8883],\n",
      "        [-0.9748],\n",
      "        [-0.1351],\n",
      "        [-0.1351],\n",
      "        [-0.0398],\n",
      "        [-0.0398],\n",
      "        [-0.7156],\n",
      "        [-0.0398],\n",
      "        [-0.7156],\n",
      "        [-0.0398],\n",
      "        [ 0.8883],\n",
      "        [-0.0398],\n",
      "        [ 0.8883],\n",
      "        [-0.9748],\n",
      "        [-0.9748],\n",
      "        [ 0.2969],\n",
      "        [ 0.2969],\n",
      "        [-0.1351],\n",
      "        [-0.0398],\n",
      "        [-0.0398],\n",
      "        [ 0.8883],\n",
      "        [-0.0398],\n",
      "        [-0.0398],\n",
      "        [-0.0398],\n",
      "        [-0.7156],\n",
      "        [-0.7156],\n",
      "        [-0.0398],\n",
      "        [-0.0398],\n",
      "        [-0.0398],\n",
      "        [-0.0398],\n",
      "        [ 0.8883],\n",
      "        [-0.9748],\n",
      "        [-0.9748],\n",
      "        [ 0.2969],\n",
      "        [-0.1351],\n",
      "        [-0.9748],\n",
      "        [-0.0398],\n",
      "        [-0.0398],\n",
      "        [-0.7156],\n",
      "        [-0.0398],\n",
      "        [-0.1351],\n",
      "        [-0.9748],\n",
      "        [-0.9748],\n",
      "        [-0.9748],\n",
      "        [ 0.2969],\n",
      "        [-0.1351],\n",
      "        [-0.0398],\n",
      "        [-0.7156],\n",
      "        [-0.9748],\n",
      "        [-0.9748]], dtype=torch.float64)\n",
      "Finished episode 1775 Average rewards:  17.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2808497   1.0001668   0.8722324   1.9999994  -0.07819005  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.87838036 0.7063662 ]\n",
      "tensor([[ 0.8566],\n",
      "        [ 0.0665],\n",
      "        [ 0.0665],\n",
      "        [ 0.0665],\n",
      "        [ 0.0665],\n",
      "        [ 0.0665],\n",
      "        [ 0.0665],\n",
      "        [ 0.0665],\n",
      "        [ 0.0665],\n",
      "        [ 0.0665],\n",
      "        [-0.2673],\n",
      "        [-0.9554],\n",
      "        [-0.2673],\n",
      "        [ 0.0665],\n",
      "        [ 0.0665],\n",
      "        [ 0.0665],\n",
      "        [ 0.0665],\n",
      "        [ 0.0665],\n",
      "        [ 0.0665],\n",
      "        [ 0.0665],\n",
      "        [-0.2673],\n",
      "        [-0.9554],\n",
      "        [ 0.0665],\n",
      "        [ 0.0665],\n",
      "        [ 0.0665],\n",
      "        [ 0.0665],\n",
      "        [ 0.0665],\n",
      "        [ 0.0665],\n",
      "        [ 0.0665],\n",
      "        [ 0.0665],\n",
      "        [ 0.8566],\n",
      "        [-0.9554],\n",
      "        [-0.9554],\n",
      "        [-0.9554],\n",
      "        [ 0.4244],\n",
      "        [ 0.4244],\n",
      "        [ 0.4244],\n",
      "        [ 0.4244],\n",
      "        [ 0.4244],\n",
      "        [ 0.4244],\n",
      "        [-0.2673],\n",
      "        [-0.9554],\n",
      "        [-0.9554],\n",
      "        [-0.9554],\n",
      "        [ 0.4244],\n",
      "        [ 0.4244],\n",
      "        [ 0.4244],\n",
      "        [ 0.4244],\n",
      "        [ 0.4244],\n",
      "        [ 0.4244]], dtype=torch.float64)\n",
      "Finished episode 1780 Average rewards:  36.4\n",
      "Monitored episode 50 Average Monitored rewards:  28.96\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2702518   1.0001595   0.86384207  1.9999994  -0.10017002  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8889783 0.6979759]\n",
      "tensor([[ 0.8808],\n",
      "        [-0.9701],\n",
      "        [-0.2184],\n",
      "        [-0.2184],\n",
      "        [-0.2184],\n",
      "        [-0.9701],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [-0.2184],\n",
      "        [-0.9701],\n",
      "        [-0.9701],\n",
      "        [-0.9701],\n",
      "        [ 0.3870],\n",
      "        [-0.2184],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.8808],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [ 0.8808],\n",
      "        [-0.9701],\n",
      "        [-0.2184],\n",
      "        [-0.9701],\n",
      "        [-0.9701],\n",
      "        [-0.9701],\n",
      "        [-0.9701],\n",
      "        [-0.9701],\n",
      "        [-0.9701],\n",
      "        [-0.9701],\n",
      "        [-0.2184],\n",
      "        [-0.2184],\n",
      "        [-0.2184],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182],\n",
      "        [-0.6645],\n",
      "        [-0.6645],\n",
      "        [-0.6645],\n",
      "        [ 0.0182],\n",
      "        [ 0.0182]], dtype=torch.float64)\n",
      "Finished episode 1785 Average rewards:  16.6\n",
      "len_game 51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[ 1.270024    1.0001556   0.86710835  1.9999994  -0.08888541  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8892061  0.70124215]\n",
      "tensor([[-0.1508],\n",
      "        [-0.9817],\n",
      "        [-0.1508],\n",
      "        [-0.0446],\n",
      "        [-0.0446],\n",
      "        [-0.7191],\n",
      "        [-0.9817],\n",
      "        [-0.9817],\n",
      "        [-0.9817],\n",
      "        [ 0.3280],\n",
      "        [ 0.9049],\n",
      "        [-0.9817],\n",
      "        [-0.9817],\n",
      "        [-0.1508],\n",
      "        [-0.0446],\n",
      "        [-0.7191],\n",
      "        [-0.9817],\n",
      "        [-0.9817],\n",
      "        [-0.9817],\n",
      "        [ 0.3280],\n",
      "        [ 0.9049],\n",
      "        [ 0.9049],\n",
      "        [-0.9817],\n",
      "        [-0.9817],\n",
      "        [-0.9817],\n",
      "        [-0.9817],\n",
      "        [-0.9817],\n",
      "        [-0.9817],\n",
      "        [ 0.3280],\n",
      "        [ 0.3280],\n",
      "        [-0.1508],\n",
      "        [-0.9817],\n",
      "        [-0.9817],\n",
      "        [-0.9817],\n",
      "        [ 0.3280],\n",
      "        [-0.9817],\n",
      "        [ 0.3280],\n",
      "        [ 0.3280],\n",
      "        [ 0.3280],\n",
      "        [-0.1508],\n",
      "        [-0.1508],\n",
      "        [-0.1508],\n",
      "        [-0.9817],\n",
      "        [-0.9817],\n",
      "        [-0.9817],\n",
      "        [-0.9817],\n",
      "        [-0.9817],\n",
      "        [-0.9817],\n",
      "        [ 0.3280],\n",
      "        [ 0.3280],\n",
      "        [ 0.3280]], dtype=torch.float64)\n",
      "Finished episode 1790 Average rewards:  104.2\n",
      "Monitored episode 50 Average Monitored rewards:  40.96\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2863024   1.0001566   0.88362414  1.9999994  -0.05660686  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8729276  0.71775794]\n",
      "tensor([[-0.1767],\n",
      "        [-0.0123],\n",
      "        [ 0.8868],\n",
      "        [-0.9749],\n",
      "        [-0.9749],\n",
      "        [-0.9749],\n",
      "        [-0.9749],\n",
      "        [-0.9749],\n",
      "        [-0.9749],\n",
      "        [-0.9749],\n",
      "        [ 0.8868],\n",
      "        [-0.9749],\n",
      "        [-0.9749],\n",
      "        [ 0.3446],\n",
      "        [ 0.3446],\n",
      "        [-0.1767],\n",
      "        [-0.0123],\n",
      "        [-0.0123],\n",
      "        [-0.0123],\n",
      "        [-0.0123],\n",
      "        [-0.1767],\n",
      "        [-0.0123],\n",
      "        [-0.0123],\n",
      "        [-0.0123],\n",
      "        [-0.6923],\n",
      "        [-0.0123],\n",
      "        [-0.0123],\n",
      "        [-0.0123],\n",
      "        [-0.0123],\n",
      "        [-0.6923],\n",
      "        [-0.1767],\n",
      "        [-0.0123],\n",
      "        [-0.6923],\n",
      "        [-0.0123],\n",
      "        [-0.0123],\n",
      "        [-0.0123],\n",
      "        [-0.0123],\n",
      "        [-0.0123],\n",
      "        [-0.6923],\n",
      "        [-0.0123],\n",
      "        [ 0.8868],\n",
      "        [ 0.8868],\n",
      "        [ 0.8868],\n",
      "        [-0.9749],\n",
      "        [-0.9749],\n",
      "        [-0.9749],\n",
      "        [-0.9749],\n",
      "        [ 0.3446],\n",
      "        [ 0.3446],\n",
      "        [-0.9749]], dtype=torch.float64)\n",
      "Finished episode 1795 Average rewards:  39.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2772616   1.000152    0.87310815  1.9999994  -0.06772242  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88196856 0.70724195]\n",
      "tensor([[-0.2736],\n",
      "        [ 0.0798],\n",
      "        [ 0.0798],\n",
      "        [ 0.0798],\n",
      "        [ 0.0798],\n",
      "        [ 0.0798],\n",
      "        [ 0.0798],\n",
      "        [ 0.0798],\n",
      "        [ 0.0798],\n",
      "        [ 0.0798],\n",
      "        [-0.2736],\n",
      "        [-0.9479],\n",
      "        [-0.9479],\n",
      "        [ 0.4244],\n",
      "        [ 0.4244],\n",
      "        [-0.9479],\n",
      "        [-0.9479],\n",
      "        [-0.9479],\n",
      "        [-0.9479],\n",
      "        [-0.9479],\n",
      "        [ 0.8419],\n",
      "        [ 0.8419],\n",
      "        [-0.9479],\n",
      "        [-0.2736],\n",
      "        [ 0.0798],\n",
      "        [ 0.0798],\n",
      "        [ 0.0798],\n",
      "        [ 0.0798],\n",
      "        [ 0.0798],\n",
      "        [ 0.0798],\n",
      "        [ 0.8419],\n",
      "        [ 0.8419],\n",
      "        [ 0.8419],\n",
      "        [-0.9479],\n",
      "        [-0.9479],\n",
      "        [-0.9479],\n",
      "        [-0.9479],\n",
      "        [ 0.4244],\n",
      "        [-0.9479],\n",
      "        [-0.9479],\n",
      "        [ 0.8419],\n",
      "        [-0.9479],\n",
      "        [-0.9479],\n",
      "        [-0.9479],\n",
      "        [-0.9479],\n",
      "        [ 0.4244],\n",
      "        [ 0.4244],\n",
      "        [-0.9479],\n",
      "        [-0.9479],\n",
      "        [-0.9479]], dtype=torch.float64)\n",
      "Finished episode 1800 Average rewards:  62.8\n",
      "Monitored episode 50 Average Monitored rewards:  23.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2697273   1.0001469   0.86260796  1.9999994  -0.08826309  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8895028  0.69674176]\n",
      "tensor([[-0.2363],\n",
      "        [ 0.0481],\n",
      "        [ 0.0481],\n",
      "        [ 0.0481],\n",
      "        [ 0.0481],\n",
      "        [-0.6392],\n",
      "        [ 0.8600],\n",
      "        [-0.9639],\n",
      "        [ 0.0481],\n",
      "        [-0.6392],\n",
      "        [-0.2363],\n",
      "        [-0.9639],\n",
      "        [-0.9639],\n",
      "        [ 0.3923],\n",
      "        [ 0.3923],\n",
      "        [-0.9639],\n",
      "        [-0.9639],\n",
      "        [-0.9639],\n",
      "        [-0.9639],\n",
      "        [ 0.3923],\n",
      "        [ 0.8600],\n",
      "        [-0.9639],\n",
      "        [-0.9639],\n",
      "        [ 0.3923],\n",
      "        [ 0.3923],\n",
      "        [-0.2363],\n",
      "        [-0.9639],\n",
      "        [-0.9639],\n",
      "        [ 0.3923],\n",
      "        [ 0.3923],\n",
      "        [ 0.8600],\n",
      "        [-0.9639],\n",
      "        [-0.9639],\n",
      "        [ 0.3923],\n",
      "        [ 0.3923],\n",
      "        [ 0.3923],\n",
      "        [ 0.3923],\n",
      "        [ 0.3923],\n",
      "        [-0.2363],\n",
      "        [-0.9639],\n",
      "        [ 0.8600],\n",
      "        [ 0.8600],\n",
      "        [ 0.0481],\n",
      "        [ 0.0481],\n",
      "        [ 0.0481],\n",
      "        [ 0.0481],\n",
      "        [ 0.0481],\n",
      "        [ 0.0481],\n",
      "        [ 0.0481],\n",
      "        [ 0.0481]], dtype=torch.float64)\n",
      "Finished episode 1805 Average rewards:  81.4\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2756743   1.0001435   0.86624044  1.9999994  -0.06661673  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8835558  0.70037425]\n",
      "tensor([[ 0.8896],\n",
      "        [-0.9796],\n",
      "        [-0.0106],\n",
      "        [-0.9796],\n",
      "        [-0.1777],\n",
      "        [-0.1777],\n",
      "        [-0.9796],\n",
      "        [-0.9796],\n",
      "        [-0.9796],\n",
      "        [-0.9796],\n",
      "        [-0.1777],\n",
      "        [-0.0106],\n",
      "        [-0.6935],\n",
      "        [ 0.8896],\n",
      "        [ 0.8896],\n",
      "        [-0.9796],\n",
      "        [-0.9796],\n",
      "        [ 0.3447],\n",
      "        [-0.1777],\n",
      "        [-0.1777],\n",
      "        [ 0.8896],\n",
      "        [ 0.8896],\n",
      "        [-0.9796],\n",
      "        [-0.9796],\n",
      "        [-0.9796],\n",
      "        [-0.9796],\n",
      "        [-0.9796],\n",
      "        [-0.9796],\n",
      "        [-0.9796],\n",
      "        [-0.9796],\n",
      "        [ 0.8896],\n",
      "        [-0.9796],\n",
      "        [-0.1777],\n",
      "        [-0.0106],\n",
      "        [-0.0106],\n",
      "        [-0.0106],\n",
      "        [-0.0106],\n",
      "        [-0.6935],\n",
      "        [-0.6935],\n",
      "        [-0.6935],\n",
      "        [-0.1777],\n",
      "        [-0.9796],\n",
      "        [-0.1777],\n",
      "        [-0.0106],\n",
      "        [-0.6935],\n",
      "        [-0.9796],\n",
      "        [-0.0106],\n",
      "        [-0.9796],\n",
      "        [-0.9796],\n",
      "        [-0.9796]], dtype=torch.float64)\n",
      "Finished episode 1810 Average rewards:  65.2\n",
      "Monitored episode 50 Average Monitored rewards:  31.38\n",
      "len_game 52\n",
      "Rot\n",
      "[ 1.2666701   1.0001379   0.85987324  1.9999994  -0.08599376  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8925601 0.694007 ]\n",
      "tensor([[-0.2364],\n",
      "        [-0.9715],\n",
      "        [-0.9715],\n",
      "        [-0.9715],\n",
      "        [ 0.3902],\n",
      "        [ 0.3902],\n",
      "        [ 0.3902],\n",
      "        [ 0.3902],\n",
      "        [-0.2364],\n",
      "        [-0.2364],\n",
      "        [-0.2364],\n",
      "        [-0.2364],\n",
      "        [-0.2364],\n",
      "        [-0.9715],\n",
      "        [ 0.0513],\n",
      "        [ 0.0513],\n",
      "        [ 0.0513],\n",
      "        [-0.6412],\n",
      "        [ 0.0513],\n",
      "        [-0.6412],\n",
      "        [ 0.0513],\n",
      "        [ 0.0513],\n",
      "        [-0.2364],\n",
      "        [ 0.0513],\n",
      "        [ 0.0513],\n",
      "        [ 0.0513],\n",
      "        [ 0.0513],\n",
      "        [ 0.0513],\n",
      "        [ 0.0513],\n",
      "        [ 0.0513],\n",
      "        [ 0.0513],\n",
      "        [ 0.0513],\n",
      "        [-0.2364],\n",
      "        [-0.9715],\n",
      "        [-0.2364],\n",
      "        [ 0.0513],\n",
      "        [ 0.0513],\n",
      "        [ 0.0513],\n",
      "        [ 0.0513],\n",
      "        [ 0.0513],\n",
      "        [ 0.0513],\n",
      "        [ 0.0513],\n",
      "        [-0.2364],\n",
      "        [-0.9715],\n",
      "        [-0.2364],\n",
      "        [ 0.0513],\n",
      "        [ 0.0513],\n",
      "        [ 0.0513],\n",
      "        [ 0.0513],\n",
      "        [ 0.0513],\n",
      "        [ 0.0513],\n",
      "        [-0.6412]], dtype=torch.float64)\n",
      "Finished episode 1815 Average rewards:  15.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2836038   1.0001384   0.87600607  1.9999994  -0.05570123  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.87562644 0.7101398 ]\n",
      "tensor([[ 0.8845],\n",
      "        [-0.0041],\n",
      "        [-0.0041],\n",
      "        [-0.0041],\n",
      "        [-0.0041],\n",
      "        [-0.0041],\n",
      "        [-0.0041],\n",
      "        [-0.0041],\n",
      "        [-0.0041],\n",
      "        [-0.6898],\n",
      "        [-0.1780],\n",
      "        [-0.1780],\n",
      "        [-0.0041],\n",
      "        [-0.0041],\n",
      "        [-0.0041],\n",
      "        [-0.6898],\n",
      "        [-0.6898],\n",
      "        [-0.0041],\n",
      "        [-0.6898],\n",
      "        [-0.0041],\n",
      "        [ 0.8845],\n",
      "        [-0.9794],\n",
      "        [-0.9794],\n",
      "        [-0.1780],\n",
      "        [-0.0041],\n",
      "        [-0.0041],\n",
      "        [-0.0041],\n",
      "        [-0.6898],\n",
      "        [-0.0041],\n",
      "        [-0.6898],\n",
      "        [-0.1780],\n",
      "        [-0.9794],\n",
      "        [-0.9794],\n",
      "        [-0.9794],\n",
      "        [-0.9794],\n",
      "        [-0.9794],\n",
      "        [-0.9794],\n",
      "        [-0.9794],\n",
      "        [ 0.3399],\n",
      "        [-0.9794],\n",
      "        [ 0.8845],\n",
      "        [-0.9794],\n",
      "        [-0.9794],\n",
      "        [ 0.3399],\n",
      "        [ 0.3399],\n",
      "        [ 0.3399],\n",
      "        [-0.1780],\n",
      "        [-0.1780],\n",
      "        [-0.0041],\n",
      "        [-0.6898]], dtype=torch.float64)\n",
      "Finished episode 1820 Average rewards:  38.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  28.9\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2747908   1.0001334   0.8681768   1.9999994  -0.07746768  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8844395 0.7023106]\n",
      "tensor([[ 0.8474],\n",
      "        [-0.9591],\n",
      "        [-0.9591],\n",
      "        [-0.9591],\n",
      "        [-0.9591],\n",
      "        [-0.2718],\n",
      "        [-0.2718],\n",
      "        [ 0.0824],\n",
      "        [ 0.0824],\n",
      "        [ 0.0824],\n",
      "        [ 0.8474],\n",
      "        [ 0.8474],\n",
      "        [ 0.8474],\n",
      "        [ 0.8474],\n",
      "        [-0.9591],\n",
      "        [-0.9591],\n",
      "        [ 0.4202],\n",
      "        [-0.2718],\n",
      "        [ 0.0824],\n",
      "        [ 0.0824],\n",
      "        [-0.2718],\n",
      "        [ 0.0824],\n",
      "        [ 0.0824],\n",
      "        [ 0.0824],\n",
      "        [ 0.0824],\n",
      "        [ 0.0824],\n",
      "        [ 0.0824],\n",
      "        [ 0.0824],\n",
      "        [ 0.0824],\n",
      "        [ 0.0824],\n",
      "        [-0.2718],\n",
      "        [-0.9591],\n",
      "        [-0.9591],\n",
      "        [-0.9591],\n",
      "        [-0.9591],\n",
      "        [ 0.4202],\n",
      "        [ 0.4202],\n",
      "        [ 0.4202],\n",
      "        [ 0.4202],\n",
      "        [ 0.4202],\n",
      "        [-0.2718],\n",
      "        [ 0.0824],\n",
      "        [ 0.0824],\n",
      "        [ 0.0824],\n",
      "        [ 0.0824],\n",
      "        [ 0.0824],\n",
      "        [ 0.0824],\n",
      "        [ 0.0824],\n",
      "        [ 0.0824],\n",
      "        [ 0.0824]], dtype=torch.float64)\n",
      "Finished episode 1825 Average rewards:  15.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.259857    1.0001265   0.8631465   1.9999994  -0.09250095  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8993732 0.6972802]\n",
      "tensor([[-0.2106],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [ 0.3734],\n",
      "        [ 0.3734],\n",
      "        [-0.2106],\n",
      "        [ 0.0203],\n",
      "        [-0.6656],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [ 0.8762],\n",
      "        [ 0.8762],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [ 0.3734],\n",
      "        [ 0.3734],\n",
      "        [ 0.3734],\n",
      "        [ 0.3734],\n",
      "        [ 0.8762],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [ 0.3734],\n",
      "        [ 0.3734],\n",
      "        [-0.2106],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [-0.2106],\n",
      "        [-0.9726],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [-0.6656],\n",
      "        [ 0.8762],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [ 0.8762],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [ 0.3734],\n",
      "        [ 0.3734],\n",
      "        [ 0.3734],\n",
      "        [ 0.3734],\n",
      "        [ 0.3734]], dtype=torch.float64)\n",
      "Finished episode 1830 Average rewards:  60.4\n",
      "Monitored episode 50 Average Monitored rewards:  60.1\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2931808   1.0001286   0.8857854   1.9999994  -0.04636112  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.86604947 0.7199192 ]\n",
      "tensor([[-0.1513],\n",
      "        [-0.1513],\n",
      "        [-0.0227],\n",
      "        [-0.7027],\n",
      "        [-0.7027],\n",
      "        [ 0.8818],\n",
      "        [-0.9735],\n",
      "        [-0.0227],\n",
      "        [-0.0227],\n",
      "        [-0.7027],\n",
      "        [-0.1513],\n",
      "        [-0.9735],\n",
      "        [-0.1513],\n",
      "        [-0.9735],\n",
      "        [-0.9735],\n",
      "        [-0.9735],\n",
      "        [ 0.3103],\n",
      "        [-0.0227],\n",
      "        [-0.0227],\n",
      "        [-0.0227],\n",
      "        [-0.1513],\n",
      "        [-0.0227],\n",
      "        [-0.0227],\n",
      "        [-0.7027],\n",
      "        [-0.7027],\n",
      "        [-0.0227],\n",
      "        [-0.0227],\n",
      "        [-0.0227],\n",
      "        [-0.0227],\n",
      "        [-0.7027],\n",
      "        [ 0.8818],\n",
      "        [-0.9735],\n",
      "        [-0.1513],\n",
      "        [-0.0227],\n",
      "        [-0.0227],\n",
      "        [-0.0227],\n",
      "        [-0.0227],\n",
      "        [-0.0227],\n",
      "        [-0.0227],\n",
      "        [-0.0227],\n",
      "        [ 0.8818],\n",
      "        [-0.9735],\n",
      "        [-0.1513],\n",
      "        [-0.0227],\n",
      "        [-0.0227],\n",
      "        [-0.0227],\n",
      "        [-0.0227],\n",
      "        [-0.7027],\n",
      "        [-0.0227],\n",
      "        [-0.0227]], dtype=torch.float64)\n",
      "Finished episode 1835 Average rewards:  -8.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2823936   1.0001242   0.87546474  1.9999994  -0.06251805  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.87683654 0.7095985 ]\n",
      "tensor([[ 0.8326],\n",
      "        [ 0.8326],\n",
      "        [-0.9439],\n",
      "        [-0.9439],\n",
      "        [-0.9439],\n",
      "        [-0.9439],\n",
      "        [-0.9439],\n",
      "        [-0.9439],\n",
      "        [-0.9439],\n",
      "        [-0.9439],\n",
      "        [ 0.8326],\n",
      "        [-0.9439],\n",
      "        [-0.9439],\n",
      "        [-0.9439],\n",
      "        [ 0.4468],\n",
      "        [ 0.4468],\n",
      "        [ 0.1089],\n",
      "        [ 0.1089],\n",
      "        [ 0.1089],\n",
      "        [ 0.1089],\n",
      "        [ 0.8326],\n",
      "        [-0.9439],\n",
      "        [-0.9439],\n",
      "        [-0.9439],\n",
      "        [-0.9439],\n",
      "        [-0.9439],\n",
      "        [ 0.4468],\n",
      "        [-0.9439],\n",
      "        [-0.9439],\n",
      "        [-0.9439],\n",
      "        [ 0.8326],\n",
      "        [ 0.1089],\n",
      "        [ 0.1089],\n",
      "        [ 0.1089],\n",
      "        [ 0.1089],\n",
      "        [ 0.1089],\n",
      "        [ 0.1089],\n",
      "        [ 0.1089],\n",
      "        [ 0.1089],\n",
      "        [ 0.1089],\n",
      "        [-0.3044],\n",
      "        [-0.9439],\n",
      "        [ 0.1089],\n",
      "        [ 0.1089],\n",
      "        [ 0.1089],\n",
      "        [ 0.1089],\n",
      "        [ 0.1089],\n",
      "        [ 0.1089],\n",
      "        [ 0.1089],\n",
      "        [ 0.1089]], dtype=torch.float64)\n",
      "Finished episode 1840 Average rewards:  39.8\n",
      "Monitored episode 50 Average Monitored rewards:  30.16\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2694529  1.0001183  0.8594698  1.9999994 -0.0826255  1.8641111\n",
      "  1.7464267  0.7518858]\n",
      "Enc\n",
      "[0.8897773 0.6936036]\n",
      "tensor([[-0.2553],\n",
      "        [ 0.0629],\n",
      "        [ 0.0629],\n",
      "        [ 0.0629],\n",
      "        [ 0.0629],\n",
      "        [-0.6249],\n",
      "        [-0.6249],\n",
      "        [ 0.8566],\n",
      "        [-0.9617],\n",
      "        [-0.9617],\n",
      "        [ 0.8566],\n",
      "        [-0.9617],\n",
      "        [-0.2553],\n",
      "        [-0.9617],\n",
      "        [ 0.4099],\n",
      "        [-0.9617],\n",
      "        [ 0.4099],\n",
      "        [ 0.4099],\n",
      "        [-0.9617],\n",
      "        [-0.9617],\n",
      "        [-0.2553],\n",
      "        [-0.9617],\n",
      "        [-0.9617],\n",
      "        [-0.9617],\n",
      "        [-0.9617],\n",
      "        [ 0.4099],\n",
      "        [ 0.4099],\n",
      "        [ 0.4099],\n",
      "        [ 0.4099],\n",
      "        [ 0.4099],\n",
      "        [-0.2553],\n",
      "        [-0.9617],\n",
      "        [-0.9617],\n",
      "        [-0.9617],\n",
      "        [-0.9617],\n",
      "        [-0.9617],\n",
      "        [-0.9617],\n",
      "        [-0.9617],\n",
      "        [-0.9617],\n",
      "        [-0.9617],\n",
      "        [-0.2553],\n",
      "        [-0.2553],\n",
      "        [-0.9617],\n",
      "        [-0.9617],\n",
      "        [-0.2553],\n",
      "        [ 0.0629],\n",
      "        [ 0.0629],\n",
      "        [ 0.0629],\n",
      "        [ 0.0629],\n",
      "        [ 0.0629]], dtype=torch.float64)\n",
      "Finished episode 1845 Average rewards:  83.6\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2591288   1.0001137   0.85910213  1.9999994  -0.09604308  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9001014  0.69323593]\n",
      "tensor([[ 0.8839],\n",
      "        [ 0.8839],\n",
      "        [ 0.8839],\n",
      "        [ 0.8839],\n",
      "        [ 0.0056],\n",
      "        [ 0.8839],\n",
      "        [ 0.8839],\n",
      "        [-0.9805],\n",
      "        [-0.9805],\n",
      "        [ 0.3524],\n",
      "        [ 0.8839],\n",
      "        [-0.9805],\n",
      "        [-0.9805],\n",
      "        [-0.9805],\n",
      "        [-0.9805],\n",
      "        [-0.9805],\n",
      "        [-0.9805],\n",
      "        [-0.9805],\n",
      "        [-0.9805],\n",
      "        [ 0.3524],\n",
      "        [ 0.8839],\n",
      "        [-0.9805],\n",
      "        [-0.9805],\n",
      "        [ 0.3524],\n",
      "        [ 0.3524],\n",
      "        [ 0.3524],\n",
      "        [ 0.3524],\n",
      "        [ 0.3524],\n",
      "        [ 0.0056],\n",
      "        [ 0.0056],\n",
      "        [ 0.8839],\n",
      "        [-0.9805],\n",
      "        [-0.9805],\n",
      "        [-0.9805],\n",
      "        [ 0.3524],\n",
      "        [ 0.3524],\n",
      "        [ 0.3524],\n",
      "        [ 0.3524],\n",
      "        [-0.1903],\n",
      "        [ 0.0056],\n",
      "        [ 0.8839],\n",
      "        [-0.9805],\n",
      "        [-0.1903],\n",
      "        [ 0.0056],\n",
      "        [ 0.0056],\n",
      "        [ 0.0056],\n",
      "        [ 0.0056],\n",
      "        [ 0.0056],\n",
      "        [ 0.0056],\n",
      "        [ 0.0056]], dtype=torch.float64)\n",
      "Finished episode 1850 Average rewards:  39.0\n",
      "Monitored episode 50 Average Monitored rewards:  56.18\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2725126   1.0001115   0.8663307   1.9999994  -0.07536229  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8867177 0.7004645]\n",
      "tensor([[-0.1416],\n",
      "        [-0.9784],\n",
      "        [-0.9784],\n",
      "        [-0.9784],\n",
      "        [-0.9784],\n",
      "        [-0.9784],\n",
      "        [-0.9784],\n",
      "        [-0.9784],\n",
      "        [ 0.3021],\n",
      "        [ 0.3021],\n",
      "        [-0.1416],\n",
      "        [-0.9784],\n",
      "        [-0.0328],\n",
      "        [-0.0328],\n",
      "        [ 0.8889],\n",
      "        [ 0.8889],\n",
      "        [-0.9784],\n",
      "        [-0.9784],\n",
      "        [-0.1416],\n",
      "        [-0.0328],\n",
      "        [-0.1416],\n",
      "        [-0.0328],\n",
      "        [-0.9784],\n",
      "        [-0.9784],\n",
      "        [-0.9784],\n",
      "        [-0.9784],\n",
      "        [ 0.3021],\n",
      "        [ 0.3021],\n",
      "        [ 0.3021],\n",
      "        [-0.9784],\n",
      "        [-0.1416],\n",
      "        [-0.0328],\n",
      "        [-0.7125],\n",
      "        [-0.9784],\n",
      "        [-0.9784],\n",
      "        [-0.9784],\n",
      "        [-0.9784],\n",
      "        [-0.9784],\n",
      "        [ 0.3021],\n",
      "        [ 0.3021],\n",
      "        [-0.1416],\n",
      "        [-0.0328],\n",
      "        [-0.7125],\n",
      "        [-0.0328],\n",
      "        [-0.7125],\n",
      "        [-0.9784],\n",
      "        [-0.9784],\n",
      "        [-0.9784],\n",
      "        [-0.9784],\n",
      "        [-0.9784]], dtype=torch.float64)\n",
      "Finished episode 1855 Average rewards:  84.8\n",
      "len_game 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[ 1.2639942   1.0001082   0.86325294  1.9999994  -0.08334476  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8952361  0.69738674]\n",
      "tensor([[-0.2118],\n",
      "        [ 0.0263],\n",
      "        [-0.6618],\n",
      "        [ 0.8718],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [ 0.3708],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [ 0.8718],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [ 0.3708],\n",
      "        [ 0.3708],\n",
      "        [-0.2118],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [ 0.3708],\n",
      "        [ 0.3708],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [ 0.3708],\n",
      "        [-0.2118],\n",
      "        [-0.9726],\n",
      "        [ 0.0263],\n",
      "        [ 0.0263],\n",
      "        [ 0.0263],\n",
      "        [ 0.0263],\n",
      "        [ 0.0263],\n",
      "        [ 0.0263],\n",
      "        [ 0.0263],\n",
      "        [ 0.0263],\n",
      "        [-0.2118],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [ 0.3708],\n",
      "        [ 0.3708],\n",
      "        [-0.9726],\n",
      "        [-0.9726],\n",
      "        [ 0.3708],\n",
      "        [ 0.3708]], dtype=torch.float64)\n",
      "Finished episode 1860 Average rewards:  84.0\n",
      "Monitored episode 50 Average Monitored rewards:  37.38\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2542943   1.0001023   0.8483768   1.9999994  -0.11669344  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.904936   0.68251055]\n",
      "tensor([[-0.1798],\n",
      "        [-0.1798],\n",
      "        [-0.1798],\n",
      "        [-0.9727],\n",
      "        [-0.9727],\n",
      "        [ 0.3368],\n",
      "        [ 0.3368],\n",
      "        [-0.1798],\n",
      "        [ 0.0035],\n",
      "        [ 0.0035],\n",
      "        [-0.1798],\n",
      "        [ 0.0035],\n",
      "        [ 0.0035],\n",
      "        [ 0.0035],\n",
      "        [ 0.0035],\n",
      "        [ 0.0035],\n",
      "        [ 0.0035],\n",
      "        [ 0.0035],\n",
      "        [ 0.0035],\n",
      "        [ 0.0035],\n",
      "        [-0.1798],\n",
      "        [-0.9727],\n",
      "        [-0.9727],\n",
      "        [-0.9727],\n",
      "        [-0.9727],\n",
      "        [ 0.3368],\n",
      "        [ 0.3368],\n",
      "        [ 0.3368],\n",
      "        [ 0.3368],\n",
      "        [ 0.3368],\n",
      "        [ 0.8743],\n",
      "        [ 0.8743],\n",
      "        [ 0.8743],\n",
      "        [ 0.8743],\n",
      "        [-0.9727],\n",
      "        [-0.9727],\n",
      "        [-0.1798],\n",
      "        [-0.9727],\n",
      "        [ 0.0035],\n",
      "        [ 0.0035],\n",
      "        [ 0.8743],\n",
      "        [ 0.8743],\n",
      "        [-0.9727],\n",
      "        [ 0.0035],\n",
      "        [ 0.0035],\n",
      "        [ 0.0035],\n",
      "        [ 0.0035],\n",
      "        [ 0.0035],\n",
      "        [ 0.0035],\n",
      "        [ 0.0035]], dtype=torch.float64)\n",
      "Finished episode 1865 Average rewards:  16.2\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2574627   1.0000993   0.8471489   1.9999994  -0.11418926  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.90176755 0.68128264]\n",
      "tensor([[ 0.9158],\n",
      "        [-0.9904],\n",
      "        [-0.0916],\n",
      "        [-0.0916],\n",
      "        [ 0.9158],\n",
      "        [ 0.9158],\n",
      "        [-0.9904],\n",
      "        [-0.0916],\n",
      "        [ 0.9158],\n",
      "        [-0.9904],\n",
      "        [ 0.9158],\n",
      "        [-0.9904],\n",
      "        [-0.9904],\n",
      "        [-0.0830],\n",
      "        [-0.9904],\n",
      "        [-0.0830],\n",
      "        [-0.0830],\n",
      "        [-0.0830],\n",
      "        [-0.0830],\n",
      "        [-0.0830],\n",
      "        [-0.0830],\n",
      "        [-0.0916],\n",
      "        [-0.0916],\n",
      "        [-0.0916],\n",
      "        [-0.0916],\n",
      "        [-0.0916],\n",
      "        [-0.0916],\n",
      "        [-0.0916],\n",
      "        [-0.0916],\n",
      "        [-0.0916],\n",
      "        [-0.0830],\n",
      "        [-0.9904],\n",
      "        [-0.9904],\n",
      "        [-0.9904],\n",
      "        [-0.9904],\n",
      "        [-0.9904],\n",
      "        [-0.9904],\n",
      "        [-0.9904],\n",
      "        [-0.9904],\n",
      "        [ 0.2503],\n",
      "        [ 0.9158],\n",
      "        [-0.9904],\n",
      "        [-0.9904],\n",
      "        [-0.9904],\n",
      "        [ 0.2503],\n",
      "        [ 0.2503],\n",
      "        [ 0.2503],\n",
      "        [-0.0830],\n",
      "        [-0.9904],\n",
      "        [-0.9904],\n",
      "        [-0.0830]], dtype=torch.float64)\n",
      "Finished episode 1870 Average rewards:  39.6\n",
      "Monitored episode 50 Average Monitored rewards:  46.32\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2888869   1.0001011   0.86840534  1.9999994  -0.07418008  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8703434  0.70253915]\n",
      "tensor([[ 0.9171],\n",
      "        [-0.9922],\n",
      "        [-0.9922],\n",
      "        [ 0.2653],\n",
      "        [-0.0949],\n",
      "        [-0.0845],\n",
      "        [-0.0845],\n",
      "        [-0.0845],\n",
      "        [-0.0845],\n",
      "        [-0.0845],\n",
      "        [ 0.9171],\n",
      "        [-0.9922],\n",
      "        [-0.0949],\n",
      "        [-0.0949],\n",
      "        [-0.9922],\n",
      "        [-0.0949],\n",
      "        [-0.0949],\n",
      "        [-0.0949],\n",
      "        [-0.0845],\n",
      "        [-0.0845],\n",
      "        [ 0.9171],\n",
      "        [-0.0845],\n",
      "        [-0.0845],\n",
      "        [-0.0845],\n",
      "        [-0.0845],\n",
      "        [-0.7554],\n",
      "        [-0.0845],\n",
      "        [-0.7554],\n",
      "        [-0.7554],\n",
      "        [-0.7554],\n",
      "        [-0.0949],\n",
      "        [-0.0845],\n",
      "        [-0.0845],\n",
      "        [-0.0845],\n",
      "        [-0.0845],\n",
      "        [-0.0845],\n",
      "        [-0.0845],\n",
      "        [-0.7554],\n",
      "        [-0.0845],\n",
      "        [-0.0845],\n",
      "        [ 0.9171],\n",
      "        [-0.0845],\n",
      "        [ 0.9171],\n",
      "        [-0.0845],\n",
      "        [-0.0845],\n",
      "        [-0.0845],\n",
      "        [-0.7554],\n",
      "        [-0.9922],\n",
      "        [-0.9922],\n",
      "        [ 0.2653],\n",
      "        [-0.0949]], dtype=torch.float64)\n",
      "Finished episode 1875 Average rewards:  -6.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2786714   1.0000981   0.870611    1.9999994  -0.07767989  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8805589 0.7047448]\n",
      "tensor([[ 0.8899],\n",
      "        [-0.9765],\n",
      "        [-0.2395],\n",
      "        [-0.9765],\n",
      "        [-0.9765],\n",
      "        [-0.9765],\n",
      "        [-0.9765],\n",
      "        [-0.9765],\n",
      "        [ 0.4101],\n",
      "        [-0.9765],\n",
      "        [-0.2395],\n",
      "        [-0.9765],\n",
      "        [ 0.0297],\n",
      "        [ 0.0297],\n",
      "        [ 0.0297],\n",
      "        [ 0.0297],\n",
      "        [-0.6578],\n",
      "        [-0.6578],\n",
      "        [-0.9765],\n",
      "        [-0.2395],\n",
      "        [-0.2395],\n",
      "        [ 0.0297],\n",
      "        [ 0.0297],\n",
      "        [ 0.0297],\n",
      "        [ 0.0297],\n",
      "        [ 0.0297],\n",
      "        [ 0.0297],\n",
      "        [ 0.0297],\n",
      "        [ 0.0297],\n",
      "        [ 0.0297],\n",
      "        [-0.2395],\n",
      "        [-0.2395],\n",
      "        [ 0.0297],\n",
      "        [ 0.0297],\n",
      "        [ 0.0297],\n",
      "        [ 0.0297],\n",
      "        [ 0.0297],\n",
      "        [ 0.0297],\n",
      "        [ 0.0297],\n",
      "        [-0.6578],\n",
      "        [-0.2395],\n",
      "        [ 0.0297],\n",
      "        [ 0.0297],\n",
      "        [ 0.0297],\n",
      "        [-0.6578],\n",
      "        [-0.6578],\n",
      "        [-0.9765],\n",
      "        [-0.2395],\n",
      "        [ 0.0297],\n",
      "        [ 0.0297]], dtype=torch.float64)\n",
      "Finished episode 1880 Average rewards:  36.4\n",
      "Monitored episode 50 Average Monitored rewards:  35.9\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2652605   1.0000939   0.8672888   1.9999994  -0.08506319  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8939697  0.70142263]\n",
      "tensor([[-0.2161],\n",
      "        [-0.9714],\n",
      "        [-0.2161],\n",
      "        [-0.2161],\n",
      "        [-0.2161],\n",
      "        [-0.2161],\n",
      "        [ 0.0197],\n",
      "        [ 0.0197],\n",
      "        [ 0.0197],\n",
      "        [-0.6645],\n",
      "        [ 0.8791],\n",
      "        [-0.9714],\n",
      "        [-0.9714],\n",
      "        [-0.9714],\n",
      "        [-0.9714],\n",
      "        [-0.9714],\n",
      "        [-0.9714],\n",
      "        [-0.9714],\n",
      "        [-0.9714],\n",
      "        [-0.9714],\n",
      "        [ 0.8791],\n",
      "        [-0.9714],\n",
      "        [-0.9714],\n",
      "        [-0.9714],\n",
      "        [ 0.3825],\n",
      "        [ 0.3825],\n",
      "        [ 0.3825],\n",
      "        [ 0.3825],\n",
      "        [ 0.3825],\n",
      "        [-0.9714],\n",
      "        [-0.2161],\n",
      "        [ 0.0197],\n",
      "        [-0.6645],\n",
      "        [ 0.8791],\n",
      "        [-0.9714],\n",
      "        [-0.2161],\n",
      "        [-0.9714],\n",
      "        [-0.9714],\n",
      "        [-0.9714],\n",
      "        [ 0.3825],\n",
      "        [-0.2161],\n",
      "        [-0.9714],\n",
      "        [-0.9714],\n",
      "        [ 0.3825],\n",
      "        [ 0.3825],\n",
      "        [-0.2161],\n",
      "        [ 0.0197],\n",
      "        [ 0.0197],\n",
      "        [ 0.0197],\n",
      "        [ 0.0197]], dtype=torch.float64)\n",
      "Finished episode 1885 Average rewards:  62.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.262779    1.0000921   0.8673986   1.9999994  -0.07823936  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.89645123 0.7015324 ]\n",
      "tensor([[ 0.8749],\n",
      "        [-0.9700],\n",
      "        [-0.9700],\n",
      "        [-0.9700],\n",
      "        [ 0.3375],\n",
      "        [ 0.3375],\n",
      "        [ 0.3375],\n",
      "        [ 0.3375],\n",
      "        [ 0.3375],\n",
      "        [-0.1778],\n",
      "        [-0.1778],\n",
      "        [-0.0014],\n",
      "        [-0.6836],\n",
      "        [-0.9700],\n",
      "        [-0.9700],\n",
      "        [-0.9700],\n",
      "        [-0.9700],\n",
      "        [-0.9700],\n",
      "        [-0.9700],\n",
      "        [-0.9700],\n",
      "        [-0.1778],\n",
      "        [-0.9700],\n",
      "        [-0.9700],\n",
      "        [-0.9700],\n",
      "        [-0.9700],\n",
      "        [-0.9700],\n",
      "        [-0.9700],\n",
      "        [-0.9700],\n",
      "        [-0.9700],\n",
      "        [ 0.3375],\n",
      "        [ 0.8749],\n",
      "        [-0.0014],\n",
      "        [ 0.8749],\n",
      "        [-0.9700],\n",
      "        [-0.9700],\n",
      "        [-0.9700],\n",
      "        [-0.9700],\n",
      "        [-0.9700],\n",
      "        [-0.9700],\n",
      "        [-0.9700],\n",
      "        [ 0.8749],\n",
      "        [-0.9700],\n",
      "        [-0.9700],\n",
      "        [-0.9700],\n",
      "        [-0.9700],\n",
      "        [-0.9700],\n",
      "        [-0.9700],\n",
      "        [-0.9700],\n",
      "        [-0.9700],\n",
      "        [ 0.3375]], dtype=torch.float64)\n",
      "Finished episode 1890 Average rewards:  108.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  33.86\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.250557    1.0000862   0.8529994   1.9999994  -0.11262225  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9086733 0.6871332]\n",
      "tensor([[-0.1898],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [-0.1898],\n",
      "        [-0.1898],\n",
      "        [-0.9642],\n",
      "        [-0.9642],\n",
      "        [ 0.3417],\n",
      "        [-0.1898],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.8612],\n",
      "        [ 0.8612],\n",
      "        [-0.9642],\n",
      "        [-0.9642],\n",
      "        [-0.9642],\n",
      "        [-0.1898],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [-0.1898],\n",
      "        [-0.1898],\n",
      "        [-0.9642],\n",
      "        [-0.1898],\n",
      "        [ 0.0181],\n",
      "        [-0.6679],\n",
      "        [ 0.8612],\n",
      "        [ 0.8612],\n",
      "        [-0.9642],\n",
      "        [ 0.0181],\n",
      "        [ 0.8612],\n",
      "        [-0.9642],\n",
      "        [-0.9642],\n",
      "        [-0.1898],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181],\n",
      "        [ 0.0181]], dtype=torch.float64)\n",
      "Finished episode 1895 Average rewards:  -4.6\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2585876   1.0000863   0.8605685   1.9999994  -0.09635482  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.90064263 0.6947023 ]\n",
      "tensor([[ 0.9038],\n",
      "        [ 0.9038],\n",
      "        [-0.9833],\n",
      "        [-0.9833],\n",
      "        [ 0.2454],\n",
      "        [-0.9833],\n",
      "        [-0.9833],\n",
      "        [ 0.2454],\n",
      "        [ 0.2454],\n",
      "        [ 0.2454],\n",
      "        [-0.0862],\n",
      "        [-0.0800],\n",
      "        [-0.0800],\n",
      "        [-0.0800],\n",
      "        [-0.0800],\n",
      "        [-0.0800],\n",
      "        [-0.0800],\n",
      "        [-0.0800],\n",
      "        [-0.0800],\n",
      "        [-0.7504],\n",
      "        [ 0.9038],\n",
      "        [-0.0800],\n",
      "        [-0.0800],\n",
      "        [-0.0800],\n",
      "        [-0.7504],\n",
      "        [-0.0800],\n",
      "        [-0.0800],\n",
      "        [-0.0800],\n",
      "        [-0.7504],\n",
      "        [-0.7504],\n",
      "        [-0.0862],\n",
      "        [-0.0862],\n",
      "        [-0.0800],\n",
      "        [-0.7504],\n",
      "        [ 0.9038],\n",
      "        [ 0.9038],\n",
      "        [-0.0800],\n",
      "        [-0.0800],\n",
      "        [-0.0800],\n",
      "        [-0.0800],\n",
      "        [-0.0862],\n",
      "        [-0.9833],\n",
      "        [-0.9833],\n",
      "        [-0.9833],\n",
      "        [-0.9833],\n",
      "        [ 0.2454],\n",
      "        [ 0.2454],\n",
      "        [-0.9833],\n",
      "        [ 0.2454],\n",
      "        [-0.0862]], dtype=torch.float64)\n",
      "Finished episode 1900 Average rewards:  35.8\n",
      "Monitored episode 50 Average Monitored rewards:  52.06\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2641561   1.0000846   0.86541075  1.9999994  -0.07885513  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8950741  0.69954455]\n",
      "tensor([[-0.1399],\n",
      "        [-0.0337],\n",
      "        [-0.0337],\n",
      "        [-0.0337],\n",
      "        [-0.0337],\n",
      "        [-0.7125],\n",
      "        [-0.0337],\n",
      "        [-0.0337],\n",
      "        [-0.7125],\n",
      "        [-0.7125],\n",
      "        [-0.1399],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [ 0.3000],\n",
      "        [-0.1399],\n",
      "        [-0.0337],\n",
      "        [-0.0337],\n",
      "        [-0.0337],\n",
      "        [-0.0337],\n",
      "        [-0.1399],\n",
      "        [-0.0337],\n",
      "        [-0.7125],\n",
      "        [-0.7125],\n",
      "        [-0.7125],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [ 0.8875],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [-0.1399],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [ 0.3000],\n",
      "        [-0.1399],\n",
      "        [-0.9768],\n",
      "        [-0.1399],\n",
      "        [-0.9768],\n",
      "        [-0.1399],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [-0.9768],\n",
      "        [ 0.3000],\n",
      "        [ 0.3000]], dtype=torch.float64)\n",
      "Finished episode 1905 Average rewards:  61.0\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2549565   1.0000803   0.85327905  1.9999994  -0.11135561  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.90427375 0.68741286]\n",
      "tensor([[ 0.8660],\n",
      "        [-0.9682],\n",
      "        [ 0.0163],\n",
      "        [ 0.0163],\n",
      "        [ 0.0163],\n",
      "        [ 0.0163],\n",
      "        [ 0.0163],\n",
      "        [ 0.0163],\n",
      "        [ 0.0163],\n",
      "        [ 0.0163],\n",
      "        [ 0.8660],\n",
      "        [-0.9682],\n",
      "        [-0.9682],\n",
      "        [ 0.3443],\n",
      "        [ 0.3443],\n",
      "        [ 0.3443],\n",
      "        [ 0.3443],\n",
      "        [ 0.3443],\n",
      "        [ 0.0163],\n",
      "        [ 0.0163],\n",
      "        [ 0.8660],\n",
      "        [ 0.0163],\n",
      "        [ 0.0163],\n",
      "        [ 0.0163],\n",
      "        [ 0.0163],\n",
      "        [ 0.0163],\n",
      "        [ 0.0163],\n",
      "        [ 0.0163],\n",
      "        [ 0.0163],\n",
      "        [ 0.0163],\n",
      "        [ 0.8660],\n",
      "        [-0.9682],\n",
      "        [-0.9682],\n",
      "        [ 0.3443],\n",
      "        [ 0.3443],\n",
      "        [ 0.3443],\n",
      "        [ 0.0163],\n",
      "        [ 0.0163],\n",
      "        [ 0.0163],\n",
      "        [ 0.0163],\n",
      "        [-0.1906],\n",
      "        [-0.9682],\n",
      "        [-0.9682],\n",
      "        [-0.9682],\n",
      "        [ 0.3443],\n",
      "        [ 0.3443],\n",
      "        [-0.9682],\n",
      "        [-0.9682],\n",
      "        [-0.9682],\n",
      "        [-0.9682]], dtype=torch.float64)\n",
      "Finished episode 1910 Average rewards:  17.2\n",
      "Monitored episode 50 Average Monitored rewards:  61.64\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.274246    1.0000794   0.861379    1.9999994  -0.08980484  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8849843  0.69551283]\n",
      "tensor([[ 0.9076],\n",
      "        [-0.9861],\n",
      "        [-0.9861],\n",
      "        [-0.9861],\n",
      "        [-0.9861],\n",
      "        [ 0.2622],\n",
      "        [ 0.2622],\n",
      "        [-0.0972],\n",
      "        [-0.0764],\n",
      "        [-0.0764],\n",
      "        [ 0.9076],\n",
      "        [ 0.9076],\n",
      "        [-0.9861],\n",
      "        [-0.0972],\n",
      "        [-0.0764],\n",
      "        [-0.0764],\n",
      "        [-0.0764],\n",
      "        [-0.0764],\n",
      "        [-0.0764],\n",
      "        [-0.0764],\n",
      "        [ 0.9076],\n",
      "        [ 0.9076],\n",
      "        [-0.9861],\n",
      "        [-0.0972],\n",
      "        [-0.0972],\n",
      "        [-0.9861],\n",
      "        [-0.9861],\n",
      "        [-0.9861],\n",
      "        [-0.9861],\n",
      "        [-0.9861],\n",
      "        [ 0.9076],\n",
      "        [ 0.9076],\n",
      "        [ 0.9076],\n",
      "        [-0.0764],\n",
      "        [-0.0764],\n",
      "        [-0.0764],\n",
      "        [-0.0764],\n",
      "        [-0.0764],\n",
      "        [-0.7477],\n",
      "        [-0.0764],\n",
      "        [ 0.9076],\n",
      "        [-0.0764],\n",
      "        [ 0.9076],\n",
      "        [ 0.9076],\n",
      "        [-0.9861],\n",
      "        [-0.9861],\n",
      "        [-0.9861],\n",
      "        [-0.9861],\n",
      "        [-0.9861],\n",
      "        [-0.9861]], dtype=torch.float64)\n",
      "Finished episode 1915 Average rewards:  38.2\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2924467   1.0000788   0.87604153  1.9999994  -0.05670986  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8667836  0.71017534]\n",
      "tensor([[-0.1815],\n",
      "        [-0.0150],\n",
      "        [ 0.8986],\n",
      "        [-0.9835],\n",
      "        [-0.1815],\n",
      "        [-0.0150],\n",
      "        [-0.6976],\n",
      "        [-0.0150],\n",
      "        [-0.0150],\n",
      "        [-0.6976],\n",
      "        [-0.1815],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [ 0.3546],\n",
      "        [ 0.3546],\n",
      "        [ 0.3546],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [ 0.8986],\n",
      "        [ 0.8986],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [-0.0150],\n",
      "        [-0.9835],\n",
      "        [-0.0150],\n",
      "        [-0.0150],\n",
      "        [ 0.8986],\n",
      "        [ 0.8986],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [ 0.3546],\n",
      "        [ 0.3546],\n",
      "        [ 0.3546],\n",
      "        [ 0.3546],\n",
      "        [-0.1815],\n",
      "        [-0.0150],\n",
      "        [ 0.8986],\n",
      "        [-0.9835],\n",
      "        [-0.9835],\n",
      "        [ 0.3546],\n",
      "        [ 0.3546],\n",
      "        [ 0.3546],\n",
      "        [-0.1815],\n",
      "        [-0.0150],\n",
      "        [-0.6976],\n",
      "        [-0.0150]], dtype=torch.float64)\n",
      "Finished episode 1920 Average rewards:  18.6\n",
      "Monitored episode 50 Average Monitored rewards:  29.66\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2837179   1.000077    0.87965     1.9999994  -0.05866712  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.87551236 0.7137838 ]\n",
      "tensor([[ 0.8613],\n",
      "        [-0.9636],\n",
      "        [-0.9636],\n",
      "        [-0.9636],\n",
      "        [-0.9636],\n",
      "        [-0.9636],\n",
      "        [-0.9636],\n",
      "        [-0.9636],\n",
      "        [ 0.4356],\n",
      "        [ 0.4356],\n",
      "        [-0.2819],\n",
      "        [-0.2819],\n",
      "        [ 0.0795],\n",
      "        [ 0.0795],\n",
      "        [-0.6103],\n",
      "        [ 0.0795],\n",
      "        [ 0.0795],\n",
      "        [ 0.0795],\n",
      "        [ 0.0795],\n",
      "        [ 0.0795],\n",
      "        [ 0.8613],\n",
      "        [ 0.8613],\n",
      "        [-0.9636],\n",
      "        [-0.2819],\n",
      "        [ 0.0795],\n",
      "        [ 0.0795],\n",
      "        [-0.6103],\n",
      "        [-0.6103],\n",
      "        [-0.9636],\n",
      "        [-0.2819],\n",
      "        [ 0.8613],\n",
      "        [ 0.8613],\n",
      "        [-0.9636],\n",
      "        [-0.9636],\n",
      "        [-0.9636],\n",
      "        [ 0.4356],\n",
      "        [ 0.4356],\n",
      "        [ 0.4356],\n",
      "        [ 0.4356],\n",
      "        [ 0.4356],\n",
      "        [-0.2819],\n",
      "        [-0.9636],\n",
      "        [-0.9636],\n",
      "        [-0.9636],\n",
      "        [-0.9636],\n",
      "        [-0.9636],\n",
      "        [-0.9636],\n",
      "        [-0.9636],\n",
      "        [-0.9636],\n",
      "        [-0.9636]], dtype=torch.float64)\n",
      "Finished episode 1925 Average rewards:  63.8\n",
      "len_game 52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[ 1.277828    1.0000758   0.88137716  1.9999994  -0.06060607  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88140225 0.71551096]\n",
      "tensor([[ 0.8472],\n",
      "        [ 0.8472],\n",
      "        [-0.9543],\n",
      "        [-0.9543],\n",
      "        [-0.9543],\n",
      "        [-0.9543],\n",
      "        [-0.9543],\n",
      "        [ 0.4171],\n",
      "        [ 0.4171],\n",
      "        [ 0.4171],\n",
      "        [-0.2655],\n",
      "        [ 0.0739],\n",
      "        [ 0.0739],\n",
      "        [ 0.0739],\n",
      "        [ 0.0739],\n",
      "        [ 0.0739],\n",
      "        [-0.6122],\n",
      "        [-0.6122],\n",
      "        [-0.6122],\n",
      "        [-0.6122],\n",
      "        [ 0.8472],\n",
      "        [-0.2655],\n",
      "        [-0.9543],\n",
      "        [-0.9543],\n",
      "        [-0.9543],\n",
      "        [ 0.4171],\n",
      "        [-0.9543],\n",
      "        [-0.9543],\n",
      "        [-0.9543],\n",
      "        [-0.9543],\n",
      "        [ 0.4171],\n",
      "        [-0.2655],\n",
      "        [-0.9543],\n",
      "        [-0.9543],\n",
      "        [-0.9543],\n",
      "        [ 0.4171],\n",
      "        [ 0.4171],\n",
      "        [ 0.4171],\n",
      "        [-0.2655],\n",
      "        [-0.9543],\n",
      "        [ 0.4171],\n",
      "        [-0.2655],\n",
      "        [-0.2655],\n",
      "        [ 0.0739],\n",
      "        [ 0.0739],\n",
      "        [ 0.0739],\n",
      "        [ 0.0739],\n",
      "        [ 0.0739],\n",
      "        [ 0.0739],\n",
      "        [ 0.0739],\n",
      "        [ 0.0739],\n",
      "        [ 0.0739]], dtype=torch.float64)\n",
      "Finished episode 1930 Average rewards:  61.4\n",
      "Monitored episode 50 Average Monitored rewards:  45.08\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2630112   1.0000716   0.8670086   1.9999994  -0.08454179  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8962191  0.70114243]\n",
      "tensor([[ 0.8393],\n",
      "        [ 0.8393],\n",
      "        [-0.9481],\n",
      "        [-0.2529],\n",
      "        [-0.9481],\n",
      "        [-0.9481],\n",
      "        [-0.9481],\n",
      "        [ 0.4027],\n",
      "        [-0.9481],\n",
      "        [-0.9481],\n",
      "        [ 0.8393],\n",
      "        [-0.9481],\n",
      "        [-0.9481],\n",
      "        [-0.2529],\n",
      "        [ 0.0684],\n",
      "        [ 0.8393],\n",
      "        [ 0.0684],\n",
      "        [ 0.0684],\n",
      "        [ 0.0684],\n",
      "        [ 0.0684],\n",
      "        [ 0.8393],\n",
      "        [ 0.8393],\n",
      "        [ 0.8393],\n",
      "        [-0.9481],\n",
      "        [-0.9481],\n",
      "        [-0.9481],\n",
      "        [ 0.4027],\n",
      "        [ 0.4027],\n",
      "        [ 0.4027],\n",
      "        [ 0.4027],\n",
      "        [-0.2529],\n",
      "        [ 0.8393],\n",
      "        [-0.9481],\n",
      "        [ 0.0684],\n",
      "        [ 0.0684],\n",
      "        [ 0.0684],\n",
      "        [-0.6154],\n",
      "        [ 0.8393],\n",
      "        [-0.9481],\n",
      "        [-0.2529],\n",
      "        [-0.9481],\n",
      "        [ 0.8393],\n",
      "        [-0.9481],\n",
      "        [-0.9481],\n",
      "        [-0.2529],\n",
      "        [ 0.0684],\n",
      "        [ 0.0684],\n",
      "        [ 0.0684],\n",
      "        [ 0.0684],\n",
      "        [ 0.0684],\n",
      "        [ 0.0684]], dtype=torch.float64)\n",
      "Finished episode 1935 Average rewards:  59.8\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2584733   1.0000705   0.8670933   1.9999994  -0.08845029  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.90075696 0.7012271 ]\n",
      "tensor([[-1.7540e-01],\n",
      "        [ 7.7383e-05],\n",
      "        [ 7.7383e-05],\n",
      "        [ 7.7383e-05],\n",
      "        [ 7.7383e-05],\n",
      "        [ 7.7383e-05],\n",
      "        [ 7.7383e-05],\n",
      "        [ 7.7383e-05],\n",
      "        [-6.8257e-01],\n",
      "        [-6.8257e-01],\n",
      "        [ 8.7129e-01],\n",
      "        [-9.6820e-01],\n",
      "        [-9.6820e-01],\n",
      "        [-9.6820e-01],\n",
      "        [ 3.3224e-01],\n",
      "        [ 3.3224e-01],\n",
      "        [ 3.3224e-01],\n",
      "        [-9.6820e-01],\n",
      "        [-9.6820e-01],\n",
      "        [-9.6820e-01],\n",
      "        [-1.7540e-01],\n",
      "        [-9.6820e-01],\n",
      "        [-9.6820e-01],\n",
      "        [ 7.7383e-05],\n",
      "        [ 8.7129e-01],\n",
      "        [-9.6820e-01],\n",
      "        [-9.6820e-01],\n",
      "        [-9.6820e-01],\n",
      "        [ 3.3224e-01],\n",
      "        [ 3.3224e-01],\n",
      "        [ 8.7129e-01],\n",
      "        [ 7.7383e-05],\n",
      "        [ 7.7383e-05],\n",
      "        [ 7.7383e-05],\n",
      "        [ 7.7383e-05],\n",
      "        [ 7.7383e-05],\n",
      "        [ 7.7383e-05],\n",
      "        [ 7.7383e-05],\n",
      "        [ 7.7383e-05],\n",
      "        [ 7.7383e-05],\n",
      "        [-1.7540e-01],\n",
      "        [ 7.7383e-05],\n",
      "        [ 7.7383e-05],\n",
      "        [ 7.7383e-05],\n",
      "        [ 7.7383e-05],\n",
      "        [ 7.7383e-05],\n",
      "        [ 7.7383e-05],\n",
      "        [ 7.7383e-05],\n",
      "        [ 7.7383e-05],\n",
      "        [ 7.7383e-05]], dtype=torch.float64)\n",
      "Finished episode 1940 Average rewards:  38.6\n",
      "Monitored episode 50 Average Monitored rewards:  45.24\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2640989   1.0000691   0.8618331   1.9999994  -0.08884423  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8951314 0.6959669]\n",
      "tensor([[ 0.8706],\n",
      "        [-0.9658],\n",
      "        [-0.0111],\n",
      "        [-0.9658],\n",
      "        [-0.9658],\n",
      "        [ 0.3131],\n",
      "        [-0.9658],\n",
      "        [-0.9658],\n",
      "        [-0.9658],\n",
      "        [-0.9658],\n",
      "        [-0.1587],\n",
      "        [-0.9658],\n",
      "        [-0.9658],\n",
      "        [ 0.3131],\n",
      "        [-0.9658],\n",
      "        [-0.9658],\n",
      "        [ 0.3131],\n",
      "        [ 0.3131],\n",
      "        [-0.1587],\n",
      "        [-0.9658],\n",
      "        [ 0.8706],\n",
      "        [-0.9658],\n",
      "        [-0.9658],\n",
      "        [-0.9658],\n",
      "        [-0.9658],\n",
      "        [-0.9658],\n",
      "        [ 0.3131],\n",
      "        [ 0.3131],\n",
      "        [ 0.3131],\n",
      "        [ 0.3131],\n",
      "        [-0.1587],\n",
      "        [-0.9658],\n",
      "        [-0.9658],\n",
      "        [-0.9658],\n",
      "        [-0.9658],\n",
      "        [-0.9658],\n",
      "        [-0.9658],\n",
      "        [-0.9658],\n",
      "        [-0.9658],\n",
      "        [-0.9658],\n",
      "        [-0.1587],\n",
      "        [-0.0111],\n",
      "        [-0.0111],\n",
      "        [-0.0111],\n",
      "        [-0.6914],\n",
      "        [-0.6914],\n",
      "        [-0.6914],\n",
      "        [-0.0111],\n",
      "        [-0.0111],\n",
      "        [-0.0111]], dtype=torch.float64)\n",
      "Finished episode 1945 Average rewards:  82.8\n",
      "len_game 51\n",
      "Rot\n",
      "[ 1.2690861   1.0000674   0.86145043  1.9999994  -0.0770995   1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8901442  0.69558424]\n",
      "tensor([[-0.1670],\n",
      "        [-0.9767],\n",
      "        [-0.9767],\n",
      "        [ 0.3283],\n",
      "        [-0.1670],\n",
      "        [-0.9767],\n",
      "        [-0.1670],\n",
      "        [-0.0122],\n",
      "        [ 0.8835],\n",
      "        [-0.9767],\n",
      "        [ 0.8835],\n",
      "        [-0.9767],\n",
      "        [-0.0122],\n",
      "        [-0.0122],\n",
      "        [-0.0122],\n",
      "        [-0.0122],\n",
      "        [-0.6952],\n",
      "        [-0.6952],\n",
      "        [-0.6952],\n",
      "        [ 0.8835],\n",
      "        [ 0.8835],\n",
      "        [-0.1670],\n",
      "        [-0.0122],\n",
      "        [-0.0122],\n",
      "        [-0.6952],\n",
      "        [-0.6952],\n",
      "        [-0.0122],\n",
      "        [-0.0122],\n",
      "        [-0.6952],\n",
      "        [ 0.8835],\n",
      "        [-0.9767],\n",
      "        [ 0.8835],\n",
      "        [-0.9767],\n",
      "        [-0.9767],\n",
      "        [ 0.3283],\n",
      "        [-0.1670],\n",
      "        [-0.9767],\n",
      "        [-0.9767],\n",
      "        [-0.9767],\n",
      "        [-0.9767],\n",
      "        [-0.9767],\n",
      "        [ 0.8835],\n",
      "        [-0.9767],\n",
      "        [-0.9767],\n",
      "        [ 0.3283],\n",
      "        [ 0.3283],\n",
      "        [ 0.3283],\n",
      "        [-0.1670],\n",
      "        [-0.9767],\n",
      "        [-0.9767],\n",
      "        [-0.9767]], dtype=torch.float64)\n",
      "Finished episode 1950 Average rewards:  81.2\n",
      "Monitored episode 50 Average Monitored rewards:  47.1\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2632467   1.0000663   0.86283475  1.9999994  -0.07494592  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.89598364 0.69696856]\n",
      "tensor([[ 0.8739],\n",
      "        [-0.9760],\n",
      "        [-0.9760],\n",
      "        [ 0.3597],\n",
      "        [-0.9760],\n",
      "        [-0.9760],\n",
      "        [-0.9760],\n",
      "        [-0.9760],\n",
      "        [-0.9760],\n",
      "        [-0.9760],\n",
      "        [-0.2025],\n",
      "        [ 0.0213],\n",
      "        [ 0.0213],\n",
      "        [ 0.0213],\n",
      "        [ 0.0213],\n",
      "        [ 0.0213],\n",
      "        [ 0.0213],\n",
      "        [ 0.0213],\n",
      "        [ 0.0213],\n",
      "        [ 0.0213],\n",
      "        [ 0.8739],\n",
      "        [ 0.8739],\n",
      "        [ 0.8739],\n",
      "        [-0.9760],\n",
      "        [-0.2025],\n",
      "        [-0.9760],\n",
      "        [-0.9760],\n",
      "        [-0.9760],\n",
      "        [-0.9760],\n",
      "        [ 0.3597],\n",
      "        [-0.2025],\n",
      "        [ 0.0213],\n",
      "        [ 0.0213],\n",
      "        [ 0.0213],\n",
      "        [ 0.0213],\n",
      "        [ 0.0213],\n",
      "        [ 0.0213],\n",
      "        [ 0.0213],\n",
      "        [ 0.0213],\n",
      "        [ 0.0213],\n",
      "        [ 0.8739],\n",
      "        [-0.9760],\n",
      "        [-0.9760],\n",
      "        [ 0.3597],\n",
      "        [-0.9760],\n",
      "        [-0.9760],\n",
      "        [-0.9760],\n",
      "        [ 0.3597],\n",
      "        [ 0.3597],\n",
      "        [ 0.3597]], dtype=torch.float64)\n",
      "Finished episode 1955 Average rewards:  61.4\n",
      "len_game 53\n",
      "Rot\n",
      "[ 1.2540841   1.0000632   0.8540721   1.9999994  -0.09857184  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.9051461 0.6882059]\n",
      "tensor([[ 0.8610],\n",
      "        [-0.9679],\n",
      "        [-0.1983],\n",
      "        [-0.9679],\n",
      "        [ 0.0275],\n",
      "        [ 0.0275],\n",
      "        [ 0.0275],\n",
      "        [ 0.0275],\n",
      "        [ 0.0275],\n",
      "        [ 0.0275],\n",
      "        [-0.1983],\n",
      "        [ 0.0275],\n",
      "        [ 0.0275],\n",
      "        [ 0.0275],\n",
      "        [ 0.0275],\n",
      "        [-0.6629],\n",
      "        [-0.6629],\n",
      "        [ 0.8610],\n",
      "        [ 0.8610],\n",
      "        [-0.9679],\n",
      "        [-0.1983],\n",
      "        [-0.1983],\n",
      "        [-0.1983],\n",
      "        [ 0.0275],\n",
      "        [ 0.0275],\n",
      "        [ 0.0275],\n",
      "        [ 0.0275],\n",
      "        [ 0.0275],\n",
      "        [ 0.0275],\n",
      "        [ 0.0275],\n",
      "        [ 0.0275],\n",
      "        [ 0.0275],\n",
      "        [ 0.8610],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [-0.9679],\n",
      "        [ 0.3481],\n",
      "        [ 0.3481],\n",
      "        [ 0.3481],\n",
      "        [ 0.3481],\n",
      "        [-0.1983],\n",
      "        [-0.1983],\n",
      "        [ 0.8610],\n",
      "        [-0.9679],\n",
      "        [-0.1983],\n",
      "        [-0.1983],\n",
      "        [-0.9679],\n",
      "        [-0.1983],\n",
      "        [-0.1983],\n",
      "        [ 0.0275],\n",
      "        [ 0.0275],\n",
      "        [ 0.0275]], dtype=torch.float64)\n",
      "Finished episode 1960 Average rewards:  15.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  48.94\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2679276   1.0000627   0.863026    1.9999994  -0.07746083  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.89130265 0.6971598 ]\n",
      "tensor([[-0.1268],\n",
      "        [-0.0400],\n",
      "        [-0.0400],\n",
      "        [-0.7202],\n",
      "        [-0.0400],\n",
      "        [-0.0400],\n",
      "        [-0.7202],\n",
      "        [-0.7202],\n",
      "        [-0.0400],\n",
      "        [-0.0400],\n",
      "        [ 0.8888],\n",
      "        [-0.9790],\n",
      "        [-0.1268],\n",
      "        [-0.9790],\n",
      "        [-0.9790],\n",
      "        [-0.9790],\n",
      "        [ 0.2825],\n",
      "        [ 0.2825],\n",
      "        [-0.1268],\n",
      "        [-0.1268],\n",
      "        [ 0.8888],\n",
      "        [ 0.8888],\n",
      "        [-0.9790],\n",
      "        [-0.1268],\n",
      "        [-0.0400],\n",
      "        [ 0.8888],\n",
      "        [-0.9790],\n",
      "        [ 0.2825],\n",
      "        [-0.1268],\n",
      "        [-0.9790],\n",
      "        [-0.1268],\n",
      "        [-0.0400],\n",
      "        [-0.0400],\n",
      "        [ 0.8888],\n",
      "        [-0.9790],\n",
      "        [ 0.2825],\n",
      "        [-0.1268],\n",
      "        [-0.9790],\n",
      "        [-0.9790],\n",
      "        [-0.9790],\n",
      "        [-0.1268],\n",
      "        [-0.0400],\n",
      "        [-0.0400],\n",
      "        [-0.0400],\n",
      "        [-0.0400],\n",
      "        [-0.7202],\n",
      "        [-0.7202],\n",
      "        [-0.0400],\n",
      "        [-0.0400],\n",
      "        [-0.7202]], dtype=torch.float64)\n",
      "Finished episode 1965 Average rewards:  58.8\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2607596   1.0000601   0.85403925  1.9999994  -0.10470472  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8984707  0.68817306]\n",
      "tensor([[-0.1998],\n",
      "        [-0.1998],\n",
      "        [ 0.0203],\n",
      "        [-0.6686],\n",
      "        [-0.9736],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [ 0.8714],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [-0.1998],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [-0.6686],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [-0.6686],\n",
      "        [-0.1998],\n",
      "        [-0.9736],\n",
      "        [-0.9736],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [-0.1998],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [ 0.0203],\n",
      "        [-0.6686],\n",
      "        [-0.6686],\n",
      "        [ 0.8714],\n",
      "        [ 0.8714],\n",
      "        [ 0.8714],\n",
      "        [ 0.8714]], dtype=torch.float64)\n",
      "Finished episode 1970 Average rewards:  14.8\n",
      "Monitored episode 50 Average Monitored rewards:  44.86\n",
      "len_game 53\n",
      "Rot\n",
      "[ 1.2662868  1.0000587  0.8605549  1.9999994 -0.0859912  1.8641111\n",
      "  1.7464267  0.7518858]\n",
      "Enc\n",
      "[0.8929434 0.6946887]\n",
      "tensor([[ 0.9059],\n",
      "        [-0.9871],\n",
      "        [-0.9871],\n",
      "        [-0.0575],\n",
      "        [-0.0575],\n",
      "        [-0.7334],\n",
      "        [-0.7334],\n",
      "        [-0.9871],\n",
      "        [-0.9871],\n",
      "        [-0.9871],\n",
      "        [-0.1236],\n",
      "        [-0.9871],\n",
      "        [ 0.2923],\n",
      "        [-0.1236],\n",
      "        [-0.0575],\n",
      "        [-0.0575],\n",
      "        [-0.7334],\n",
      "        [-0.7334],\n",
      "        [-0.0575],\n",
      "        [-0.0575],\n",
      "        [-0.1236],\n",
      "        [-0.0575],\n",
      "        [-0.7334],\n",
      "        [-0.9871],\n",
      "        [-0.9871],\n",
      "        [ 0.2923],\n",
      "        [ 0.2923],\n",
      "        [ 0.2923],\n",
      "        [ 0.2923],\n",
      "        [ 0.2923],\n",
      "        [-0.1236],\n",
      "        [-0.1236],\n",
      "        [-0.1236],\n",
      "        [-0.1236],\n",
      "        [-0.9871],\n",
      "        [-0.9871],\n",
      "        [-0.9871],\n",
      "        [-0.9871],\n",
      "        [ 0.2923],\n",
      "        [ 0.2923],\n",
      "        [ 0.2923],\n",
      "        [ 0.2923],\n",
      "        [ 0.2923],\n",
      "        [-0.1236],\n",
      "        [-0.9871],\n",
      "        [-0.9871],\n",
      "        [-0.9871],\n",
      "        [-0.9871],\n",
      "        [ 0.2923],\n",
      "        [ 0.2923],\n",
      "        [ 0.2923],\n",
      "        [-0.1236],\n",
      "        [-0.1236]], dtype=torch.float64)\n",
      "Finished episode 1975 Average rewards:  80.0\n",
      "len_game 52\n",
      "Rot\n",
      "[ 1.286202    1.0000592   0.87229794  1.9999994  -0.06790179  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8730282  0.70643175]\n",
      "tensor([[ 0.8835],\n",
      "        [ 0.8835],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [ 0.3389],\n",
      "        [ 0.3389],\n",
      "        [ 0.3389],\n",
      "        [-0.1773],\n",
      "        [ 0.8835],\n",
      "        [ 0.8835],\n",
      "        [-0.0041],\n",
      "        [-0.0041],\n",
      "        [-0.0041],\n",
      "        [-0.0041],\n",
      "        [-0.6895],\n",
      "        [-0.0041],\n",
      "        [-0.0041],\n",
      "        [-0.6895],\n",
      "        [ 0.8835],\n",
      "        [-0.1773],\n",
      "        [-0.0041],\n",
      "        [-0.0041],\n",
      "        [-0.0041],\n",
      "        [-0.6895],\n",
      "        [-0.6895],\n",
      "        [-0.6895],\n",
      "        [-0.0041],\n",
      "        [-0.0041],\n",
      "        [-0.0041],\n",
      "        [-0.1773],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [-0.9785],\n",
      "        [ 0.3389],\n",
      "        [ 0.3389],\n",
      "        [ 0.3389],\n",
      "        [ 0.3389],\n",
      "        [-0.9785],\n",
      "        [-0.1773],\n",
      "        [-0.0041],\n",
      "        [-0.0041],\n",
      "        [-0.6895],\n",
      "        [-0.6895],\n",
      "        [-0.0041],\n",
      "        [-0.0041],\n",
      "        [-0.0041],\n",
      "        [-0.0041],\n",
      "        [-0.0041]], dtype=torch.float64)\n",
      "Finished episode 1980 Average rewards:  36.8\n",
      "Monitored episode 50 Average Monitored rewards:  38.06\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2718431   1.0000564   0.8612292   1.9999994  -0.08756368  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.88738716 0.6953629 ]\n",
      "tensor([[ 0.8735],\n",
      "        [-0.9696],\n",
      "        [-0.2491],\n",
      "        [ 0.0476],\n",
      "        [ 0.0476],\n",
      "        [ 0.0476],\n",
      "        [ 0.0476],\n",
      "        [ 0.0476],\n",
      "        [ 0.0476],\n",
      "        [ 0.0476],\n",
      "        [ 0.8735],\n",
      "        [-0.9696],\n",
      "        [-0.9696],\n",
      "        [-0.9696],\n",
      "        [-0.9696],\n",
      "        [-0.9696],\n",
      "        [ 0.4115],\n",
      "        [-0.9696],\n",
      "        [ 0.4115],\n",
      "        [-0.9696],\n",
      "        [ 0.8735],\n",
      "        [-0.9696],\n",
      "        [-0.9696],\n",
      "        [-0.9696],\n",
      "        [-0.2491],\n",
      "        [-0.9696],\n",
      "        [ 0.0476],\n",
      "        [ 0.0476],\n",
      "        [ 0.0476],\n",
      "        [ 0.0476],\n",
      "        [ 0.8735],\n",
      "        [-0.9696],\n",
      "        [-0.2491],\n",
      "        [-0.9696],\n",
      "        [-0.9696],\n",
      "        [-0.9696],\n",
      "        [-0.9696],\n",
      "        [-0.9696],\n",
      "        [ 0.4115],\n",
      "        [ 0.4115],\n",
      "        [-0.2491],\n",
      "        [-0.2491],\n",
      "        [ 0.0476],\n",
      "        [-0.6403],\n",
      "        [-0.9696],\n",
      "        [-0.9696],\n",
      "        [-0.9696],\n",
      "        [-0.9696],\n",
      "        [-0.9696],\n",
      "        [-0.9696]], dtype=torch.float64)\n",
      "Finished episode 1985 Average rewards:  62.6\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2961156   1.0000563   0.8744619   1.9999994  -0.05706789  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.8631146 0.7085957]\n",
      "tensor([[-0.1828],\n",
      "        [-0.9820],\n",
      "        [-0.9820],\n",
      "        [-0.9820],\n",
      "        [-0.9820],\n",
      "        [-0.9820],\n",
      "        [-0.9820],\n",
      "        [ 0.3514],\n",
      "        [-0.9820],\n",
      "        [-0.9820],\n",
      "        [-0.1828],\n",
      "        [-0.0086],\n",
      "        [-0.6927],\n",
      "        [-0.9820],\n",
      "        [-0.9820],\n",
      "        [ 0.3514],\n",
      "        [-0.1828],\n",
      "        [-0.0086],\n",
      "        [-0.6927],\n",
      "        [-0.0086],\n",
      "        [ 0.8926],\n",
      "        [ 0.8926],\n",
      "        [-0.9820],\n",
      "        [-0.0086],\n",
      "        [-0.0086],\n",
      "        [-0.0086],\n",
      "        [-0.0086],\n",
      "        [-0.0086],\n",
      "        [-0.0086],\n",
      "        [-0.0086],\n",
      "        [ 0.8926],\n",
      "        [-0.9820],\n",
      "        [-0.1828],\n",
      "        [-0.1828],\n",
      "        [-0.0086],\n",
      "        [-0.0086],\n",
      "        [-0.6927],\n",
      "        [-0.0086],\n",
      "        [-0.0086],\n",
      "        [-0.0086],\n",
      "        [ 0.8926],\n",
      "        [-0.9820],\n",
      "        [-0.9820],\n",
      "        [-0.1828],\n",
      "        [-0.9820],\n",
      "        [ 0.3514],\n",
      "        [-0.1828],\n",
      "        [-0.9820],\n",
      "        [-0.1828],\n",
      "        [-0.0086]], dtype=torch.float64)\n",
      "Finished episode 1990 Average rewards:  15.0\n",
      "Monitored episode 50 Average Monitored rewards:  29.6\n",
      "len_game 50\n",
      "Rot\n",
      "[ 1.2902087   1.0000547   0.86364764  1.9999994  -0.07809412  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.86902153 0.69778144]\n",
      "tensor([[ 0.8688],\n",
      "        [ 0.8688],\n",
      "        [ 0.8688],\n",
      "        [-0.9669],\n",
      "        [ 0.0785],\n",
      "        [ 0.0785],\n",
      "        [ 0.0785],\n",
      "        [ 0.0785],\n",
      "        [ 0.0785],\n",
      "        [ 0.0785],\n",
      "        [-0.2862],\n",
      "        [-0.9669],\n",
      "        [-0.9669],\n",
      "        [-0.9669],\n",
      "        [-0.9669],\n",
      "        [-0.9669],\n",
      "        [-0.9669],\n",
      "        [-0.9669],\n",
      "        [-0.9669],\n",
      "        [-0.9669],\n",
      "        [ 0.8688],\n",
      "        [ 0.0785],\n",
      "        [ 0.0785],\n",
      "        [ 0.0785],\n",
      "        [ 0.0785],\n",
      "        [ 0.0785],\n",
      "        [ 0.0785],\n",
      "        [ 0.0785],\n",
      "        [ 0.0785],\n",
      "        [ 0.0785],\n",
      "        [-0.2862],\n",
      "        [ 0.0785],\n",
      "        [ 0.0785],\n",
      "        [ 0.0785],\n",
      "        [ 0.0785],\n",
      "        [ 0.0785],\n",
      "        [ 0.0785],\n",
      "        [ 0.0785],\n",
      "        [ 0.0785],\n",
      "        [ 0.0785],\n",
      "        [ 0.8688],\n",
      "        [-0.9669],\n",
      "        [-0.9669],\n",
      "        [-0.9669],\n",
      "        [ 0.4418],\n",
      "        [ 0.4418],\n",
      "        [ 0.4418],\n",
      "        [ 0.4418],\n",
      "        [ 0.4418],\n",
      "        [ 0.4418]], dtype=torch.float64)\n",
      "Finished episode 1995 Average rewards:  36.6\n",
      "len_game 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot\n",
      "[ 1.279325    1.0000522   0.85120666  1.9999994  -0.10596696  1.8641111\n",
      "  1.7464267   0.7518858 ]\n",
      "Enc\n",
      "[0.87990516 0.68534046]\n",
      "tensor([[ 0.9014],\n",
      "        [-0.9825],\n",
      "        [-0.9825],\n",
      "        [-0.9825],\n",
      "        [-0.9825],\n",
      "        [-0.9825],\n",
      "        [-0.9825],\n",
      "        [-0.9825],\n",
      "        [-0.9825],\n",
      "        [-0.9825],\n",
      "        [ 0.9014],\n",
      "        [-0.9825],\n",
      "        [-0.9825],\n",
      "        [ 0.0185],\n",
      "        [ 0.0185],\n",
      "        [ 0.0185],\n",
      "        [ 0.0185],\n",
      "        [ 0.0185],\n",
      "        [ 0.0185],\n",
      "        [ 0.0185],\n",
      "        [ 0.9014],\n",
      "        [-0.9825],\n",
      "        [ 0.0185],\n",
      "        [ 0.0185],\n",
      "        [ 0.0185],\n",
      "        [-0.6698],\n",
      "        [ 0.0185],\n",
      "        [ 0.0185],\n",
      "        [ 0.0185],\n",
      "        [ 0.0185],\n",
      "        [ 0.9014],\n",
      "        [-0.9825],\n",
      "        [-0.2330],\n",
      "        [ 0.0185],\n",
      "        [-0.6698],\n",
      "        [ 0.0185],\n",
      "        [ 0.0185],\n",
      "        [ 0.0185],\n",
      "        [ 0.0185],\n",
      "        [ 0.0185],\n",
      "        [-0.2330],\n",
      "        [ 0.0185],\n",
      "        [ 0.0185],\n",
      "        [ 0.0185],\n",
      "        [ 0.0185],\n",
      "        [ 0.0185],\n",
      "        [ 0.0185],\n",
      "        [ 0.0185],\n",
      "        [ 0.0185],\n",
      "        [ 0.0185]], dtype=torch.float64)\n",
      "Finished episode 2000 Average rewards:  17.2\n",
      "Monitored episode 50 Average Monitored rewards:  55.64\n"
     ]
    }
   ],
   "source": [
    "# Start training the agent\n",
    "episode_reward_history = []\n",
    "reward_history = []\n",
    "# Monitoring reward\n",
    "monitor_reward_history = []\n",
    "for batch in tqdm(range(n_episodes // batch_size)):\n",
    "    # Gather episodes\n",
    "    episodes = gather_episodes(state_bounds, n_actions, agent, batch_size, env_name)\n",
    "\n",
    "    # Group states, actions and returns in numpy arrays\n",
    "    states = torch.from_numpy(np.concatenate([ep['states'] for ep in episodes]))\n",
    "    actions = torch.from_numpy(np.concatenate([ep['actions'] for ep in episodes]))\n",
    "    action_probs = torch.from_numpy(np.concatenate([ep['action probs'] for ep in episodes]))\n",
    "    rewards = [ep['rewards'] for ep in episodes]\n",
    "    returns = np.concatenate([compute_returns(ep_rwds, gamma) for ep_rwds in rewards])\n",
    "    returns = torch.from_numpy(np.array(returns))\n",
    "    print('len_game', len(states))\n",
    "#     action_probs = [ep['action_probs'] for ep in episodes]\n",
    "\n",
    "#     id_action_pairs = torch.from_numpy(np.array([[i, a] for i, a in enumerate(actions)]))\n",
    "\n",
    "    # Update model parameters.\n",
    "    agent.update_policy(states, returns, batch_size, action_probs)\n",
    "    \n",
    "#     if batch % 25 == 0 and batch != 0:\n",
    "#         agent.lr *= 0.5\n",
    "#     print(states)\n",
    "#     print(actions)\n",
    "#     print(rewards)\n",
    "    print(action_probs)\n",
    "\n",
    "    # Store collected rewards\n",
    "    for ep_rwds in rewards:\n",
    "        episode_reward_history.append(np.sum(ep_rwds))\n",
    "\n",
    "    avg_rewards = np.mean(episode_reward_history[-batch_size:])\n",
    "\n",
    "    print('Finished episode', (batch + 1) * batch_size,\n",
    "          'Average rewards: ', avg_rewards)\n",
    "    \n",
    "    if batch % 2 == 1:\n",
    "        # Gather episodes\n",
    "        episodes_monitor = gather_episodes(state_bounds, n_actions, agent, 50, env_name)\n",
    "\n",
    "        # Group states, actions and returns in numpy arrays\n",
    "        states_monitor = torch.from_numpy(np.concatenate([ep['states'] for ep in episodes_monitor]))\n",
    "        actions_monitor = torch.from_numpy(np.concatenate([ep['actions'] for ep in episodes_monitor]))\n",
    "        action_probs_monitor = torch.from_numpy(np.concatenate([ep['action probs'] for ep in episodes_monitor]))\n",
    "        rewards_monitor = [ep['rewards'] for ep in episodes_monitor]\n",
    "        # Store collected rewards\n",
    "        temp_hist = []\n",
    "        for ep_rwds in rewards_monitor:\n",
    "            temp_hist.append(np.sum(ep_rwds))\n",
    "        avg_rewards_monitor = np.mean(temp_hist)\n",
    "        monitor_reward_history.append(avg_rewards_monitor)\n",
    "        \n",
    "        print('Monitored episode', 50,\n",
    "              'Average Monitored rewards: ', avg_rewards_monitor)\n",
    "        \n",
    "    if avg_rewards >= 500.0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x226762137c0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(len(episode_reward_history)), episode_reward_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x226762c2370>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(episode_reward_history[:20], bins=20)\n",
    "plt.hist(episode_reward_history[-20:], bins=20, label='last',alpha = 0.5)\n",
    "plt.legend()\n",
    "# plt.savefig('hist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22676215820>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(monitor_reward_history)\n",
    "# plt.savefig('rewardmonitor.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22676770e80>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt \n",
    "import pickle as pkl\n",
    "\n",
    "def linear(x, y_intercept, slope):\n",
    "    return y_intercept + (x * slope)\n",
    "\n",
    "def third_poly(x, a, b, c, d):\n",
    "    return a + b * x + c * x**2 + d * x**3\n",
    "data_len = len(monitor_reward_history)\n",
    "x = np.arange(data_len)\n",
    "popt, pcov = curve_fit(linear, x, monitor_reward_history)\n",
    "plt.plot(linear(x, popt[0], popt[1]))\n",
    "plt.plot(monitor_reward_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNE3QY8UA5xCDFR4Ht9tSPe",
   "collapsed_sections": [
    "ksJVcTLxzskm",
    "jySdpQf_zuiE",
    "MIKgmnTWM8yz",
    "eLm2LW4zBqPo"
   ],
   "name": "QuantumCircuitLearning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1b23efbb8db748a2af8554186cf2a3d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "235d4532e52e4aadbc6c049c0c7369b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25885ff5cc014bafa5442805d676c0be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_235d4532e52e4aadbc6c049c0c7369b3",
      "max": 50,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4ede1074ee2f496ab3d864be52157d03",
      "value": 50
     }
    },
    "40ae390ed75a46f292ffc969fdd0509e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4ede1074ee2f496ab3d864be52157d03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "68c55b17e042416c91105f585c6f622a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec14bbc210b743f085734c3bf858fd72",
      "placeholder": "",
      "style": "IPY_MODEL_40ae390ed75a46f292ffc969fdd0509e",
      "value": " 50/50 [11:53&lt;00:00, 14.28s/it]"
     }
    },
    "cc511557b8a54d408c9d2ddcaa7aa7dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_25885ff5cc014bafa5442805d676c0be",
       "IPY_MODEL_68c55b17e042416c91105f585c6f622a"
      ],
      "layout": "IPY_MODEL_1b23efbb8db748a2af8554186cf2a3d8"
     }
    },
    "ec14bbc210b743f085734c3bf858fd72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
