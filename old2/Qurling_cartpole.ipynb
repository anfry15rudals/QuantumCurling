{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ksJVcTLxzskm"
   },
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "N8fPchWjlyM1"
   },
   "outputs": [],
   "source": [
    "import qiskit\n",
    "import pylatexenc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from functools import reduce\n",
    "from collections import deque, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GfudJfnDmH06"
   },
   "outputs": [],
   "source": [
    "import qiskit\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math, random, time, itertools\n",
    "from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister, Aer\n",
    "from qiskit.quantum_info.operators import Operator\n",
    "from qiskit.circuit import Parameter, ParameterVector\n",
    "from tqdm.notebook import tqdm\n",
    "from qiskit.opflow import Z, X, I, StateFn, CircuitStateFn, SummedOp, CircuitOp, AerPauliExpectation\n",
    "from qiskit.opflow.gradients import Gradient, NaturalGradient, QFI, Hessian\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "from qiskit_machine_learning.neural_networks import OpflowQNN\n",
    "from qiskit.utils import QuantumInstance, algorithm_globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Curling import Curling\n",
    "from ansatz import build_circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jySdpQf_zuiE"
   },
   "source": [
    "# Build CIrucit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ansatz list\n",
    "- 'base'\n",
    "- 'hw_eff'\n",
    "- 'universal'\n",
    "- 'universal_encoding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1062.63x144.48 with 1 Axes>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def draw_example():\n",
    "    quantum_circuit, param_rot, param_enc = build_circuit(n_qubits=2, n_layers=1, opt='universal_encoding')\n",
    "    return quantum_circuit\n",
    "draw_example().draw('mpl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# circuit, rot_params, enc_params = build_circuit(n_qubits=2, n_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PQC_with_DataReuploading(nn.Module):\n",
    "    def __init__(self, n_qubits, n_layers, output_dim, observables=None, ansatz='base', activation='linear'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_layers = n_layers\n",
    "        self.output_dim = output_dim\n",
    "        self.activation = activation\n",
    "        self.ansatz = ansatz\n",
    "        \n",
    "        if observables == None:\n",
    "            self.observables = Z^n_qubits\n",
    "        else:\n",
    "            self.observables = observables\n",
    "        \n",
    "        # Build circuits / Parameter Vectors\n",
    "        self.circuit, self.rot_params, self.enc_params = build_circuit(self.n_qubits, self.n_layers, ansatz)\n",
    "        self.len_rot_params = len(self.rot_params)\n",
    "        self.len_enc_params = len(self.enc_params)\n",
    "        \n",
    "        self.psi = CircuitStateFn(primitive=self.circuit, coeff=1.)\n",
    "        self.Op = ~StateFn(self.observables) @ self.psi\n",
    "        \n",
    "        # set method to calculcate expected values\n",
    "        expval = AerPauliExpectation()\n",
    "        # define gradient method\n",
    "        gradient = Gradient()\n",
    "        # define quantum instances (statevector and sample based)\n",
    "        qi_sv = QuantumInstance(Aer.get_backend(\"aer_simulator_statevector\"))\n",
    "        # we set shots to 10 as this will determine the number of samples later on.\n",
    "        qi_qasm = QuantumInstance(Aer.get_backend(\"aer_simulator\"), shots=1000)\n",
    "        \n",
    "        self.qnn = OpflowQNN(operator=self.Op, input_params=self.enc_params, weight_params=self.rot_params, \n",
    "                             exp_val=expval, gradient=gradient, quantum_instance=qi_sv, input_gradients=True)\n",
    "        \n",
    "        self.total_params = []\n",
    "        for p in self.rot_params:\n",
    "            self.total_params.append(p)\n",
    "        for p in self.enc_params:\n",
    "            self.total_params.append(p)\n",
    "        \n",
    "        # Initial Parameters for circuit\n",
    "#         self.rot_param_vals = nn.Parameter(2*np.pi * torch.rand(len(self.rot_params)))\n",
    "        self.rot_param_vals = nn.Parameter(2*np.pi * torch.rand(len(self.rot_params)))\n",
    "#         self.enc_param_vals = nn.Parameter(torch.ones(len(self.enc_params)))\n",
    "#         self.enc_param_vals  = nn.Parameter(nn.Parameter(torch.rand(len(self.enc_params))))\n",
    "        self.enc_param_vals  = nn.Parameter(torch.rand(len(self.enc_params)))\n",
    "        \n",
    "        # Parameter for circuit output\n",
    "#         self.w = nn.Parameter(nn.Parameter(torch.rand(self.output_dim)))\n",
    "        self.w = nn.Parameter(torch.tensor([-1,1], dtype=torch.float32))\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        input_tiled = self.get_input_tiled(inputs)\n",
    "        input_scaled = self.enc_param_vals * input_tiled\n",
    "        input_params = input_scaled\n",
    "    \n",
    "        expectation = self.qnn.forward(input_params.detach(), self.rot_param_vals.detach())\n",
    "        \n",
    "        action_exp = torch.tensor(expectation) * self.w\n",
    "        action_prob = F.softmax(action_exp, dim=1)\n",
    "        \n",
    "        return action_prob\n",
    "\n",
    "    def backward(self, inputs):\n",
    "        input_tiled = self.get_input_tiled(inputs)\n",
    "        input_scaled = self.enc_param_vals * input_tiled\n",
    "        input_params = input_scaled\n",
    "        expectation = self.qnn.forward(input_params.detach(), self.rot_param_vals.detach())\n",
    "        enc_grad, rot_grad = self.qnn.backward(input_params.detach(), self.rot_param_vals.detach())\n",
    "        w_grad = torch.tensor(expectation).tile(self.output_dim)\n",
    "        return torch.tensor(rot_grad.squeeze()), torch.tensor(enc_grad.squeeze()), w_grad\n",
    "    \n",
    "    def get_input_tiled(self, inputs):\n",
    "        # Input: State values -> Need to insert into Encoding gates with scaling parameters(encoding params)\n",
    "        if self.ansatz == 'universal_encoding' or self.ansatz == 'hw_eff':\n",
    "            input_tiled = inputs.tile(2)\n",
    "            input_tiled = input_tiled.tile(self.n_layers)\n",
    "        elif self.ansatz == 'universal':\n",
    "            input_tiled = torch.zeros((inputs.shape[0], inputs.shape[1]+1))\n",
    "            input_tiled[:,:2] = inputs\n",
    "            input_tiled[:,-1] = inputs[:,-1]\n",
    "        else:\n",
    "            input_tiled = inputs.tile(self.n_layers)\n",
    "        return input_tiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = PQC_with_DataReuploading(n_qubits=2, n_layers=1, output_dim=2, ansatz='universal_encoding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PauliOp(Pauli('ZZ'), coeff=1.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1062.78x144.48 with 1 Axes>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.circuit.draw('mpl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.rand((10,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([4.9470, 0.2622, 0.6299, 4.9670, 3.1092, 5.1508, 0.7052, 1.0232, 1.3515,\n",
       "        4.7922, 4.8586, 4.6548, 2.4173], requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.rot_param_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.4910, 0.7748, 0.5581, 0.4010], requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.enc_param_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-1.,  1.], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4158, 0.5842],\n",
       "        [0.2752, 0.7248],\n",
       "        [0.2722, 0.7278],\n",
       "        [0.3236, 0.6764],\n",
       "        [0.2389, 0.7611],\n",
       "        [0.2636, 0.7364],\n",
       "        [0.2658, 0.7342],\n",
       "        [0.2328, 0.7672],\n",
       "        [0.4455, 0.5545],\n",
       "        [0.3456, 0.6544]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.forward(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7641711235046387\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "a,b,c = policy.backward(inputs)\n",
    "print(time.time()-s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Quantum Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumAgent():\n",
    "    def __init__(self, input_state_dim, n_actions, n_layers=1, ansatz='base'):\n",
    "        self.policy = PQC_with_DataReuploading(n_qubits=input_state_dim, n_layers=n_layers, \n",
    "                                               output_dim=n_actions, observables=None, ansatz=ansatz,\n",
    "                                               activation='linear')\n",
    "        self.n_layers = n_layers\n",
    "#         self.variational_optim = torch.optim.Adam([self.policy.rot_param_vals], lr=0.1)\n",
    "#         self.encoding_optim = torch.optim.Adam([self.policy.enc_param_vals], lr=0.1)\n",
    "#         self.weight_optim = torch.optim.Adam([self.policy.w], lr=0.01)\n",
    "        \n",
    "        self.lr = 1\n",
    "        \n",
    "#         self.optims = [self.variational_optim, self.encoding_optim, self.weight_optim]\n",
    "        \n",
    "    def get_actions(self, input_state):\n",
    "        return self.policy.forward(input_state)\n",
    "    \n",
    "    def update_policy(self, states, id_action_pairs, returns, action_probs, batch_size):\n",
    "        r_grad, e_grad, w_grad = self.policy.backward(states)\n",
    "        \n",
    "        p_actions = torch.tensor([action_probs[id_action_pairs[i][0], id_action_pairs[i][1]] for i in range(action_probs.shape[0])])\n",
    "        p_actions = p_actions.reshape(p_actions.shape[0], -1)\n",
    "        action_idxs = id_action_pairs[:,1]\n",
    "        \n",
    "        returns = returns.reshape(returns.shape[0], -1)\n",
    "        action_weights = agent.policy.w.detach().numpy()[id_action_pairs[:,1]]\n",
    "        action_weights = action_weights[:,np.newaxis]\n",
    "        \n",
    "        w = agent.policy.w.tile(len(states)).reshape(len(states),-1)\n",
    "        \n",
    "        rot_grad = returns * ( r_grad * torch.tensor(action_weights) - torch.mean(p_actions * w) * r_grad)\n",
    "        input_scaled = self.policy.enc_param_vals * self.policy.get_input_tiled(states)\n",
    "        enc_grad = returns * ( e_grad * torch.tensor(action_weights) - input_scaled * torch.mean(p_actions * w) * e_grad)\n",
    "        weight_grad = returns * ( w_grad * torch.tensor(action_weights) - torch.mean(p_actions * w) * w_grad)\n",
    "        \n",
    "        prev = self.policy.rot_param_vals.detach().numpy().copy()\n",
    "        prev1 = self.policy.enc_param_vals.detach().numpy().copy()\n",
    "        prev2 = self.policy.w.detach().numpy().copy()\n",
    "        \n",
    "#         rot_update = (torch.mean(rot_grad.detach(), dim=0) / batch_size).type(torch.float32)\n",
    "#         enc_update = (torch.mean(enc_grad, dim=0).detach() / batch_size).type(torch.float32)\n",
    "#         w_update = (torch.mean(weight_grad, dim=0).detach() / batch_size).type(torch.float32)\n",
    "\n",
    "        rot_update = torch.mean(rot_grad, dim=0) / batch_size\n",
    "        enc_update = torch.mean(enc_grad, dim=0) / batch_size\n",
    "        w_update = torch.mean(weight_grad, dim=0) / batch_size\n",
    "        \n",
    "        with torch.no_grad():            \n",
    "            self.policy.rot_param_vals += 5 * rot_update\n",
    "            self.policy.enc_param_vals += 5 * enc_update\n",
    "            self.policy.w += 5 * w_update\n",
    "#         self.policy.rot_param_vals.grad = -1*rot_update\n",
    "#         self.policy.enc_param_vals.grad = -1*enc_update\n",
    "#         self.policy.w.grad = -1*w_update\n",
    "                \n",
    "#         print(rot_update)\n",
    "#         print(enc_update)\n",
    "        \n",
    "#         self.variational_optim.step()\n",
    "#         self.encoding_optim.step()\n",
    "#         self.weight_optim.step()\n",
    "\n",
    "        print(self.policy.rot_param_vals.detach() - prev)\n",
    "        print(rot_update)\n",
    "        print(self.policy.enc_param_vals.detach() - prev1)\n",
    "        print(enc_update)\n",
    "        print(self.policy.w.detach() - prev2)\n",
    "        print(w_update)\n",
    "        \n",
    "        print('w', self.policy.w)\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             self.policy.rot_param_vals[self.policy.rot_param_vals > 2*np.pi] = 2*np.pi\n",
    "#             self.policy.enc_param_vals[self.policy.enc_param_vals > 2*np.pi] = 2*np.pi\n",
    "#             self.policy.rot_param_vals[self.policy.rot_param_vals < 0] = 0\n",
    "#             self.policy.enc_param_vals[self.policy.enc_param_vals < 0] = 0\n",
    "        \n",
    "#         print(self.policy.rot_param_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "n_qubits = 4 # Dimension of the state vectors in CartPole\n",
    "n_layers = 1\n",
    "n_actions = 2 # Number of actions in CartPole\n",
    "agent = QuantumAgent(input_state_dim = n_qubits, n_actions=n_actions, n_layers=n_layers, ansatz='base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1102.74x264.88 with 1 Axes>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.policy.circuit.draw('mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Episodes and Update Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_episodes(state_bounds, n_actions, agent, n_episodes, env_name):\n",
    "    \"\"\"Interact with environment in batched fashion.\"\"\"\n",
    "\n",
    "    trajectories = [defaultdict(list) for _ in range(n_episodes)]\n",
    "#     envs = [Curling() for _ in range(n_episodes)]\n",
    "    envs = [gym.make(env_name) for _ in range(n_episodes)]\n",
    "\n",
    "    done = [False for _ in range(n_episodes)]\n",
    "    states = [e.reset() for e in envs]\n",
    "\n",
    "    while not all(done):\n",
    "        unfinished_ids = [i for i in range(n_episodes) if not done[i]]\n",
    "        normalized_states = [s/state_bounds for i, s in enumerate(states) if not done[i]]\n",
    "\n",
    "        for i, state in zip(unfinished_ids, normalized_states):\n",
    "            trajectories[i]['states'].append(state)\n",
    "\n",
    "        states = torch.from_numpy(np.array(normalized_states))\n",
    "        action_probs = agent.get_actions(states)\n",
    "\n",
    "        # Store action and transition all environments to the next state\n",
    "        states = [None for i in range(n_episodes)]\n",
    "        for i, action_prob in zip(unfinished_ids, action_probs.detach().numpy()):\n",
    "            action = np.random.choice(n_actions, p=action_prob)\n",
    "            states[i], reward, done[i], _ = envs[i].step(action)\n",
    "            trajectories[i]['actions'].append(action)\n",
    "            trajectories[i]['rewards'].append(reward)\n",
    "            trajectories[i]['action probs'].append(action_prob)\n",
    "\n",
    "    return trajectories\n",
    "\n",
    "def compute_returns(rewards_history, gamma):\n",
    "    \"\"\"Compute discounted returns with discount factor `gamma`.\"\"\"\n",
    "    returns = []\n",
    "    discounted_sum = 0\n",
    "    for r in rewards_history[::-1]:\n",
    "        discounted_sum = r + gamma * discounted_sum\n",
    "        returns.insert(0, discounted_sum)\n",
    "\n",
    "    # Normalize them for faster and more stable learning\n",
    "    returns = np.array(returns)\n",
    "    returns = (returns - np.mean(returns)) / (np.std(returns) + 1e-8)\n",
    "    returns = returns.tolist()\n",
    "\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"CartPole-v1\"\n",
    "# env_name = \"Curling\"\n",
    "if env_name == \"CartPole-v1\":\n",
    "    state_bounds = np.array([2.4, 2.5, 0.21, 2.5])\n",
    "elif env_name == 'Curling':\n",
    "    state_bounds = np.array([3, 1])\n",
    "gamma = 1\n",
    "batch_size = 1\n",
    "n_episodes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b672b6813544f8b7af405c8a37d346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3476, -0.0182, -0.2247, -0.3546,  0.1404,  0.4691,  0.0420, -0.0100,\n",
      "         0.0692,  0.0450,  0.3570,  0.3596, -0.1506,  0.3944,  0.0000,  0.0093,\n",
      "         1.0075,  0.0000, -0.4409,  0.1262,  0.0000, -0.4058,  0.3539,  0.0000])\n",
      "tensor([ 6.9519e-02, -3.6385e-03, -4.4931e-02, -7.0915e-02,  2.8072e-02,\n",
      "         9.3813e-02,  8.3956e-03, -1.9982e-03,  1.3842e-02,  9.0005e-03,\n",
      "         7.1402e-02,  7.1912e-02, -3.0113e-02,  7.8889e-02, -1.7509e-17,\n",
      "         1.8668e-03,  2.0151e-01, -4.2719e-18, -8.8178e-02,  2.5239e-02,\n",
      "         0.0000e+00, -8.1158e-02,  7.0789e-02, -2.3165e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.1506,  0.0093, -0.4409, -0.4058])\n",
      "tensor([-0.0301,  0.0019, -0.0882, -0.0812], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-0.1909, -0.1909])\n",
      "tensor([-0.0382, -0.0382], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([-1.1909,  0.8091], requires_grad=True)\n",
      "tensor([[0.4271, 0.5729],\n",
      "        [0.4243, 0.5757],\n",
      "        [0.4273, 0.5727],\n",
      "        [0.4304, 0.5696],\n",
      "        [0.4276, 0.5724],\n",
      "        [0.4308, 0.5692],\n",
      "        [0.4280, 0.5720],\n",
      "        [0.4312, 0.5688],\n",
      "        [0.4285, 0.5715],\n",
      "        [0.4318, 0.5682],\n",
      "        [0.4291, 0.5709],\n",
      "        [0.4265, 0.5735],\n",
      "        [0.4296, 0.5704],\n",
      "        [0.4330, 0.5670],\n",
      "        [0.4304, 0.5696],\n",
      "        [0.4338, 0.5662],\n",
      "        [0.4375, 0.5625],\n",
      "        [0.4414, 0.5586],\n",
      "        [0.4456, 0.5544],\n",
      "        [0.4501, 0.5499]], dtype=torch.float64)\n",
      "Finished episode 1 Average rewards:  20.0\n",
      "tensor([-0.0328, -0.0994,  0.0170, -0.0128,  0.0624,  0.0607, -0.0480,  0.0003,\n",
      "        -0.0480,  0.0847,  0.0473,  0.0694,  0.0528,  0.0877,  0.0000, -0.1232,\n",
      "         0.0258,  0.0000, -0.1136,  0.0261,  0.0000, -0.0319,  0.1291,  0.0000])\n",
      "tensor([-6.5689e-03, -1.9882e-02,  3.4033e-03, -2.5693e-03,  1.2476e-02,\n",
      "         1.2136e-02, -9.6022e-03,  6.2231e-05, -9.6004e-03,  1.6949e-02,\n",
      "         9.4665e-03,  1.3870e-02,  1.0565e-02,  1.7531e-02,  7.4212e-18,\n",
      "        -2.4646e-02,  5.1585e-03,  3.5005e-19, -2.2718e-02,  5.2148e-03,\n",
      "         0.0000e+00, -6.3831e-03,  2.5812e-02, -1.0143e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 0.0482, -0.1237, -0.1361, -0.0444])\n",
      "tensor([ 0.0096, -0.0247, -0.0272, -0.0089], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.0399, 0.0399])\n",
      "tensor([0.0080, 0.0080], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([-1.1510,  0.8490], requires_grad=True)\n",
      "tensor([[0.5095, 0.4905],\n",
      "        [0.5159, 0.4841],\n",
      "        [0.5245, 0.4755],\n",
      "        [0.5237, 0.4763],\n",
      "        [0.5203, 0.4797],\n",
      "        [0.5266, 0.4734],\n",
      "        [0.5233, 0.4767],\n",
      "        [0.5297, 0.4703],\n",
      "        [0.5265, 0.4735],\n",
      "        [0.5209, 0.4791],\n",
      "        [0.5128, 0.4872],\n",
      "        [0.5150, 0.4850],\n",
      "        [0.5071, 0.4929],\n",
      "        [0.4967, 0.5033],\n",
      "        [0.4966, 0.5034],\n",
      "        [0.4861, 0.5139],\n",
      "        [0.4859, 0.5141],\n",
      "        [0.4879, 0.5121],\n",
      "        [0.4921, 0.5079],\n",
      "        [0.4986, 0.5014],\n",
      "        [0.5072, 0.4928],\n",
      "        [0.5180, 0.4820],\n",
      "        [0.5194, 0.4806],\n",
      "        [0.5181, 0.4819],\n",
      "        [0.5143, 0.4857],\n",
      "        [0.5080, 0.4920],\n",
      "        [0.4991, 0.5009],\n",
      "        [0.4877, 0.5123],\n",
      "        [0.4737, 0.5263],\n",
      "        [0.4700, 0.5300],\n",
      "        [0.4558, 0.5442],\n",
      "        [0.4517, 0.5483],\n",
      "        [0.4496, 0.5504],\n",
      "        [0.4372, 0.5628],\n",
      "        [0.4345, 0.5655],\n",
      "        [0.4214, 0.5786],\n",
      "        [0.4178, 0.5822]], dtype=torch.float64)\n",
      "Monitored episode 50 Average Monitored rewards:  16.58\n",
      "Finished episode 2 Average rewards:  16.0\n",
      "tensor([-0.0948, -0.4611,  0.0399,  0.0038,  0.2627,  0.2030, -0.2010,  0.0091,\n",
      "        -0.2190,  0.3896,  0.1754,  0.2921,  0.2302,  0.5233,  0.0000, -0.6181,\n",
      "        -0.0027,  0.0000, -0.4284,  0.4078,  0.0000, -0.0018,  0.7262,  0.0000])\n",
      "tensor([-1.8953e-02, -9.2226e-02,  7.9707e-03,  7.5635e-04,  5.2530e-02,\n",
      "         4.0594e-02, -4.0209e-02,  1.8156e-03, -4.3799e-02,  7.7924e-02,\n",
      "         3.5077e-02,  5.8429e-02,  4.6039e-02,  1.0466e-01,  8.4188e-18,\n",
      "        -1.2362e-01, -5.4650e-04,  1.5638e-17, -8.5683e-02,  8.1554e-02,\n",
      "         0.0000e+00, -3.5763e-04,  1.4525e-01,  4.1520e-20],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 0.2345, -0.6267, -0.4086,  0.0074])\n",
      "tensor([ 0.0469, -0.1253, -0.0817,  0.0015], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.2557, 0.2557])\n",
      "tensor([0.0511, 0.0511], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([-0.8954,  1.1046], requires_grad=True)\n",
      "tensor([[0.3570, 0.6430],\n",
      "        [0.3599, 0.6401],\n",
      "        [0.3592, 0.6408],\n",
      "        [0.3624, 0.6376],\n",
      "        [0.3682, 0.6318],\n",
      "        [0.3706, 0.6294],\n",
      "        [0.3767, 0.6233],\n",
      "        [0.3795, 0.6205],\n",
      "        [0.3860, 0.6140],\n",
      "        [0.3954, 0.6046],\n",
      "        [0.4015, 0.5985],\n",
      "        [0.4114, 0.5886],\n",
      "        [0.4181, 0.5819],\n",
      "        [0.4225, 0.5775],\n",
      "        [0.4308, 0.5692]], dtype=torch.float64)\n",
      "Finished episode 3 Average rewards:  15.0\n",
      "tensor([-4.0054e-05,  4.5693e-04,  6.3896e-05,  4.5946e-03,  3.5657e-03,\n",
      "        -1.7760e-03, -2.6885e-02,  1.5130e-03, -2.7250e-02, -1.5402e-03,\n",
      "         3.8338e-04,  1.7729e-03,  2.9880e-03,  1.7274e-02,  0.0000e+00,\n",
      "        -1.7689e-02, -1.2971e-02,  0.0000e+00,  1.5259e-03, -4.9470e-02,\n",
      "         0.0000e+00,  7.4005e-04,  2.7032e-02,  0.0000e+00])\n",
      "tensor([-8.0065e-06,  9.1386e-05,  1.2764e-05,  9.1892e-04,  7.1315e-04,\n",
      "        -3.5518e-04, -5.3770e-03,  3.0264e-04, -5.4499e-03, -3.0805e-04,\n",
      "         7.6638e-05,  3.5454e-04,  5.9760e-04,  3.4548e-03,  7.8441e-18,\n",
      "        -3.5379e-03, -2.5943e-03,  4.9621e-18,  3.0518e-04, -9.8940e-03,\n",
      "         0.0000e+00,  1.4802e-04,  5.4065e-03,  1.8047e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 0.0026, -0.0128,  0.0013,  0.0008])\n",
      "tensor([ 0.0005, -0.0026,  0.0003,  0.0002], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-0.0045, -0.0045])\n",
      "tensor([-0.0009, -0.0009], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([-0.8999,  1.1001], requires_grad=True)\n",
      "tensor([[0.4692, 0.5308],\n",
      "        [0.4568, 0.5432],\n",
      "        [0.4732, 0.5268],\n",
      "        [0.4859, 0.5141],\n",
      "        [0.4701, 0.5299],\n",
      "        [0.4584, 0.5416],\n",
      "        [0.4509, 0.5491],\n",
      "        [0.4475, 0.5525],\n",
      "        [0.4723, 0.5277],\n",
      "        [0.4931, 0.5069],\n",
      "        [0.5102, 0.4898],\n",
      "        [0.5241, 0.4759],\n",
      "        [0.5350, 0.4650],\n",
      "        [0.5429, 0.4571],\n",
      "        [0.5480, 0.4520],\n",
      "        [0.5256, 0.4744],\n",
      "        [0.5064, 0.4936],\n",
      "        [0.4909, 0.5091],\n",
      "        [0.4796, 0.5204],\n",
      "        [0.4724, 0.5276],\n",
      "        [0.4692, 0.5308],\n",
      "        [0.4940, 0.5060],\n",
      "        [0.4909, 0.5091],\n",
      "        [0.5147, 0.4853],\n",
      "        [0.5346, 0.4654],\n",
      "        [0.5286, 0.4714],\n",
      "        [0.5476, 0.4524],\n",
      "        [0.5420, 0.4580]], dtype=torch.float64)\n",
      "Finished episode 4 Average rewards:  28.0\n",
      "tensor([ 0.0151,  0.0249, -0.0130, -0.0371, -0.0252,  0.0164,  0.1083, -0.0051,\n",
      "         0.1086,  0.0027, -0.0004, -0.0019, -0.0475, -0.3002,  0.0000,  0.3404,\n",
      "         0.0681,  0.0000,  0.1381,  0.2945,  0.0000,  0.0083, -0.3665,  0.0000])\n",
      "tensor([ 3.0166e-03,  4.9712e-03, -2.5905e-03, -7.4182e-03, -5.0447e-03,\n",
      "         3.2833e-03,  2.1663e-02, -1.0282e-03,  2.1723e-02,  5.3370e-04,\n",
      "        -8.2115e-05, -3.8982e-04, -9.4952e-03, -6.0032e-02,  5.7916e-18,\n",
      "         6.8081e-02,  1.3622e-02,  1.8812e-17,  2.7613e-02,  5.8908e-02,\n",
      "         0.0000e+00,  1.6597e-03, -7.3300e-02, -1.5837e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.0481,  0.3566,  0.1295,  0.0087])\n",
      "tensor([-0.0096,  0.0713,  0.0259,  0.0017], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-0.0220, -0.0220])\n",
      "tensor([-0.0044, -0.0044], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([-0.9218,  1.0782], requires_grad=True)\n",
      "tensor([[0.4646, 0.5354],\n",
      "        [0.4524, 0.5476],\n",
      "        [0.4700, 0.5300],\n",
      "        [0.4831, 0.5169],\n",
      "        [0.4661, 0.5339],\n",
      "        [0.4792, 0.5208],\n",
      "        [0.4621, 0.5379],\n",
      "        [0.4498, 0.5502],\n",
      "        [0.4422, 0.5578],\n",
      "        [0.4642, 0.5358],\n",
      "        [0.4817, 0.5183],\n",
      "        [0.4693, 0.5307],\n",
      "        [0.4616, 0.5384],\n",
      "        [0.4586, 0.5414],\n",
      "        [0.4602, 0.5398],\n",
      "        [0.4906, 0.5094],\n",
      "        [0.4919, 0.5081],\n",
      "        [0.5208, 0.4792],\n",
      "        [0.5216, 0.4784],\n",
      "        [0.5258, 0.4742],\n",
      "        [0.5533, 0.4467]], dtype=torch.float64)\n",
      "Finished episode 5 Average rewards:  21.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0224,  0.2339,  0.0341, -0.2482, -0.1506,  0.1201, -0.6626,  0.0252,\n",
      "        -0.6697, -0.2035,  0.0097,  0.0551,  0.1476,  0.3472,  0.0000, -0.4889,\n",
      "         0.0451,  0.0000, -0.0382,  0.8231,  0.0000,  0.0493,  0.3863,  0.0000])\n",
      "tensor([-4.4804e-03,  4.6785e-02,  6.8274e-03, -4.9634e-02, -3.0121e-02,\n",
      "         2.4012e-02, -1.3253e-01,  5.0444e-03, -1.3394e-01, -4.0696e-02,\n",
      "         1.9425e-03,  1.1014e-02,  2.9519e-02,  6.9440e-02,  6.0178e-18,\n",
      "        -9.7788e-02,  9.0131e-03, -5.0909e-17, -7.6326e-03,  1.6462e-01,\n",
      "         0.0000e+00,  9.8644e-03,  7.7257e-02, -3.7790e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 0.1473, -0.4903, -0.0327,  0.0505])\n",
      "tensor([ 0.0295, -0.0981, -0.0065,  0.0101], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-1.0168, -1.0168])\n",
      "tensor([-0.2034, -0.2034], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([-1.9386,  0.0614], requires_grad=True)\n",
      "tensor([[0.2123, 0.7877],\n",
      "        [0.2113, 0.7887],\n",
      "        [0.2129, 0.7871],\n",
      "        [0.2141, 0.7859],\n",
      "        [0.2125, 0.7875],\n",
      "        [0.2137, 0.7863],\n",
      "        [0.2145, 0.7855],\n",
      "        [0.2148, 0.7852],\n",
      "        [0.2147, 0.7853],\n",
      "        [0.2118, 0.7882],\n",
      "        [0.2119, 0.7881],\n",
      "        [0.2117, 0.7883],\n",
      "        [0.2114, 0.7886],\n",
      "        [0.2111, 0.7889],\n",
      "        [0.2111, 0.7889]], dtype=torch.float64)\n",
      "Finished episode 6 Average rewards:  15.0\n",
      "tensor([-0.0134,  0.2649,  0.0386, -0.2191, -0.0693,  0.1319,  0.0298, -0.0203,\n",
      "         0.0330, -0.1219,  0.0266,  0.0670, -0.0751, -0.5904,  0.0000,  0.9481,\n",
      "         0.1032,  0.0000,  0.4178, -0.3248,  0.0000,  0.0412, -0.6660,  0.0000])\n",
      "tensor([-2.6811e-03,  5.2978e-02,  7.7279e-03, -4.3820e-02, -1.3867e-02,\n",
      "         2.6390e-02,  5.9639e-03, -4.0501e-03,  6.5920e-03, -2.4383e-02,\n",
      "         5.3183e-03,  1.3390e-02, -1.5013e-02, -1.1807e-01, -5.3791e-19,\n",
      "         1.8962e-01,  2.0643e-02, -7.8552e-18,  8.3554e-02, -6.4969e-02,\n",
      "         0.0000e+00,  8.2458e-03, -1.3320e-01,  4.3208e-19],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.0890,  0.8224,  0.5735,  0.0366])\n",
      "tensor([-0.0178,  0.1645,  0.1147,  0.0073], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-0.3395, -0.3395])\n",
      "tensor([-0.0679, -0.0679], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([-2.2781, -0.2781], requires_grad=True)\n",
      "tensor([[0.4491, 0.5509],\n",
      "        [0.4635, 0.5365],\n",
      "        [0.4455, 0.5545],\n",
      "        [0.4313, 0.5687],\n",
      "        [0.4203, 0.5797],\n",
      "        [0.4405, 0.5595],\n",
      "        [0.4576, 0.5424],\n",
      "        [0.4712, 0.5288],\n",
      "        [0.4811, 0.5189],\n",
      "        [0.4584, 0.5416],\n",
      "        [0.4396, 0.5604],\n",
      "        [0.4524, 0.5476],\n",
      "        [0.4336, 0.5664],\n",
      "        [0.4457, 0.5543],\n",
      "        [0.4542, 0.5458],\n",
      "        [0.4588, 0.5412],\n",
      "        [0.4332, 0.5668],\n",
      "        [0.4372, 0.5628],\n",
      "        [0.4132, 0.5868],\n",
      "        [0.3938, 0.6062],\n",
      "        [0.3782, 0.6218],\n",
      "        [0.3654, 0.6346],\n",
      "        [0.3549, 0.6451],\n",
      "        [0.3459, 0.6541],\n",
      "        [0.3382, 0.6618],\n",
      "        [0.3315, 0.6685],\n",
      "        [0.3439, 0.6561],\n",
      "        [0.3559, 0.6441],\n",
      "        [0.3461, 0.6539],\n",
      "        [0.3379, 0.6621],\n",
      "        [0.3310, 0.6690],\n",
      "        [0.3253, 0.6747],\n",
      "        [0.3210, 0.6790],\n",
      "        [0.3184, 0.6816],\n",
      "        [0.3180, 0.6820],\n",
      "        [0.3205, 0.6795],\n",
      "        [0.3269, 0.6731],\n",
      "        [0.3385, 0.6615],\n",
      "        [0.3565, 0.6435],\n",
      "        [0.4061, 0.5939]], dtype=torch.float64)\n",
      "Monitored episode 50 Average Monitored rewards:  18.94\n",
      "Finished episode 7 Average rewards:  12.0\n",
      "tensor([ 0.0517, -0.3934, -0.0945,  0.2595,  0.0649, -0.1612, -0.1879,  0.0908,\n",
      "        -0.2021,  0.1107,  0.1284,  0.1986,  0.1801,  0.4199,  0.0000, -0.1687,\n",
      "        -0.3746,  0.0000, -0.2976, -0.0776,  0.0000,  0.0308,  0.5203,  0.0000])\n",
      "tensor([ 1.0338e-02, -7.8674e-02, -1.8900e-02,  5.1898e-02,  1.2981e-02,\n",
      "        -3.2237e-02, -3.7575e-02,  1.8159e-02, -4.0430e-02,  2.2131e-02,\n",
      "         2.5675e-02,  3.9721e-02,  3.6023e-02,  8.3971e-02, -9.2612e-18,\n",
      "        -3.3745e-02, -7.4923e-02, -6.2341e-18, -5.9528e-02, -1.5524e-02,\n",
      "         0.0000e+00,  6.1603e-03,  1.0406e-01, -5.2401e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 0.2200, -0.2185, -0.2782,  0.0553])\n",
      "tensor([ 0.0440, -0.0437, -0.0556,  0.0111], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.2431, 0.2431])\n",
      "tensor([0.0486, 0.0486], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([-2.0350, -0.0350], requires_grad=True)\n",
      "tensor([[0.6111, 0.3889],\n",
      "        [0.6118, 0.3882],\n",
      "        [0.6131, 0.3869],\n",
      "        [0.6150, 0.3850],\n",
      "        [0.6177, 0.3823],\n",
      "        [0.6209, 0.3791],\n",
      "        [0.6238, 0.3762],\n",
      "        [0.6269, 0.3731],\n",
      "        [0.6306, 0.3694],\n",
      "        [0.6342, 0.3658]], dtype=torch.float64)\n",
      "Finished episode 8 Average rewards:  10.0\n",
      "tensor([ 0.0067, -0.0421, -0.0088,  0.0382,  0.0583, -0.0019,  0.0883, -0.0166,\n",
      "         0.0887,  0.0200, -0.0099, -0.0250,  0.0444,  0.1632,  0.0000, -0.1319,\n",
      "        -0.0987,  0.0000, -0.0846,  0.3933,  0.0000,  0.0038,  0.1991,  0.0000])\n",
      "tensor([ 1.3465e-03, -8.4253e-03, -1.7641e-03,  7.6326e-03,  1.1667e-02,\n",
      "        -3.8342e-04,  1.7666e-02, -3.3293e-03,  1.7746e-02,  3.9911e-03,\n",
      "        -1.9757e-03, -5.0080e-03,  8.8895e-03,  3.2647e-02,  8.1147e-18,\n",
      "        -2.6372e-02, -1.9743e-02,  1.7371e-17, -1.6915e-02,  7.8663e-02,\n",
      "         0.0000e+00,  7.6000e-04,  3.9820e-02,  6.9643e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 0.0610, -0.1684, -0.1867,  0.0060])\n",
      "tensor([ 0.0122, -0.0337, -0.0373,  0.0012], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.0218, 0.0218])\n",
      "tensor([0.0044, 0.0044], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([-2.0132, -0.0132], requires_grad=True)\n",
      "tensor([[0.7180, 0.2820],\n",
      "        [0.7180, 0.2820],\n",
      "        [0.7174, 0.2826],\n",
      "        [0.7161, 0.2839],\n",
      "        [0.7155, 0.2845],\n",
      "        [0.7143, 0.2857],\n",
      "        [0.7125, 0.2875],\n",
      "        [0.7098, 0.2902],\n",
      "        [0.7062, 0.2938],\n",
      "        [0.7031, 0.2969],\n",
      "        [0.7007, 0.2993],\n",
      "        [0.6975, 0.3025],\n",
      "        [0.6932, 0.3068]], dtype=torch.float64)\n",
      "Finished episode 9 Average rewards:  13.0\n",
      "tensor([-0.0133, -0.0235,  0.0109,  0.0047,  0.0108,  0.0013,  0.0006,  0.0030,\n",
      "         0.0002,  0.0507, -0.0237, -0.0630, -0.0121, -0.0677,  0.0000,  0.0836,\n",
      "         0.0286,  0.0000,  0.0641,  0.0608,  0.0000,  0.0014, -0.1239,  0.0000])\n",
      "tensor([-2.6507e-03, -4.6901e-03,  2.1763e-03,  9.3468e-04,  2.1688e-03,\n",
      "         2.6070e-04,  1.1773e-04,  5.9989e-04,  3.5947e-05,  1.0148e-02,\n",
      "        -4.7415e-03, -1.2608e-02, -2.4288e-03, -1.3538e-02,  8.9384e-18,\n",
      "         1.6716e-02,  5.7178e-03,  5.9347e-18,  1.2816e-02,  1.2162e-02,\n",
      "         0.0000e+00,  2.8350e-04, -2.4783e-02, -4.3707e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.0063,  0.1350, -0.0828, -0.0130])\n",
      "tensor([-0.0013,  0.0270, -0.0166, -0.0026], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.0697, 0.0697])\n",
      "tensor([0.0139, 0.0139], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([-1.9435,  0.0565], requires_grad=True)\n",
      "tensor([[0.5957, 0.4043],\n",
      "        [0.5990, 0.4010],\n",
      "        [0.5933, 0.4067],\n",
      "        [0.5911, 0.4089],\n",
      "        [0.5979, 0.4021],\n",
      "        [0.5956, 0.4044],\n",
      "        [0.5968, 0.4032],\n",
      "        [0.6071, 0.3929],\n",
      "        [0.6137, 0.3863],\n",
      "        [0.6170, 0.3830],\n",
      "        [0.6170, 0.3830],\n",
      "        [0.6136, 0.3864],\n",
      "        [0.6068, 0.3932],\n",
      "        [0.5965, 0.4035],\n",
      "        [0.5823, 0.4177],\n",
      "        [0.5587, 0.4413],\n",
      "        [0.5441, 0.4559],\n",
      "        [0.5204, 0.4796],\n",
      "        [0.5006, 0.4994],\n",
      "        [0.4895, 0.5105]], dtype=torch.float64)\n",
      "Finished episode 10 Average rewards:  20.0\n",
      "tensor([-0.0215, -0.0777,  0.0155,  0.0424,  0.0884,  0.0069,  0.0216, -0.0043,\n",
      "         0.0218,  0.0853, -0.0311, -0.0957,  0.0265,  0.0929,  0.0000, -0.0738,\n",
      "        -0.0657,  0.0000, -0.0958,  0.2163,  0.0000, -0.0045,  0.1125,  0.0000])\n",
      "tensor([-4.3066e-03, -1.5538e-02,  3.0986e-03,  8.4817e-03,  1.7682e-02,\n",
      "         1.3826e-03,  4.3166e-03, -8.5067e-04,  4.3558e-03,  1.7059e-02,\n",
      "        -6.2202e-03, -1.9140e-02,  5.2940e-03,  1.8573e-02, -1.0149e-17,\n",
      "        -1.4762e-02, -1.3148e-02,  2.3536e-17, -1.9155e-02,  4.3269e-02,\n",
      "         0.0000e+00, -9.0706e-04,  2.2493e-02, -3.1574e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 0.0569, -0.1301, -0.4440, -0.0107])\n",
      "tensor([ 0.0114, -0.0260, -0.0888, -0.0021], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.1816, 0.1816])\n",
      "tensor([0.0363, 0.0363], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([-1.7619,  0.2381], requires_grad=True)\n",
      "tensor([[0.7114, 0.2886],\n",
      "        [0.7111, 0.2889],\n",
      "        [0.7153, 0.2847],\n",
      "        [0.7163, 0.2837],\n",
      "        [0.7142, 0.2858],\n",
      "        [0.7090, 0.2910],\n",
      "        [0.7003, 0.2997],\n",
      "        [0.6876, 0.3124],\n",
      "        [0.6700, 0.3300],\n",
      "        [0.6470, 0.3530],\n",
      "        [0.6180, 0.3820],\n",
      "        [0.5831, 0.4169]], dtype=torch.float64)\n",
      "Finished episode 11 Average rewards:  12.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0912, -0.1729,  0.0779,  0.0442,  0.1474,  0.0277,  0.0296,  0.0157,\n",
      "         0.0269,  0.2254, -0.0729, -0.2847, -0.0150, -0.1645,  0.0000,  0.1509,\n",
      "         0.1378,  0.0000,  0.1724,  0.3286,  0.0000, -0.0250, -0.2830,  0.0000])\n",
      "tensor([-1.8240e-02, -3.4577e-02,  1.5589e-02,  8.8446e-03,  2.9487e-02,\n",
      "         5.5494e-03,  5.9192e-03,  3.1309e-03,  5.3767e-03,  4.5081e-02,\n",
      "        -1.4570e-02, -5.6933e-02, -3.0087e-03, -3.2903e-02, -5.2574e-18,\n",
      "         3.0175e-02,  2.7556e-02,  1.4360e-17,  3.4481e-02,  6.5722e-02,\n",
      "         0.0000e+00, -4.9994e-03, -5.6606e-02,  2.7407e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.0008,  0.1794, -0.2490, -0.0627])\n",
      "tensor([-0.0002,  0.0359, -0.0498, -0.0125], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.6154, 0.6154])\n",
      "tensor([0.1231, 0.1231], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([-1.1465,  0.8535], requires_grad=True)\n",
      "tensor([[0.6409, 0.3591],\n",
      "        [0.6388, 0.3612],\n",
      "        [0.6463, 0.3537],\n",
      "        [0.6685, 0.3315],\n",
      "        [0.6759, 0.3241],\n",
      "        [0.6915, 0.3085],\n",
      "        [0.7185, 0.2815],\n",
      "        [0.7362, 0.2638],\n",
      "        [0.7429, 0.2571],\n",
      "        [0.7588, 0.2412],\n",
      "        [0.7685, 0.2315],\n",
      "        [0.7737, 0.2263],\n",
      "        [0.7752, 0.2248],\n",
      "        [0.7731, 0.2269],\n",
      "        [0.7671, 0.2329],\n",
      "        [0.7560, 0.2440],\n",
      "        [0.7382, 0.2618],\n",
      "        [0.7111, 0.2889],\n",
      "        [0.6666, 0.3334],\n",
      "        [0.6314, 0.3686],\n",
      "        [0.5773, 0.4227],\n",
      "        [0.5314, 0.4686],\n",
      "        [0.4957, 0.5043],\n",
      "        [0.4769, 0.5231],\n",
      "        [0.4420, 0.5580],\n",
      "        [0.4236, 0.5764],\n",
      "        [0.3912, 0.6088],\n",
      "        [0.3688, 0.6312],\n",
      "        [0.3543, 0.6457],\n",
      "        [0.3510, 0.6490],\n",
      "        [0.3407, 0.6593],\n",
      "        [0.3212, 0.6788],\n",
      "        [0.3123, 0.6877]], dtype=torch.float64)\n",
      "Monitored episode 50 Average Monitored rewards:  12.98\n",
      "Finished episode 12 Average rewards:  13.0\n",
      "tensor([ 0.0479, -0.0388, -0.0488,  0.0310,  0.0590, -0.0061,  0.0279,  0.0156,\n",
      "         0.0253,  0.0168,  0.0008,  0.0124,  0.0164,  0.1124,  0.0000, -0.0652,\n",
      "        -0.0557,  0.0000, -0.0848, -0.0306,  0.0000,  0.0002,  0.1246,  0.0000])\n",
      "tensor([ 9.5743e-03, -7.7589e-03, -9.7684e-03,  6.1973e-03,  1.1795e-02,\n",
      "        -1.2158e-03,  5.5756e-03,  3.1127e-03,  5.0680e-03,  3.3509e-03,\n",
      "         1.5657e-04,  2.4845e-03,  3.2861e-03,  2.2478e-02, -1.8092e-17,\n",
      "        -1.3048e-02, -1.1143e-02, -8.1789e-18, -1.6955e-02, -6.1139e-03,\n",
      "         0.0000e+00,  3.2232e-05,  2.4917e-02,  1.6702e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 0.0326, -0.1205, -0.2913,  0.0035])\n",
      "tensor([ 0.0065, -0.0241, -0.0583,  0.0007], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.3058, 0.3058])\n",
      "tensor([0.0612, 0.0612], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([-0.8407,  1.1593], requires_grad=True)\n",
      "tensor([[0.8266, 0.1734],\n",
      "        [0.8257, 0.1743],\n",
      "        [0.8187, 0.1813],\n",
      "        [0.8179, 0.1821],\n",
      "        [0.8105, 0.1895],\n",
      "        [0.7947, 0.2053],\n",
      "        [0.7667, 0.2333],\n",
      "        [0.7208, 0.2792],\n",
      "        [0.6495, 0.3505],\n",
      "        [0.5487, 0.4513],\n",
      "        [0.4272, 0.5728]], dtype=torch.float64)\n",
      "Finished episode 13 Average rewards:  11.0\n",
      "tensor([ 1.0490e-04,  4.0459e-02,  6.9380e-04, -2.5547e-02, -6.6376e-02,\n",
      "         6.9833e-04, -5.9721e-02, -1.6875e-02, -5.6772e-02, -2.1287e-02,\n",
      "         7.1001e-04,  1.9835e-02,  1.0219e-02,  7.0376e-02,  0.0000e+00,\n",
      "        -7.0651e-02, -5.0562e-02,  0.0000e+00, -1.0946e-01, -7.4828e-02,\n",
      "         0.0000e+00,  2.0981e-04,  7.8216e-02,  0.0000e+00])\n",
      "tensor([ 2.0998e-05,  8.0917e-03,  1.3874e-04, -5.1094e-03, -1.3275e-02,\n",
      "         1.3969e-04, -1.1944e-02, -3.3749e-03, -1.1354e-02, -4.2575e-03,\n",
      "         1.4196e-04,  3.9671e-03,  2.0438e-03,  1.4075e-02, -3.6458e-18,\n",
      "        -1.4130e-02, -1.0112e-02,  5.7573e-19, -2.1892e-02, -1.4966e-02,\n",
      "         0.0000e+00,  4.1972e-05,  1.5643e-02, -4.3326e-19],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 0.0150, -0.0823, -0.1700,  0.0003])\n",
      "tensor([ 3.0021e-03, -1.6466e-02, -3.3998e-02,  6.3642e-05],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.5007, -0.5007])\n",
      "tensor([-0.1001, -0.1001], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([-1.3414,  0.6586], requires_grad=True)\n",
      "tensor([[0.8198, 0.1802],\n",
      "        [0.8199, 0.1801],\n",
      "        [0.8117, 0.1883],\n",
      "        [0.7928, 0.2072],\n",
      "        [0.7583, 0.2417],\n",
      "        [0.6956, 0.3044],\n",
      "        [0.6386, 0.3614],\n",
      "        [0.6014, 0.3986],\n",
      "        [0.5402, 0.4598],\n",
      "        [0.4501, 0.5499],\n",
      "        [0.3845, 0.6155],\n",
      "        [0.3419, 0.6581],\n",
      "        [0.3222, 0.6778],\n",
      "        [0.2839, 0.7161],\n",
      "        [0.2618, 0.7382],\n",
      "        [0.2514, 0.7486],\n",
      "        [0.2504, 0.7496],\n",
      "        [0.2623, 0.7377],\n",
      "        [0.2574, 0.7426],\n",
      "        [0.2621, 0.7379],\n",
      "        [0.2776, 0.7224],\n",
      "        [0.3070, 0.6930],\n",
      "        [0.3605, 0.6395],\n",
      "        [0.3999, 0.6001],\n",
      "        [0.4136, 0.5864],\n",
      "        [0.4462, 0.5538],\n",
      "        [0.5056, 0.4944],\n",
      "        [0.5421, 0.4579],\n",
      "        [0.5551, 0.4449],\n",
      "        [0.5452, 0.4548],\n",
      "        [0.5122, 0.4878],\n",
      "        [0.4509, 0.5491],\n",
      "        [0.4111, 0.5889],\n",
      "        [0.3965, 0.6035],\n",
      "        [0.3568, 0.6432],\n",
      "        [0.3354, 0.6646],\n",
      "        [0.3295, 0.6705],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3328, 0.6672],\n",
      "        [0.3372, 0.6628],\n",
      "        [0.3624, 0.6376],\n",
      "        [0.3680, 0.6320],\n",
      "        [0.3484, 0.6516],\n",
      "        [0.3447, 0.6553],\n",
      "        [0.3618, 0.6382],\n",
      "        [0.3538, 0.6462],\n",
      "        [0.3616, 0.6384],\n",
      "        [0.3863, 0.6137],\n",
      "        [0.4305, 0.5695],\n",
      "        [0.4967, 0.5033],\n",
      "        [0.5839, 0.4161],\n",
      "        [0.6869, 0.3131],\n",
      "        [0.7529, 0.2471],\n",
      "        [0.7919, 0.2081],\n",
      "        [0.8110, 0.1890],\n",
      "        [0.8364, 0.1636],\n",
      "        [0.8497, 0.1503],\n",
      "        [0.8560, 0.1440],\n",
      "        [0.8577, 0.1423],\n",
      "        [0.8557, 0.1443],\n",
      "        [0.8490, 0.1510],\n",
      "        [0.8350, 0.1650],\n",
      "        [0.8089, 0.1911],\n",
      "        [0.7619, 0.2381],\n",
      "        [0.6819, 0.3181],\n",
      "        [0.5592, 0.4408],\n",
      "        [0.4019, 0.5981],\n",
      "        [0.2913, 0.7087],\n",
      "        [0.2274, 0.7726],\n",
      "        [0.1946, 0.8054]], dtype=torch.float64)\n",
      "Finished episode 14 Average rewards:  70.0\n",
      "tensor([ 0.0749,  0.0960, -0.0715, -0.0009, -0.0801, -0.0296, -0.2465, -0.0457,\n",
      "        -0.2369, -0.0616,  0.0047,  0.0832,  0.0584,  0.4668,  0.0000, -0.4464,\n",
      "        -0.3974,  0.0000, -0.7151, -0.1289,  0.0000, -0.0128,  0.6176,  0.0000])\n",
      "tensor([ 1.4982e-02,  1.9193e-02, -1.4306e-02, -1.7587e-04, -1.6024e-02,\n",
      "        -5.9188e-03, -4.9291e-02, -9.1409e-03, -4.7376e-02, -1.2323e-02,\n",
      "         9.4690e-04,  1.6630e-02,  1.1682e-02,  9.3359e-02,  1.1946e-17,\n",
      "        -8.9273e-02, -7.9480e-02, -1.7553e-17, -1.4303e-01, -2.5788e-02,\n",
      "         0.0000e+00, -2.5571e-03,  1.2352e-01,  4.4323e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 0.0492, -0.3509, -0.6129, -0.0093])\n",
      "tensor([ 0.0098, -0.0702, -0.1226, -0.0019], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-0.8555, -0.8555])\n",
      "tensor([-0.1711, -0.1711], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([-2.1969, -0.1969], requires_grad=True)\n",
      "tensor([[0.6877, 0.3123],\n",
      "        [0.6920, 0.3080],\n",
      "        [0.6781, 0.3219],\n",
      "        [0.6443, 0.3557],\n",
      "        [0.5779, 0.4221],\n",
      "        [0.5305, 0.4695],\n",
      "        [0.5048, 0.4952],\n",
      "        [0.5010, 0.4990],\n",
      "        [0.5190, 0.4810],\n",
      "        [0.5589, 0.4411],\n",
      "        [0.6277, 0.3723],\n",
      "        [0.6627, 0.3373],\n",
      "        [0.7126, 0.2874],\n",
      "        [0.7738, 0.2262],\n",
      "        [0.8087, 0.1913],\n",
      "        [0.8276, 0.1724],\n",
      "        [0.8367, 0.1633],\n",
      "        [0.8393, 0.1607],\n",
      "        [0.8362, 0.1638],\n",
      "        [0.8265, 0.1735],\n",
      "        [0.8067, 0.1933],\n",
      "        [0.7707, 0.2293],\n",
      "        [0.7086, 0.2914],\n",
      "        [0.6100, 0.3900],\n",
      "        [0.4762, 0.5238],\n",
      "        [0.3379, 0.6621],\n",
      "        [0.2353, 0.7647],\n",
      "        [0.2026, 0.7974]], dtype=torch.float64)\n",
      "Finished episode 15 Average rewards:  28.0\n",
      "tensor([-0.4124, -0.1396,  0.3975, -0.0576,  0.2537,  0.1606,  0.1363,  0.0565,\n",
      "         0.1279,  0.0574, -0.0205, -0.1718, -0.1052, -0.2740,  0.0000, -0.0260,\n",
      "         0.1943,  0.0000, -0.1301, -0.0532,  0.0000, -0.1656, -0.0113,  0.0000])\n",
      "tensor([-8.2473e-02, -2.7914e-02,  7.9496e-02, -1.1514e-02,  5.0730e-02,\n",
      "         3.2118e-02,  2.7258e-02,  1.1303e-02,  2.5582e-02,  1.1490e-02,\n",
      "        -4.1086e-03, -3.4369e-02, -2.1048e-02, -5.4791e-02, -1.2316e-18,\n",
      "        -5.2093e-03,  3.8854e-02, -3.3718e-18, -2.6021e-02, -1.0638e-02,\n",
      "         0.0000e+00, -3.3126e-02, -2.2599e-03, -3.0912e-19],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.2734, -0.6469,  0.2951, -0.1266])\n",
      "tensor([-0.0547, -0.1294,  0.0590, -0.0253], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.7130, 0.7130])\n",
      "tensor([0.1426, 0.1426], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([-1.4839,  0.5161], requires_grad=True)\n",
      "tensor([[0.2187, 0.7813],\n",
      "        [0.2203, 0.7797],\n",
      "        [0.2207, 0.7793],\n",
      "        [0.2212, 0.7788],\n",
      "        [0.2253, 0.7747],\n",
      "        [0.2393, 0.7607],\n",
      "        [0.2571, 0.7429],\n",
      "        [0.2901, 0.7099],\n",
      "        [0.3458, 0.6542],\n",
      "        [0.4375, 0.5625],\n",
      "        [0.5179, 0.4821],\n",
      "        [0.5629, 0.4371]], dtype=torch.float64)\n",
      "Finished episode 16 Average rewards:  12.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3195, -0.0527, -0.3211,  0.2256,  0.1481, -0.1847, -0.3721, -0.0504,\n",
      "        -0.3625,  0.0649, -0.0125, -0.1970,  0.0681, -0.5165,  0.0000,  0.6518,\n",
      "        -0.5990,  0.0000,  1.0066,  0.7149,  0.0000,  0.2726, -0.9529,  0.0000])\n",
      "tensor([ 6.3891e-02, -1.0549e-02, -6.4220e-02,  4.5114e-02,  2.9623e-02,\n",
      "        -3.6932e-02, -7.4428e-02, -1.0086e-02, -7.2491e-02,  1.2981e-02,\n",
      "        -2.5022e-03, -3.9404e-02,  1.3620e-02, -1.0329e-01, -4.5520e-17,\n",
      "         1.3036e-01, -1.1979e-01, -4.3353e-18,  2.0131e-01,  1.4297e-01,\n",
      "         0.0000e+00,  5.4517e-02, -1.9059e-01, -8.6706e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([0.0392, 0.1751, 1.1366, 0.1987])\n",
      "tensor([0.0078, 0.0350, 0.2273, 0.0397], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.6207, 0.6207])\n",
      "tensor([0.1241, 0.1241], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([-0.8632,  1.1368], requires_grad=True)\n",
      "tensor([[0.1558, 0.8442],\n",
      "        [0.1559, 0.8441],\n",
      "        [0.1554, 0.8446],\n",
      "        [0.1550, 0.8450],\n",
      "        [0.1575, 0.8425],\n",
      "        [0.1677, 0.8323],\n",
      "        [0.1931, 0.8069],\n",
      "        [0.2452, 0.7548],\n",
      "        [0.3365, 0.6635]], dtype=torch.float64)\n",
      "Monitored episode 50 Average Monitored rewards:  28.52\n",
      "Finished episode 17 Average rewards:  15.0\n",
      "tensor([-4.1603e-01,  6.7922e-03,  4.1587e-01,  1.4884e-01, -8.9196e-03,\n",
      "        -1.4889e-01, -4.9622e-01,  4.9798e-02, -4.8675e-01,  1.8601e-02,\n",
      "         2.4319e-05, -2.4130e-01,  4.3157e-02, -4.5470e-01,  0.0000e+00,\n",
      "         2.2954e-02,  1.7042e-01,  0.0000e+00, -7.4175e-01,  6.1471e-01,\n",
      "         0.0000e+00,  2.7796e-02, -2.9620e-01,  0.0000e+00])\n",
      "tensor([-8.3206e-02,  1.3584e-03,  8.3174e-02,  2.9769e-02, -1.7839e-03,\n",
      "        -2.9778e-02, -9.9245e-02,  9.9597e-03, -9.7350e-02,  3.7202e-03,\n",
      "         4.8324e-06, -4.8260e-02,  8.6313e-03, -9.0941e-02, -9.0735e-18,\n",
      "         4.5907e-03,  3.4084e-02,  1.0711e-17, -1.4835e-01,  1.2294e-01,\n",
      "         0.0000e+00,  5.5592e-03, -5.9239e-02, -4.4397e-19],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 0.0629,  0.0151, -0.8226,  0.0301])\n",
      "tensor([ 0.0126,  0.0030, -0.1645,  0.0060], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.0343, 0.0343])\n",
      "tensor([0.0069, 0.0069], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([-0.8289,  1.1711], requires_grad=True)\n",
      "tensor([[0.4025, 0.5975],\n",
      "        [0.4025, 0.5975],\n",
      "        [0.3948, 0.6052],\n",
      "        [0.3937, 0.6063],\n",
      "        [0.3993, 0.6007],\n",
      "        [0.4121, 0.5879],\n",
      "        [0.4330, 0.5670],\n",
      "        [0.4626, 0.5374],\n",
      "        [0.5014, 0.4986],\n",
      "        [0.5466, 0.4534],\n",
      "        [0.5815, 0.4185],\n",
      "        [0.6070, 0.3930],\n",
      "        [0.6246, 0.3754],\n",
      "        [0.6358, 0.3642],\n",
      "        [0.6419, 0.3581],\n",
      "        [0.6438, 0.3562],\n",
      "        [0.6419, 0.3581],\n",
      "        [0.6396, 0.3604],\n",
      "        [0.6431, 0.3569],\n",
      "        [0.6486, 0.3514],\n",
      "        [0.6503, 0.3497],\n",
      "        [0.6520, 0.3480],\n",
      "        [0.6553, 0.3447]], dtype=torch.float64)\n",
      "Finished episode 18 Average rewards:  23.0\n",
      "tensor([ 7.5598e-02, -1.3256e-04, -7.5546e-02, -6.4254e-02,  1.7977e-02,\n",
      "         6.7881e-02,  1.6705e-01,  4.2812e-02,  1.6726e-01,  1.4142e-02,\n",
      "         2.5616e-03, -1.3757e-01, -1.4393e-02,  8.4589e-02,  0.0000e+00,\n",
      "        -2.2694e-02, -2.5333e-02,  0.0000e+00,  1.0817e-02, -1.5746e-01,\n",
      "         0.0000e+00,  1.0984e-01,  1.2018e-02,  0.0000e+00])\n",
      "tensor([ 1.5120e-02, -2.6516e-05, -1.5109e-02, -1.2851e-02,  3.5953e-03,\n",
      "         1.3576e-02,  3.3411e-02,  8.5624e-03,  3.3453e-02,  2.8285e-03,\n",
      "         5.1233e-04, -2.7513e-02, -2.8786e-03,  1.6918e-02, -7.9714e-18,\n",
      "        -4.5388e-03, -5.0666e-03, -1.2944e-18,  2.1635e-03, -3.1493e-02,\n",
      "         0.0000e+00,  2.1967e-02,  2.4037e-03, -5.7079e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.0283, -0.0342,  0.0002,  0.1314])\n",
      "tensor([-5.6680e-03, -6.8400e-03,  3.1387e-05,  2.6286e-02],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([0.2697, 0.2697])\n",
      "tensor([0.0539, 0.0539], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([-0.5592,  1.4408], requires_grad=True)\n",
      "tensor([[0.5296, 0.4704],\n",
      "        [0.5332, 0.4668],\n",
      "        [0.5366, 0.4634],\n",
      "        [0.5333, 0.4667],\n",
      "        [0.5299, 0.4701],\n",
      "        [0.5328, 0.4672],\n",
      "        [0.5354, 0.4646],\n",
      "        [0.5313, 0.4687],\n",
      "        [0.5272, 0.4728],\n",
      "        [0.5293, 0.4707],\n",
      "        [0.5310, 0.4690],\n",
      "        [0.5326, 0.4674],\n",
      "        [0.5403, 0.4597],\n",
      "        [0.5545, 0.4455],\n",
      "        [0.5756, 0.4244],\n",
      "        [0.6041, 0.3959],\n",
      "        [0.6388, 0.3612],\n",
      "        [0.6764, 0.3236],\n",
      "        [0.7097, 0.2903],\n",
      "        [0.7285, 0.2715],\n",
      "        [0.7363, 0.2637],\n",
      "        [0.7368, 0.2632]], dtype=torch.float64)\n",
      "Finished episode 19 Average rewards:  22.0\n",
      "tensor([-0.5620,  0.0361,  0.5625,  0.4203, -0.0029, -0.4173, -0.5175,  0.0080,\n",
      "        -0.5136,  0.0645,  0.0166, -0.5098,  0.1728, -0.5835,  0.0000,  0.1319,\n",
      "         0.0869,  0.0000, -0.6289,  0.1793,  0.0000,  0.1428, -0.5314,  0.0000])\n",
      "tensor([-1.1241e-01,  7.2163e-03,  1.1250e-01,  8.4059e-02, -5.8137e-04,\n",
      "        -8.3464e-02, -1.0351e-01,  1.6089e-03, -1.0273e-01,  1.2910e-02,\n",
      "         3.3295e-03, -1.0195e-01,  3.4551e-02, -1.1670e-01,  1.4035e-17,\n",
      "         2.6387e-02,  1.7386e-02,  7.5433e-18, -1.2577e-01,  3.5870e-02,\n",
      "         0.0000e+00,  2.8558e-02, -1.0628e-01,  3.5656e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 0.2271,  0.1129, -0.6231,  0.1859])\n",
      "tensor([ 0.0454,  0.0226, -0.1246,  0.0372], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.3501, 0.3501])\n",
      "tensor([0.0700, 0.0700], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([-0.2091,  1.7909], requires_grad=True)\n",
      "tensor([[0.5236, 0.4764],\n",
      "        [0.5270, 0.4730],\n",
      "        [0.5430, 0.4570],\n",
      "        [0.5718, 0.4282],\n",
      "        [0.6121, 0.3879],\n",
      "        [0.6601, 0.3399],\n",
      "        [0.7082, 0.2918],\n",
      "        [0.7460, 0.2540]], dtype=torch.float64)\n",
      "Finished episode 20 Average rewards:  8.0\n",
      "tensor([ 0.6412, -0.0123, -0.6414,  0.1946, -0.0032, -0.1950, -0.2013,  0.0035,\n",
      "        -0.1997, -0.0013,  0.0091, -0.0929, -0.0152,  0.7297,  0.0000,  0.0368,\n",
      "         0.1045,  0.0000,  0.0063,  0.0150,  0.0000, -0.0093, -0.0913,  0.0000])\n",
      "tensor([ 1.2823e-01, -2.4620e-03, -1.2828e-01,  3.8911e-02, -6.3947e-04,\n",
      "        -3.9005e-02, -4.0264e-02,  7.0180e-04, -3.9948e-02, -2.6229e-04,\n",
      "         1.8237e-03, -1.8586e-02, -3.0401e-03,  1.4595e-01,  3.1940e-17,\n",
      "         7.3621e-03,  2.0894e-02, -2.4324e-18,  1.2657e-03,  2.9996e-03,\n",
      "         0.0000e+00, -1.8654e-03, -1.8250e-02, -1.1352e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.0546,  0.1622,  0.0128, -0.1413])\n",
      "tensor([-0.0109,  0.0324,  0.0026, -0.0283], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.2044, 0.2044])\n",
      "tensor([0.0409, 0.0409], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([-0.0047,  1.9953], requires_grad=True)\n",
      "tensor([[0.4530, 0.5470],\n",
      "        [0.4516, 0.5484],\n",
      "        [0.4533, 0.5467],\n",
      "        [0.4607, 0.5393],\n",
      "        [0.4710, 0.5290],\n",
      "        [0.4838, 0.5162],\n",
      "        [0.5064, 0.4936],\n",
      "        [0.5257, 0.4743],\n",
      "        [0.5522, 0.4478],\n",
      "        [0.5845, 0.4155],\n",
      "        [0.6021, 0.3979],\n",
      "        [0.6208, 0.3792],\n",
      "        [0.6213, 0.3787],\n",
      "        [0.6165, 0.3835]], dtype=torch.float64)\n",
      "Finished episode 21 Average rewards:  14.0\n",
      "tensor([-2.0409e-03, -6.9795e-03,  1.7996e-03,  3.1141e-01,  1.4138e-04,\n",
      "        -3.1572e-01,  3.0764e-02,  2.3913e-02,  3.3762e-02, -2.0536e-02,\n",
      "         1.8854e-02, -1.9303e-01, -2.5335e-01, -1.6898e-01,  0.0000e+00,\n",
      "         8.0712e-02, -3.9150e-01,  0.0000e+00, -3.6900e-01, -1.0277e-01,\n",
      "         0.0000e+00,  2.4695e-01, -1.8025e-01,  0.0000e+00])\n",
      "tensor([-4.0815e-04, -1.3959e-03,  3.5992e-04,  6.2281e-02,  2.8266e-05,\n",
      "        -6.3145e-02,  6.1528e-03,  4.7825e-03,  6.7524e-03, -4.1072e-03,\n",
      "         3.7708e-03, -3.8606e-02, -5.0670e-02, -3.3797e-02, -1.5829e-17,\n",
      "         1.6142e-02, -7.8300e-02,  4.6536e-18, -7.3799e-02, -2.0555e-02,\n",
      "         0.0000e+00,  4.9390e-02, -3.6050e-02, -2.0900e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.4364,  0.1229, -1.0255,  0.4132])\n",
      "tensor([-0.0873,  0.0246, -0.2051,  0.0826], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.1253, 0.1253])\n",
      "tensor([0.0251, 0.0251], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([0.1206, 2.1206], requires_grad=True)\n",
      "tensor([[0.4545, 0.5455],\n",
      "        [0.4489, 0.5511],\n",
      "        [0.4464, 0.5536],\n",
      "        [0.4404, 0.5596],\n",
      "        [0.4383, 0.5617],\n",
      "        [0.4322, 0.5678],\n",
      "        [0.4222, 0.5778],\n",
      "        [0.4200, 0.5800],\n",
      "        [0.4222, 0.5778],\n",
      "        [0.4186, 0.5814],\n",
      "        [0.4233, 0.5767],\n",
      "        [0.4281, 0.5719],\n",
      "        [0.4318, 0.5682],\n",
      "        [0.4347, 0.5653],\n",
      "        [0.4307, 0.5693],\n",
      "        [0.4274, 0.5726],\n",
      "        [0.4312, 0.5688],\n",
      "        [0.4277, 0.5723],\n",
      "        [0.4240, 0.5760],\n",
      "        [0.4225, 0.5775],\n",
      "        [0.4288, 0.5712],\n",
      "        [0.4528, 0.5472],\n",
      "        [0.4774, 0.5226],\n",
      "        [0.5197, 0.4803]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  19.14\n",
      "Finished episode 22 Average rewards:  27.0\n",
      "tensor([ 0.3050, -0.0153, -0.3050,  0.2371,  0.0112, -0.2396,  0.1286,  0.0015,\n",
      "         0.1283,  0.0106,  0.0067, -0.0889, -0.1122,  0.3271,  0.0000,  0.0045,\n",
      "         0.0279,  0.0000, -0.0549, -0.3615,  0.0000, -0.2017, -0.1476,  0.0000])\n",
      "tensor([ 6.1000e-02, -3.0687e-03, -6.1001e-02,  4.7418e-02,  2.2431e-03,\n",
      "        -4.7916e-02,  2.5728e-02,  2.9374e-04,  2.5665e-02,  2.1250e-03,\n",
      "         1.3369e-03, -1.7789e-02, -2.2438e-02,  6.5410e-02, -8.8781e-18,\n",
      "         8.9097e-04,  5.5832e-03,  5.5167e-18, -1.0988e-02, -7.2292e-02,\n",
      "         0.0000e+00, -4.0333e-02, -2.9516e-02, -3.4947e-20],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.5259,  0.0069, -0.0937, -0.0025])\n",
      "tensor([-0.1052,  0.0014, -0.0187, -0.0005], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.1240, 0.1240])\n",
      "tensor([0.0248, 0.0248], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([0.2446, 2.2446], requires_grad=True)\n",
      "tensor([[0.3217, 0.6783],\n",
      "        [0.3137, 0.6863],\n",
      "        [0.3078, 0.6922],\n",
      "        [0.3148, 0.6852],\n",
      "        [0.3474, 0.6526],\n",
      "        [0.3773, 0.6227],\n",
      "        [0.3954, 0.6046],\n",
      "        [0.4074, 0.5926],\n",
      "        [0.4440, 0.5560],\n",
      "        [0.5112, 0.4888],\n",
      "        [0.5883, 0.4117],\n",
      "        [0.6388, 0.3612],\n",
      "        [0.6673, 0.3327],\n",
      "        [0.6896, 0.3104],\n",
      "        [0.7133, 0.2867],\n",
      "        [0.7246, 0.2754],\n",
      "        [0.7282, 0.2718],\n",
      "        [0.7250, 0.2750],\n",
      "        [0.7126, 0.2874],\n",
      "        [0.6970, 0.3030],\n",
      "        [0.6849, 0.3151],\n",
      "        [0.6572, 0.3428],\n",
      "        [0.6260, 0.3740],\n",
      "        [0.5981, 0.4019],\n",
      "        [0.5500, 0.4500],\n",
      "        [0.4833, 0.5167],\n",
      "        [0.4112, 0.5888],\n",
      "        [0.3586, 0.6414],\n",
      "        [0.3444, 0.6556],\n",
      "        [0.3467, 0.6533],\n",
      "        [0.3903, 0.6097],\n",
      "        [0.4422, 0.5578],\n",
      "        [0.5282, 0.4718],\n",
      "        [0.6371, 0.3629],\n",
      "        [0.7306, 0.2694],\n",
      "        [0.7652, 0.2348],\n",
      "        [0.7050, 0.2950]], dtype=torch.float64)\n",
      "Finished episode 23 Average rewards:  37.0\n",
      "tensor([ 0.1814, -0.0638, -0.1818, -0.6785,  0.0474,  0.6637, -0.4034, -0.0205,\n",
      "        -0.4035, -0.1089,  0.0229, -0.2510, -0.3677, -0.4739,  0.0000, -0.0478,\n",
      "        -0.4060,  0.0000, -0.9555, -0.5502,  0.0000,  0.8230, -0.2979,  0.0000])\n",
      "tensor([ 3.6281e-02, -1.2766e-02, -3.6354e-02, -1.3570e-01,  9.4879e-03,\n",
      "         1.3274e-01, -8.0670e-02, -4.0932e-03, -8.0695e-02, -2.1776e-02,\n",
      "         4.5818e-03, -5.0204e-02, -7.3534e-02, -9.4779e-02, -5.2031e-17,\n",
      "        -9.5686e-03, -8.1195e-02,  3.4992e-17, -1.9109e-01, -1.1005e-01,\n",
      "         0.0000e+00,  1.6461e-01, -5.9571e-02, -2.1109e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.6541, -0.0958, -0.2150,  1.3408])\n",
      "tensor([-0.1308, -0.0192, -0.0430,  0.2682], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([2.4583, 2.4583])\n",
      "tensor([0.4917, 0.4917], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([2.7030, 4.7030], requires_grad=True)\n",
      "tensor([[0.1374, 0.8626],\n",
      "        [0.1364, 0.8636],\n",
      "        [0.1396, 0.8604],\n",
      "        [0.1596, 0.8404],\n",
      "        [0.2238, 0.7762],\n",
      "        [0.3846, 0.6154],\n",
      "        [0.6416, 0.3584],\n",
      "        [0.8024, 0.1976],\n",
      "        [0.8479, 0.1521],\n",
      "        [0.8400, 0.1600],\n",
      "        [0.8033, 0.1967]], dtype=torch.float64)\n",
      "Finished episode 24 Average rewards:  11.0\n",
      "tensor([ 1.0336, -0.0262, -1.0333, -1.1267,  0.0081,  1.1283, -3.1996, -0.1545,\n",
      "        -3.2164,  0.1194, -0.0306, -1.3504, -0.4574,  2.3891,  0.0000, -0.2285,\n",
      "         2.6088,  0.0000,  2.5161, -1.9589,  0.0000, -1.4840, -1.3008,  0.0000])\n",
      "tensor([ 2.0672e-01, -5.2358e-03, -2.0666e-01, -2.2534e-01,  1.6257e-03,\n",
      "         2.2565e-01, -6.3992e-01, -3.0895e-02, -6.4329e-01,  2.3876e-02,\n",
      "        -6.1181e-03, -2.7008e-01, -9.1488e-02,  4.7781e-01,  5.6524e-17,\n",
      "        -4.5696e-02,  5.2176e-01, -3.5783e-17,  5.0321e-01, -3.9178e-01,\n",
      "         0.0000e+00, -2.9679e-01, -2.6016e-01, -7.2756e-20],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.7910, -0.6115,  0.0609, -4.1849])\n",
      "tensor([-0.1582, -0.1223,  0.0122, -0.8370], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-1.4961, -1.4961])\n",
      "tensor([-0.2992, -0.2992], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([1.2069, 3.2069], requires_grad=True)\n",
      "tensor([[0.5932, 0.4068],\n",
      "        [0.5932, 0.4068],\n",
      "        [0.5909, 0.4091],\n",
      "        [0.5822, 0.4178],\n",
      "        [0.5473, 0.4527],\n",
      "        [0.4643, 0.5357],\n",
      "        [0.4343, 0.5657],\n",
      "        [0.3342, 0.6658],\n",
      "        [0.2413, 0.7587],\n",
      "        [0.2356, 0.7644],\n",
      "        [0.2197, 0.7803],\n",
      "        [0.2603, 0.7397],\n",
      "        [0.3509, 0.6491],\n",
      "        [0.5599, 0.4401],\n",
      "        [0.7602, 0.2398]], dtype=torch.float64)\n",
      "Finished episode 25 Average rewards:  15.0\n",
      "tensor([-0.1524,  0.0028,  0.1524,  0.0045,  0.0164, -0.0041, -1.5733, -0.1329,\n",
      "        -1.6058, -0.0230,  0.0167, -0.1689, -0.3090,  0.8700,  0.0000, -0.4006,\n",
      "         0.2835,  0.0000,  1.0745,  1.1857,  0.0000, -0.0258,  0.4573,  0.0000])\n",
      "tensor([-3.0482e-02,  5.5107e-04,  3.0488e-02,  8.9575e-04,  3.2835e-03,\n",
      "        -8.2001e-04, -3.1467e-01, -2.6581e-02, -3.2116e-01, -4.5986e-03,\n",
      "         3.3423e-03, -3.3780e-02, -6.1796e-02,  1.7400e-01, -2.9997e-17,\n",
      "        -8.0120e-02,  5.6700e-02, -3.6275e-18,  2.1490e-01,  2.3713e-01,\n",
      "         0.0000e+00, -5.1687e-03,  9.1456e-02, -1.1635e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.8487, -1.2534,  1.5951, -0.0293])\n",
      "tensor([-0.1697, -0.2507,  0.3190, -0.0059], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.4421, 0.4421])\n",
      "tensor([0.0884, 0.0884], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([1.6490, 3.6490], requires_grad=True)\n",
      "tensor([[0.2927, 0.7073],\n",
      "        [0.2941, 0.7059],\n",
      "        [0.2808, 0.7192],\n",
      "        [0.2577, 0.7423],\n",
      "        [0.2311, 0.7689],\n",
      "        [0.2077, 0.7923],\n",
      "        [0.1937, 0.8063],\n",
      "        [0.1933, 0.8067]], dtype=torch.float64)\n",
      "Finished episode 26 Average rewards:  8.0\n",
      "tensor([ 1.9559e-01,  2.1534e-02, -1.9417e-01, -2.0828e-01,  3.2468e-02,\n",
      "         2.0856e-01, -3.9583e-01, -1.8702e-01, -3.3759e-01,  3.2473e-02,\n",
      "         7.7915e-04, -1.4476e-02, -8.2087e-01,  1.2203e+00,  0.0000e+00,\n",
      "        -8.0346e-01,  1.0512e+00,  0.0000e+00,  1.2490e+00,  1.1176e+00,\n",
      "         0.0000e+00,  2.5674e-02,  1.8788e+00,  0.0000e+00])\n",
      "tensor([ 3.9118e-02,  4.3068e-03, -3.8834e-02, -4.1655e-02,  6.4936e-03,\n",
      "         4.1711e-02, -7.9166e-02, -3.7403e-02, -6.7518e-02,  6.4946e-03,\n",
      "         1.5580e-04, -2.8952e-03, -1.6417e-01,  2.4405e-01, -2.2027e-17,\n",
      "        -1.6069e-01,  2.1025e-01,  1.9958e-17,  2.4980e-01,  2.2352e-01,\n",
      "         0.0000e+00,  5.1348e-03,  3.7575e-01,  9.8544e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-1.1601, -1.0083,  0.7881, -0.2295])\n",
      "tensor([-0.2320, -0.2017,  0.1576, -0.0459], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.0827, 0.0827])\n",
      "tensor([0.0165, 0.0165], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([1.7317, 3.7317], requires_grad=True)\n",
      "tensor([[0.5219, 0.4781],\n",
      "        [0.4934, 0.5066],\n",
      "        [0.5130, 0.4870],\n",
      "        [0.4860, 0.5140],\n",
      "        [0.4629, 0.5371],\n",
      "        [0.4690, 0.5310],\n",
      "        [0.4876, 0.5124],\n",
      "        [0.4675, 0.5325],\n",
      "        [0.4560, 0.5440],\n",
      "        [0.4568, 0.5432],\n",
      "        [0.4732, 0.5268],\n",
      "        [0.4910, 0.5090],\n",
      "        [0.5261, 0.4739],\n",
      "        [0.5642, 0.4358],\n",
      "        [0.5890, 0.4110]], dtype=torch.float64)\n",
      "Monitored episode 50 Average Monitored rewards:  16.4\n",
      "Finished episode 27 Average rewards:  19.0\n",
      "tensor([ 1.0627, -0.0507, -1.0647,  1.1231,  0.1695, -1.1225,  0.0870, -0.2925,\n",
      "         0.0702,  0.0681,  0.0995, -0.9347, -0.1303, -1.4535,  0.0000,  0.2696,\n",
      "        -1.2468,  0.0000,  1.4104, -0.5032,  0.0000,  0.9965,  0.5897,  0.0000])\n",
      "tensor([ 2.1255e-01, -1.0147e-02, -2.1295e-01,  2.2463e-01,  3.3904e-02,\n",
      "        -2.2451e-01,  1.7410e-02, -5.8506e-02,  1.4042e-02,  1.3614e-02,\n",
      "         1.9892e-02, -1.8694e-01, -2.6054e-02, -2.9070e-01,  2.4733e-17,\n",
      "         5.3916e-02, -2.4937e-01,  2.1689e-17,  2.8208e-01, -1.0064e-01,\n",
      "         0.0000e+00,  1.9930e-01,  1.1794e-01,  2.8053e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.4870, -0.0970,  4.9724,  3.9702])\n",
      "tensor([-0.0974, -0.0194,  0.9945,  0.7940], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.3770, 0.3770])\n",
      "tensor([0.0754, 0.0754], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([2.1087, 4.1087], requires_grad=True)\n",
      "tensor([[0.5492, 0.4508],\n",
      "        [0.6012, 0.3988],\n",
      "        [0.6570, 0.3430],\n",
      "        [0.7010, 0.2990],\n",
      "        [0.7229, 0.2771],\n",
      "        [0.7171, 0.2829],\n",
      "        [0.6813, 0.3187],\n",
      "        [0.6722, 0.3278],\n",
      "        [0.6078, 0.3922],\n",
      "        [0.5791, 0.4209],\n",
      "        [0.5511, 0.4489],\n",
      "        [0.5328, 0.4672]], dtype=torch.float64)\n",
      "Finished episode 28 Average rewards:  12.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.6831, -0.1623,  1.6983,  0.0829,  0.0723, -0.1131, -0.3594,  0.4935,\n",
      "        -0.2582, -0.5651, -0.2277,  1.3870,  0.5477,  1.7197,  0.0000,  0.4004,\n",
      "         0.4454,  0.0000,  0.4509,  0.9201,  0.0000, -0.1502,  1.9967,  0.0000])\n",
      "tensor([-3.3662e-01, -3.2451e-02,  3.3966e-01,  1.6583e-02,  1.4465e-02,\n",
      "        -2.2610e-02, -7.1888e-02,  9.8710e-02, -5.1632e-02, -1.1303e-01,\n",
      "        -4.5543e-02,  2.7740e-01,  1.0953e-01,  3.4395e-01, -4.9006e-17,\n",
      "         8.0088e-02,  8.9085e-02,  1.3349e-17,  9.0182e-02,  1.8402e-01,\n",
      "         0.0000e+00, -3.0045e-02,  3.9933e-01,  1.0352e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 0.9595,  0.9834,  0.3564, -0.2419])\n",
      "tensor([ 0.1919,  0.1967,  0.0713, -0.0484], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.9480, 0.9480])\n",
      "tensor([0.1896, 0.1896], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([3.0567, 5.0567], requires_grad=True)\n",
      "tensor([[0.4464, 0.5536],\n",
      "        [0.4586, 0.5414],\n",
      "        [0.4374, 0.5626],\n",
      "        [0.4252, 0.5748],\n",
      "        [0.4469, 0.5531],\n",
      "        [0.4348, 0.5652],\n",
      "        [0.4322, 0.5678],\n",
      "        [0.4354, 0.5646],\n",
      "        [0.4363, 0.5637],\n",
      "        [0.4915, 0.5085],\n",
      "        [0.5444, 0.4556],\n",
      "        [0.5816, 0.4184],\n",
      "        [0.6014, 0.3986],\n",
      "        [0.5905, 0.4095],\n",
      "        [0.5731, 0.4269],\n",
      "        [0.5498, 0.4502],\n",
      "        [0.5269, 0.4731],\n",
      "        [0.5205, 0.4795]], dtype=torch.float64)\n",
      "Finished episode 29 Average rewards:  18.0\n",
      "tensor([ 1.2100, -0.0037, -1.1760, -0.5249, -0.0934,  0.5920, -0.5537, -0.2794,\n",
      "        -0.5455, -0.5760, -0.2526, -0.6152,  1.0794, -0.3833,  0.0000, -0.6074,\n",
      "         0.2897,  0.0000, -0.4814,  0.5730,  0.0000, -1.8310, -1.1199,  0.0000])\n",
      "tensor([ 2.4199e-01, -7.4376e-04, -2.3520e-01, -1.0498e-01, -1.8686e-02,\n",
      "         1.1841e-01, -1.1075e-01, -5.5875e-02, -1.0909e-01, -1.1519e-01,\n",
      "        -5.0523e-02, -1.2304e-01,  2.1587e-01, -7.6653e-02, -3.3768e-17,\n",
      "        -1.2147e-01,  5.7936e-02,  3.1660e-17, -9.6276e-02,  1.1459e-01,\n",
      "         0.0000e+00, -3.6619e-01, -2.2399e-01,  1.6352e-19],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 2.6674, -1.8258,  1.0500, -4.4837])\n",
      "tensor([ 0.5335, -0.3652,  0.2100, -0.8967], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.5577, 0.5577])\n",
      "tensor([0.1115, 0.1115], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([3.6144, 5.6144], requires_grad=True)\n",
      "tensor([[0.4077, 0.5923],\n",
      "        [0.4319, 0.5681],\n",
      "        [0.4135, 0.5865],\n",
      "        [0.3869, 0.6131],\n",
      "        [0.3617, 0.6383],\n",
      "        [0.3831, 0.6169],\n",
      "        [0.3998, 0.6002],\n",
      "        [0.3829, 0.6171],\n",
      "        [0.3981, 0.6019],\n",
      "        [0.3829, 0.6171],\n",
      "        [0.3664, 0.6336],\n",
      "        [0.3598, 0.6402],\n",
      "        [0.3749, 0.6251],\n",
      "        [0.4242, 0.5758],\n",
      "        [0.5104, 0.4896],\n",
      "        [0.6024, 0.3976],\n",
      "        [0.6380, 0.3620],\n",
      "        [0.5318, 0.4682],\n",
      "        [0.4056, 0.5944]], dtype=torch.float64)\n",
      "Finished episode 30 Average rewards:  19.0\n",
      "tensor([ 0.3834, -0.0046, -0.3581,  0.2990,  0.0551, -0.3038,  1.5332,  0.3308,\n",
      "         1.4412,  0.2980,  0.2615,  0.2501,  0.0690,  0.2211,  0.0000,  0.0379,\n",
      "        -0.0098,  0.0000,  0.1036,  0.3458,  0.0000, -1.3646, -0.3903,  0.0000])\n",
      "tensor([ 7.6671e-02, -9.2340e-04, -7.1616e-02,  5.9807e-02,  1.1021e-02,\n",
      "        -6.0752e-02,  3.0664e-01,  6.6160e-02,  2.8824e-01,  5.9608e-02,\n",
      "         5.2301e-02,  5.0027e-02,  1.3798e-02,  4.4216e-02, -1.4734e-17,\n",
      "         7.5850e-03, -1.9612e-03, -2.4851e-17,  2.0723e-02,  6.9163e-02,\n",
      "         0.0000e+00, -2.7291e-01, -7.8065e-02, -5.6177e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 0.1216,  0.0625,  0.4063, -4.0462])\n",
      "tensor([ 0.0243,  0.0125,  0.0813, -0.8092], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-0.2583, -0.2583])\n",
      "tensor([-0.0517, -0.0517], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([3.3561, 5.3561], requires_grad=True)\n",
      "tensor([[0.5122, 0.4878],\n",
      "        [0.4641, 0.5359],\n",
      "        [0.4156, 0.5844],\n",
      "        [0.4561, 0.5439],\n",
      "        [0.5004, 0.4996],\n",
      "        [0.4495, 0.5505],\n",
      "        [0.4918, 0.5082],\n",
      "        [0.4409, 0.5591],\n",
      "        [0.3889, 0.6111],\n",
      "        [0.4185, 0.5815],\n",
      "        [0.3728, 0.6272],\n",
      "        [0.3935, 0.6065],\n",
      "        [0.4153, 0.5847],\n",
      "        [0.3803, 0.6197],\n",
      "        [0.3568, 0.6432],\n",
      "        [0.3647, 0.6353],\n",
      "        [0.3730, 0.6270],\n",
      "        [0.3621, 0.6379],\n",
      "        [0.3737, 0.6263],\n",
      "        [0.4134, 0.5866],\n",
      "        [0.4640, 0.5360],\n",
      "        [0.4847, 0.5153]], dtype=torch.float64)\n",
      "Finished episode 31 Average rewards:  22.0\n",
      "tensor([ 1.3882e-01, -7.6268e-02, -9.7128e-02, -8.7239e-01, -3.3187e-02,\n",
      "         8.6940e-01, -7.4982e-01, -1.1399e-01, -6.8034e-01, -7.7085e-01,\n",
      "         1.2292e+00,  1.5591e+00, -6.8123e-02,  7.1190e-01,  0.0000e+00,\n",
      "        -4.3187e-02,  5.7690e-01,  0.0000e+00,  6.6280e-04, -1.0666e+00,\n",
      "         0.0000e+00, -2.7793e-01, -3.0009e+00,  0.0000e+00])\n",
      "tensor([ 2.7765e-02, -1.5254e-02, -1.9426e-02, -1.7448e-01, -6.6374e-03,\n",
      "         1.7388e-01, -1.4996e-01, -2.2799e-02, -1.3607e-01, -1.5417e-01,\n",
      "         2.4584e-01,  3.1182e-01, -1.3625e-02,  1.4238e-01,  4.7056e-17,\n",
      "        -8.6373e-03,  1.1538e-01,  4.1542e-17,  1.3259e-04, -2.1333e-01,\n",
      "         0.0000e+00, -5.5586e-02, -6.0018e-01, -6.3413e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.0727, -0.0661, -0.0662,  0.3089])\n",
      "tensor([-0.0145, -0.0132, -0.0132,  0.0618], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-0.8892, -0.8892])\n",
      "tensor([-0.1778, -0.1778], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([2.4669, 4.4669], requires_grad=True)\n",
      "tensor([[0.5730, 0.4270],\n",
      "        [0.5795, 0.4205],\n",
      "        [0.5272, 0.4728],\n",
      "        [0.4513, 0.5487],\n",
      "        [0.4095, 0.5905],\n",
      "        [0.4430, 0.5570],\n",
      "        [0.4090, 0.5910],\n",
      "        [0.4341, 0.5659],\n",
      "        [0.4959, 0.5041],\n",
      "        [0.4231, 0.5769],\n",
      "        [0.4694, 0.5306]], dtype=torch.float64)\n",
      "Monitored episode 50 Average Monitored rewards:  18.9\n",
      "Finished episode 32 Average rewards:  13.0\n",
      "tensor([ 0.0322, -0.3363,  0.1254, -0.2052,  0.1234,  0.1987,  3.7166, -0.8918,\n",
      "         3.3407, -0.6933, -0.3935,  0.6372, -0.8517,  0.8182,  0.0000, -1.6786,\n",
      "         2.0241,  0.0000,  1.0375, -1.1161,  0.0000,  0.0997,  2.3100,  0.0000])\n",
      "tensor([ 6.4463e-03, -6.7261e-02,  2.5078e-02, -4.1046e-02,  2.4690e-02,\n",
      "         3.9749e-02,  7.4332e-01, -1.7837e-01,  6.6815e-01, -1.3865e-01,\n",
      "        -7.8706e-02,  1.2745e-01, -1.7035e-01,  1.6364e-01,  3.5644e-17,\n",
      "        -3.3571e-01,  4.0482e-01, -1.0848e-17,  2.0750e-01, -2.2322e-01,\n",
      "         0.0000e+00,  1.9949e-02,  4.6199e-01, -5.3024e-20],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-1.4933, -4.6468, -1.0695,  2.1158])\n",
      "tensor([-0.2987, -0.9294, -0.2139,  0.4232], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-0.1478, -0.1478])\n",
      "tensor([-0.0296, -0.0296], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([2.3190, 4.3190], requires_grad=True)\n",
      "tensor([[0.5585, 0.4415],\n",
      "        [0.4448, 0.5552],\n",
      "        [0.3521, 0.6479],\n",
      "        [0.3536, 0.6464],\n",
      "        [0.4574, 0.5426],\n",
      "        [0.4790, 0.5210],\n",
      "        [0.5820, 0.4180],\n",
      "        [0.6173, 0.3827],\n",
      "        [0.4421, 0.5579],\n",
      "        [0.2647, 0.7353],\n",
      "        [0.3622, 0.6378],\n",
      "        [0.5623, 0.4377]], dtype=torch.float64)\n",
      "Finished episode 33 Average rewards:  12.0\n",
      "tensor([ 1.7099, -0.6192, -0.8339, -0.4862,  0.0892,  0.4677, -0.8033,  0.4834,\n",
      "        -0.4565,  0.4749,  0.7519, -0.6698, -0.1575, -1.4420,  0.0000,  0.8105,\n",
      "        -0.0093,  0.0000, -0.0692,  0.8882,  0.0000,  0.2584, -0.8816,  0.0000])\n",
      "tensor([ 3.4198e-01, -1.2383e-01, -1.6679e-01, -9.7239e-02,  1.7835e-02,\n",
      "         9.3531e-02, -1.6065e-01,  9.6680e-02, -9.1302e-02,  9.4985e-02,\n",
      "         1.5039e-01, -1.3396e-01, -3.1496e-02, -2.8841e-01,  2.7039e-17,\n",
      "         1.6211e-01, -1.8575e-03,  4.3898e-17, -1.3844e-02,  1.7763e-01,\n",
      "         0.0000e+00,  5.1674e-02, -1.7633e-01,  1.9891e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.3555,  3.2623, -0.6394, -0.5097])\n",
      "tensor([-0.0711,  0.6525, -0.1279, -0.1019], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([1.0814, 1.0814])\n",
      "tensor([0.2163, 0.2163], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([3.4004, 5.4004], requires_grad=True)\n",
      "tensor([[0.4610, 0.5390],\n",
      "        [0.4880, 0.5120],\n",
      "        [0.4972, 0.5028],\n",
      "        [0.5065, 0.4935],\n",
      "        [0.5178, 0.4822],\n",
      "        [0.5296, 0.4704],\n",
      "        [0.5429, 0.4571],\n",
      "        [0.5374, 0.4626],\n",
      "        [0.5333, 0.4667],\n",
      "        [0.5453, 0.4547],\n",
      "        [0.6415, 0.3585],\n",
      "        [0.6467, 0.3533],\n",
      "        [0.6409, 0.3591]], dtype=torch.float64)\n",
      "Finished episode 34 Average rewards:  13.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5422, -1.2400, -1.3130,  0.8700, -0.5441, -0.9115,  1.1254,  0.6704,\n",
      "         0.8933, -0.0845,  1.5627,  0.0875,  0.8486, -0.4131,  0.0000,  1.3395,\n",
      "         0.0724,  0.0000,  0.2003, -1.2774,  0.0000,  0.6060, -1.4338,  0.0000])\n",
      "tensor([ 1.0845e-01, -2.4800e-01, -2.6259e-01,  1.7399e-01, -1.0882e-01,\n",
      "        -1.8231e-01,  2.2507e-01,  1.3408e-01,  1.7867e-01, -1.6902e-02,\n",
      "         3.1254e-01,  1.7494e-02,  1.6972e-01, -8.2628e-02, -8.9034e-18,\n",
      "         2.6789e-01,  1.4472e-02, -1.0079e-17,  4.0058e-02, -2.5547e-01,\n",
      "         0.0000e+00,  1.2121e-01, -2.8676e-01, -9.9558e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([1.7348, 1.9652, 1.1188, 1.9459])\n",
      "tensor([0.3470, 0.3930, 0.2238, 0.3892], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.0118, 0.0118])\n",
      "tensor([0.0024, 0.0024], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([3.4122, 5.4122], requires_grad=True)\n",
      "tensor([[0.5249, 0.4751],\n",
      "        [0.4924, 0.5076],\n",
      "        [0.5175, 0.4825],\n",
      "        [0.4843, 0.5157],\n",
      "        [0.4605, 0.5395],\n",
      "        [0.4590, 0.5410],\n",
      "        [0.4612, 0.5388],\n",
      "        [0.4393, 0.5607],\n",
      "        [0.4696, 0.5304],\n",
      "        [0.4282, 0.5718],\n",
      "        [0.4835, 0.5165],\n",
      "        [0.5555, 0.4445],\n",
      "        [0.4950, 0.5050],\n",
      "        [0.5113, 0.4887],\n",
      "        [0.4817, 0.5183],\n",
      "        [0.4538, 0.5462],\n",
      "        [0.4406, 0.5594]], dtype=torch.float64)\n",
      "Finished episode 35 Average rewards:  17.0\n",
      "tensor([-2.0175e-01, -6.7107e-02, -3.1327e-01, -2.1101e-02, -2.2084e-03,\n",
      "         2.0590e-02, -2.9918e-01,  1.4671e-01, -3.2324e-01, -5.1030e-01,\n",
      "         4.6782e+00,  8.0431e-01,  5.4054e-02, -1.3141e+00,  0.0000e+00,\n",
      "         2.5248e-01,  7.9265e-01,  0.0000e+00, -1.1393e+00, -1.4369e-01,\n",
      "         0.0000e+00, -4.4743e-01,  2.7561e-01,  0.0000e+00])\n",
      "tensor([-4.0351e-02, -1.3421e-02, -6.2654e-02, -4.2202e-03, -4.4167e-04,\n",
      "         4.1180e-03, -5.9836e-02,  2.9342e-02, -6.4647e-02, -1.0206e-01,\n",
      "         9.3563e-01,  1.6086e-01,  1.0811e-02, -2.6283e-01, -2.6051e-17,\n",
      "         5.0496e-02,  1.5853e-01,  2.5329e-18, -2.2786e-01, -2.8738e-02,\n",
      "         0.0000e+00, -8.9487e-02,  5.5122e-02,  9.0882e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 0.0893,  0.5169, -3.7407, -0.4520])\n",
      "tensor([ 0.0179,  0.1034, -0.7481, -0.0904], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.2993, 0.2993])\n",
      "tensor([0.0599, 0.0599], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([3.7115, 5.7115], requires_grad=True)\n",
      "tensor([[0.5022, 0.4978],\n",
      "        [0.5160, 0.4840],\n",
      "        [0.5284, 0.4716],\n",
      "        [0.5258, 0.4742],\n",
      "        [0.5046, 0.4954],\n",
      "        [0.4843, 0.5157],\n",
      "        [0.4764, 0.5236],\n",
      "        [0.5029, 0.4971],\n",
      "        [0.5438, 0.4562],\n",
      "        [0.5710, 0.4290]], dtype=torch.float64)\n",
      "Finished episode 36 Average rewards:  10.0\n",
      "tensor([-0.1841,  0.0494, -0.1036, -0.3582, -0.3458,  0.3272,  2.4065, -0.0820,\n",
      "         2.4069,  0.9111, -0.0308, -0.9104, -0.4968, -0.4366,  0.0000, -0.0851,\n",
      "        -0.7068,  0.0000, -0.5608,  2.7261,  0.0000,  0.7158, -2.6732,  0.0000])\n",
      "tensor([-3.6827e-02,  9.8809e-03, -2.0720e-02, -7.1637e-02, -6.9161e-02,\n",
      "         6.5442e-02,  4.8131e-01, -1.6392e-02,  4.8138e-01,  1.8222e-01,\n",
      "        -6.1680e-03, -1.8208e-01, -9.9368e-02, -8.7320e-02,  6.6989e-17,\n",
      "        -1.7025e-02, -1.4136e-01, -7.3145e-17, -1.1216e-01,  5.4521e-01,\n",
      "         0.0000e+00,  1.4317e-01, -5.3464e-01,  1.5423e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.9888, -0.0600, -1.1414,  3.7213])\n",
      "tensor([-0.1978, -0.0120, -0.2283,  0.7443], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-2.2418, -2.2418])\n",
      "tensor([-0.4484, -0.4484], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([1.4697, 3.4697], requires_grad=True)\n",
      "tensor([[0.6940, 0.3060],\n",
      "        [0.7184, 0.2816],\n",
      "        [0.6900, 0.3100],\n",
      "        [0.7172, 0.2828],\n",
      "        [0.6868, 0.3132],\n",
      "        [0.6138, 0.3862],\n",
      "        [0.5145, 0.4855],\n",
      "        [0.4175, 0.5825],\n",
      "        [0.5201, 0.4799],\n",
      "        [0.6221, 0.3779],\n",
      "        [0.5155, 0.4845],\n",
      "        [0.6180, 0.3820],\n",
      "        [0.6920, 0.3080],\n",
      "        [0.6067, 0.3933],\n",
      "        [0.4921, 0.5079],\n",
      "        [0.5967, 0.4033],\n",
      "        [0.4763, 0.5237],\n",
      "        [0.3702, 0.6298],\n",
      "        [0.3080, 0.6920],\n",
      "        [0.3473, 0.6527],\n",
      "        [0.4204, 0.5796]], dtype=torch.float64)\n",
      "Monitored episode 50 Average Monitored rewards:  24.28\n",
      "Finished episode 37 Average rewards:  18.0\n",
      "tensor([-0.0591,  0.1354,  0.0544, -0.1134, -0.1343,  0.0966,  0.0685,  0.0177,\n",
      "         0.0685, -0.2984, -0.0167,  0.2978,  0.1745,  0.1230,  0.0000, -0.1888,\n",
      "        -0.2654,  0.0000,  0.0384, -0.0224,  0.0000,  0.2127, -0.3302,  0.0000])\n",
      "tensor([-1.1821e-02,  2.7083e-02,  1.0870e-02, -2.2682e-02, -2.6853e-02,\n",
      "         1.9314e-02,  1.3703e-02,  3.5444e-03,  1.3696e-02, -5.9676e-02,\n",
      "        -3.3334e-03,  5.9557e-02,  3.4893e-02,  2.4596e-02, -2.3576e-17,\n",
      "        -3.7753e-02, -5.3090e-02,  1.9253e-17,  7.6852e-03, -4.4882e-03,\n",
      "         0.0000e+00,  4.2531e-02, -6.6049e-02,  6.3956e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 0.2914, -0.4452,  0.0380,  0.4483])\n",
      "tensor([ 0.0583, -0.0890,  0.0076,  0.0897], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.1780, 0.1780])\n",
      "tensor([0.0356, 0.0356], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([1.6478, 3.6478], requires_grad=True)\n",
      "tensor([[0.4758, 0.5242],\n",
      "        [0.4925, 0.5075],\n",
      "        [0.5123, 0.4877],\n",
      "        [0.4927, 0.5073],\n",
      "        [0.4761, 0.5239],\n",
      "        [0.4639, 0.5361],\n",
      "        [0.4760, 0.5240],\n",
      "        [0.4637, 0.5363],\n",
      "        [0.4563, 0.5437],\n",
      "        [0.4633, 0.5367],\n",
      "        [0.4757, 0.5243],\n",
      "        [0.4632, 0.5368],\n",
      "        [0.4757, 0.5243],\n",
      "        [0.4926, 0.5074],\n",
      "        [0.5125, 0.4875],\n",
      "        [0.4928, 0.5072],\n",
      "        [0.4761, 0.5239],\n",
      "        [0.4636, 0.5364],\n",
      "        [0.4760, 0.5240],\n",
      "        [0.4929, 0.5071],\n",
      "        [0.5129, 0.4871],\n",
      "        [0.5344, 0.4656],\n",
      "        [0.5557, 0.4443],\n",
      "        [0.5349, 0.4651],\n",
      "        [0.5137, 0.4863],\n",
      "        [0.4939, 0.5061],\n",
      "        [0.5141, 0.4859],\n",
      "        [0.4943, 0.5057],\n",
      "        [0.4774, 0.5226],\n",
      "        [0.4946, 0.5054],\n",
      "        [0.5154, 0.4846],\n",
      "        [0.5379, 0.4621]], dtype=torch.float64)\n",
      "Finished episode 38 Average rewards:  32.0\n",
      "tensor([-0.0011, -0.0086, -0.0077,  0.0171, -0.0011, -0.0134, -0.0179, -0.0017,\n",
      "        -0.0179, -0.0021, -0.0055,  0.0021,  0.0102,  0.0178,  0.0000, -0.0051,\n",
      "         0.0307,  0.0000, -0.0008,  0.0644,  0.0000, -0.0073, -0.0188,  0.0000])\n",
      "tensor([-2.1061e-04, -1.7251e-03, -1.5335e-03,  3.4187e-03, -2.2468e-04,\n",
      "        -2.6815e-03, -3.5821e-03, -3.3199e-04, -3.5700e-03, -4.2284e-04,\n",
      "        -1.0967e-03,  4.2704e-04,  2.0458e-03,  3.5537e-03,  1.4961e-17,\n",
      "        -1.0120e-03,  6.1472e-03,  2.3680e-18, -1.6200e-04,  1.2877e-02,\n",
      "         0.0000e+00, -1.4693e-03, -3.7635e-03, -6.4281e-19],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 0.0112,  0.3747,  0.0647, -0.0621])\n",
      "tensor([ 0.0022,  0.0749,  0.0129, -0.0124], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-0.0326, -0.0326])\n",
      "tensor([-0.0065, -0.0065], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([1.6152, 3.6152], requires_grad=True)\n",
      "tensor([[0.6500, 0.3500],\n",
      "        [0.6019, 0.3981],\n",
      "        [0.5494, 0.4506],\n",
      "        [0.4988, 0.5012],\n",
      "        [0.5491, 0.4509],\n",
      "        [0.4982, 0.5018],\n",
      "        [0.4553, 0.5447],\n",
      "        [0.4972, 0.5028],\n",
      "        [0.5474, 0.4526],\n",
      "        [0.5996, 0.4004],\n",
      "        [0.5455, 0.4545],\n",
      "        [0.4934, 0.5066],\n",
      "        [0.4499, 0.5501]], dtype=torch.float64)\n",
      "Finished episode 39 Average rewards:  13.0\n",
      "tensor([ 0.1603, -0.0439,  0.0847,  0.2080,  0.4681, -0.1858,  0.2357,  0.0139,\n",
      "         0.2348, -0.3211, -0.0175,  0.3203,  0.4941,  0.4964,  0.0000, -0.4862,\n",
      "         0.5330,  0.0000,  0.0674,  0.6428,  0.0000, -0.3659, -0.6833,  0.0000])\n",
      "tensor([ 3.2064e-02, -8.7729e-03,  1.6932e-02,  4.1598e-02,  9.3626e-02,\n",
      "        -3.7168e-02,  4.7144e-02,  2.7760e-03,  4.6963e-02, -6.4219e-02,\n",
      "        -3.5065e-03,  6.4064e-02,  9.8811e-02,  9.9285e-02,  3.3106e-17,\n",
      "        -9.7234e-02,  1.0660e-01, -1.3057e-17,  1.3474e-02,  1.2856e-01,\n",
      "         0.0000e+00, -7.3175e-02, -1.3667e-01,  1.6776e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 0.5771, -0.2682,  0.0956, -0.4753])\n",
      "tensor([ 0.1154, -0.0536,  0.0191, -0.0951], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.0701, 0.0701])\n",
      "tensor([0.0140, 0.0140], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([1.6853, 3.6853], requires_grad=True)\n",
      "tensor([[0.6655, 0.3345],\n",
      "        [0.6265, 0.3735],\n",
      "        [0.6654, 0.3346],\n",
      "        [0.6968, 0.3032],\n",
      "        [0.6649, 0.3351],\n",
      "        [0.6257, 0.3743],\n",
      "        [0.5822, 0.4178],\n",
      "        [0.5386, 0.4614],\n",
      "        [0.4990, 0.5010],\n",
      "        [0.5394, 0.4606],\n",
      "        [0.5833, 0.4167],\n",
      "        [0.5392, 0.4608],\n",
      "        [0.5831, 0.4169],\n",
      "        [0.6261, 0.3739],\n",
      "        [0.6647, 0.3353],\n",
      "        [0.6246, 0.3754]], dtype=torch.float64)\n",
      "Finished episode 40 Average rewards:  16.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0057, -0.0291, -0.0263,  0.2589,  0.0879, -0.2517, -0.1114,  0.0584,\n",
      "        -0.1115,  0.5424,  0.0632, -0.5425, -0.1615, -0.1644,  0.0000, -0.1145,\n",
      "        -0.7485,  0.0000,  0.1162, -0.1563,  0.0000,  0.0578,  0.4448,  0.0000])\n",
      "tensor([ 1.1426e-03, -5.8252e-03, -5.2593e-03,  5.1785e-02,  1.7587e-02,\n",
      "        -5.0340e-02, -2.2281e-02,  1.1678e-02, -2.2291e-02,  1.0848e-01,\n",
      "         1.2642e-02, -1.0851e-01, -3.2304e-02, -3.2886e-02, -2.2849e-17,\n",
      "        -2.2909e-02, -1.4971e-01, -3.3078e-17,  2.3249e-02, -3.1264e-02,\n",
      "         0.0000e+00,  1.1560e-02,  8.8962e-02,  1.1742e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.0433, -0.3091, -0.0074,  0.0779])\n",
      "tensor([-0.0087, -0.0618, -0.0015,  0.0156], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.5754, 0.5754])\n",
      "tensor([0.1151, 0.1151], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([2.2607, 4.2607], requires_grad=True)\n",
      "tensor([[0.7276, 0.2724],\n",
      "        [0.7355, 0.2645],\n",
      "        [0.7274, 0.2726],\n",
      "        [0.7354, 0.2646],\n",
      "        [0.7418, 0.2582],\n",
      "        [0.7463, 0.2537],\n",
      "        [0.7484, 0.2516],\n",
      "        [0.7478, 0.2522],\n",
      "        [0.7468, 0.2532],\n",
      "        [0.7461, 0.2539],\n",
      "        [0.7425, 0.2575],\n",
      "        [0.7439, 0.2561],\n",
      "        [0.7425, 0.2575]], dtype=torch.float64)\n",
      "Finished episode 41 Average rewards:  13.0\n",
      "tensor([ 0.0796, -0.0199,  0.0425,  0.7362, -0.0442, -0.7339, -0.1322, -0.0057,\n",
      "        -0.1322,  0.1318, -0.0097, -0.1318,  0.3189,  0.5680,  0.0000, -0.0936,\n",
      "        -0.7249,  0.0000, -0.2685, -0.1330,  0.0000, -0.5544, -0.0661,  0.0000])\n",
      "tensor([ 1.5916e-02, -3.9772e-03,  8.4911e-03,  1.4724e-01, -8.8321e-03,\n",
      "        -1.4677e-01, -2.6441e-02, -1.1396e-03, -2.6433e-02,  2.6359e-02,\n",
      "        -1.9430e-03, -2.6357e-02,  6.3788e-02,  1.1360e-01,  2.0614e-17,\n",
      "        -1.8722e-02, -1.4498e-01, -1.8642e-17, -5.3702e-02, -2.6591e-02,\n",
      "         0.0000e+00, -1.1088e-01, -1.3215e-02, -1.4303e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 1.8947, -0.2831, -1.4342, -2.9181])\n",
      "tensor([ 0.3789, -0.0566, -0.2868, -0.5836], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-0.2590, -0.2590])\n",
      "tensor([-0.0518, -0.0518], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([2.0017, 4.0017], requires_grad=True)\n",
      "tensor([[0.6667, 0.3333],\n",
      "        [0.6626, 0.3374],\n",
      "        [0.6670, 0.3330],\n",
      "        [0.6769, 0.3231],\n",
      "        [0.6914, 0.3086],\n",
      "        [0.7089, 0.2911],\n",
      "        [0.7271, 0.2729],\n",
      "        [0.7435, 0.2565],\n",
      "        [0.7289, 0.2711],\n",
      "        [0.7458, 0.2542],\n",
      "        [0.7582, 0.2418],\n",
      "        [0.7640, 0.2360],\n",
      "        [0.7614, 0.2386]], dtype=torch.float64)\n",
      "Monitored episode 50 Average Monitored rewards:  16.08\n",
      "Finished episode 42 Average rewards:  11.0\n",
      "tensor([ 2.3547e-01, -6.9880e-04,  1.8819e-01, -1.2004e-02, -2.3222e-04,\n",
      "         1.1791e-02,  6.6016e-01,  2.6452e-02,  6.5998e-01, -2.5498e-02,\n",
      "         3.0367e-02,  2.5810e-02, -1.6544e-03, -4.0258e-01,  0.0000e+00,\n",
      "        -2.5961e-01,  1.1190e-01,  0.0000e+00,  2.1025e-01,  2.5315e-01,\n",
      "         0.0000e+00, -1.3226e-02, -2.7848e-01,  0.0000e+00])\n",
      "tensor([ 4.7094e-02, -1.3976e-04,  3.7639e-02, -2.4008e-03, -4.6451e-05,\n",
      "         2.3582e-03,  1.3203e-01,  5.2903e-03,  1.3200e-01, -5.0996e-03,\n",
      "         6.0733e-03,  5.1620e-03, -3.3089e-04, -8.0516e-02, -1.0258e-17,\n",
      "        -5.1923e-02,  2.2380e-02,  2.7361e-17,  4.2050e-02,  5.0630e-02,\n",
      "         0.0000e+00, -2.6452e-03, -5.5696e-02,  1.0525e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.5005, -0.8844,  2.0858,  0.3344])\n",
      "tensor([-0.1001, -0.1769,  0.4172,  0.0669], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.8338, 0.8338])\n",
      "tensor([0.1668, 0.1668], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([2.8355, 4.8355], requires_grad=True)\n",
      "tensor([[0.3409, 0.6591],\n",
      "        [0.4416, 0.5584],\n",
      "        [0.5755, 0.4245],\n",
      "        [0.6975, 0.3025],\n",
      "        [0.7765, 0.2235],\n",
      "        [0.8135, 0.1865],\n",
      "        [0.8207, 0.1793],\n",
      "        [0.8087, 0.1913],\n",
      "        [0.7997, 0.2003],\n",
      "        [0.7792, 0.2208]], dtype=torch.float64)\n",
      "Finished episode 43 Average rewards:  10.0\n",
      "tensor([ 5.5971e-02,  1.7560e-02,  9.1475e-02, -2.5703e-01,  2.5800e-03,\n",
      "         2.5485e-01, -2.7087e+00,  1.2950e-02, -2.7087e+00, -5.8297e-01,\n",
      "         2.2631e-03,  5.8296e-01, -3.7667e-01, -5.6374e-01,  0.0000e+00,\n",
      "        -6.6840e-01,  1.4396e-01,  0.0000e+00,  2.5800e-01, -3.7514e+00,\n",
      "         0.0000e+00, -1.1783e-01,  3.9630e-01,  0.0000e+00])\n",
      "tensor([ 1.1194e-02,  3.5120e-03,  1.8295e-02, -5.1406e-02,  5.1601e-04,\n",
      "         5.0970e-02, -5.4173e-01,  2.5901e-03, -5.4173e-01, -1.1659e-01,\n",
      "         4.5257e-04,  1.1659e-01, -7.5334e-02, -1.1275e-01, -2.8310e-17,\n",
      "        -1.3368e-01,  2.8791e-02,  1.6293e-18,  5.1600e-02, -7.5028e-01,\n",
      "         0.0000e+00, -2.3567e-02,  7.9260e-02, -6.3239e-19],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.9532, -4.4295,  1.2618, -0.2419])\n",
      "tensor([-0.1906, -0.8859,  0.2524, -0.0484], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([1.0755, 1.0755])\n",
      "tensor([0.2151, 0.2151], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([3.9109, 5.9109], requires_grad=True)\n",
      "tensor([[0.3070, 0.6930],\n",
      "        [0.3284, 0.6716],\n",
      "        [0.3870, 0.6130],\n",
      "        [0.4709, 0.5291],\n",
      "        [0.5599, 0.4401],\n",
      "        [0.4474, 0.5526],\n",
      "        [0.3563, 0.6437],\n",
      "        [0.4323, 0.5677],\n",
      "        [0.5242, 0.4758],\n",
      "        [0.4113, 0.5887],\n",
      "        [0.5049, 0.4951],\n",
      "        [0.3913, 0.6087],\n",
      "        [0.4869, 0.5131],\n",
      "        [0.5891, 0.4109]], dtype=torch.float64)\n",
      "Finished episode 44 Average rewards:  14.0\n",
      "tensor([ 0.2655, -0.0469,  0.0388, -0.7051,  0.2932,  0.7478,  1.5313,  0.0091,\n",
      "         1.5313, -0.5375,  0.0717,  0.5374,  1.2842, -0.1494,  0.0000, -0.1661,\n",
      "        -0.1976,  0.0000, -0.0205,  0.1930,  0.0000,  0.6227,  0.1636,  0.0000])\n",
      "tensor([ 5.3102e-02, -9.3864e-03,  7.7691e-03, -1.4102e-01,  5.8650e-02,\n",
      "         1.4957e-01,  3.0625e-01,  1.8116e-03,  3.0626e-01, -1.0750e-01,\n",
      "         1.4332e-02,  1.0748e-01,  2.5685e-01, -2.9886e-02, -9.0909e-18,\n",
      "        -3.3222e-02, -3.9522e-02,  5.9908e-17, -4.1096e-03,  3.8591e-02,\n",
      "         0.0000e+00,  1.2455e-01,  3.2713e-02,  2.7503e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 2.8822, -0.6280, -0.1261,  2.1798])\n",
      "tensor([ 0.5764, -0.1256, -0.0252,  0.4360], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-0.2029, -0.2029])\n",
      "tensor([-0.0406, -0.0406], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([3.7080, 5.7080], requires_grad=True)\n",
      "tensor([[0.5264, 0.4736],\n",
      "        [0.5885, 0.4115],\n",
      "        [0.5560, 0.4440],\n",
      "        [0.4641, 0.5359],\n",
      "        [0.4091, 0.5909],\n",
      "        [0.4378, 0.5622],\n",
      "        [0.5017, 0.4983],\n",
      "        [0.5188, 0.4812],\n",
      "        [0.4847, 0.5153],\n",
      "        [0.5169, 0.4831]], dtype=torch.float64)\n",
      "Finished episode 45 Average rewards:  10.0\n",
      "tensor([-1.0232,  0.0465, -1.1038,  1.5262, -0.4221, -1.5013,  1.1781, -0.0235,\n",
      "         1.1782, -1.5054, -0.1433,  1.4909,  0.5863,  1.1059,  0.0000, -3.6270,\n",
      "         1.0977,  0.0000,  0.0660,  1.0816,  0.0000, -0.3406, -1.9100,  0.0000])\n",
      "tensor([-2.0464e-01,  9.3051e-03, -2.2075e-01,  3.0524e-01, -8.4421e-02,\n",
      "        -3.0025e-01,  2.3562e-01, -4.7046e-03,  2.3565e-01, -3.0109e-01,\n",
      "        -2.8660e-02,  2.9818e-01,  1.1726e-01,  2.2118e-01, -2.8436e-17,\n",
      "        -7.2540e-01,  2.1955e-01,  9.4041e-17,  1.3207e-02,  2.1631e-01,\n",
      "         0.0000e+00, -6.8128e-02, -3.8199e-01, -6.7186e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([  1.4100, -17.5921,   0.3542,  -0.7175])\n",
      "tensor([ 0.2820, -3.5184,  0.0708, -0.1435], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([2.5663, 2.5663])\n",
      "tensor([0.5133, 0.5133], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([6.2743, 8.2743], requires_grad=True)\n",
      "tensor([[0.5388, 0.4612],\n",
      "        [0.2878, 0.7122],\n",
      "        [0.2006, 0.7994],\n",
      "        [0.2710, 0.7290],\n",
      "        [0.5032, 0.4968],\n",
      "        [0.7274, 0.2726],\n",
      "        [0.7868, 0.2132],\n",
      "        [0.7272, 0.2728],\n",
      "        [0.5129, 0.4871],\n",
      "        [0.7261, 0.2739]], dtype=torch.float64)\n",
      "Finished episode 46 Average rewards:  10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.2645, -0.1628,  0.9276, -0.6978, -0.0182,  0.7170, -0.9636, -0.0925,\n",
      "        -0.9634,  2.2197, -0.1363, -2.2234, -0.2358, -0.8051,  0.0000, -0.0819,\n",
      "         0.8255,  0.0000, -0.4809,  0.1467,  0.0000, -0.2306,  2.2940,  0.0000])\n",
      "tensor([ 2.5290e-01, -3.2554e-02,  1.8551e-01, -1.3957e-01, -3.6352e-03,\n",
      "         1.4340e-01, -1.9273e-01, -1.8501e-02, -1.9267e-01,  4.4394e-01,\n",
      "        -2.7262e-02, -4.4467e-01, -4.7156e-02, -1.6102e-01, -9.2186e-18,\n",
      "        -1.6379e-02,  1.6510e-01, -1.0283e-17, -9.6187e-02,  2.9333e-02,\n",
      "         0.0000e+00, -4.6125e-02,  4.5879e-01, -2.2727e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.3150,  1.0270, -1.3760, -0.6343])\n",
      "tensor([-0.0630,  0.2054, -0.2752, -0.1269], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([1.2373, 1.2373])\n",
      "tensor([0.2475, 0.2475], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([7.5115, 9.5115], requires_grad=True)\n",
      "tensor([[0.4990, 0.5010],\n",
      "        [0.4494, 0.5506],\n",
      "        [0.5712, 0.4288],\n",
      "        [0.4725, 0.5275],\n",
      "        [0.5136, 0.4864],\n",
      "        [0.4848, 0.5152],\n",
      "        [0.5980, 0.4020],\n",
      "        [0.5131, 0.4869],\n",
      "        [0.5308, 0.4692],\n",
      "        [0.5307, 0.4693],\n",
      "        [0.6191, 0.3809],\n",
      "        [0.5786, 0.4214],\n",
      "        [0.5808, 0.4192],\n",
      "        [0.5955, 0.4045]], dtype=torch.float64)\n",
      "Monitored episode 50 Average Monitored rewards:  24.6\n",
      "Finished episode 47 Average rewards:  55.0\n",
      "tensor([ 1.5602, -0.2238,  1.6723, -1.1373,  0.2198,  1.1836, -0.7646,  0.2536,\n",
      "        -0.7488, -0.2982,  0.1693,  0.2861,  1.3207, -1.8407,  0.0000, -0.0283,\n",
      "         0.6673,  0.0000, -0.1222, -0.2362,  0.0000,  0.6195, -0.2001,  0.0000])\n",
      "tensor([ 3.1203e-01, -4.4752e-02,  3.3447e-01, -2.2746e-01,  4.3966e-02,\n",
      "         2.3672e-01, -1.5292e-01,  5.0721e-02, -1.4976e-01, -5.9647e-02,\n",
      "         3.3857e-02,  5.7219e-02,  2.6414e-01, -3.6814e-01,  2.2673e-17,\n",
      "        -5.6691e-03,  1.3346e-01, -1.8108e-17, -2.4435e-02, -4.7250e-02,\n",
      "         0.0000e+00,  1.2390e-01, -4.0023e-02, -1.5258e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 1.8088,  0.6786, -0.2384,  0.5658])\n",
      "tensor([ 0.3618,  0.1357, -0.0477,  0.1132], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.7350, 0.7350])\n",
      "tensor([0.1470, 0.1470], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([ 8.2465, 10.2465], requires_grad=True)\n",
      "tensor([[0.5075, 0.4925],\n",
      "        [0.4848, 0.5152],\n",
      "        [0.5078, 0.4922],\n",
      "        [0.5267, 0.4733],\n",
      "        [0.5072, 0.4928],\n",
      "        [0.5281, 0.4719],\n",
      "        [0.5068, 0.4932],\n",
      "        [0.4852, 0.5148],\n",
      "        [0.5073, 0.4927],\n",
      "        [0.4854, 0.5146],\n",
      "        [0.5076, 0.4924],\n",
      "        [0.5273, 0.4727],\n",
      "        [0.5071, 0.4929],\n",
      "        [0.4860, 0.5140],\n",
      "        [0.5074, 0.4926],\n",
      "        [0.4864, 0.5136],\n",
      "        [0.5075, 0.4925],\n",
      "        [0.5271, 0.4729],\n",
      "        [0.5069, 0.4931],\n",
      "        [0.4875, 0.5125],\n",
      "        [0.5071, 0.4929],\n",
      "        [0.5282, 0.4718],\n",
      "        [0.4825, 0.5175],\n",
      "        [0.5328, 0.4672],\n",
      "        [0.4828, 0.5172],\n",
      "        [0.5368, 0.4632],\n",
      "        [0.5199, 0.4801],\n",
      "        [0.5418, 0.4582],\n",
      "        [0.4830, 0.5170],\n",
      "        [0.5457, 0.4543],\n",
      "        [0.5371, 0.4629],\n",
      "        [0.4960, 0.5040],\n",
      "        [0.5510, 0.4490],\n",
      "        [0.5557, 0.4443],\n",
      "        [0.5613, 0.4387],\n",
      "        [0.5627, 0.4373],\n",
      "        [0.5723, 0.4277],\n",
      "        [0.5716, 0.4284]], dtype=torch.float64)\n",
      "Finished episode 48 Average rewards:  38.0\n",
      "tensor([-0.6442, -0.3385, -0.6520,  1.0702,  0.0875, -1.0681, -1.6192,  0.0710,\n",
      "        -1.6298, -0.5371,  0.0174,  0.5362,  0.0754,  0.6740,  0.0000, -0.2390,\n",
      "        -0.1645,  0.0000, -0.7739, -1.6303,  0.0000, -0.9076, -0.6018,  0.0000])\n",
      "tensor([-1.2884e-01, -6.7691e-02, -1.3039e-01,  2.1405e-01,  1.7492e-02,\n",
      "        -2.1363e-01, -3.2383e-01,  1.4200e-02, -3.2596e-01, -1.0742e-01,\n",
      "         3.4769e-03,  1.0724e-01,  1.5078e-02,  1.3481e-01, -3.1385e-18,\n",
      "        -4.7792e-02, -3.2901e-02,  1.9083e-17, -1.5478e-01, -3.2605e-01,\n",
      "         0.0000e+00, -1.8152e-01, -1.2036e-01,  5.5096e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 0.1304,  1.0745, -2.1435, -1.5794])\n",
      "tensor([ 0.0261,  0.2149, -0.4287, -0.3159], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([1.0996, 1.0996])\n",
      "tensor([0.2199, 0.2199], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([ 9.3461, 11.3461], requires_grad=True)\n",
      "tensor([[0.3925, 0.6075],\n",
      "        [0.5495, 0.4505],\n",
      "        [0.3906, 0.6094],\n",
      "        [0.6047, 0.3953],\n",
      "        [0.6275, 0.3725],\n",
      "        [0.3934, 0.6066],\n",
      "        [0.6216, 0.3784],\n",
      "        [0.5689, 0.4311],\n",
      "        [0.4032, 0.5968],\n",
      "        [0.5600, 0.4400],\n",
      "        [0.6280, 0.3720],\n",
      "        [0.4232, 0.5768],\n",
      "        [0.4576, 0.5424],\n",
      "        [0.6621, 0.3379],\n",
      "        [0.4331, 0.5669],\n",
      "        [0.6867, 0.3133],\n",
      "        [0.4096, 0.5904],\n",
      "        [0.4337, 0.5663],\n",
      "        [0.7421, 0.2579],\n",
      "        [0.5245, 0.4755],\n",
      "        [0.7520, 0.2480],\n",
      "        [0.5190, 0.4810],\n",
      "        [0.3502, 0.6498],\n",
      "        [0.5138, 0.4862],\n",
      "        [0.7687, 0.2313],\n",
      "        [0.4311, 0.5689]], dtype=torch.float64)\n",
      "Finished episode 49 Average rewards:  26.0\n",
      "tensor([ 8.6422e-02, -3.7065e-02,  8.5375e-02,  1.6702e+00, -8.2087e-02,\n",
      "        -1.6690e+00, -6.8516e-01, -1.7305e-01, -6.7968e-01, -5.9835e-01,\n",
      "         3.1440e-02,  5.9690e-01, -9.8923e-02, -1.3867e+00,  0.0000e+00,\n",
      "        -1.6691e-01,  1.6241e-03,  0.0000e+00,  1.1170e+00, -2.6650e+00,\n",
      "         0.0000e+00,  8.7810e-01, -2.3444e+00,  0.0000e+00])\n",
      "tensor([ 1.7284e-02, -7.4129e-03,  1.7075e-02,  3.3405e-01, -1.6417e-02,\n",
      "        -3.3381e-01, -1.3703e-01, -3.4609e-02, -1.3594e-01, -1.1967e-01,\n",
      "         6.2880e-03,  1.1938e-01, -1.9785e-02, -2.7734e-01,  3.5852e-17,\n",
      "        -3.3382e-02,  3.2482e-04,  4.8334e-17,  2.2340e-01, -5.3299e-01,\n",
      "         0.0000e+00,  1.7562e-01, -4.6888e-01, -3.3217e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.1754,  2.1712,  1.9834,  3.2470])\n",
      "tensor([-0.0351,  0.4342,  0.3967,  0.6494], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([1.0206, 1.0206])\n",
      "tensor([0.2041, 0.2041], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([10.3667, 12.3667], requires_grad=True)\n",
      "tensor([[0.5255, 0.4745],\n",
      "        [0.4046, 0.5954],\n",
      "        [0.5269, 0.4731],\n",
      "        [0.4093, 0.5907],\n",
      "        [0.6067, 0.3933],\n",
      "        [0.4258, 0.5742],\n",
      "        [0.5320, 0.4680],\n",
      "        [0.5434, 0.4566],\n",
      "        [0.5318, 0.4682],\n",
      "        [0.4243, 0.5757],\n",
      "        [0.5336, 0.4664],\n",
      "        [0.5504, 0.4496],\n",
      "        [0.4902, 0.5098],\n",
      "        [0.5432, 0.4568],\n",
      "        [0.5316, 0.4684],\n",
      "        [0.4107, 0.5893],\n",
      "        [0.6286, 0.3714],\n",
      "        [0.5541, 0.4459],\n",
      "        [0.6522, 0.3478],\n",
      "        [0.5479, 0.4521],\n",
      "        [0.6758, 0.3242],\n",
      "        [0.5304, 0.4696],\n",
      "        [0.4107, 0.5893],\n",
      "        [0.4938, 0.5062],\n",
      "        [0.4549, 0.5451],\n",
      "        [0.6861, 0.3139]], dtype=torch.float64)\n",
      "Finished episode 50 Average rewards:  26.0\n",
      "tensor([-3.1155e-01,  3.3765e-03, -3.0970e-01, -2.7921e-01,  3.4695e-02,\n",
      "         2.7694e-01, -1.1917e-01,  1.0200e-02, -1.1922e-01, -9.2436e-02,\n",
      "         1.0014e-04,  9.2394e-02,  5.4330e-02,  1.0380e-01,  0.0000e+00,\n",
      "         3.0462e-01,  2.9578e-01,  0.0000e+00, -1.3413e-02,  3.0034e-01,\n",
      "         0.0000e+00, -1.6964e-01, -1.1129e-01,  0.0000e+00])\n",
      "tensor([-6.2311e-02,  6.7529e-04, -6.1939e-02, -5.5841e-02,  6.9390e-03,\n",
      "         5.5388e-02, -2.3834e-02,  2.0399e-03, -2.3844e-02, -1.8487e-02,\n",
      "         2.0078e-05,  1.8479e-02,  1.0866e-02,  2.0759e-02,  5.0548e-17,\n",
      "         6.0925e-02,  5.9156e-02,  4.2503e-17, -2.6827e-03,  6.0068e-02,\n",
      "         0.0000e+00, -3.3928e-02, -2.2258e-02, -3.7523e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 3.3899e-01,  5.6562e+00, -2.2945e-03, -3.3292e-01])\n",
      "tensor([ 6.7798e-02,  1.1312e+00, -4.5891e-04, -6.6585e-02],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.2595, -0.2595])\n",
      "tensor([-0.0519, -0.0519], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([10.1072, 12.1072], requires_grad=True)\n",
      "tensor([[0.5281, 0.4719],\n",
      "        [0.5829, 0.4171],\n",
      "        [0.6856, 0.3144],\n",
      "        [0.5840, 0.4160],\n",
      "        [0.6889, 0.3111],\n",
      "        [0.5854, 0.4146],\n",
      "        [0.6922, 0.3078],\n",
      "        [0.5873, 0.4127],\n",
      "        [0.6955, 0.3045],\n",
      "        [0.5897, 0.4103],\n",
      "        [0.5341, 0.4659],\n",
      "        [0.5918, 0.4082],\n",
      "        [0.6997, 0.3003],\n",
      "        [0.5950, 0.4050],\n",
      "        [0.5341, 0.4659],\n",
      "        [0.5979, 0.4021],\n",
      "        [0.5331, 0.4669],\n",
      "        [0.6012, 0.3988],\n",
      "        [0.5320, 0.4680],\n",
      "        [0.6680, 0.3320],\n",
      "        [0.6791, 0.3209],\n",
      "        [0.5389, 0.4611],\n",
      "        [0.6767, 0.3233],\n",
      "        [0.5395, 0.4605],\n",
      "        [0.5664, 0.4336],\n",
      "        [0.5398, 0.4602],\n",
      "        [0.6685, 0.3315],\n",
      "        [0.5406, 0.4594],\n",
      "        [0.6648, 0.3352],\n",
      "        [0.5417, 0.4583],\n",
      "        [0.6608, 0.3392],\n",
      "        [0.6012, 0.3988]], dtype=torch.float64)\n",
      "Finished episode 51 Average rewards:  32.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3.2470e-01,  5.2673e-02,  3.2621e-01, -9.8558e-01, -5.4426e-02,\n",
      "         9.8713e-01,  5.7560e-01, -6.9206e-02,  5.7686e-01,  4.9396e-01,\n",
      "        -1.2131e-03, -4.9389e-01, -1.1879e-01,  3.1826e-01,  0.0000e+00,\n",
      "        -8.8988e-01,  1.0202e+00,  0.0000e+00, -1.1718e-01,  1.2425e+00,\n",
      "         0.0000e+00,  5.9885e-02,  5.1668e-01,  0.0000e+00])\n",
      "tensor([ 6.4940e-02,  1.0535e-02,  6.5243e-02, -1.9712e-01, -1.0885e-02,\n",
      "         1.9743e-01,  1.1512e-01, -1.3841e-02,  1.1537e-01,  9.8792e-02,\n",
      "        -2.4259e-04, -9.8779e-02, -2.3759e-02,  6.3651e-02,  1.3597e-16,\n",
      "        -1.7798e-01,  2.0404e-01, -9.8322e-17, -2.3436e-02,  2.4850e-01,\n",
      "         0.0000e+00,  1.1977e-02,  1.0334e-01, -1.9411e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.1259, -2.6230, -0.6270,  0.2090])\n",
      "tensor([-0.0252, -0.5246, -0.1254,  0.0418], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([1.3773, 1.3773])\n",
      "tensor([0.2755, 0.2755], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([11.4845, 13.4845], requires_grad=True)\n",
      "tensor([[0.3506, 0.6494],\n",
      "        [0.3795, 0.6205],\n",
      "        [0.6512, 0.3488],\n",
      "        [0.3793, 0.6207],\n",
      "        [0.6518, 0.3482],\n",
      "        [0.7200, 0.2800],\n",
      "        [0.4906, 0.5094],\n",
      "        [0.3240, 0.6760],\n",
      "        [0.4895, 0.5105],\n",
      "        [0.7209, 0.2791],\n",
      "        [0.6601, 0.3399],\n",
      "        [0.3880, 0.6120],\n",
      "        [0.6658, 0.3342],\n",
      "        [0.3948, 0.6052]], dtype=torch.float64)\n",
      "Monitored episode 50 Average Monitored rewards:  19.02\n",
      "Finished episode 52 Average rewards:  26.0\n",
      "tensor([-0.4852, -0.0235, -0.4848, -0.5961,  0.0141,  0.5986, -0.4869, -0.0270,\n",
      "        -0.4869,  0.1942, -0.0048, -0.1943,  0.1343,  0.7465,  0.0000, -0.1163,\n",
      "        -0.8202,  0.0000,  0.4858, -0.5141,  0.0000,  0.4236,  0.2242,  0.0000])\n",
      "tensor([-9.7040e-02, -4.7041e-03, -9.6967e-02, -1.1923e-01,  2.8161e-03,\n",
      "         1.1973e-01, -9.7383e-02, -5.3964e-03, -9.7379e-02,  3.8847e-02,\n",
      "        -9.6891e-04, -3.8856e-02,  2.6870e-02,  1.4930e-01,  1.4286e-17,\n",
      "        -2.3265e-02, -1.6405e-01,  4.4687e-17,  9.7160e-02, -1.0282e-01,\n",
      "         0.0000e+00,  8.4712e-02,  4.4842e-02, -2.0595e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([0.7412, 3.2671, 1.9024, 1.1145])\n",
      "tensor([0.1482, 0.6534, 0.3805, 0.2229], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-0.5542, -0.5542])\n",
      "tensor([-0.1108, -0.1108], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([10.9303, 12.9303], requires_grad=True)\n",
      "tensor([[0.4131, 0.5869],\n",
      "        [0.3048, 0.6952],\n",
      "        [0.3736, 0.6264],\n",
      "        [0.4812, 0.5188],\n",
      "        [0.3765, 0.6235],\n",
      "        [0.4715, 0.5285],\n",
      "        [0.3872, 0.6128],\n",
      "        [0.3122, 0.6878],\n",
      "        [0.3911, 0.6089],\n",
      "        [0.3198, 0.6802],\n",
      "        [0.3999, 0.6001],\n",
      "        [0.4118, 0.5882],\n",
      "        [0.3277, 0.6723]], dtype=torch.float64)\n",
      "Finished episode 53 Average rewards:  13.0\n",
      "tensor([-0.4800, -0.0292, -0.4805, -0.1328, -0.0287,  0.1304,  0.1562, -0.0322,\n",
      "         0.1556,  0.2286, -0.0191, -0.2286, -0.6862,  0.6076,  0.0000,  0.6108,\n",
      "         1.3234,  0.0000, -0.2909,  0.1267,  0.0000, -0.5397,  0.3569,  0.0000])\n",
      "tensor([-9.6004e-02, -5.8369e-03, -9.6103e-02, -2.6559e-02, -5.7350e-03,\n",
      "         2.6089e-02,  3.1232e-02, -6.4326e-03,  3.1125e-02,  4.5724e-02,\n",
      "        -3.8101e-03, -4.5720e-02, -1.3723e-01,  1.2153e-01, -1.3296e-18,\n",
      "         1.2216e-01,  2.6468e-01,  4.9175e-17, -5.8178e-02,  2.5337e-02,\n",
      "         0.0000e+00, -1.0793e-01,  7.1389e-02, -1.6806e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-1.2347, -1.0589, -0.5382, -0.7440])\n",
      "tensor([-0.2469, -0.2118, -0.1076, -0.1488], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.3296, 0.3296])\n",
      "tensor([0.0659, 0.0659], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([11.2599, 13.2599], requires_grad=True)\n",
      "tensor([[0.6336, 0.3664],\n",
      "        [0.6308, 0.3692],\n",
      "        [0.6322, 0.3678],\n",
      "        [0.6338, 0.3662],\n",
      "        [0.5194, 0.4806],\n",
      "        [0.4040, 0.5960],\n",
      "        [0.5393, 0.4607],\n",
      "        [0.6594, 0.3406],\n",
      "        [0.5505, 0.4495],\n",
      "        [0.6670, 0.3330],\n",
      "        [0.5617, 0.4383],\n",
      "        [0.6736, 0.3264],\n",
      "        [0.5938, 0.4062],\n",
      "        [0.4307, 0.5693],\n",
      "        [0.3957, 0.6043],\n",
      "        [0.5072, 0.4928],\n",
      "        [0.4010, 0.5990],\n",
      "        [0.4881, 0.5119],\n",
      "        [0.6105, 0.3895],\n",
      "        [0.4603, 0.5397],\n",
      "        [0.5827, 0.4173],\n",
      "        [0.6586, 0.3414],\n",
      "        [0.6066, 0.3934],\n",
      "        [0.6528, 0.3472],\n",
      "        [0.6231, 0.3769],\n",
      "        [0.6349, 0.3651],\n",
      "        [0.6177, 0.3823]], dtype=torch.float64)\n",
      "Finished episode 54 Average rewards:  27.0\n",
      "tensor([ 1.0517,  0.1207,  1.0763, -2.3084,  0.4807,  2.3296,  0.2105,  0.1594,\n",
      "         0.2128, -3.6359,  0.0251,  3.6347,  0.9673, -2.8516,  0.0000,  2.3938,\n",
      "        -0.6310,  0.0000, -0.9638,  2.8699,  0.0000, -1.3920, -4.4935,  0.0000])\n",
      "tensor([ 2.1035e-01,  2.4131e-02,  2.1525e-01, -4.6169e-01,  9.6132e-02,\n",
      "         4.6592e-01,  4.2106e-02,  3.1881e-02,  4.2560e-02, -7.2718e-01,\n",
      "         5.0135e-03,  7.2694e-01,  1.9346e-01, -5.7031e-01, -1.4131e-17,\n",
      "         4.7877e-01, -1.2621e-01,  2.7205e-16, -1.9276e-01,  5.7399e-01,\n",
      "         0.0000e+00, -2.7840e-01, -8.9871e-01,  1.0440e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([  2.2061,  34.3072, -11.4396,  -7.4842])\n",
      "tensor([ 0.4412,  6.8614, -2.2879, -1.4968], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([7.1500, 7.1500])\n",
      "tensor([1.4300, 1.4300], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([18.4099, 20.4099], requires_grad=True)\n",
      "tensor([[0.2495, 0.7505],\n",
      "        [0.3912, 0.6088],\n",
      "        [0.3680, 0.6320],\n",
      "        [0.2291, 0.7709],\n",
      "        [0.2138, 0.7862],\n",
      "        [0.3936, 0.6064],\n",
      "        [0.5703, 0.4297],\n",
      "        [0.4767, 0.5233],\n",
      "        [0.6690, 0.3310],\n",
      "        [0.5830, 0.4170]], dtype=torch.float64)\n",
      "Finished episode 55 Average rewards:  10.0\n",
      "tensor([-4.6979e-01, -2.2252e-01, -4.6923e-01,  8.9233e-01,  8.0424e-02,\n",
      "        -1.0290e+00,  2.2252e+00,  4.7018e-01,  2.2130e+00, -7.2839e-01,\n",
      "         4.1437e-03,  7.2845e-01,  1.3194e+00,  3.2973e+00,  0.0000e+00,\n",
      "         2.7843e+00,  1.9781e+00,  0.0000e+00, -8.8046e-01, -1.5580e+00,\n",
      "         0.0000e+00,  1.0001e+00,  2.7628e-03,  0.0000e+00])\n",
      "tensor([-9.3959e-02, -4.4503e-02, -9.3847e-02,  1.7847e-01,  1.6085e-02,\n",
      "        -2.0580e-01,  4.4503e-01,  9.4036e-02,  4.4259e-01, -1.4568e-01,\n",
      "         8.2883e-04,  1.4569e-01,  2.6388e-01,  6.5946e-01,  9.1302e-17,\n",
      "         5.5686e-01,  3.9562e-01, -9.0618e-17, -1.7609e-01, -3.1160e-01,\n",
      "         0.0000e+00,  2.0002e-01,  5.5264e-04,  5.2362e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([  4.5030,  30.0290, -31.8547,   3.5853])\n",
      "tensor([ 0.9006,  6.0058, -6.3710,  0.7171], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-7.7009, -7.7009])\n",
      "tensor([-1.5402, -1.5402], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([10.7090, 12.7090], requires_grad=True)\n",
      "tensor([[0.7323, 0.2677],\n",
      "        [0.8575, 0.1425],\n",
      "        [0.8233, 0.1767],\n",
      "        [0.8033, 0.1967],\n",
      "        [0.6743, 0.3257],\n",
      "        [0.7662, 0.2338],\n",
      "        [0.4830, 0.5170],\n",
      "        [0.4161, 0.5839],\n",
      "        [0.2922, 0.7078],\n",
      "        [0.8259, 0.1741],\n",
      "        [0.6828, 0.3172],\n",
      "        [0.3881, 0.6119],\n",
      "        [0.5191, 0.4809]], dtype=torch.float64)\n",
      "Finished episode 56 Average rewards:  13.0\n",
      "tensor([ 0.8050,  0.2867,  0.8278, -1.8149,  0.3082,  1.7771, -0.2553, -0.2295,\n",
      "        -0.0384, -0.7007, -0.0179,  0.7010, -0.9784,  0.5337,  0.0000, -0.5040,\n",
      "        -2.2264,  0.0000, -1.2264,  1.8793,  0.0000,  0.4082,  3.2100,  0.0000])\n",
      "tensor([ 1.6101e-01,  5.7330e-02,  1.6557e-01, -3.6298e-01,  6.1643e-02,\n",
      "         3.5541e-01, -5.1054e-02, -4.5890e-02, -7.6757e-03, -1.4013e-01,\n",
      "        -3.5896e-03,  1.4020e-01, -1.9568e-01,  1.0674e-01,  5.2323e-18,\n",
      "        -1.0080e-01, -4.4529e-01, -8.7086e-17, -2.4528e-01,  3.7586e-01,\n",
      "         0.0000e+00,  8.1640e-02,  6.4200e-01, -1.4365e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 0.1323, 14.1117, 48.4829, -2.1696])\n",
      "tensor([ 0.0265,  2.8223,  9.6966, -0.4339], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.3923, 0.3923])\n",
      "tensor([0.0785, 0.0785], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([11.1013, 13.1013], requires_grad=True)\n",
      "tensor([[0.7211, 0.2789],\n",
      "        [0.4206, 0.5794],\n",
      "        [0.4984, 0.5016],\n",
      "        [0.1504, 0.8496],\n",
      "        [0.8368, 0.1632],\n",
      "        [0.3876, 0.6124],\n",
      "        [0.8303, 0.1697],\n",
      "        [0.2456, 0.7544],\n",
      "        [0.4739, 0.5261],\n",
      "        [0.5205, 0.4795],\n",
      "        [0.5334, 0.4666],\n",
      "        [0.4050, 0.5950],\n",
      "        [0.6444, 0.3556],\n",
      "        [0.4812, 0.5188],\n",
      "        [0.3414, 0.6586],\n",
      "        [0.4400, 0.5600],\n",
      "        [0.4109, 0.5891],\n",
      "        [0.7048, 0.2952],\n",
      "        [0.6318, 0.3682],\n",
      "        [0.5050, 0.4950],\n",
      "        [0.2834, 0.7166],\n",
      "        [0.6816, 0.3184],\n",
      "        [0.6674, 0.3326]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  22.2\n",
      "Finished episode 57 Average rewards:  27.0\n",
      "tensor([ 1.8591,  0.3922,  1.8596,  0.9137, -0.4484, -0.4905, -0.5663,  0.0437,\n",
      "        -0.5739, -0.5919,  0.3577,  0.5934, -0.4801, -0.6614,  0.0000, -1.8815,\n",
      "         0.7651,  0.0000,  0.4414,  3.8399,  0.0000,  0.5167,  1.2870,  0.0000])\n",
      "tensor([ 3.7181e-01,  7.8431e-02,  3.7193e-01,  1.8275e-01, -8.9685e-02,\n",
      "        -9.8093e-02, -1.1326e-01,  8.7321e-03, -1.1479e-01, -1.1839e-01,\n",
      "         7.1532e-02,  1.1868e-01, -9.6012e-02, -1.3228e-01, -3.9031e-17,\n",
      "        -3.7629e-01,  1.5302e-01,  1.0881e-16,  8.8284e-02,  7.6798e-01,\n",
      "         0.0000e+00,  1.0335e-01,  2.5739e-01, -5.2667e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([  -1.2267, -106.2889,    0.5989,   -9.0815])\n",
      "tensor([ -0.2453, -21.2578,   0.1198,  -1.8163], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([1.4278, 1.4278])\n",
      "tensor([0.2856, 0.2856], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([12.5291, 14.5291], requires_grad=True)\n",
      "tensor([[0.4141, 0.5859],\n",
      "        [0.3978, 0.6022],\n",
      "        [0.4885, 0.5115],\n",
      "        [0.3715, 0.6285],\n",
      "        [0.4473, 0.5527],\n",
      "        [0.3689, 0.6311],\n",
      "        [0.3147, 0.6853],\n",
      "        [0.4262, 0.5738],\n",
      "        [0.5358, 0.4642],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.5323, 0.4677],\n",
      "        [0.4601, 0.5399],\n",
      "        [0.5560, 0.4440],\n",
      "        [0.2965, 0.7035],\n",
      "        [0.4513, 0.5487],\n",
      "        [0.3241, 0.6759],\n",
      "        [0.4798, 0.5202],\n",
      "        [0.6714, 0.3286],\n",
      "        [0.6779, 0.3221],\n",
      "        [0.6424, 0.3576],\n",
      "        [0.7614, 0.2386],\n",
      "        [0.5929, 0.4071],\n",
      "        [0.2302, 0.7698],\n",
      "        [0.3994, 0.6006],\n",
      "        [0.7165, 0.2835],\n",
      "        [0.5916, 0.4084],\n",
      "        [0.5358, 0.4642],\n",
      "        [0.3733, 0.6267],\n",
      "        [0.1692, 0.8308],\n",
      "        [0.6453, 0.3547],\n",
      "        [0.4581, 0.5419]], dtype=torch.float64)\n",
      "Finished episode 58 Average rewards:  31.0\n",
      "tensor([-0.7981,  0.0667, -0.7665, -1.8051, -0.0422,  1.7994, -2.1938, -0.1853,\n",
      "        -2.3519, -0.0330,  0.2103,  0.0406, -1.0555, -0.3889,  0.0000,  1.1608,\n",
      "         0.5766,  0.0000,  0.7512,  2.2232,  0.0000, -2.9348, -1.9342,  0.0000])\n",
      "tensor([-1.5962e-01,  1.3346e-02, -1.5330e-01, -3.6101e-01, -8.4373e-03,\n",
      "         3.5988e-01, -4.3876e-01, -3.7054e-02, -4.7037e-01, -6.6005e-03,\n",
      "         4.2057e-02,  8.1275e-03, -2.1109e-01, -7.7788e-02, -7.8644e-17,\n",
      "         2.3217e-01,  1.1533e-01, -2.7559e-16,  1.5023e-01,  4.4464e-01,\n",
      "         0.0000e+00, -5.8696e-01, -3.8683e-01,  4.2115e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ -2.0715,  -3.9577,  10.9171, -30.8519])\n",
      "tensor([-0.4143, -0.7915,  2.1834, -6.1704], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-1.5836, -1.5836])\n",
      "tensor([-0.3167, -0.3167], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([10.9454, 12.9454], requires_grad=True)\n",
      "tensor([[0.6220, 0.3780],\n",
      "        [0.3442, 0.6558],\n",
      "        [0.5171, 0.4829],\n",
      "        [0.7397, 0.2603],\n",
      "        [0.4500, 0.5500],\n",
      "        [0.6995, 0.3005],\n",
      "        [0.6276, 0.3724],\n",
      "        [0.3387, 0.6613],\n",
      "        [0.6559, 0.3441],\n",
      "        [0.4683, 0.5317],\n",
      "        [0.4105, 0.5895]], dtype=torch.float64)\n",
      "Finished episode 59 Average rewards:  11.0\n",
      "tensor([ 0.3467,  0.0198,  0.3300, -0.5308,  0.0794,  0.5200, -0.7916,  0.3355,\n",
      "        -0.8487, -0.6058,  0.2288,  0.5338,  0.6180,  0.1722,  0.0000,  0.0048,\n",
      "        -1.2897,  0.0000, -0.5184,  1.0348,  0.0000,  0.3602, -1.8645,  0.0000])\n",
      "tensor([ 6.9343e-02,  3.9517e-03,  6.5999e-02, -1.0616e-01,  1.5880e-02,\n",
      "         1.0400e-01, -1.5833e-01,  6.7100e-02, -1.6974e-01, -1.2116e-01,\n",
      "         4.5762e-02,  1.0676e-01,  1.2359e-01,  3.4447e-02, -5.2212e-17,\n",
      "         9.5601e-04, -2.5794e-01, -1.1631e-18, -1.0369e-01,  2.0697e-01,\n",
      "         0.0000e+00,  7.2040e-02, -3.7291e-01,  1.4555e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 0.9787,  0.0790, -2.0651, -5.9562])\n",
      "tensor([ 0.1957,  0.0158, -0.4130, -1.1912], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-0.0946, -0.0946])\n",
      "tensor([-0.0189, -0.0189], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([10.8508, 12.8508], requires_grad=True)\n",
      "tensor([[0.4814, 0.5186],\n",
      "        [0.5033, 0.4967],\n",
      "        [0.5530, 0.4470],\n",
      "        [0.5679, 0.4321],\n",
      "        [0.5350, 0.4650],\n",
      "        [0.4313, 0.5687],\n",
      "        [0.4021, 0.5979],\n",
      "        [0.4173, 0.5827],\n",
      "        [0.3866, 0.6134],\n",
      "        [0.4174, 0.5826],\n",
      "        [0.4021, 0.5979],\n",
      "        [0.3778, 0.6222],\n",
      "        [0.3720, 0.6280],\n",
      "        [0.3860, 0.6140],\n",
      "        [0.4245, 0.5755],\n",
      "        [0.5171, 0.4829],\n",
      "        [0.5445, 0.4555],\n",
      "        [0.5384, 0.4616],\n",
      "        [0.5330, 0.4670],\n",
      "        [0.5425, 0.4575],\n",
      "        [0.5488, 0.4512],\n",
      "        [0.5387, 0.4613],\n",
      "        [0.5333, 0.4667],\n",
      "        [0.5223, 0.4777],\n",
      "        [0.4871, 0.5129],\n",
      "        [0.5086, 0.4914],\n",
      "        [0.5271, 0.4729],\n",
      "        [0.5408, 0.4592],\n",
      "        [0.5498, 0.4502],\n",
      "        [0.5260, 0.4740],\n",
      "        [0.4724, 0.5276],\n",
      "        [0.3556, 0.6444],\n",
      "        [0.3439, 0.6561],\n",
      "        [0.4551, 0.5449],\n",
      "        [0.5433, 0.4567],\n",
      "        [0.3330, 0.6670],\n",
      "        [0.4261, 0.5739],\n",
      "        [0.5431, 0.4569],\n",
      "        [0.4124, 0.5876]], dtype=torch.float64)\n",
      "Finished episode 60 Average rewards:  39.0\n",
      "tensor([ 0.4614, -0.0110,  0.5212,  0.3831, -0.1160, -0.4123,  1.7579,  0.0581,\n",
      "         2.0140,  0.5460, -0.2516, -0.5586, -0.7765, -0.8758,  0.0000, -1.5030,\n",
      "        -0.3772,  0.0000, -1.4412,  1.2991,  0.0000, -0.2120,  0.2140,  0.0000])\n",
      "tensor([ 9.2274e-02, -2.2073e-03,  1.0424e-01,  7.6626e-02, -2.3201e-02,\n",
      "        -8.2457e-02,  3.5158e-01,  1.1613e-02,  4.0281e-01,  1.0920e-01,\n",
      "        -5.0322e-02, -1.1172e-01, -1.5529e-01, -1.7516e-01,  5.2687e-18,\n",
      "        -3.0060e-01, -7.5438e-02, -1.0829e-16, -2.8825e-01,  2.5982e-01,\n",
      "         0.0000e+00, -4.2403e-02,  4.2798e-02, -6.5799e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ -1.8534,   4.5695,  -5.3347, -30.8093])\n",
      "tensor([-0.3707,  0.9139, -1.0669, -6.1619], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-0.3570, -0.3570])\n",
      "tensor([-0.0714, -0.0714], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([10.4937, 12.4937], requires_grad=True)\n",
      "tensor([[0.2684, 0.7316],\n",
      "        [0.5579, 0.4421],\n",
      "        [0.4050, 0.5950],\n",
      "        [0.5656, 0.4344],\n",
      "        [0.3556, 0.6444],\n",
      "        [0.6243, 0.3757],\n",
      "        [0.3434, 0.6566],\n",
      "        [0.6272, 0.3728],\n",
      "        [0.5186, 0.4814],\n",
      "        [0.4015, 0.5985],\n",
      "        [0.3865, 0.6135],\n",
      "        [0.3295, 0.6705],\n",
      "        [0.6595, 0.3405],\n",
      "        [0.6305, 0.3695],\n",
      "        [0.4003, 0.5997],\n",
      "        [0.3359, 0.6641],\n",
      "        [0.3186, 0.6814],\n",
      "        [0.4619, 0.5381],\n",
      "        [0.5216, 0.4784]], dtype=torch.float64)\n",
      "Finished episode 61 Average rewards:  19.0\n",
      "tensor([ 3.0015, -0.1658,  2.7166, -2.4161,  0.8644,  2.4697,  0.7169,  3.1515,\n",
      "         0.8218,  1.3764,  0.3112, -1.1463,  0.0983, -2.4886,  0.0000,  0.6186,\n",
      "        -0.5146,  0.0000, -0.5862,  1.7813,  0.0000,  1.5209,  1.3422,  0.0000])\n",
      "tensor([ 6.0030e-01, -3.3163e-02,  5.4331e-01, -4.8323e-01,  1.7287e-01,\n",
      "         4.9395e-01,  1.4339e-01,  6.3031e-01,  1.6435e-01,  2.7527e-01,\n",
      "         6.2247e-02, -2.2927e-01,  1.9659e-02, -4.9771e-01,  1.4240e-17,\n",
      "         1.2372e-01, -1.0292e-01, -5.7406e-17, -1.1724e-01,  3.5626e-01,\n",
      "         0.0000e+00,  3.0419e-01,  2.6845e-01,  6.7404e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 2.9957e-02,  1.8865e+01,  1.9358e+00, -7.3001e+01])\n",
      "tensor([ 5.9915e-03,  3.7730e+00,  3.8715e-01, -1.4600e+01],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-4.3567, -4.3567])\n",
      "tensor([-0.8713, -0.8713], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([6.1371, 8.1371], requires_grad=True)\n",
      "tensor([[0.7221, 0.2779],\n",
      "        [0.7548, 0.2452],\n",
      "        [0.7104, 0.2896],\n",
      "        [0.7048, 0.2952],\n",
      "        [0.6791, 0.3209],\n",
      "        [0.6872, 0.3128],\n",
      "        [0.6407, 0.3593],\n",
      "        [0.6108, 0.3892],\n",
      "        [0.5658, 0.4342],\n",
      "        [0.5316, 0.4684],\n",
      "        [0.5218, 0.4782],\n",
      "        [0.4781, 0.5219],\n",
      "        [0.5185, 0.4815],\n",
      "        [0.4813, 0.5187],\n",
      "        [0.5432, 0.4568],\n",
      "        [0.5019, 0.4981],\n",
      "        [0.6195, 0.3805],\n",
      "        [0.5759, 0.4241],\n",
      "        [0.7261, 0.2739],\n",
      "        [0.3370, 0.6630],\n",
      "        [0.4734, 0.5266]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  25.86\n",
      "Finished episode 62 Average rewards:  28.0\n",
      "tensor([-0.5572, -0.0283, -0.4892, -0.6232,  0.4436,  0.2074,  0.1310,  0.1059,\n",
      "        -0.1754, -0.3313, -0.1159,  0.4137, -0.0469,  0.5784,  0.0000,  0.0124,\n",
      "         1.1413,  0.0000,  0.0603,  0.0108,  0.0000,  0.0495, -0.9750,  0.0000])\n",
      "tensor([-1.1144e-01, -5.6582e-03, -9.7847e-02, -1.2464e-01,  8.8730e-02,\n",
      "         4.1485e-02,  2.6192e-02,  2.1183e-02, -3.5086e-02, -6.6257e-02,\n",
      "        -2.3183e-02,  8.2734e-02, -9.3704e-03,  1.1568e-01, -1.1820e-17,\n",
      "         2.4890e-03,  2.2826e-01, -2.8025e-17,  1.2066e-02,  2.1642e-03,\n",
      "         0.0000e+00,  9.8957e-03, -1.9500e-01, -3.3716e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 0.0644,  1.6061, -0.6244, -3.0163])\n",
      "tensor([ 0.0129,  0.3212, -0.1249, -0.6033], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-0.0600, -0.0600])\n",
      "tensor([-0.0120, -0.0120], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([6.0771, 8.0771], requires_grad=True)\n",
      "tensor([[0.5501, 0.4499],\n",
      "        [0.4190, 0.5810],\n",
      "        [0.5444, 0.4556],\n",
      "        [0.4228, 0.5772],\n",
      "        [0.6379, 0.3621],\n",
      "        [0.4992, 0.5008],\n",
      "        [0.5458, 0.4542],\n",
      "        [0.5968, 0.4032],\n",
      "        [0.5100, 0.4900],\n",
      "        [0.6199, 0.3801],\n",
      "        [0.4295, 0.5705],\n",
      "        [0.5398, 0.4602],\n",
      "        [0.5081, 0.4919],\n",
      "        [0.2689, 0.7311],\n",
      "        [0.5991, 0.4009],\n",
      "        [0.4156, 0.5844],\n",
      "        [0.5461, 0.4539],\n",
      "        [0.5749, 0.4251],\n",
      "        [0.5118, 0.4882],\n",
      "        [0.5230, 0.4770],\n",
      "        [0.6352, 0.3648],\n",
      "        [0.4819, 0.5181],\n",
      "        [0.3842, 0.6158],\n",
      "        [0.4426, 0.5574],\n",
      "        [0.5438, 0.4562],\n",
      "        [0.4685, 0.5315],\n",
      "        [0.3782, 0.6218],\n",
      "        [0.5362, 0.4638],\n",
      "        [0.5172, 0.4828],\n",
      "        [0.4319, 0.5681],\n",
      "        [0.5743, 0.4257],\n",
      "        [0.4335, 0.5665],\n",
      "        [0.5570, 0.4430],\n",
      "        [0.4121, 0.5879],\n",
      "        [0.4927, 0.5073],\n",
      "        [0.3150, 0.6850],\n",
      "        [0.6131, 0.3869],\n",
      "        [0.5374, 0.4626],\n",
      "        [0.6317, 0.3683],\n",
      "        [0.5197, 0.4803],\n",
      "        [0.6356, 0.3644],\n",
      "        [0.5500, 0.4500]], dtype=torch.float64)\n",
      "Finished episode 63 Average rewards:  42.0\n",
      "tensor([ 0.9958,  0.0390,  1.0039,  0.2626, -0.4449, -0.2141,  0.1089, -0.1213,\n",
      "         0.0330,  0.4052,  0.0955, -0.3697,  0.2925, -0.9778,  0.0000,  0.6053,\n",
      "        -0.3515,  0.0000,  0.0377,  0.6779,  0.0000,  0.2978,  0.2473,  0.0000])\n",
      "tensor([ 1.9916e-01,  7.8097e-03,  2.0079e-01,  5.2517e-02, -8.8987e-02,\n",
      "        -4.2815e-02,  2.1788e-02, -2.4261e-02,  6.5902e-03,  8.1048e-02,\n",
      "         1.9094e-02, -7.3944e-02,  5.8500e-02, -1.9557e-01,  1.4281e-17,\n",
      "         1.2106e-01, -7.0302e-02, -1.9468e-17,  7.5321e-03,  1.3559e-01,\n",
      "         0.0000e+00,  5.9567e-02,  4.9452e-02, -3.3256e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ -0.3277,  -1.3557,   3.6990, -42.9874])\n",
      "tensor([-0.0655, -0.2711,  0.7398, -8.5975], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-0.4066, -0.4066])\n",
      "tensor([-0.0813, -0.0813], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([5.6705, 7.6705], requires_grad=True)\n",
      "tensor([[0.5243, 0.4757],\n",
      "        [0.6701, 0.3299],\n",
      "        [0.4944, 0.5056],\n",
      "        [0.2930, 0.7070],\n",
      "        [0.6116, 0.3884],\n",
      "        [0.4030, 0.5970],\n",
      "        [0.5765, 0.4235],\n",
      "        [0.6129, 0.3871],\n",
      "        [0.5109, 0.4891],\n",
      "        [0.4239, 0.5761],\n",
      "        [0.6682, 0.3318],\n",
      "        [0.2700, 0.7300],\n",
      "        [0.4187, 0.5813],\n",
      "        [0.6849, 0.3151],\n",
      "        [0.5975, 0.4025],\n",
      "        [0.6388, 0.3612],\n",
      "        [0.5477, 0.4523],\n",
      "        [0.5364, 0.4636],\n",
      "        [0.6224, 0.3776],\n",
      "        [0.4932, 0.5068],\n",
      "        [0.4371, 0.5629],\n",
      "        [0.4011, 0.5989],\n",
      "        [0.4620, 0.5380],\n",
      "        [0.5829, 0.4171],\n",
      "        [0.4724, 0.5276],\n",
      "        [0.4407, 0.5593],\n",
      "        [0.4689, 0.5311],\n",
      "        [0.5048, 0.4952],\n",
      "        [0.4133, 0.5867],\n",
      "        [0.4333, 0.5667],\n",
      "        [0.3954, 0.6046],\n",
      "        [0.5171, 0.4829],\n",
      "        [0.5368, 0.4632],\n",
      "        [0.5535, 0.4465],\n",
      "        [0.5039, 0.4961],\n",
      "        [0.4310, 0.5690],\n",
      "        [0.3307, 0.6693],\n",
      "        [0.5800, 0.4200]], dtype=torch.float64)\n",
      "Finished episode 64 Average rewards:  38.0\n",
      "tensor([-1.2417,  0.0844, -1.1778,  0.5076, -0.7959, -0.3546, -0.1703, -0.2781,\n",
      "         0.4318,  0.3180, -0.2104,  0.2139, -0.4161,  0.7395,  0.0000, -1.1084,\n",
      "        -0.0176,  0.0000,  0.6247, -0.1371,  0.0000,  0.4070, -0.8882,  0.0000])\n",
      "tensor([-2.4835e-01,  1.6878e-02, -2.3556e-01,  1.0151e-01, -1.5917e-01,\n",
      "        -7.0918e-02, -3.4051e-02, -5.5615e-02,  8.6364e-02,  6.3604e-02,\n",
      "        -4.2073e-02,  4.2788e-02, -8.3210e-02,  1.4790e-01, -2.3135e-18,\n",
      "        -2.2167e-01, -3.5282e-03,  1.0039e-16,  1.2495e-01, -2.7429e-02,\n",
      "         0.0000e+00,  8.1394e-02, -1.7764e-01,  8.3027e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.6805, -3.7834,  1.9623, 41.1773])\n",
      "tensor([-0.1361, -0.7567,  0.3925,  8.2355], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.9497, 0.9497])\n",
      "tensor([0.1899, 0.1899], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([6.6202, 8.6202], requires_grad=True)\n",
      "tensor([[0.5187, 0.4813],\n",
      "        [0.2803, 0.7197],\n",
      "        [0.3658, 0.6342],\n",
      "        [0.4881, 0.5119],\n",
      "        [0.4699, 0.5301],\n",
      "        [0.7606, 0.2394],\n",
      "        [0.5276, 0.4724],\n",
      "        [0.4129, 0.5871],\n",
      "        [0.4453, 0.5547],\n",
      "        [0.5409, 0.4591],\n",
      "        [0.4415, 0.5585],\n",
      "        [0.4745, 0.5255],\n",
      "        [0.7087, 0.2913],\n",
      "        [0.3739, 0.6261],\n",
      "        [0.6000, 0.4000],\n",
      "        [0.4395, 0.5605],\n",
      "        [0.4670, 0.5330],\n",
      "        [0.4622, 0.5378],\n",
      "        [0.5131, 0.4869],\n",
      "        [0.6215, 0.3785],\n",
      "        [0.5337, 0.4663]], dtype=torch.float64)\n",
      "Finished episode 65 Average rewards:  21.0\n",
      "tensor([ 0.6260,  0.1779,  0.7311,  0.5615,  0.1897, -0.5556,  0.3002,  0.1774,\n",
      "        -0.3555,  0.1624,  0.0135, -0.4075, -0.6414, -0.9359,  0.0000,  0.9383,\n",
      "        -2.9999,  0.0000, -0.8051, -1.5368,  0.0000, -0.6195, -0.7036,  0.0000])\n",
      "tensor([ 1.2520e-01,  3.5585e-02,  1.4622e-01,  1.1231e-01,  3.7950e-02,\n",
      "        -1.1112e-01,  6.0048e-02,  3.5476e-02, -7.1095e-02,  3.2475e-02,\n",
      "         2.6907e-03, -8.1495e-02, -1.2829e-01, -1.8718e-01,  7.3454e-17,\n",
      "         1.8767e-01, -5.9998e-01,  7.8278e-19, -1.6102e-01, -3.0736e-01,\n",
      "         0.0000e+00, -1.2389e-01, -1.4073e-01,  6.3350e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-3.6668e-01,  9.7923e-03,  1.7962e-01,  5.2833e+01])\n",
      "tensor([-7.3336e-02,  1.9585e-03,  3.5923e-02,  1.0567e+01],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-1.0062, -1.0062])\n",
      "tensor([-0.2012, -0.2012], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([5.6139, 7.6139], requires_grad=True)\n",
      "tensor([[0.6342, 0.3658],\n",
      "        [0.6299, 0.3701],\n",
      "        [0.4494, 0.5506],\n",
      "        [0.6334, 0.3666],\n",
      "        [0.3425, 0.6575],\n",
      "        [0.5990, 0.4010],\n",
      "        [0.6906, 0.3094],\n",
      "        [0.5293, 0.4707],\n",
      "        [0.4397, 0.5603],\n",
      "        [0.6430, 0.3570],\n",
      "        [0.3025, 0.6975],\n",
      "        [0.5195, 0.4805],\n",
      "        [0.4275, 0.5725],\n",
      "        [0.4173, 0.5827],\n",
      "        [0.3028, 0.6972],\n",
      "        [0.4002, 0.5998],\n",
      "        [0.7270, 0.2730],\n",
      "        [0.3993, 0.6007],\n",
      "        [0.3508, 0.6492],\n",
      "        [0.7677, 0.2323],\n",
      "        [0.6765, 0.3235],\n",
      "        [0.5414, 0.4586],\n",
      "        [0.3696, 0.6304],\n",
      "        [0.6790, 0.3210],\n",
      "        [0.3874, 0.6126],\n",
      "        [0.2913, 0.7087],\n",
      "        [0.3599, 0.6401],\n",
      "        [0.5142, 0.4858],\n",
      "        [0.6469, 0.3531],\n",
      "        [0.2860, 0.7140],\n",
      "        [0.3499, 0.6501],\n",
      "        [0.4441, 0.5559],\n",
      "        [0.4709, 0.5291],\n",
      "        [0.7527, 0.2473]], dtype=torch.float64)\n",
      "Finished episode 66 Average rewards:  34.0\n",
      "tensor([ 0.3907, -0.1495,  0.7860,  0.7562, -0.1127, -0.5995,  0.1254, -0.1690,\n",
      "         0.0995, -0.4600,  0.0288,  0.4976, -0.4891, -0.3555,  0.0000,  1.4867,\n",
      "        -0.0469,  0.0000,  0.7864, -1.5742,  0.0000,  0.2447,  1.1562,  0.0000])\n",
      "tensor([ 7.8149e-02, -2.9892e-02,  1.5721e-01,  1.5125e-01, -2.2535e-02,\n",
      "        -1.1990e-01,  2.5079e-02, -3.3797e-02,  1.9897e-02, -9.1993e-02,\n",
      "         5.7692e-03,  9.9521e-02, -9.7820e-02, -7.1091e-02, -3.7891e-17,\n",
      "         2.9733e-01, -9.3736e-03,  9.6515e-17,  1.5728e-01, -3.1484e-01,\n",
      "         0.0000e+00,  4.8943e-02,  2.3123e-01,  4.6957e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ -1.4743,  20.9570,  14.3911, -20.4191])\n",
      "tensor([-0.2949,  4.1914,  2.8782, -4.0838], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([3.4955, 3.4955])\n",
      "tensor([0.6991, 0.6991], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([ 9.1094, 11.1094], requires_grad=True)\n",
      "tensor([[0.1582, 0.8418],\n",
      "        [0.5724, 0.4276],\n",
      "        [0.1373, 0.8627],\n",
      "        [0.6824, 0.3176],\n",
      "        [0.1546, 0.8454],\n",
      "        [0.7322, 0.2678],\n",
      "        [0.3595, 0.6405],\n",
      "        [0.6150, 0.3850],\n",
      "        [0.4729, 0.5271],\n",
      "        [0.5505, 0.4495],\n",
      "        [0.1981, 0.8019],\n",
      "        [0.7043, 0.2957],\n",
      "        [0.5107, 0.4893],\n",
      "        [0.2604, 0.7396],\n",
      "        [0.5012, 0.4988],\n",
      "        [0.7159, 0.2841],\n",
      "        [0.4926, 0.5074],\n",
      "        [0.6561, 0.3439],\n",
      "        [0.5529, 0.4471]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored episode 50 Average Monitored rewards:  22.9\n",
      "Finished episode 67 Average rewards:  32.0\n",
      "tensor([ 1.1208, -0.3523,  1.2410,  1.2016, -0.0121, -1.1708,  0.9291,  0.0128,\n",
      "        -0.9009,  0.0077, -0.0357,  0.0586,  0.1980,  0.4369,  0.0000,  1.4178,\n",
      "        -0.1478,  0.0000,  0.8784,  1.9893,  0.0000,  0.0483,  1.0393,  0.0000])\n",
      "tensor([ 2.2417e-01, -7.0455e-02,  2.4821e-01,  2.4031e-01, -2.4237e-03,\n",
      "        -2.3416e-01,  1.8583e-01,  2.5581e-03, -1.8017e-01,  1.5400e-03,\n",
      "        -7.1382e-03,  1.1723e-02,  3.9597e-02,  8.7382e-02, -1.9840e-17,\n",
      "         2.8356e-01, -2.9559e-02, -2.0213e-17,  1.7568e-01,  3.9786e-01,\n",
      "         0.0000e+00,  9.6669e-03,  2.0786e-01,  1.4648e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([  0.5188,  -2.5783, -12.9171,  45.1837])\n",
      "tensor([ 0.1038, -0.5157, -2.5834,  9.0367], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.2978, 0.2978])\n",
      "tensor([0.0596, 0.0596], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([ 9.4072, 11.4072], requires_grad=True)\n",
      "tensor([[0.4631, 0.5369],\n",
      "        [0.3780, 0.6220],\n",
      "        [0.5228, 0.4772],\n",
      "        [0.4245, 0.5755],\n",
      "        [0.6131, 0.3869],\n",
      "        [0.4010, 0.5990],\n",
      "        [0.5716, 0.4284],\n",
      "        [0.3796, 0.6204],\n",
      "        [0.4949, 0.5051],\n",
      "        [0.4084, 0.5916],\n",
      "        [0.4240, 0.5760],\n",
      "        [0.5074, 0.4926],\n",
      "        [0.4785, 0.5215],\n",
      "        [0.3686, 0.6314],\n",
      "        [0.5386, 0.4614],\n",
      "        [0.4571, 0.5429],\n",
      "        [0.4584, 0.5416],\n",
      "        [0.5423, 0.4577],\n",
      "        [0.4595, 0.5405]], dtype=torch.float64)\n",
      "Finished episode 68 Average rewards:  19.0\n",
      "tensor([-0.9485,  0.0935, -0.9354,  0.1580,  0.0825, -0.1386, -0.0212, -0.1712,\n",
      "        -0.0451, -0.5594, -0.1410,  0.7042,  0.3719,  0.1977,  0.0000, -0.9504,\n",
      "        -0.9537,  0.0000,  0.8666, -2.8681,  0.0000,  1.3354, -1.6015,  0.0000])\n",
      "tensor([-1.8971e-01,  1.8704e-02, -1.8708e-01,  3.1600e-02,  1.6501e-02,\n",
      "        -2.7724e-02, -4.2312e-03, -3.4236e-02, -9.0210e-03, -1.1189e-01,\n",
      "        -2.8205e-02,  1.4083e-01,  7.4390e-02,  3.9536e-02, -1.3121e-16,\n",
      "        -1.9007e-01, -1.9073e-01,  1.3446e-16,  1.7332e-01, -5.7363e-01,\n",
      "         0.0000e+00,  2.6709e-01, -3.2030e-01, -5.2351e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([  0.7780,   1.4126, -11.8563,  49.3799])\n",
      "tensor([ 0.1556,  0.2825, -2.3713,  9.8760], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-0.0029, -0.0029])\n",
      "tensor([-0.0006, -0.0006], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([ 9.4043, 11.4043], requires_grad=True)\n",
      "tensor([[0.5454, 0.4546],\n",
      "        [0.5212, 0.4788],\n",
      "        [0.5821, 0.4179],\n",
      "        [0.5221, 0.4779],\n",
      "        [0.4133, 0.5867],\n",
      "        [0.4305, 0.5695],\n",
      "        [0.4622, 0.5378],\n",
      "        [0.5169, 0.4831],\n",
      "        [0.4148, 0.5852],\n",
      "        [0.5070, 0.4930],\n",
      "        [0.6172, 0.3828]], dtype=torch.float64)\n",
      "Finished episode 69 Average rewards:  11.0\n",
      "tensor([-0.8299,  0.1497, -0.8438, -0.0739,  0.0461,  0.0691, -0.2556, -0.0454,\n",
      "         0.2439, -0.3216, -0.1008,  0.3238, -0.7261,  0.9326,  0.0000, -0.5222,\n",
      "         0.7931,  0.0000,  1.5765, -0.4888,  0.0000,  0.1290,  1.5218,  0.0000])\n",
      "tensor([-1.6598e-01,  2.9939e-02, -1.6876e-01, -1.4775e-02,  9.2145e-03,\n",
      "         1.3824e-02, -5.1128e-02, -9.0765e-03,  4.8788e-02, -6.4328e-02,\n",
      "        -2.0155e-02,  6.4751e-02, -1.4522e-01,  1.8652e-01, -7.5301e-17,\n",
      "        -1.0444e-01,  1.5861e-01, -1.2549e-17,  3.1530e-01, -9.7752e-02,\n",
      "         0.0000e+00,  2.5793e-02,  3.0436e-01, -3.7617e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-1.4807, -1.2878,  6.5099, 11.3688])\n",
      "tensor([-0.2961, -0.2576,  1.3020,  2.2738], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-0.6773, -0.6773])\n",
      "tensor([-0.1355, -0.1355], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([ 8.7270, 10.7270], requires_grad=True)\n",
      "tensor([[0.6728, 0.3272],\n",
      "        [0.3644, 0.6356],\n",
      "        [0.6353, 0.3647],\n",
      "        [0.3543, 0.6457],\n",
      "        [0.6984, 0.3016],\n",
      "        [0.4337, 0.5663],\n",
      "        [0.6545, 0.3455],\n",
      "        [0.5357, 0.4643],\n",
      "        [0.5802, 0.4198],\n",
      "        [0.4021, 0.5979],\n",
      "        [0.5673, 0.4327],\n",
      "        [0.4909, 0.5091],\n",
      "        [0.6057, 0.3943],\n",
      "        [0.3604, 0.6396],\n",
      "        [0.6787, 0.3213],\n",
      "        [0.4513, 0.5487],\n",
      "        [0.5830, 0.4170],\n",
      "        [0.5129, 0.4871],\n",
      "        [0.3456, 0.6544],\n",
      "        [0.5618, 0.4382],\n",
      "        [0.6211, 0.3789],\n",
      "        [0.2806, 0.7194],\n",
      "        [0.5573, 0.4427],\n",
      "        [0.3141, 0.6859],\n",
      "        [0.4874, 0.5126],\n",
      "        [0.6521, 0.3479],\n",
      "        [0.5072, 0.4928],\n",
      "        [0.5991, 0.4009],\n",
      "        [0.4690, 0.5310],\n",
      "        [0.5396, 0.4604],\n",
      "        [0.3389, 0.6611],\n",
      "        [0.5541, 0.4459],\n",
      "        [0.5498, 0.4502]], dtype=torch.float64)\n",
      "Finished episode 70 Average rewards:  33.0\n",
      "tensor([ 2.1903e+00,  6.4552e-02,  2.3402e+00, -4.2727e-02, -4.2026e-01,\n",
      "        -3.8080e-03,  7.7468e-01, -6.2624e-02, -7.8525e-01,  4.0643e-01,\n",
      "        -1.0269e+00, -2.2804e-01, -1.5824e+00, -4.1559e+00,  0.0000e+00,\n",
      "         3.1471e+00,  2.6647e-01,  0.0000e+00, -3.1318e+00,  4.4655e-01,\n",
      "         0.0000e+00,  1.4540e-01, -5.7888e-01,  0.0000e+00])\n",
      "tensor([ 4.3807e-01,  1.2910e-02,  4.6805e-01, -8.5453e-03, -8.4052e-02,\n",
      "        -7.6163e-04,  1.5494e-01, -1.2525e-02, -1.5705e-01,  8.1286e-02,\n",
      "        -2.0539e-01, -4.5609e-02, -3.1648e-01, -8.3119e-01, -1.8410e-17,\n",
      "         6.2943e-01,  5.3295e-02,  4.2773e-17, -6.2636e-01,  8.9311e-02,\n",
      "         0.0000e+00,  2.9080e-02, -1.1578e-01,  2.7605e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-3.8555,  1.8267, 10.4909,  2.0419])\n",
      "tensor([-0.7711,  0.3653,  2.0982,  0.4084], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([3.6024, 3.6024])\n",
      "tensor([0.7205, 0.7205], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([12.3294, 14.3294], requires_grad=True)\n",
      "tensor([[0.2598, 0.7402],\n",
      "        [0.3434, 0.6566],\n",
      "        [0.5697, 0.4303],\n",
      "        [0.2156, 0.7844],\n",
      "        [0.2759, 0.7241],\n",
      "        [0.6184, 0.3816],\n",
      "        [0.7288, 0.2712],\n",
      "        [0.7550, 0.2450],\n",
      "        [0.3821, 0.6179],\n",
      "        [0.3485, 0.6515],\n",
      "        [0.2088, 0.7912],\n",
      "        [0.5416, 0.4584],\n",
      "        [0.2898, 0.7102],\n",
      "        [0.3560, 0.6440],\n",
      "        [0.6908, 0.3092],\n",
      "        [0.6010, 0.3990],\n",
      "        [0.7698, 0.2302],\n",
      "        [0.8026, 0.1974],\n",
      "        [0.5322, 0.4678],\n",
      "        [0.5009, 0.4991],\n",
      "        [0.6664, 0.3336],\n",
      "        [0.3909, 0.6091],\n",
      "        [0.2425, 0.7575],\n",
      "        [0.8164, 0.1836],\n",
      "        [0.8247, 0.1753]], dtype=torch.float64)\n",
      "Finished episode 71 Average rewards:  25.0\n",
      "tensor([ 0.0968, -0.1185,  0.0549, -1.4737, -0.6795,  1.4564, -0.7762, -0.0227,\n",
      "         0.7749, -1.3405,  0.9179,  1.6149,  0.2897,  0.4038,  0.0000, -0.1237,\n",
      "         2.5446,  0.0000,  0.3534, -2.7837,  0.0000, -0.0391, -0.5006,  0.0000])\n",
      "tensor([ 1.9367e-02, -2.3702e-02,  1.0974e-02, -2.9475e-01, -1.3590e-01,\n",
      "         2.9127e-01, -1.5523e-01, -4.5482e-03,  1.5499e-01, -2.6810e-01,\n",
      "         1.8358e-01,  3.2298e-01,  5.7932e-02,  8.0768e-02, -1.5071e-16,\n",
      "        -2.4746e-02,  5.0892e-01, -4.0601e-17,  7.0676e-02, -5.5675e-01,\n",
      "         0.0000e+00, -7.8235e-03, -1.0011e-01, -4.3624e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 0.5576,  3.7567, -2.2594,  0.4700])\n",
      "tensor([ 0.1115,  0.7513, -0.4519,  0.0940], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.7547, 0.7547])\n",
      "tensor([0.1509, 0.1509], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([13.0840, 15.0840], requires_grad=True)\n",
      "tensor([[0.4299, 0.5701],\n",
      "        [0.5538, 0.4462],\n",
      "        [0.3665, 0.6335],\n",
      "        [0.5269, 0.4731],\n",
      "        [0.4086, 0.5914],\n",
      "        [0.6004, 0.3996],\n",
      "        [0.5166, 0.4834],\n",
      "        [0.5275, 0.4725],\n",
      "        [0.5971, 0.4029],\n",
      "        [0.4835, 0.5165],\n",
      "        [0.5675, 0.4325],\n",
      "        [0.4322, 0.5678],\n",
      "        [0.5704, 0.4296],\n",
      "        [0.5204, 0.4796],\n",
      "        [0.6388, 0.3612],\n",
      "        [0.4235, 0.5765],\n",
      "        [0.4874, 0.5126],\n",
      "        [0.4438, 0.5562],\n",
      "        [0.5950, 0.4050],\n",
      "        [0.4287, 0.5713],\n",
      "        [0.5428, 0.4572]], dtype=torch.float64)\n",
      "Monitored episode 50 Average Monitored rewards:  23.6\n",
      "Finished episode 72 Average rewards:  27.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.4280,  0.1633,  2.3269,  1.1633, -0.1151, -1.3919, -0.6883,  0.1834,\n",
      "         0.6977, -1.0122,  0.2428,  1.0160, -1.9299,  1.4905,  0.0000, -1.7464,\n",
      "         0.3627,  0.0000, -1.6477, -0.7779,  0.0000, -1.2573,  5.7978,  0.0000])\n",
      "tensor([ 4.8561e-01,  3.2667e-02,  4.6538e-01,  2.3267e-01, -2.3019e-02,\n",
      "        -2.7839e-01, -1.3766e-01,  3.6677e-02,  1.3955e-01, -2.0244e-01,\n",
      "         4.8554e-02,  2.0320e-01, -3.8599e-01,  2.9810e-01,  3.9577e-17,\n",
      "        -3.4929e-01,  7.2540e-02,  1.8300e-17, -3.2954e-01, -1.5557e-01,\n",
      "         0.0000e+00, -2.5146e-01,  1.1596e+00,  4.0081e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ -3.7291,  -6.6449, -24.2623,  12.8535])\n",
      "tensor([-0.7458, -1.3290, -4.8525,  2.5707], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([1.6031, 1.6031])\n",
      "tensor([0.3206, 0.3206], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([14.6872, 16.6872], requires_grad=True)\n",
      "tensor([[0.2101, 0.7899],\n",
      "        [0.5858, 0.4142],\n",
      "        [0.3443, 0.6557],\n",
      "        [0.7288, 0.2712],\n",
      "        [0.5786, 0.4214],\n",
      "        [0.2806, 0.7194],\n",
      "        [0.4851, 0.5149],\n",
      "        [0.2505, 0.7495],\n",
      "        [0.2579, 0.7421],\n",
      "        [0.6937, 0.3063]], dtype=torch.float64)\n",
      "Finished episode 73 Average rewards:  10.0\n",
      "tensor([ 4.6921e-04,  1.9771e-01, -6.7997e-03,  1.5005e+00,  3.2669e+00,\n",
      "        -2.4680e+00, -4.6931e+00, -1.7688e-01,  4.7254e+00,  2.7733e+00,\n",
      "         1.5755e-03, -2.6098e+00, -1.4815e+00, -2.0601e+00,  0.0000e+00,\n",
      "        -6.8714e-01, -3.6943e+00,  0.0000e+00, -2.2767e+00, -4.9583e+00,\n",
      "         0.0000e+00, -2.1736e+00, -4.9146e-01,  0.0000e+00])\n",
      "tensor([ 9.3773e-05,  3.9542e-02, -1.3599e-03,  3.0010e-01,  6.5339e-01,\n",
      "        -4.9360e-01, -9.3861e-01, -3.5376e-02,  9.4507e-01,  5.5465e-01,\n",
      "         3.1508e-04, -5.2197e-01, -2.9630e-01, -4.1201e-01, -5.3758e-17,\n",
      "        -1.3743e-01, -7.3886e-01, -5.4977e-17, -4.5534e-01, -9.9167e-01,\n",
      "         0.0000e+00, -4.3471e-01, -9.8292e-02,  3.4222e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-3.4609,  3.0645, -4.6099, -0.6355])\n",
      "tensor([-0.6922,  0.6129, -0.9220, -0.1271], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([2.2782, 2.2782])\n",
      "tensor([0.4556, 0.4556], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([16.9654, 18.9654], requires_grad=True)\n",
      "tensor([[0.4271, 0.5729],\n",
      "        [0.2374, 0.7626],\n",
      "        [0.7029, 0.2971],\n",
      "        [0.2684, 0.7316],\n",
      "        [0.3844, 0.6156],\n",
      "        [0.2904, 0.7096],\n",
      "        [0.7398, 0.2602],\n",
      "        [0.3455, 0.6545],\n",
      "        [0.7457, 0.2543],\n",
      "        [0.4165, 0.5835],\n",
      "        [0.7309, 0.2691],\n",
      "        [0.4937, 0.5063],\n",
      "        [0.6835, 0.3165],\n",
      "        [0.5549, 0.4451],\n",
      "        [0.4365, 0.5635],\n",
      "        [0.4388, 0.5612],\n",
      "        [0.5391, 0.4609],\n",
      "        [0.4317, 0.5683],\n",
      "        [0.4613, 0.5387],\n",
      "        [0.4187, 0.5813],\n",
      "        [0.5091, 0.4909],\n",
      "        [0.5243, 0.4757],\n",
      "        [0.4315, 0.5685],\n",
      "        [0.6552, 0.3448]], dtype=torch.float64)\n",
      "Finished episode 74 Average rewards:  24.0\n",
      "tensor([-2.6109,  6.4277, -2.2997, -1.3264,  0.4650, -1.4586,  3.8833,  0.2338,\n",
      "        -3.8797,  1.2973,  0.4837, -1.7402, -0.4545,  0.3578,  0.0000,  7.4632,\n",
      "        -5.0116,  0.0000,  1.2033, -3.5811,  0.0000,  0.3470, -4.5355,  0.0000])\n",
      "tensor([-5.2219e-01,  1.2855e+00, -4.5994e-01, -2.6528e-01,  9.3001e-02,\n",
      "        -2.9172e-01,  7.7665e-01,  4.6761e-02, -7.7594e-01,  2.5947e-01,\n",
      "         9.6745e-02, -3.4803e-01, -9.0910e-02,  7.1556e-02, -2.5506e-17,\n",
      "         1.4926e+00, -1.0023e+00, -1.7351e-16,  2.4066e-01, -7.1623e-01,\n",
      "         0.0000e+00,  6.9400e-02, -9.0710e-01, -1.2061e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ -0.7468,  16.2462,   2.7995, -13.4315])\n",
      "tensor([-0.1494,  3.2492,  0.5599, -2.6863], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-8.0272, -8.0272])\n",
      "tensor([-1.6054, -1.6054], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([ 8.9381, 10.9381], requires_grad=True)\n",
      "tensor([[0.5755, 0.4245],\n",
      "        [0.3400, 0.6600],\n",
      "        [0.5885, 0.4115],\n",
      "        [0.7134, 0.2866],\n",
      "        [0.5743, 0.4257],\n",
      "        [0.7051, 0.2949],\n",
      "        [0.5633, 0.4367],\n",
      "        [0.6958, 0.3042],\n",
      "        [0.6142, 0.3858],\n",
      "        [0.5136, 0.4864],\n",
      "        [0.5012, 0.4988],\n",
      "        [0.4266, 0.5734],\n",
      "        [0.4026, 0.5974],\n",
      "        [0.2754, 0.7246],\n",
      "        [0.2024, 0.7976],\n",
      "        [0.2787, 0.7213],\n",
      "        [0.4990, 0.5010]], dtype=torch.float64)\n",
      "Finished episode 75 Average rewards:  17.0\n",
      "tensor([-0.0523,  0.3690,  0.1014, -0.5357,  0.0232, -0.5302,  1.8681,  0.3015,\n",
      "        -1.8457,  0.2582,  1.2352,  0.6444, -3.2889, -1.7278,  0.0000,  0.9798,\n",
      "        -0.6530,  0.0000,  2.3259,  0.9831,  0.0000, -0.4743, -1.4830,  0.0000])\n",
      "tensor([-1.0464e-02,  7.3804e-02,  2.0279e-02, -1.0714e-01,  4.6308e-03,\n",
      "        -1.0603e-01,  3.7361e-01,  6.0306e-02, -3.6914e-01,  5.1636e-02,\n",
      "         2.4705e-01,  1.2887e-01, -6.5778e-01, -3.4556e-01,  1.4374e-16,\n",
      "         1.9596e-01, -1.3060e-01, -4.6525e-17,  4.6519e-01,  1.9661e-01,\n",
      "         0.0000e+00, -9.4852e-02, -2.9659e-01, -2.5148e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-7.0206,  3.1444,  9.9695, -2.9978])\n",
      "tensor([-1.4041,  0.6289,  1.9939, -0.5996], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-1.5426, -1.5426])\n",
      "tensor([-0.3085, -0.3085], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([7.3955, 9.3955], requires_grad=True)\n",
      "tensor([[0.6131, 0.3869],\n",
      "        [0.4874, 0.5126],\n",
      "        [0.6076, 0.3924],\n",
      "        [0.5134, 0.4866],\n",
      "        [0.6077, 0.3923],\n",
      "        [0.5772, 0.4228],\n",
      "        [0.5673, 0.4327],\n",
      "        [0.6286, 0.3714],\n",
      "        [0.4609, 0.5391],\n",
      "        [0.4166, 0.5834],\n",
      "        [0.4590, 0.5410]], dtype=torch.float64)\n",
      "Finished episode 76 Average rewards:  11.0\n",
      "tensor([ 0.3271,  0.4901,  0.3095, -0.7371,  0.1872, -0.7075,  0.0793,  0.1976,\n",
      "         0.0378, -0.5944, -0.7760, -0.6161, -0.6273,  0.5382,  0.0000, -0.1877,\n",
      "        -0.2456,  0.0000,  0.0410, -0.7662,  0.0000,  0.8486,  0.2574,  0.0000])\n",
      "tensor([ 6.5425e-02,  9.8024e-02,  6.1904e-02, -1.4742e-01,  3.7434e-02,\n",
      "        -1.4150e-01,  1.5860e-02,  3.9518e-02,  7.5686e-03, -1.1888e-01,\n",
      "        -1.5520e-01, -1.2323e-01, -1.2546e-01,  1.0764e-01, -5.3260e-18,\n",
      "        -3.7533e-02, -4.9127e-02,  3.2864e-17,  8.2077e-03, -1.5325e-01,\n",
      "         0.0000e+00,  1.6972e-01,  5.1474e-02, -3.4464e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.4458, -0.8372,  0.0474,  9.0682])\n",
      "tensor([-0.0892, -0.1674,  0.0095,  1.8136], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-0.6240, -0.6240])\n",
      "tensor([-0.1248, -0.1248], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([6.7715, 8.7715], requires_grad=True)\n",
      "tensor([[0.5087, 0.4913],\n",
      "        [0.4679, 0.5321],\n",
      "        [0.5189, 0.4811],\n",
      "        [0.4589, 0.5411],\n",
      "        [0.5332, 0.4668],\n",
      "        [0.5180, 0.4820],\n",
      "        [0.5532, 0.4468],\n",
      "        [0.4336, 0.5664],\n",
      "        [0.5684, 0.4316],\n",
      "        [0.4245, 0.5755],\n",
      "        [0.5487, 0.4513],\n",
      "        [0.4294, 0.5706],\n",
      "        [0.5240, 0.4760],\n",
      "        [0.4893, 0.5107],\n",
      "        [0.5054, 0.4946],\n",
      "        [0.4887, 0.5113],\n",
      "        [0.3702, 0.6298]], dtype=torch.float64)\n",
      "Monitored episode 50 Average Monitored rewards:  21.9\n",
      "Finished episode 77 Average rewards:  13.0\n",
      "tensor([-1.4313, -0.8386, -0.5486,  0.7090,  0.0184,  0.7245, -1.5153,  1.2875,\n",
      "         1.8464,  0.4534, -0.0514, -0.1265, -0.0799, -1.4766,  0.0000,  1.9604,\n",
      "         0.8273,  0.0000,  0.8794, -1.1177,  0.0000, -0.8721,  3.0273,  0.0000])\n",
      "tensor([-2.8626e-01, -1.6773e-01, -1.0972e-01,  1.4180e-01,  3.6871e-03,\n",
      "         1.4490e-01, -3.0307e-01,  2.5750e-01,  3.6928e-01,  9.0690e-02,\n",
      "        -1.0273e-02, -2.5301e-02, -1.5988e-02, -2.9532e-01,  2.3562e-17,\n",
      "         3.9208e-01,  1.6545e-01, -6.3978e-20,  1.7587e-01, -2.2355e-01,\n",
      "         0.0000e+00, -1.7441e-01,  6.0545e-01,  1.4944e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.3980,  1.2493,  2.9674,  0.2098])\n",
      "tensor([-0.0796,  0.2499,  0.5935,  0.0420], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-0.9826, -0.9826])\n",
      "tensor([-0.1965, -0.1965], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([5.7889, 7.7889], requires_grad=True)\n",
      "tensor([[0.6765, 0.3235],\n",
      "        [0.5100, 0.4900],\n",
      "        [0.5020, 0.4980],\n",
      "        [0.5515, 0.4485],\n",
      "        [0.5156, 0.4844],\n",
      "        [0.5764, 0.4236],\n",
      "        [0.4568, 0.5432],\n",
      "        [0.5439, 0.4561],\n",
      "        [0.4805, 0.5195],\n",
      "        [0.5855, 0.4145],\n",
      "        [0.4483, 0.5517],\n",
      "        [0.5484, 0.4516],\n",
      "        [0.4672, 0.5328],\n",
      "        [0.5430, 0.4570],\n",
      "        [0.4606, 0.5394],\n",
      "        [0.4599, 0.5401],\n",
      "        [0.4669, 0.5331],\n",
      "        [0.4998, 0.5002],\n",
      "        [0.4551, 0.5449],\n",
      "        [0.4798, 0.5202],\n",
      "        [0.4352, 0.5648],\n",
      "        [0.4363, 0.5637],\n",
      "        [0.2542, 0.7458],\n",
      "        [0.6446, 0.3554],\n",
      "        [0.5904, 0.4096],\n",
      "        [0.4312, 0.5688],\n",
      "        [0.5561, 0.4439]], dtype=torch.float64)\n",
      "Finished episode 78 Average rewards:  27.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.8691, -0.1068, -1.1368,  0.2810, -0.2809,  0.3189, -0.5680, -0.1476,\n",
      "        -0.0883,  0.6029, -0.3443, -0.2957,  0.4801, -3.0201,  0.0000, -2.0242,\n",
      "         2.2172,  0.0000, -0.6346,  2.9609,  0.0000,  1.2931,  1.0646,  0.0000])\n",
      "tensor([-3.7381e-01, -2.1358e-02, -2.2736e-01,  5.6207e-02, -5.6177e-02,\n",
      "         6.3789e-02, -1.1361e-01, -2.9529e-02, -1.7656e-02,  1.2058e-01,\n",
      "        -6.8870e-02, -5.9138e-02,  9.6026e-02, -6.0403e-01, -4.2800e-17,\n",
      "        -4.0485e-01,  4.4343e-01,  6.8008e-17, -1.2692e-01,  5.9218e-01,\n",
      "         0.0000e+00,  2.5862e-01,  2.1292e-01, -2.8803e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 1.4953, -2.5793,  8.2259,  3.8648])\n",
      "tensor([ 0.2991, -0.5159,  1.6452,  0.7730], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.1807, 0.1807])\n",
      "tensor([0.0361, 0.0361], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([5.9696, 7.9696], requires_grad=True)\n",
      "tensor([[0.3253, 0.6747],\n",
      "        [0.3958, 0.6042],\n",
      "        [0.3308, 0.6692],\n",
      "        [0.7348, 0.2652],\n",
      "        [0.3936, 0.6064],\n",
      "        [0.3822, 0.6178],\n",
      "        [0.6200, 0.3800],\n",
      "        [0.3060, 0.6940],\n",
      "        [0.5926, 0.4074],\n",
      "        [0.4556, 0.5444],\n",
      "        [0.4660, 0.5340],\n",
      "        [0.3889, 0.6111],\n",
      "        [0.3421, 0.6579],\n",
      "        [0.4202, 0.5798],\n",
      "        [0.3042, 0.6958],\n",
      "        [0.5070, 0.4930],\n",
      "        [0.3058, 0.6942],\n",
      "        [0.4883, 0.5117],\n",
      "        [0.5914, 0.4086],\n",
      "        [0.4544, 0.5456],\n",
      "        [0.4512, 0.5488],\n",
      "        [0.4997, 0.5003],\n",
      "        [0.3279, 0.6721],\n",
      "        [0.5249, 0.4751]], dtype=torch.float64)\n",
      "Finished episode 79 Average rewards:  24.0\n",
      "tensor([ 2.0576,  0.8490,  1.8651, -0.0179,  0.2617,  0.0191,  0.0098,  0.7961,\n",
      "        -0.2776,  0.3402, -0.0556, -0.1614,  0.9175,  1.9063,  0.0000, -0.7982,\n",
      "        -0.0694,  0.0000, -0.1875, -0.4119,  0.0000,  0.3810, -0.2439,  0.0000])\n",
      "tensor([ 4.1152e-01,  1.6979e-01,  3.7302e-01, -3.5896e-03,  5.2333e-02,\n",
      "         3.8152e-03,  1.9533e-03,  1.5921e-01, -5.5520e-02,  6.8042e-02,\n",
      "        -1.1122e-02, -3.2274e-02,  1.8350e-01,  3.8127e-01, -5.9128e-17,\n",
      "        -1.5964e-01, -1.3881e-02, -1.9276e-17, -3.7510e-02, -8.2371e-02,\n",
      "         0.0000e+00,  7.6206e-02, -4.8784e-02,  1.5613e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 1.5629, -2.0958, -0.2595,  0.8995])\n",
      "tensor([ 0.3126, -0.4192, -0.0519,  0.1799], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.2041, 0.2041])\n",
      "tensor([0.0408, 0.0408], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([6.1737, 8.1737], requires_grad=True)\n",
      "tensor([[0.4817, 0.5183],\n",
      "        [0.4783, 0.5217],\n",
      "        [0.5367, 0.4633],\n",
      "        [0.4281, 0.5719],\n",
      "        [0.5179, 0.4821],\n",
      "        [0.4690, 0.5310],\n",
      "        [0.5131, 0.4869],\n",
      "        [0.4349, 0.5651],\n",
      "        [0.5180, 0.4820],\n",
      "        [0.4416, 0.5584],\n",
      "        [0.5153, 0.4847],\n",
      "        [0.4631, 0.5369],\n",
      "        [0.5036, 0.4964],\n",
      "        [0.5088, 0.4912],\n",
      "        [0.5142, 0.4858],\n",
      "        [0.5141, 0.4859],\n",
      "        [0.5202, 0.4798],\n",
      "        [0.5215, 0.4785],\n",
      "        [0.5235, 0.4765],\n",
      "        [0.4883, 0.5117],\n",
      "        [0.5149, 0.4851],\n",
      "        [0.4009, 0.5991],\n",
      "        [0.4796, 0.5204],\n",
      "        [0.4907, 0.5093],\n",
      "        [0.4993, 0.5007],\n",
      "        [0.5011, 0.4989],\n",
      "        [0.5717, 0.4283],\n",
      "        [0.5005, 0.4995],\n",
      "        [0.4046, 0.5954],\n",
      "        [0.5642, 0.4358],\n",
      "        [0.4872, 0.5128]], dtype=torch.float64)\n",
      "Finished episode 80 Average rewards:  31.0\n",
      "tensor([ 0.7652,  2.4836, -1.4254, -0.2734, -0.0309, -0.2705,  0.7937, -0.1265,\n",
      "         0.7380, -0.6386, -0.5913,  0.5605, -0.0104,  0.8621,  0.0000,  0.0099,\n",
      "         0.0272,  0.0000,  0.2237, -0.7681,  0.0000, -0.7110, -0.1769,  0.0000])\n",
      "tensor([ 1.5303e-01,  4.9672e-01, -2.8507e-01, -5.4684e-02, -6.1759e-03,\n",
      "        -5.4090e-02,  1.5875e-01, -2.5294e-02,  1.4761e-01, -1.2772e-01,\n",
      "        -1.1827e-01,  1.1210e-01, -2.0716e-03,  1.7241e-01,  5.1495e-17,\n",
      "         1.9882e-03,  5.4364e-03, -7.0255e-18,  4.4738e-02, -1.5361e-01,\n",
      "         0.0000e+00, -1.4220e-01, -3.5390e-02,  5.7502e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.0223, -0.0342,  2.8530, -0.1963])\n",
      "tensor([-0.0045, -0.0068,  0.5706, -0.0393], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-0.3034, -0.3034])\n",
      "tensor([-0.0607, -0.0607], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([5.8703, 7.8702], requires_grad=True)\n",
      "tensor([[0.4626, 0.5374],\n",
      "        [0.5368, 0.4632],\n",
      "        [0.6020, 0.3980],\n",
      "        [0.4952, 0.5048],\n",
      "        [0.4913, 0.5087],\n",
      "        [0.4974, 0.5026],\n",
      "        [0.5039, 0.4961],\n",
      "        [0.5126, 0.4874],\n",
      "        [0.4878, 0.5122],\n",
      "        [0.5161, 0.4839]], dtype=torch.float64)\n",
      "Finished episode 81 Average rewards:  10.0\n",
      "tensor([ 4.8299, -3.1841, -2.1215, -1.0191, -0.0226, -1.0162,  0.4938,  0.3045,\n",
      "         0.0386,  0.2826, -1.3473, -0.3828,  0.2943, -2.1560,  0.0000, -3.1304,\n",
      "         0.1675,  0.0000,  0.3621,  0.1284,  0.0000,  2.3095, -0.2738,  0.0000])\n",
      "tensor([ 9.6599e-01, -6.3682e-01, -4.2429e-01, -2.0383e-01, -4.5124e-03,\n",
      "        -2.0324e-01,  9.8767e-02,  6.0894e-02,  7.7267e-03,  5.6518e-02,\n",
      "        -2.6946e-01, -7.6554e-02,  5.8862e-02, -4.3120e-01, -5.8620e-17,\n",
      "        -6.2608e-01,  3.3506e-02,  1.0638e-16,  7.2414e-02,  2.5677e-02,\n",
      "         0.0000e+00,  4.6191e-01, -5.4751e-02, -2.7464e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 0.7407, -3.3792,  1.2287,  0.6924])\n",
      "tensor([ 0.1481, -0.6758,  0.2457,  0.1385], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([4.4216, 4.4216])\n",
      "tensor([0.8843, 0.8843], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([10.2919, 12.2919], requires_grad=True)\n",
      "tensor([[0.3706, 0.6294],\n",
      "        [0.2449, 0.7551],\n",
      "        [0.2532, 0.7468],\n",
      "        [0.3818, 0.6182],\n",
      "        [0.5643, 0.4357],\n",
      "        [0.5168, 0.4832],\n",
      "        [0.5877, 0.4123],\n",
      "        [0.6048, 0.3952],\n",
      "        [0.6197, 0.3803],\n",
      "        [0.5876, 0.4124]], dtype=torch.float64)\n",
      "Monitored episode 50 Average Monitored rewards:  20.3\n",
      "Finished episode 82 Average rewards:  23.0\n",
      "tensor([ 0.7182,  0.1739,  0.0867,  0.7606,  0.5785,  0.7986, -2.1508, -0.0419,\n",
      "        -2.2067,  0.5053,  0.1470, -0.2952,  3.1700, -0.3264,  0.0000,  0.9914,\n",
      "        -0.4529,  0.0000,  0.2447,  2.5655,  0.0000,  0.2368, -0.4721,  0.0000])\n",
      "tensor([ 1.4365e-01,  3.4772e-02,  1.7336e-02,  1.5213e-01,  1.1571e-01,\n",
      "         1.5973e-01, -4.3016e-01, -8.3837e-03, -4.4134e-01,  1.0105e-01,\n",
      "         2.9406e-02, -5.9046e-02,  6.3400e-01, -6.5280e-02, -1.2801e-16,\n",
      "         1.9827e-01, -9.0585e-02,  1.3214e-16,  4.8934e-02,  5.1310e-01,\n",
      "         0.0000e+00,  4.7352e-02, -9.4421e-02,  5.1296e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([7.5298, 1.6412, 1.6789, 1.8980])\n",
      "tensor([1.5060, 0.3282, 0.3358, 0.3796], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([4.6565, 4.6565])\n",
      "tensor([0.9313, 0.9313], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([14.9484, 16.9484], requires_grad=True)\n",
      "tensor([[0.2322, 0.7678],\n",
      "        [0.2281, 0.7719],\n",
      "        [0.2371, 0.7629],\n",
      "        [0.2369, 0.7631],\n",
      "        [0.5148, 0.4852],\n",
      "        [0.7863, 0.2137],\n",
      "        [0.5203, 0.4797],\n",
      "        [0.2478, 0.7522],\n",
      "        [0.5314, 0.4686],\n",
      "        [0.7664, 0.2336],\n",
      "        [0.6049, 0.3951],\n",
      "        [0.3317, 0.6683],\n",
      "        [0.2488, 0.7512],\n",
      "        [0.3767, 0.6233],\n",
      "        [0.2633, 0.7367],\n",
      "        [0.3085, 0.6915],\n",
      "        [0.2846, 0.7154],\n",
      "        [0.5291, 0.4709],\n",
      "        [0.7489, 0.2511],\n",
      "        [0.6229, 0.3771],\n",
      "        [0.4005, 0.5995],\n",
      "        [0.6753, 0.3247],\n",
      "        [0.7225, 0.2775]], dtype=torch.float64)\n",
      "Finished episode 83 Average rewards:  23.0\n",
      "tensor([-1.1219, -1.2113,  0.0364, -0.4186,  0.3837, -0.9333, -3.0187, -1.6377,\n",
      "        -3.1456,  1.8939,  3.6145,  0.2692, -2.3925,  0.6124,  0.0000, -1.1749,\n",
      "         0.9000,  0.0000,  1.8281, -5.0671,  0.0000,  5.2155, -5.7637,  0.0000])\n",
      "tensor([-2.2438e-01, -2.4227e-01,  7.2889e-03, -8.3712e-02,  7.6731e-02,\n",
      "        -1.8666e-01, -6.0374e-01, -3.2754e-01, -6.2912e-01,  3.7878e-01,\n",
      "         7.2290e-01,  5.3842e-02, -4.7850e-01,  1.2247e-01, -6.6301e-17,\n",
      "        -2.3499e-01,  1.8000e-01, -1.5250e-16,  3.6562e-01, -1.0134e+00,\n",
      "         0.0000e+00,  1.0431e+00, -1.1527e+00, -8.4253e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-5.6821, -5.8017,  9.7328, 22.2068])\n",
      "tensor([-1.1364, -1.1603,  1.9466,  4.4414], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-5.4065, -5.4065])\n",
      "tensor([-1.0813, -1.0813], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([ 9.5419, 11.5419], requires_grad=True)\n",
      "tensor([[0.5808, 0.4192],\n",
      "        [0.5530, 0.4470],\n",
      "        [0.5041, 0.4959],\n",
      "        [0.4185, 0.5815],\n",
      "        [0.4164, 0.5836],\n",
      "        [0.6740, 0.3260],\n",
      "        [0.7883, 0.2117],\n",
      "        [0.7107, 0.2893],\n",
      "        [0.7508, 0.2492],\n",
      "        [0.6813, 0.3187],\n",
      "        [0.8022, 0.1978],\n",
      "        [0.7202, 0.2798],\n",
      "        [0.7620, 0.2380],\n",
      "        [0.6823, 0.3177],\n",
      "        [0.5538, 0.4462],\n",
      "        [0.5211, 0.4789],\n",
      "        [0.3446, 0.6554],\n",
      "        [0.2960, 0.7040],\n",
      "        [0.5750, 0.4250],\n",
      "        [0.7789, 0.2211],\n",
      "        [0.6446, 0.3554],\n",
      "        [0.5222, 0.4778],\n",
      "        [0.5313, 0.4687],\n",
      "        [0.2865, 0.7135],\n",
      "        [0.4964, 0.5036],\n",
      "        [0.7416, 0.2584],\n",
      "        [0.5785, 0.4215],\n",
      "        [0.7498, 0.2502],\n",
      "        [0.5883, 0.4117],\n",
      "        [0.3429, 0.6571],\n",
      "        [0.3451, 0.6549],\n",
      "        [0.3037, 0.6963],\n",
      "        [0.5239, 0.4761],\n",
      "        [0.3372, 0.6628],\n",
      "        [0.2487, 0.7513],\n",
      "        [0.4596, 0.5404],\n",
      "        [0.3971, 0.6029],\n",
      "        [0.4819, 0.5181]], dtype=torch.float64)\n",
      "Finished episode 84 Average rewards:  38.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.4349,  0.0576,  0.2104,  0.0330,  0.0051,  0.0850, -0.0585,  0.2690,\n",
      "         0.1195,  0.8349,  0.2603,  0.8598,  0.5320,  1.4398,  0.0000,  2.8444,\n",
      "         0.1767,  0.0000, -0.6746,  0.4776,  0.0000, -2.0442, -2.3561,  0.0000])\n",
      "tensor([ 8.6989e-02,  1.1518e-02,  4.2081e-02,  6.5913e-03,  1.0115e-03,\n",
      "         1.6997e-02, -1.1707e-02,  5.3808e-02,  2.3902e-02,  1.6697e-01,\n",
      "         5.2052e-02,  1.7195e-01,  1.0640e-01,  2.8797e-01, -8.3991e-17,\n",
      "         5.6888e-01,  3.5336e-02, -3.0481e-17, -1.3493e-01,  9.5519e-02,\n",
      "         0.0000e+00, -4.0884e-01, -4.7122e-01, -3.1897e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([  0.9036,   6.6150,  -5.7363, -11.7398])\n",
      "tensor([ 0.1807,  1.3230, -1.1473, -2.3480], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.2971, 0.2971])\n",
      "tensor([0.0594, 0.0594], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([ 9.8390, 11.8390], requires_grad=True)\n",
      "tensor([[0.4506, 0.5494],\n",
      "        [0.6336, 0.3664],\n",
      "        [0.5427, 0.4573],\n",
      "        [0.3785, 0.6215],\n",
      "        [0.5146, 0.4854],\n",
      "        [0.4278, 0.5722],\n",
      "        [0.5064, 0.4936],\n",
      "        [0.4398, 0.5602],\n",
      "        [0.4790, 0.5210],\n",
      "        [0.5179, 0.4821],\n",
      "        [0.5102, 0.4898],\n",
      "        [0.5726, 0.4274],\n",
      "        [0.5622, 0.4378],\n",
      "        [0.5956, 0.4044],\n",
      "        [0.5720, 0.4280],\n",
      "        [0.4040, 0.5960],\n",
      "        [0.4688, 0.5312],\n",
      "        [0.5408, 0.4592]], dtype=torch.float64)\n",
      "Finished episode 85 Average rewards:  18.0\n",
      "tensor([ 0.0157, -0.1275, -0.0049,  0.2241,  0.0098,  0.3940, -3.0586, -1.4258,\n",
      "        -0.3347, -1.8854, -0.0258, -1.8829, -0.8304,  1.4701,  0.0000,  2.6275,\n",
      "         0.3727,  0.0000, -1.4537,  0.4401,  0.0000, -0.2277, -4.5452,  0.0000])\n",
      "tensor([ 3.1322e-03, -2.5503e-02, -9.7541e-04,  4.4810e-02,  1.9574e-03,\n",
      "         7.8796e-02, -6.1173e-01, -2.8517e-01, -6.6945e-02, -3.7709e-01,\n",
      "        -5.1599e-03, -3.7658e-01, -1.6607e-01,  2.9401e-01, -3.9591e-17,\n",
      "         5.2551e-01,  7.4550e-02, -9.7569e-18, -2.9075e-01,  8.8016e-02,\n",
      "         0.0000e+00, -4.5535e-02, -9.0904e-01,  3.0457e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-1.5628,  5.8836, -4.7780, -1.2168])\n",
      "tensor([-0.3126,  1.1767, -0.9556, -0.2434], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([1.5416, 1.5416])\n",
      "tensor([0.3083, 0.3083], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([11.3806, 13.3806], requires_grad=True)\n",
      "tensor([[0.3963, 0.6037],\n",
      "        [0.4900, 0.5100],\n",
      "        [0.4544, 0.5456],\n",
      "        [0.3722, 0.6278],\n",
      "        [0.3819, 0.6181],\n",
      "        [0.3838, 0.6162],\n",
      "        [0.3820, 0.6180],\n",
      "        [0.4743, 0.5257],\n",
      "        [0.5779, 0.4221],\n",
      "        [0.5703, 0.4297],\n",
      "        [0.4575, 0.5425],\n",
      "        [0.4942, 0.5058],\n",
      "        [0.5754, 0.4246],\n",
      "        [0.5241, 0.4759],\n",
      "        [0.4389, 0.5611],\n",
      "        [0.4343, 0.5657],\n",
      "        [0.4790, 0.5210],\n",
      "        [0.5785, 0.4215],\n",
      "        [0.5632, 0.4368],\n",
      "        [0.4702, 0.5298],\n",
      "        [0.4054, 0.5946],\n",
      "        [0.4770, 0.5230],\n",
      "        [0.4636, 0.5364],\n",
      "        [0.6458, 0.3542]], dtype=torch.float64)\n",
      "Finished episode 86 Average rewards:  24.0\n",
      "tensor([ 0.1116,  0.0645,  0.1377, -0.1550,  0.0531, -0.3112,  1.6613,  0.0244,\n",
      "        -1.6595,  0.6564,  0.0220,  0.6445, -1.0988, -1.3143,  0.0000, -0.9121,\n",
      "         0.4373,  0.0000,  0.4295,  0.0881,  0.0000, -0.8284,  0.1326,  0.0000])\n",
      "tensor([ 2.2320e-02,  1.2900e-02,  2.7550e-02, -3.1009e-02,  1.0610e-02,\n",
      "        -6.2243e-02,  3.3225e-01,  4.8875e-03, -3.3191e-01,  1.3127e-01,\n",
      "         4.3905e-03,  1.2890e-01, -2.1976e-01, -2.6285e-01,  3.1407e-17,\n",
      "        -1.8241e-01,  8.7452e-02, -7.0023e-17,  8.5890e-02,  1.7628e-02,\n",
      "         0.0000e+00, -1.6569e-01,  2.6526e-02, -6.4938e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-2.4071, -3.0254, -0.0412, -1.0823])\n",
      "tensor([-0.4814, -0.6051, -0.0082, -0.2165], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-0.3895, -0.3895])\n",
      "tensor([-0.0779, -0.0779], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([10.9912, 12.9911], requires_grad=True)\n",
      "tensor([[0.6049, 0.3951],\n",
      "        [0.5531, 0.4469],\n",
      "        [0.5935, 0.4065],\n",
      "        [0.7765, 0.2235],\n",
      "        [0.3737, 0.6263],\n",
      "        [0.4576, 0.5424],\n",
      "        [0.6777, 0.3223],\n",
      "        [0.4611, 0.5389],\n",
      "        [0.4075, 0.5925],\n",
      "        [0.5562, 0.4438],\n",
      "        [0.6247, 0.3753],\n",
      "        [0.5989, 0.4011],\n",
      "        [0.4321, 0.5679],\n",
      "        [0.4927, 0.5073],\n",
      "        [0.3883, 0.6117],\n",
      "        [0.4649, 0.5351],\n",
      "        [0.6572, 0.3428],\n",
      "        [0.6191, 0.3809],\n",
      "        [0.6156, 0.3844]], dtype=torch.float64)\n",
      "Monitored episode 50 Average Monitored rewards:  22.3\n",
      "Finished episode 87 Average rewards:  12.0\n",
      "tensor([ 0.5489, -0.0172,  0.5403, -0.4464,  0.0342, -0.9863,  0.3867,  0.0102,\n",
      "        -0.3884,  0.1897, -0.0149,  0.1880, -0.0224,  1.1396,  0.0000, -0.2357,\n",
      "        -2.1972,  0.0000,  1.4958,  4.7393,  0.0000, -0.1867,  0.2591,  0.0000])\n",
      "tensor([ 1.0977e-01, -3.4382e-03,  1.0806e-01, -8.9273e-02,  6.8422e-03,\n",
      "        -1.9726e-01,  7.7344e-02,  2.0399e-03, -7.7681e-02,  3.7942e-02,\n",
      "        -2.9873e-03,  3.7590e-02, -4.4864e-03,  2.2792e-01,  2.4132e-17,\n",
      "        -4.7133e-02, -4.3943e-01, -3.5588e-17,  2.9916e-01,  9.4786e-01,\n",
      "         0.0000e+00, -3.7332e-02,  5.1815e-02,  1.6490e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.1206, -0.6754, -5.6383, -0.3196])\n",
      "tensor([-0.0241, -0.1351, -1.1276, -0.0639], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-1.2440, -1.2440])\n",
      "tensor([-0.2488, -0.2488], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([ 9.7472, 11.7472], requires_grad=True)\n",
      "tensor([[0.7030, 0.2970],\n",
      "        [0.6730, 0.3270],\n",
      "        [0.6952, 0.3048],\n",
      "        [0.6280, 0.3720],\n",
      "        [0.4715, 0.5285],\n",
      "        [0.4627, 0.5373],\n",
      "        [0.6122, 0.3878],\n",
      "        [0.5681, 0.4319],\n",
      "        [0.4143, 0.5857],\n",
      "        [0.2737, 0.7263],\n",
      "        [0.3972, 0.6028],\n",
      "        [0.6266, 0.3734],\n",
      "        [0.5297, 0.4703],\n",
      "        [0.2758, 0.7242],\n",
      "        [0.3058, 0.6942],\n",
      "        [0.3785, 0.6215],\n",
      "        [0.3926, 0.6074],\n",
      "        [0.5516, 0.4484],\n",
      "        [0.5601, 0.4399],\n",
      "        [0.4539, 0.5461],\n",
      "        [0.5563, 0.4437],\n",
      "        [0.7574, 0.2426],\n",
      "        [0.7884, 0.2116],\n",
      "        [0.7708, 0.2292],\n",
      "        [0.6624, 0.3376],\n",
      "        [0.4074, 0.5926],\n",
      "        [0.3178, 0.6822],\n",
      "        [0.2875, 0.7125],\n",
      "        [0.5189, 0.4811],\n",
      "        [0.6982, 0.3018],\n",
      "        [0.5160, 0.4840],\n",
      "        [0.3749, 0.6251],\n",
      "        [0.3396, 0.6604],\n",
      "        [0.5830, 0.4170],\n",
      "        [0.5362, 0.4638],\n",
      "        [0.4066, 0.5934],\n",
      "        [0.5486, 0.4514],\n",
      "        [0.6216, 0.3784],\n",
      "        [0.3685, 0.6315],\n",
      "        [0.6056, 0.3944],\n",
      "        [0.4322, 0.5678],\n",
      "        [0.4741, 0.5259]], dtype=torch.float64)\n",
      "Finished episode 88 Average rewards:  42.0\n",
      "tensor([-2.9198e+00, -6.4714e-01, -2.9390e+00, -3.5033e-01, -3.5264e-02,\n",
      "        -2.3371e-01, -1.3038e+00,  1.2517e-02,  1.3074e+00,  5.7864e-01,\n",
      "         8.0948e-03,  5.7797e-01, -4.1232e-01, -3.7547e+00,  0.0000e+00,\n",
      "        -1.4344e+00, -1.2707e+00,  0.0000e+00,  2.5103e-03,  7.4237e-01,\n",
      "         0.0000e+00, -3.5747e-01,  7.4582e-01,  0.0000e+00])\n",
      "tensor([-5.8396e-01, -1.2943e-01, -5.8781e-01, -7.0066e-02, -7.0527e-03,\n",
      "        -4.6742e-02, -2.6075e-01,  2.5035e-03,  2.6147e-01,  1.1573e-01,\n",
      "         1.6188e-03,  1.1559e-01, -8.2464e-02, -7.5095e-01,  1.1521e-16,\n",
      "        -2.8688e-01, -2.5415e-01,  6.6465e-17,  5.0207e-04,  1.4847e-01,\n",
      "         0.0000e+00, -7.1495e-02,  1.4916e-01,  2.1513e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.4503, -4.1798, -0.0264, -1.3337])\n",
      "tensor([-0.0901, -0.8360, -0.0053, -0.2667], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-0.3465, -0.3465])\n",
      "tensor([-0.0693, -0.0693], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([ 9.4006, 11.4006], requires_grad=True)\n",
      "tensor([[0.5591, 0.4409],\n",
      "        [0.5747, 0.4253],\n",
      "        [0.5588, 0.4412],\n",
      "        [0.5377, 0.4623],\n",
      "        [0.5229, 0.4771],\n",
      "        [0.5360, 0.4640],\n",
      "        [0.5207, 0.4793],\n",
      "        [0.5349, 0.4651],\n",
      "        [0.5194, 0.4806],\n",
      "        [0.5216, 0.4784],\n",
      "        [0.5190, 0.4810],\n",
      "        [0.5333, 0.4667],\n",
      "        [0.5186, 0.4814],\n",
      "        [0.5218, 0.4782],\n",
      "        [0.5447, 0.4553],\n",
      "        [0.5193, 0.4807],\n",
      "        [0.5467, 0.4533],\n",
      "        [0.5203, 0.4797],\n",
      "        [0.5119, 0.4881],\n",
      "        [0.5181, 0.4819],\n",
      "        [0.5081, 0.4919],\n",
      "        [0.5176, 0.4824],\n",
      "        [0.5504, 0.4496]], dtype=torch.float64)\n",
      "Finished episode 89 Average rewards:  23.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.8170,  0.1501,  0.6014, -1.0116, -1.3019, -1.6951,  3.4738,  0.1110,\n",
      "        -3.4645, -0.4457, -0.1844, -0.4485, -0.5075,  0.5209,  0.0000, -1.8973,\n",
      "        -1.1624,  0.0000, -0.7068,  0.2190,  0.0000, -0.6377, -0.5280,  0.0000])\n",
      "tensor([ 1.6340e-01,  3.0023e-02,  1.2029e-01, -2.0233e-01, -2.6038e-01,\n",
      "        -3.3903e-01,  6.9476e-01,  2.2203e-02, -6.9291e-01, -8.9144e-02,\n",
      "        -3.6875e-02, -8.9693e-02, -1.0151e-01,  1.0417e-01, -4.3208e-17,\n",
      "        -3.7947e-01, -2.3248e-01,  1.8419e-17, -1.4136e-01,  4.3793e-02,\n",
      "         0.0000e+00, -1.2755e-01, -1.0559e-01,  9.2933e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-1.0871, -4.0735, -4.4182, -1.1624])\n",
      "tensor([-0.2174, -0.8147, -0.8836, -0.2325], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-0.3194, -0.3194])\n",
      "tensor([-0.0639, -0.0639], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([ 9.0813, 11.0813], requires_grad=True)\n",
      "tensor([[0.5489, 0.4511],\n",
      "        [0.5788, 0.4212],\n",
      "        [0.5339, 0.4661],\n",
      "        [0.5148, 0.4852],\n",
      "        [0.4991, 0.5009],\n",
      "        [0.4588, 0.5412],\n",
      "        [0.4923, 0.5077],\n",
      "        [0.4832, 0.5168],\n",
      "        [0.4490, 0.5510],\n",
      "        [0.4189, 0.5811],\n",
      "        [0.4085, 0.5915],\n",
      "        [0.4835, 0.5165],\n",
      "        [0.6373, 0.3627],\n",
      "        [0.5181, 0.4819],\n",
      "        [0.3964, 0.6036],\n",
      "        [0.6434, 0.3566],\n",
      "        [0.3858, 0.6142],\n",
      "        [0.3916, 0.6084],\n",
      "        [0.6634, 0.3366]], dtype=torch.float64)\n",
      "Finished episode 90 Average rewards:  19.0\n",
      "tensor([-5.5201,  0.3622, -4.5414,  0.0278,  0.0909,  0.0314, -1.6422,  0.3561,\n",
      "         1.5474,  0.5168,  0.2046,  0.5481, -2.2929, -5.6057,  0.0000, -2.2548,\n",
      "         3.6905,  0.0000,  2.9452,  1.4276,  0.0000,  3.5375,  3.2577,  0.0000])\n",
      "tensor([-1.1040e+00,  7.2449e-02, -9.0828e-01,  5.5552e-03,  1.8184e-02,\n",
      "         6.2761e-03, -3.2845e-01,  7.1211e-02,  3.0948e-01,  1.0336e-01,\n",
      "         4.0930e-02,  1.0961e-01, -4.5858e-01, -1.1211e+00,  1.0724e-16,\n",
      "        -4.5096e-01,  7.3810e-01, -9.8084e-17,  5.8903e-01,  2.8552e-01,\n",
      "         0.0000e+00,  7.0751e-01,  6.5154e-01,  6.8526e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-4.8293, -6.1448, -1.1090,  9.4908])\n",
      "tensor([-0.9659, -1.2290, -0.2218,  1.8982], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-4.2883, -4.2883])\n",
      "tensor([-0.8577, -0.8577], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([4.7930, 6.7930], requires_grad=True)\n",
      "tensor([[0.6971, 0.3029],\n",
      "        [0.6480, 0.3520],\n",
      "        [0.7449, 0.2551],\n",
      "        [0.6951, 0.3049],\n",
      "        [0.7762, 0.2238],\n",
      "        [0.8042, 0.1958],\n",
      "        [0.8031, 0.1969],\n",
      "        [0.7471, 0.2529],\n",
      "        [0.5591, 0.4409],\n",
      "        [0.3169, 0.6831],\n",
      "        [0.3798, 0.6202],\n",
      "        [0.4423, 0.5577],\n",
      "        [0.6605, 0.3395],\n",
      "        [0.6983, 0.3017],\n",
      "        [0.6664, 0.3336],\n",
      "        [0.4975, 0.5025],\n",
      "        [0.3114, 0.6886],\n",
      "        [0.4473, 0.5527]], dtype=torch.float64)\n",
      "Finished episode 91 Average rewards:  18.0\n",
      "tensor([-0.1637,  0.0523, -0.2119,  0.4192, -0.2544,  0.4076,  1.1313, -0.0249,\n",
      "        -0.9788,  0.9718, -0.1751,  0.9693, -3.5698,  1.2911,  0.0000, -3.8640,\n",
      "        -2.7395,  0.0000, -2.6235,  0.4604,  0.0000,  4.1279,  1.8216,  0.0000])\n",
      "tensor([-3.2739e-02,  1.0470e-02, -4.2380e-02,  8.3845e-02, -5.0883e-02,\n",
      "         8.1516e-02,  2.2627e-01, -4.9870e-03, -1.9576e-01,  1.9436e-01,\n",
      "        -3.5022e-02,  1.9387e-01, -7.1396e-01,  2.5822e-01, -2.1077e-17,\n",
      "        -7.7280e-01, -5.4790e-01,  4.6445e-17, -5.2470e-01,  9.2070e-02,\n",
      "         0.0000e+00,  8.2559e-01,  3.6432e-01, -1.0839e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-7.5605, -9.5967, -5.8794, 10.8805])\n",
      "tensor([-1.5121, -1.9193, -1.1759,  2.1761], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.4452, 0.4452])\n",
      "tensor([0.0890, 0.0890], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([5.2382, 7.2382], requires_grad=True)\n",
      "tensor([[0.4662, 0.5338],\n",
      "        [0.6330, 0.3670],\n",
      "        [0.3981, 0.6019],\n",
      "        [0.5562, 0.4438],\n",
      "        [0.6510, 0.3490],\n",
      "        [0.6234, 0.3766],\n",
      "        [0.4247, 0.5753],\n",
      "        [0.4616, 0.5384],\n",
      "        [0.5169, 0.4831],\n",
      "        [0.6606, 0.3394],\n",
      "        [0.6561, 0.3439],\n",
      "        [0.5195, 0.4805]], dtype=torch.float64)\n",
      "Monitored episode 50 Average Monitored rewards:  21.66\n",
      "Finished episode 92 Average rewards:  50.0\n",
      "tensor([-4.5526e-02, -4.1723e-04, -4.4104e-02, -4.1253e-01, -5.5103e-01,\n",
      "        -3.2324e-01,  2.5468e-01, -9.6006e-03, -2.1871e-01, -1.6899e-01,\n",
      "        -2.1847e-02, -1.6089e-01, -4.3254e-01, -1.0547e+00,  0.0000e+00,\n",
      "         1.4914e-01, -2.0428e+00,  0.0000e+00,  1.6102e+00,  2.9466e+00,\n",
      "         0.0000e+00, -1.3190e-01, -8.4410e-01,  0.0000e+00])\n",
      "tensor([-9.1051e-03, -8.3413e-05, -8.8208e-03, -8.2505e-02, -1.1021e-01,\n",
      "        -6.4649e-02,  5.0937e-02, -1.9201e-03, -4.3741e-02, -3.3797e-02,\n",
      "        -4.3695e-03, -3.2178e-02, -8.6508e-02, -2.1095e-01,  4.9725e-17,\n",
      "         2.9829e-02, -4.0855e-01,  1.4084e-17,  3.2204e-01,  5.8931e-01,\n",
      "         0.0000e+00, -2.6380e-02, -1.6882e-01, -4.5085e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.3307, -4.5669,  0.1512,  2.3524])\n",
      "tensor([-0.0661, -0.9134,  0.0302,  0.4705], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-0.9199, -0.9199])\n",
      "tensor([-0.1840, -0.1840], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([4.3183, 6.3183], requires_grad=True)\n",
      "tensor([[0.5367, 0.4633],\n",
      "        [0.5625, 0.4375],\n",
      "        [0.5890, 0.4110],\n",
      "        [0.5218, 0.4782],\n",
      "        [0.4964, 0.5036],\n",
      "        [0.4998, 0.5002],\n",
      "        [0.5243, 0.4757],\n",
      "        [0.5176, 0.4824],\n",
      "        [0.4111, 0.5889],\n",
      "        [0.3813, 0.6187],\n",
      "        [0.4579, 0.5421],\n",
      "        [0.5272, 0.4728]], dtype=torch.float64)\n",
      "Finished episode 93 Average rewards:  12.0\n",
      "tensor([ 1.3883, -0.0917,  1.3926,  0.9035,  0.7346,  0.6186, -0.8238, -0.1620,\n",
      "         0.7558,  0.6200,  0.1545,  0.5797, -0.2419,  1.6699,  0.0000, -0.0178,\n",
      "         0.1390,  0.0000,  0.5455, -0.8443,  0.0000,  0.1135,  0.2398,  0.0000])\n",
      "tensor([ 2.7766e-01, -1.8335e-02,  2.7852e-01,  1.8071e-01,  1.4693e-01,\n",
      "         1.2372e-01, -1.6475e-01, -3.2390e-02,  1.5116e-01,  1.2400e-01,\n",
      "         3.0905e-02,  1.1594e-01, -4.8384e-02,  3.3398e-01,  3.1333e-17,\n",
      "        -3.5544e-03,  2.7792e-02,  1.0000e-17,  1.0911e-01, -1.6886e-01,\n",
      "         0.0000e+00,  2.2702e-02,  4.7966e-02, -3.1761e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.4573, -0.4331,  0.3053, -0.1168])\n",
      "tensor([-0.0915, -0.0866,  0.0611, -0.0234], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.2620, 0.2620])\n",
      "tensor([0.0524, 0.0524], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([4.5804, 6.5804], requires_grad=True)\n",
      "tensor([[0.4186, 0.5814],\n",
      "        [0.5393, 0.4607],\n",
      "        [0.4790, 0.5210],\n",
      "        [0.5199, 0.4801],\n",
      "        [0.4500, 0.5500],\n",
      "        [0.5071, 0.4929],\n",
      "        [0.4259, 0.5741],\n",
      "        [0.5019, 0.4981],\n",
      "        [0.4154, 0.5846],\n",
      "        [0.5551, 0.4449],\n",
      "        [0.4950, 0.5050],\n",
      "        [0.5986, 0.4014],\n",
      "        [0.4768, 0.5232]], dtype=torch.float64)\n",
      "Finished episode 94 Average rewards:  13.0\n",
      "tensor([ 2.0413, -0.1851,  1.8906,  1.2885, -0.3394,  1.3250,  0.3250,  0.2251,\n",
      "        -0.2753,  4.1629, -0.1329,  4.1757,  0.1723,  2.0573,  0.0000,  0.1735,\n",
      "         0.0155,  0.0000, -0.5615,  0.6760,  0.0000, -0.0492, -0.7095,  0.0000])\n",
      "tensor([ 4.0825e-01, -3.7020e-02,  3.7812e-01,  2.5769e-01, -6.7884e-02,\n",
      "         2.6501e-01,  6.4992e-02,  4.5011e-02, -5.5062e-02,  8.3259e-01,\n",
      "        -2.6584e-02,  8.3514e-01,  3.4459e-02,  4.1145e-01,  8.9620e-18,\n",
      "         3.4707e-02,  3.1087e-03, -2.1912e-17, -1.1231e-01,  1.3521e-01,\n",
      "         0.0000e+00, -9.8494e-03, -1.4190e-01,  5.0345e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 0.5949,  0.9120, -0.9750, -1.5693])\n",
      "tensor([ 0.1190,  0.1824, -0.1950, -0.3139], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-1.5196, -1.5196])\n",
      "tensor([-0.3039, -0.3039], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([3.0608, 5.0608], requires_grad=True)\n",
      "tensor([[0.6373, 0.3627],\n",
      "        [0.5998, 0.4002],\n",
      "        [0.6324, 0.3676],\n",
      "        [0.5229, 0.4771],\n",
      "        [0.6379, 0.3621],\n",
      "        [0.6067, 0.3933],\n",
      "        [0.5142, 0.4858],\n",
      "        [0.5968, 0.4032],\n",
      "        [0.6119, 0.3881],\n",
      "        [0.5905, 0.4095],\n",
      "        [0.6047, 0.3953],\n",
      "        [0.5628, 0.4372],\n",
      "        [0.6159, 0.3841],\n",
      "        [0.5541, 0.4459],\n",
      "        [0.6052, 0.3948],\n",
      "        [0.6125, 0.3875],\n",
      "        [0.5299, 0.4701],\n",
      "        [0.6179, 0.3821],\n",
      "        [0.5860, 0.4140],\n",
      "        [0.5620, 0.4380],\n",
      "        [0.5131, 0.4869],\n",
      "        [0.4812, 0.5188],\n",
      "        [0.4173, 0.5827],\n",
      "        [0.4322, 0.5678],\n",
      "        [0.3829, 0.6171],\n",
      "        [0.4392, 0.5608],\n",
      "        [0.4614, 0.5386]], dtype=torch.float64)\n",
      "Finished episode 95 Average rewards:  27.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7522,  0.0775, -0.8613, -0.1364,  0.0851, -0.0228,  0.6920, -0.7774,\n",
      "        -0.5894, -0.3933, -0.1551, -0.4292,  0.0091, -3.0994,  0.0000,  0.7173,\n",
      "        -1.8004,  0.0000, -3.0028,  0.8835,  0.0000, -0.1984, -3.1242,  0.0000])\n",
      "tensor([-1.5043e-01,  1.5502e-02, -1.7226e-01, -2.7278e-02,  1.7024e-02,\n",
      "        -4.5553e-03,  1.3840e-01, -1.5548e-01, -1.1788e-01, -7.8656e-02,\n",
      "        -3.1025e-02, -8.5843e-02,  1.8178e-03, -6.1987e-01, -4.7943e-17,\n",
      "         1.4346e-01, -3.6008e-01, -1.9586e-17, -6.0055e-01,  1.7670e-01,\n",
      "         0.0000e+00, -3.9688e-02, -6.2484e-01, -8.9470e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 0.0164,  3.2885, -8.5476,  2.6549])\n",
      "tensor([ 0.0033,  0.6577, -1.7095,  0.5310], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.1739, 0.1739])\n",
      "tensor([0.0348, 0.0348], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([3.2346, 5.2346], requires_grad=True)\n",
      "tensor([[0.4731, 0.5269],\n",
      "        [0.6122, 0.3878],\n",
      "        [0.4072, 0.5928],\n",
      "        [0.4092, 0.5908],\n",
      "        [0.5650, 0.4350],\n",
      "        [0.2270, 0.7730],\n",
      "        [0.3586, 0.6414],\n",
      "        [0.3574, 0.6426],\n",
      "        [0.6968, 0.3032]], dtype=torch.float64)\n",
      "Finished episode 96 Average rewards:  9.0\n",
      "tensor([ 0.6055, -0.5115,  0.7079,  0.0288, -0.0354, -0.0235, -0.2067, -0.1279,\n",
      "         0.1835,  1.2243,  0.0973,  1.2843,  0.0025,  0.7255,  0.0000,  0.2956,\n",
      "        -0.1385,  0.0000, -0.0890, -0.0189,  0.0000,  0.3380, -1.2997,  0.0000])\n",
      "tensor([ 1.2111e-01, -1.0231e-01,  1.4159e-01,  5.7691e-03, -7.0791e-03,\n",
      "        -4.6989e-03, -4.1346e-02, -2.5573e-02,  3.6705e-02,  2.4486e-01,\n",
      "         1.9469e-02,  2.5686e-01,  4.9186e-04,  1.4510e-01,  1.6544e-17,\n",
      "         5.9130e-02, -2.7708e-02,  2.5381e-17, -1.7807e-02, -3.7734e-03,\n",
      "         0.0000e+00,  6.7605e-02, -2.5993e-01,  9.5271e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.0021, -0.0159, -0.1785, -0.5462])\n",
      "tensor([-0.0004, -0.0032, -0.0357, -0.1092], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-1.2694, -1.2694])\n",
      "tensor([-0.2539, -0.2539], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([1.9652, 3.9652], requires_grad=True)\n",
      "tensor([[0.7733, 0.2267],\n",
      "        [0.5189, 0.4811],\n",
      "        [0.7554, 0.2446],\n",
      "        [0.5174, 0.4826],\n",
      "        [0.7242, 0.2758],\n",
      "        [0.5212, 0.4788],\n",
      "        [0.6748, 0.3252],\n",
      "        [0.5336, 0.4664],\n",
      "        [0.6050, 0.3950],\n",
      "        [0.5583, 0.4417],\n",
      "        [0.2935, 0.7065],\n",
      "        [0.5979, 0.4021],\n",
      "        [0.4506, 0.5494],\n",
      "        [0.4462, 0.5538],\n",
      "        [0.3471, 0.6529],\n",
      "        [0.4528, 0.5472],\n",
      "        [0.2165, 0.7835],\n",
      "        [0.4638, 0.5362],\n",
      "        [0.6870, 0.3130],\n",
      "        [0.5977, 0.4023],\n",
      "        [0.4332, 0.5668],\n",
      "        [0.2772, 0.7228]], dtype=torch.float64)\n",
      "Monitored episode 50 Average Monitored rewards:  22.2\n",
      "Finished episode 97 Average rewards:  13.0\n",
      "tensor([ 0.4808, -0.2060,  0.7704,  0.1003,  0.0973,  0.2186, -1.4384,  0.0520,\n",
      "         1.3726,  1.1080, -0.0299,  1.0660,  0.6712,  0.4963,  0.0000, -0.3163,\n",
      "        -0.6097,  0.0000,  0.1729, -1.2853,  0.0000,  0.4035,  0.9574,  0.0000])\n",
      "tensor([ 9.6152e-02, -4.1206e-02,  1.5408e-01,  2.0064e-02,  1.9451e-02,\n",
      "         4.3717e-02, -2.8768e-01,  1.0403e-02,  2.7451e-01,  2.2159e-01,\n",
      "        -5.9784e-03,  2.1321e-01,  1.3423e-01,  9.9256e-02, -2.6711e-18,\n",
      "        -6.3265e-02, -1.2193e-01, -2.9739e-17,  3.4579e-02, -2.5707e-01,\n",
      "         0.0000e+00,  8.0691e-02,  1.9148e-01,  3.6926e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 1.3635, -2.5969, -0.1511,  3.2387])\n",
      "tensor([ 0.2727, -0.5194, -0.0302,  0.6477], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-0.8088, -0.8088])\n",
      "tensor([-0.1618, -0.1618], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([1.1564, 3.1564], requires_grad=True)\n",
      "tensor([[0.4891, 0.5109],\n",
      "        [0.5820, 0.4180],\n",
      "        [0.5043, 0.4957],\n",
      "        [0.5861, 0.4139],\n",
      "        [0.4925, 0.5075],\n",
      "        [0.5836, 0.4164],\n",
      "        [0.4813, 0.5187],\n",
      "        [0.5792, 0.4208],\n",
      "        [0.4715, 0.5285],\n",
      "        [0.4837, 0.5163],\n",
      "        [0.5215, 0.4785],\n",
      "        [0.4822, 0.5178],\n",
      "        [0.4427, 0.5573],\n",
      "        [0.4485, 0.5515],\n",
      "        [0.3967, 0.6033]], dtype=torch.float64)\n",
      "Finished episode 98 Average rewards:  15.0\n",
      "tensor([ 0.0209, -0.0195, -0.1080, -0.3121, -0.1124, -0.3797,  0.1875, -0.0155,\n",
      "        -0.1745, -0.9469,  0.0827, -0.9425, -0.6893, -0.3107,  0.0000,  0.2103,\n",
      "         0.1933,  0.0000,  0.1338,  0.5646,  0.0000,  0.1838,  0.8478,  0.0000])\n",
      "tensor([ 4.1798e-03, -3.9019e-03, -2.1596e-02, -6.2429e-02, -2.2479e-02,\n",
      "        -7.5935e-02,  3.7496e-02, -3.1025e-03, -3.4902e-02, -1.8939e-01,\n",
      "         1.6531e-02, -1.8849e-01, -1.3785e-01, -6.2139e-02, -8.7043e-19,\n",
      "         4.2069e-02,  3.8655e-02, -1.3204e-17,  2.6751e-02,  1.1292e-01,\n",
      "         0.0000e+00,  3.6756e-02,  1.6957e-01,  8.4410e-18],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([-0.7853, -0.0063,  2.7043, -3.3199])\n",
      "tensor([-0.1571, -0.0013,  0.5409, -0.6640], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([-1.2321, -1.2321])\n",
      "tensor([-0.2464, -0.2464], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([-0.0757,  1.9243], requires_grad=True)\n",
      "tensor([[0.4975, 0.5025],\n",
      "        [0.6070, 0.3930],\n",
      "        [0.5524, 0.4476],\n",
      "        [0.4041, 0.5959],\n",
      "        [0.4787, 0.5213],\n",
      "        [0.5163, 0.4837],\n",
      "        [0.3820, 0.6180],\n",
      "        [0.5669, 0.4331],\n",
      "        [0.4506, 0.5494],\n",
      "        [0.6105, 0.3895],\n",
      "        [0.4072, 0.5928],\n",
      "        [0.6019, 0.3981],\n",
      "        [0.5374, 0.4626],\n",
      "        [0.6670, 0.3330],\n",
      "        [0.2892, 0.7108],\n",
      "        [0.6500, 0.3500],\n",
      "        [0.3138, 0.6862],\n",
      "        [0.6692, 0.3308],\n",
      "        [0.3096, 0.6904],\n",
      "        [0.7267, 0.2733],\n",
      "        [0.2353, 0.7647],\n",
      "        [0.7512, 0.2488],\n",
      "        [0.2081, 0.7919]], dtype=torch.float64)\n",
      "Finished episode 99 Average rewards:  23.0\n",
      "tensor([-0.0735,  0.0034, -0.0111,  0.1574,  0.0213,  0.2134, -0.1334,  0.0770,\n",
      "         0.1060, -0.1247,  0.1108, -0.1231,  0.1402, -0.0815,  0.0000,  0.1888,\n",
      "         0.2567,  0.0000, -0.0996,  0.1441,  0.0000, -0.1373,  0.1862,  0.0000])\n",
      "tensor([-1.4692e-02,  6.7092e-04, -2.2169e-03,  3.1490e-02,  4.2502e-03,\n",
      "         4.2676e-02, -2.6681e-02,  1.5410e-02,  2.1192e-02, -2.4943e-02,\n",
      "         2.2163e-02, -2.4612e-02,  2.8040e-02, -1.6297e-02, -3.2675e-17,\n",
      "         3.7766e-02,  5.1334e-02,  6.8290e-18, -1.9928e-02,  2.8811e-02,\n",
      "         0.0000e+00, -2.7456e-02,  3.7234e-02,  1.3621e-17],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([ 0.3462,  0.9012, -0.0570,  0.2180])\n",
      "tensor([ 0.0692,  0.1802, -0.0114,  0.0436], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([0.4661, 0.4661])\n",
      "tensor([0.0932, 0.0932], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([0.3904, 2.3904], requires_grad=True)\n",
      "tensor([[0.2168, 0.7832],\n",
      "        [0.4364, 0.5636],\n",
      "        [0.2138, 0.7862],\n",
      "        [0.5940, 0.4060],\n",
      "        [0.7473, 0.2527],\n",
      "        [0.5664, 0.4336],\n",
      "        [0.2294, 0.7706],\n",
      "        [0.5506, 0.4494],\n",
      "        [0.7281, 0.2719],\n",
      "        [0.5109, 0.4891],\n",
      "        [0.7082, 0.2918],\n",
      "        [0.4709, 0.5291],\n",
      "        [0.6866, 0.3134],\n",
      "        [0.4488, 0.5512],\n",
      "        [0.6658, 0.3342],\n",
      "        [0.4946, 0.5054],\n",
      "        [0.3573, 0.6427],\n",
      "        [0.3785, 0.6215],\n",
      "        [0.5692, 0.4308]], dtype=torch.float64)\n",
      "Finished episode 100 Average rewards:  19.0\n"
     ]
    }
   ],
   "source": [
    "# Start training the agent\n",
    "episode_reward_history = []\n",
    "# Monitoring reward\n",
    "monitor_reward_history = []\n",
    "for batch in tqdm(range(n_episodes // batch_size)):\n",
    "    # Gather episodes\n",
    "    episodes = gather_episodes(state_bounds, n_actions, agent, batch_size, env_name)\n",
    "\n",
    "    # Group states, actions and returns in numpy arrays\n",
    "    states = torch.from_numpy(np.concatenate([ep['states'] for ep in episodes]))\n",
    "    actions = torch.from_numpy(np.concatenate([ep['actions'] for ep in episodes]))\n",
    "    action_probs = torch.from_numpy(np.concatenate([ep['action probs'] for ep in episodes]))\n",
    "    rewards = [ep['rewards'] for ep in episodes]\n",
    "    returns = np.concatenate([compute_returns(ep_rwds, gamma) for ep_rwds in rewards])\n",
    "    returns = torch.from_numpy(np.array(returns))\n",
    "#     print(action_probs)\n",
    "\n",
    "    id_action_pairs = torch.from_numpy(np.array([[i, a] for i, a in enumerate(actions)]))\n",
    "\n",
    "    # Update model parameters.\n",
    "    agent.update_policy(states, id_action_pairs, returns, action_probs, batch_size)\n",
    "    print(action_probs)\n",
    "\n",
    "    if batch % 5 == 1:\n",
    "        # Gather episodes\n",
    "        episodes = gather_episodes(state_bounds, n_actions, agent, 50, env_name)\n",
    "\n",
    "        # Group states, actions and returns in numpy arrays\n",
    "        states = torch.from_numpy(np.concatenate([ep['states'] for ep in episodes]))\n",
    "        actions = torch.from_numpy(np.concatenate([ep['actions'] for ep in episodes]))\n",
    "        action_probs = torch.from_numpy(np.concatenate([ep['action probs'] for ep in episodes]))\n",
    "        rewards = [ep['rewards'] for ep in episodes]\n",
    "        # Store collected rewards\n",
    "        temp_hist = []\n",
    "        for ep_rwds in rewards:\n",
    "            temp_hist.append(np.sum(ep_rwds))\n",
    "        avg_rewards = np.mean(temp_hist)\n",
    "        monitor_reward_history.append(avg_rewards)\n",
    "        \n",
    "        print('Monitored episode', 50,\n",
    "              'Average Monitored rewards: ', avg_rewards)\n",
    "\n",
    "    # Store collected rewards\n",
    "    for ep_rwds in rewards:\n",
    "        episode_reward_history.append(np.sum(ep_rwds))\n",
    "\n",
    "    avg_rewards = np.mean(episode_reward_history[-batch_size:])\n",
    "\n",
    "    print('Finished episode', (batch + 1) * batch_size,\n",
    "          'Average rewards: ', avg_rewards)\n",
    "\n",
    "    if avg_rewards >= 500.0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(episode_reward_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(episode_reward_history[:400], bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(episode_reward_history[-400:], bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(monitor_reward_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNE3QY8UA5xCDFR4Ht9tSPe",
   "collapsed_sections": [
    "ksJVcTLxzskm",
    "jySdpQf_zuiE",
    "MIKgmnTWM8yz",
    "eLm2LW4zBqPo"
   ],
   "name": "QuantumCircuitLearning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1b23efbb8db748a2af8554186cf2a3d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "235d4532e52e4aadbc6c049c0c7369b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25885ff5cc014bafa5442805d676c0be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_235d4532e52e4aadbc6c049c0c7369b3",
      "max": 50,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4ede1074ee2f496ab3d864be52157d03",
      "value": 50
     }
    },
    "40ae390ed75a46f292ffc969fdd0509e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4ede1074ee2f496ab3d864be52157d03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "68c55b17e042416c91105f585c6f622a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec14bbc210b743f085734c3bf858fd72",
      "placeholder": "​",
      "style": "IPY_MODEL_40ae390ed75a46f292ffc969fdd0509e",
      "value": " 50/50 [11:53&lt;00:00, 14.28s/it]"
     }
    },
    "cc511557b8a54d408c9d2ddcaa7aa7dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_25885ff5cc014bafa5442805d676c0be",
       "IPY_MODEL_68c55b17e042416c91105f585c6f622a"
      ],
      "layout": "IPY_MODEL_1b23efbb8db748a2af8554186cf2a3d8"
     }
    },
    "ec14bbc210b743f085734c3bf858fd72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
